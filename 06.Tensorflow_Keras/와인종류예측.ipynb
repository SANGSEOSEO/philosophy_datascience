{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4MHT0olrkMP"
   },
   "source": [
    "# 와인 측정치를 통해 베스트모델 만들기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "355R211FsHl-"
   },
   "source": [
    "## 1. 데이터의 확인 및 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tZLi-MuKsRo2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_pre = pd.read_csv(\"/content/sample_data/wine.csv\", header = None)\n",
    "df = df_pre.sample(frac = 1) # 원본 데이터의 100퍼센트를 불러오라는 의미, 0.5는 50%만 랜덤으로 불러옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "KQRgeGkitAsK",
    "outputId": "e1971f12-d670-4b8b-8dbf-634d44a36e3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>11.4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.090</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.044</td>\n",
       "      <td>18.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.64</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.089</td>\n",
       "      <td>23.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.99636</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.037</td>\n",
       "      <td>28.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6482</th>\n",
       "      <td>4.9</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.035</td>\n",
       "      <td>60.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.98964</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>11.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5   ...       7     8     9     10  11  12\n",
       "468   11.4  0.36  0.69  2.1  0.090   6.0  ...  1.00000  3.17  0.62   9.2   6   1\n",
       "2604   6.6  0.18  0.28  3.3  0.044  18.0  ...  0.99300  3.42  0.64  10.8   6   0\n",
       "1496   7.7  0.54  0.26  1.9  0.089  23.0  ...  0.99636  3.26  0.59   9.7   5   1\n",
       "2479   7.1  0.21  0.32  2.2  0.037  28.0  ...  0.99300  3.20  0.57  10.0   7   0\n",
       "6482   4.9  0.47  0.17  1.9  0.035  60.0  ...  0.98964  3.27  0.35  11.5   6   0\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hP0D4jVStGEK",
    "outputId": "e3e47897-7f60-466e-ee5d-1a8e5209d7a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6497 entries, 468 to 6109\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6497 non-null   float64\n",
      " 1   1       6497 non-null   float64\n",
      " 2   2       6497 non-null   float64\n",
      " 3   3       6497 non-null   float64\n",
      " 4   4       6497 non-null   float64\n",
      " 5   5       6497 non-null   float64\n",
      " 6   6       6497 non-null   float64\n",
      " 7   7       6497 non-null   float64\n",
      " 8   8       6497 non-null   float64\n",
      " 9   9       6497 non-null   float64\n",
      " 10  10      6497 non-null   float64\n",
      " 11  11      6497 non-null   int64  \n",
      " 12  12      6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 710.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlJrrtqqtI3w"
   },
   "source": [
    "## 2. 변수 설명 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pia-W2YytQuU"
   },
   "source": [
    "1) Alcohol - 주석산 농도\n",
    "\n",
    "2 Malic acid - 아세트산 농도\n",
    "\n",
    "3) Ash - 구연산 농도\n",
    "\n",
    "4) Alcalinity of ash - 잔류 당분 농도\n",
    "\n",
    "5) Magnesium - 염화나트륨 농도\n",
    "\n",
    "6) Total phenols - 유리 아황산 농도\n",
    "\n",
    "7) Flavanoids - 총 아황산 농도\n",
    "\n",
    "8) Nonflavanoid phenols - 밀도\n",
    "\n",
    "9) Proanthocyanins - ph\n",
    "\n",
    "10)Color intensity - 황산칼륨농도\n",
    "\n",
    "11)Hue - 알코올 도수\n",
    "\n",
    "12)OD280/OD315 of diluted wines - 와인의 맛(0 ~ 10등급)\n",
    "\n",
    "13)Proline - (1: 레드와인, 0 : 화이트 와인)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs2ZKmegwKHw"
   },
   "source": [
    "## 2.1 와인 데이터 확인 및 예측 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bvI3q0aYtVWJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 조기중단\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QPxHaMQZuMEL"
   },
   "outputs": [],
   "source": [
    "#seed값 설정\n",
    "seed = 156\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "J3zUG_5QuZHy"
   },
   "outputs": [],
   "source": [
    "# 데이터 입력\n",
    "dataset = df.values\n",
    "X = dataset[:, 0:12]\n",
    "Y = dataset[:, 12]  # label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tfSF5cbsuyLg"
   },
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim = 12))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fY9M0YuCvPbh"
   },
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPMYMBSJvdQm",
    "outputId": "c1973464-3043-4441-b275-ff82ef74822a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "33/33 [==============================] - 2s 3ms/step - loss: 0.4650 - accuracy: 0.8611\n",
      "Epoch 2/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.9253\n",
      "Epoch 3/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9219\n",
      "Epoch 4/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9316\n",
      "Epoch 5/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9379\n",
      "Epoch 6/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1847 - accuracy: 0.9369\n",
      "Epoch 7/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1720 - accuracy: 0.9405\n",
      "Epoch 8/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9440\n",
      "Epoch 9/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1608 - accuracy: 0.9433\n",
      "Epoch 10/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9463\n",
      "Epoch 11/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9463\n",
      "Epoch 12/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9491\n",
      "Epoch 13/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1331 - accuracy: 0.9509\n",
      "Epoch 14/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9536\n",
      "Epoch 15/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.9545\n",
      "Epoch 16/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9533\n",
      "Epoch 17/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9608\n",
      "Epoch 18/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9641\n",
      "Epoch 19/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.9598\n",
      "Epoch 20/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1067 - accuracy: 0.9640\n",
      "Epoch 21/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9683\n",
      "Epoch 22/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9722\n",
      "Epoch 23/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9731\n",
      "Epoch 24/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9712\n",
      "Epoch 25/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0895 - accuracy: 0.9718\n",
      "Epoch 26/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9716\n",
      "Epoch 27/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9760\n",
      "Epoch 28/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9771\n",
      "Epoch 29/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9732\n",
      "Epoch 30/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0758 - accuracy: 0.9765\n",
      "Epoch 31/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9787\n",
      "Epoch 32/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9759\n",
      "Epoch 33/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9747\n",
      "Epoch 34/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9763\n",
      "Epoch 35/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9759\n",
      "Epoch 36/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9794\n",
      "Epoch 37/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9769\n",
      "Epoch 38/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9783\n",
      "Epoch 39/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9790\n",
      "Epoch 40/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9792\n",
      "Epoch 41/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9794\n",
      "Epoch 42/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9782\n",
      "Epoch 43/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9814\n",
      "Epoch 44/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9820\n",
      "Epoch 45/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9821\n",
      "Epoch 46/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9800\n",
      "Epoch 47/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9804\n",
      "Epoch 48/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9784\n",
      "Epoch 49/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.9773\n",
      "Epoch 50/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9820\n",
      "Epoch 51/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.9834\n",
      "Epoch 52/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9812\n",
      "Epoch 53/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9851\n",
      "Epoch 54/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9836\n",
      "Epoch 55/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9815\n",
      "Epoch 56/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9825\n",
      "Epoch 57/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9840\n",
      "Epoch 58/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9781\n",
      "Epoch 59/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9811\n",
      "Epoch 60/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9822\n",
      "Epoch 61/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9818\n",
      "Epoch 62/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9843\n",
      "Epoch 63/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9816\n",
      "Epoch 64/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9818\n",
      "Epoch 65/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9840\n",
      "Epoch 66/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9835\n",
      "Epoch 67/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9818\n",
      "Epoch 68/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9799\n",
      "Epoch 69/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9856\n",
      "Epoch 70/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9859\n",
      "Epoch 71/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.9847\n",
      "Epoch 72/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9851\n",
      "Epoch 73/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9852\n",
      "Epoch 74/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9865\n",
      "Epoch 75/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9855\n",
      "Epoch 76/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9814\n",
      "Epoch 77/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9850\n",
      "Epoch 78/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9842\n",
      "Epoch 79/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9799\n",
      "Epoch 80/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9858\n",
      "Epoch 81/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9812\n",
      "Epoch 82/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9862\n",
      "Epoch 83/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9809\n",
      "Epoch 84/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9824\n",
      "Epoch 85/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9839\n",
      "Epoch 86/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9846\n",
      "Epoch 87/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9872\n",
      "Epoch 88/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9856\n",
      "Epoch 89/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9821\n",
      "Epoch 90/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9853\n",
      "Epoch 91/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9840\n",
      "Epoch 92/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9841\n",
      "Epoch 93/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9851\n",
      "Epoch 94/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9847\n",
      "Epoch 95/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9868\n",
      "Epoch 96/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9837\n",
      "Epoch 97/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9773\n",
      "Epoch 98/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9856\n",
      "Epoch 99/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9840\n",
      "Epoch 100/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9856\n",
      "Epoch 101/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9840\n",
      "Epoch 102/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9852\n",
      "Epoch 103/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9856\n",
      "Epoch 104/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9858\n",
      "Epoch 105/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9855\n",
      "Epoch 106/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9835\n",
      "Epoch 107/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9842\n",
      "Epoch 108/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9818\n",
      "Epoch 109/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9859\n",
      "Epoch 110/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9865\n",
      "Epoch 111/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9896\n",
      "Epoch 112/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9851\n",
      "Epoch 113/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9837\n",
      "Epoch 114/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9864\n",
      "Epoch 115/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9853\n",
      "Epoch 116/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9841\n",
      "Epoch 117/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9861\n",
      "Epoch 118/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9839\n",
      "Epoch 119/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9873\n",
      "Epoch 120/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9861\n",
      "Epoch 121/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9860\n",
      "Epoch 122/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9867\n",
      "Epoch 123/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9824\n",
      "Epoch 124/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9864\n",
      "Epoch 125/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9878\n",
      "Epoch 126/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9850\n",
      "Epoch 127/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9809\n",
      "Epoch 128/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9877\n",
      "Epoch 129/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9860\n",
      "Epoch 130/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9875\n",
      "Epoch 131/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9843\n",
      "Epoch 132/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9883\n",
      "Epoch 133/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9848\n",
      "Epoch 134/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9868\n",
      "Epoch 135/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9851\n",
      "Epoch 136/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 0.9858\n",
      "Epoch 137/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9833\n",
      "Epoch 138/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9803\n",
      "Epoch 139/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9890\n",
      "Epoch 140/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9874\n",
      "Epoch 141/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9857\n",
      "Epoch 142/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9835\n",
      "Epoch 143/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9847\n",
      "Epoch 144/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9883\n",
      "Epoch 145/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9845\n",
      "Epoch 146/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9853\n",
      "Epoch 147/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9880\n",
      "Epoch 148/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9858\n",
      "Epoch 149/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9895\n",
      "Epoch 150/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9827\n",
      "Epoch 151/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9880\n",
      "Epoch 152/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9812\n",
      "Epoch 153/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9846\n",
      "Epoch 154/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9855\n",
      "Epoch 155/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9856\n",
      "Epoch 156/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9852\n",
      "Epoch 157/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9900\n",
      "Epoch 158/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9873\n",
      "Epoch 159/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9869\n",
      "Epoch 160/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9882\n",
      "Epoch 161/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9871\n",
      "Epoch 162/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9857\n",
      "Epoch 163/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9894\n",
      "Epoch 164/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9846\n",
      "Epoch 165/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9834\n",
      "Epoch 166/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9857\n",
      "Epoch 167/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9846\n",
      "Epoch 168/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9852\n",
      "Epoch 169/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9870\n",
      "Epoch 170/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9883\n",
      "Epoch 171/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9772\n",
      "Epoch 172/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9870\n",
      "Epoch 173/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9838\n",
      "Epoch 174/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9890\n",
      "Epoch 175/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9878\n",
      "Epoch 176/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9879\n",
      "Epoch 177/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9881\n",
      "Epoch 178/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9882\n",
      "Epoch 179/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9869\n",
      "Epoch 180/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9881\n",
      "Epoch 181/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9873\n",
      "Epoch 182/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9868\n",
      "Epoch 183/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9871\n",
      "Epoch 184/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9837\n",
      "Epoch 185/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9874\n",
      "Epoch 186/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9870\n",
      "Epoch 187/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9848\n",
      "Epoch 188/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9826\n",
      "Epoch 189/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9864\n",
      "Epoch 190/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9871\n",
      "Epoch 191/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9873\n",
      "Epoch 192/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9866\n",
      "Epoch 193/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9859\n",
      "Epoch 194/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9879\n",
      "Epoch 195/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9864\n",
      "Epoch 196/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9851\n",
      "Epoch 197/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9850\n",
      "Epoch 198/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 0.9898\n",
      "Epoch 199/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9878\n",
      "Epoch 200/200\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f54a066c5c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 수행\n",
    "model.fit(X, Y, epochs=200, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_Q06KP2v8up",
    "outputId": "20a561f9-da98-4594-c5e8-9da361f74c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 1s 2ms/step - loss: 0.0429 - accuracy: 0.9877\n",
      "\n",
      " Accuracy : 0.9877\n"
     ]
    }
   ],
   "source": [
    "# 결과 및 정확도 출력\n",
    "print(\"\\n Accuracy : %.4f\" % (model.evaluate(X, Y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xz4zmuQ-wmSj"
   },
   "source": [
    "* 정확도가 98.8퍼센트의 딥러닝 프레임워크 완"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dysU5c0WwtYT"
   },
   "outputs": [],
   "source": [
    " 정확도가 98.8퍼센트의 딥러닝 프레임워크 완성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xZl9f1MslFB"
   },
   "source": [
    "## 3. 모델 업데이트 \n",
    "* epoch마다 모델의 정확도를 기록하고 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dscAYkihxAqk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MODEL_DIR = \"/content/sample_data/model/\"\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "  os.mkdir(MODEL_DIR)\n",
    "\n",
    "# 모델 이름 \n",
    "modelpath = MODEL_DIR+\"{epoch:02d}-{val_loss:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4I6FlDCzzP4G"
   },
   "outputs": [],
   "source": [
    "# ModelCheckPoint클래스를 이용해 모니터할 지정값 설정\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# verbose = 1(기록 저장), 0(저장안함)\n",
    "# save_best_only = True는 모델이 앞서 저장한 모델보다 나아졌을때만 저장하게끔 하는 옵션(기본값 : False)\n",
    "checkpoint = ModelCheckpoint(filepath=modelpath,monitor = 'val_loss', verbose=1, save_best_only= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOlO4Kot0Bkx",
    "outputId": "05c5b022-c2e9-4060-8e55-075996183544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06729, saving model to /content/sample_data/model/01-0.0673.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06729 to 0.06646, saving model to /content/sample_data/model/02-0.0665.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.06646\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.06646 to 0.06513, saving model to /content/sample_data/model/04-0.0651.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.06513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f54a06bf208>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습수행\n",
    "# validation_split = 0.2의 의미는 20퍼센트를 테스트용으로 사용\n",
    "model.fit(X, Y, validation_split= 0.2,  epochs= 200, batch_size=200, verbose=0, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pi_xRHmV0yCc"
   },
   "source": [
    "## 4. 와인종류 예측 - 모델 업데이트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "lMkWYXKZ1oAN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ydMAZJcR1-us"
   },
   "outputs": [],
   "source": [
    "#seed값 설정\n",
    "seed = 11\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "cJjwMZ5i2Kok"
   },
   "outputs": [],
   "source": [
    "df_pre = pd.read_csv(\"/content/sample_data/wine.csv\", header = None)\n",
    "df = df_pre.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "gyJXOW0w2ehK"
   },
   "outputs": [],
   "source": [
    "# 데이터 셋 분리\n",
    "dataset = df.values\n",
    "X = dataset[:, 0:12]\n",
    "Y = dataset[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "lzyI7_ze2nrB"
   },
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "e-_mu5rX3Fye"
   },
   "outputs": [],
   "source": [
    "# model compile\n",
    "model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "dGj3Qntb3YL4"
   },
   "outputs": [],
   "source": [
    "# 모델이 저장할 폴더 설정\n",
    "MODEL_DIR = \"/content/sample_data/model/\"\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "  os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "R0cNiqzr3tnb"
   },
   "outputs": [],
   "source": [
    "# 모델이 저장할 조건 설정\n",
    "modelpath = MODEL_DIR+\"{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor='val_loss', verbose = 1, save_best_only = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0cnOPJN4e8Z",
    "outputId": "13a1125c-3d6b-4ed0-ad23-6353645dafc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20875, saving model to /content/sample_data/model/01-0.2087.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20875 to 0.19218, saving model to /content/sample_data/model/02-0.1922.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.19218 to 0.18843, saving model to /content/sample_data/model/03-0.1884.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.18843 to 0.18374, saving model to /content/sample_data/model/04-0.1837.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.18374 to 0.17339, saving model to /content/sample_data/model/05-0.1734.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.17339\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.17339 to 0.16509, saving model to /content/sample_data/model/07-0.1651.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.16509 to 0.15913, saving model to /content/sample_data/model/08-0.1591.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15913\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.15913 to 0.15144, saving model to /content/sample_data/model/10-0.1514.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.15144 to 0.15045, saving model to /content/sample_data/model/11-0.1505.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.15045 to 0.14353, saving model to /content/sample_data/model/12-0.1435.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.14353 to 0.13822, saving model to /content/sample_data/model/13-0.1382.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.13822 to 0.12975, saving model to /content/sample_data/model/14-0.1298.hdf5\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.12975\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.12975 to 0.12196, saving model to /content/sample_data/model/16-0.1220.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.12196 to 0.11880, saving model to /content/sample_data/model/17-0.1188.hdf5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.11880\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.11880 to 0.11491, saving model to /content/sample_data/model/19-0.1149.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.11491 to 0.11104, saving model to /content/sample_data/model/20-0.1110.hdf5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.11104\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.11104 to 0.10709, saving model to /content/sample_data/model/22-0.1071.hdf5\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.10709\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.10709 to 0.10592, saving model to /content/sample_data/model/24-0.1059.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.10592 to 0.10306, saving model to /content/sample_data/model/25-0.1031.hdf5\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.10306\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.10306 to 0.10061, saving model to /content/sample_data/model/27-0.1006.hdf5\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.10061 to 0.09993, saving model to /content/sample_data/model/28-0.0999.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.09993 to 0.09442, saving model to /content/sample_data/model/29-0.0944.hdf5\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.09442\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.09442 to 0.09217, saving model to /content/sample_data/model/31-0.0922.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.09217 to 0.09067, saving model to /content/sample_data/model/32-0.0907.hdf5\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.09067\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.09067 to 0.08840, saving model to /content/sample_data/model/34-0.0884.hdf5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.08840\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.08840 to 0.08613, saving model to /content/sample_data/model/36-0.0861.hdf5\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.08613 to 0.08279, saving model to /content/sample_data/model/37-0.0828.hdf5\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.08279\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08279\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.08279 to 0.08081, saving model to /content/sample_data/model/40-0.0808.hdf5\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.08081 to 0.07933, saving model to /content/sample_data/model/41-0.0793.hdf5\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.07933 to 0.07696, saving model to /content/sample_data/model/42-0.0770.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.07696 to 0.07585, saving model to /content/sample_data/model/43-0.0758.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07585\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.07585 to 0.07434, saving model to /content/sample_data/model/45-0.0743.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.07434 to 0.07338, saving model to /content/sample_data/model/46-0.0734.hdf5\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.07338 to 0.07172, saving model to /content/sample_data/model/47-0.0717.hdf5\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.07172 to 0.07154, saving model to /content/sample_data/model/48-0.0715.hdf5\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07154\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07154\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.07154 to 0.06884, saving model to /content/sample_data/model/51-0.0688.hdf5\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.06884\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.06884 to 0.06718, saving model to /content/sample_data/model/53-0.0672.hdf5\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.06718\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.06718\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.06718 to 0.06506, saving model to /content/sample_data/model/56-0.0651.hdf5\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.06506\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.06506\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.06506 to 0.06293, saving model to /content/sample_data/model/59-0.0629.hdf5\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.06293 to 0.06268, saving model to /content/sample_data/model/60-0.0627.hdf5\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.06268\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.06268 to 0.06246, saving model to /content/sample_data/model/62-0.0625.hdf5\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.06246 to 0.06121, saving model to /content/sample_data/model/63-0.0612.hdf5\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.06121\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.06121 to 0.06019, saving model to /content/sample_data/model/65-0.0602.hdf5\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.06019\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.06019\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.06019\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.06019\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06019 to 0.05987, saving model to /content/sample_data/model/70-0.0599.hdf5\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.05987 to 0.05929, saving model to /content/sample_data/model/71-0.0593.hdf5\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.05929 to 0.05831, saving model to /content/sample_data/model/72-0.0583.hdf5\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.05831 to 0.05658, saving model to /content/sample_data/model/73-0.0566.hdf5\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.05658\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.05658\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05658\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.05658\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05658 to 0.05581, saving model to /content/sample_data/model/78-0.0558.hdf5\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05581 to 0.05475, saving model to /content/sample_data/model/79-0.0547.hdf5\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.05475\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05475\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05475 to 0.05405, saving model to /content/sample_data/model/82-0.0540.hdf5\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.05405\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.05405 to 0.05324, saving model to /content/sample_data/model/89-0.0532.hdf5\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.05324 to 0.05260, saving model to /content/sample_data/model/90-0.0526.hdf5\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05260\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05260 to 0.05229, saving model to /content/sample_data/model/92-0.0523.hdf5\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05229\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05229\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.05229\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.05229 to 0.05195, saving model to /content/sample_data/model/96-0.0519.hdf5\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.05195 to 0.05111, saving model to /content/sample_data/model/97-0.0511.hdf5\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05111\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.05111\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.05111 to 0.04992, saving model to /content/sample_data/model/100-0.0499.hdf5\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04992\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.04992 to 0.04991, saving model to /content/sample_data/model/102-0.0499.hdf5\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04991\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04991\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04991\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04991\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.04991 to 0.04860, saving model to /content/sample_data/model/107-0.0486.hdf5\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04860\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04860\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.04860\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.04860\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04860\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04860\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.04860 to 0.04851, saving model to /content/sample_data/model/114-0.0485.hdf5\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.04851\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.04851\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.04851 to 0.04753, saving model to /content/sample_data/model/117-0.0475.hdf5\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.04753 to 0.04665, saving model to /content/sample_data/model/118-0.0466.hdf5\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.04665\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.04665\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.04665\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.04665\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.04665\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.04665\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.04665\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.04665\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.04665\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.04665\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.04665 to 0.04571, saving model to /content/sample_data/model/129-0.0457.hdf5\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.04571\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.04571\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.04571 to 0.04508, saving model to /content/sample_data/model/132-0.0451.hdf5\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.04508\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.04508\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.04508\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.04508\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.04508\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.04508\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.04508 to 0.04497, saving model to /content/sample_data/model/139-0.0450.hdf5\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04497\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.04497\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.04497 to 0.04424, saving model to /content/sample_data/model/142-0.0442.hdf5\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.04424\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.04424\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.04424\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.04424\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.04424\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.04424\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.04424\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.04424\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.04424\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.04424 to 0.04330, saving model to /content/sample_data/model/152-0.0433.hdf5\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.04330\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.04330 to 0.04219, saving model to /content/sample_data/model/172-0.0422.hdf5\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.04219\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.04219 to 0.04116, saving model to /content/sample_data/model/189-0.0412.hdf5\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.04116\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.04116\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.04116\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.04116\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.04116\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.04116\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.04116 to 0.04071, saving model to /content/sample_data/model/196-0.0407.hdf5\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.04071\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.04071\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.04071 to 0.03967, saving model to /content/sample_data/model/199-0.0397.hdf5\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.03967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f54a03b8630>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 실행 및 저장\n",
    "model.fit(X, Y, validation_split=.2, epochs=200, batch_size=200, verbose=0, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1WmM1-k4vTy"
   },
   "source": [
    "## 5. 딥러닝이 예측한 모델을 그래프로 표현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h24v5zs45X37",
    "outputId": "986f375e-2a2f-4d61-8b12-af1af924f0c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6497 entries, 1787 to 1945\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6497 non-null   float64\n",
      " 1   1       6497 non-null   float64\n",
      " 2   2       6497 non-null   float64\n",
      " 3   3       6497 non-null   float64\n",
      " 4   4       6497 non-null   float64\n",
      " 5   5       6497 non-null   float64\n",
      " 6   6       6497 non-null   float64\n",
      " 7   7       6497 non-null   float64\n",
      " 8   8       6497 non-null   float64\n",
      " 9   9       6497 non-null   float64\n",
      " 10  10      6497 non-null   float64\n",
      " 11  11      6497 non-null   int64  \n",
      " 12  12      6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 710.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYhSbdhv5ooB",
    "outputId": "0f739b76-bb8b-4615-eea1-5a264a2e140f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
      "Epoch 1001/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.0405 - val_accuracy: 0.9888\n",
      "Epoch 1002/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0584 - val_accuracy: 0.9832\n",
      "Epoch 1003/3500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0295 - accuracy: 0.9913 - val_loss: 0.0530 - val_accuracy: 0.9823\n",
      "Epoch 1004/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.0526 - val_accuracy: 0.9846\n",
      "Epoch 1005/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0408 - val_accuracy: 0.9879\n",
      "Epoch 1006/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.0432 - val_accuracy: 0.9869\n",
      "Epoch 1007/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.0411 - val_accuracy: 0.9888\n",
      "Epoch 1008/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0268 - accuracy: 0.9931 - val_loss: 0.0434 - val_accuracy: 0.9865\n",
      "Epoch 1009/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0290 - accuracy: 0.9910 - val_loss: 0.0413 - val_accuracy: 0.9879\n",
      "Epoch 1010/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0289 - accuracy: 0.9926 - val_loss: 0.0453 - val_accuracy: 0.9883\n",
      "Epoch 1011/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 0.0425 - val_accuracy: 0.9874\n",
      "Epoch 1012/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9936 - val_loss: 0.0407 - val_accuracy: 0.9888\n",
      "Epoch 1013/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.0447 - val_accuracy: 0.9855\n",
      "Epoch 1014/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0301 - accuracy: 0.9910 - val_loss: 0.0464 - val_accuracy: 0.9855\n",
      "Epoch 1015/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9915 - val_loss: 0.0429 - val_accuracy: 0.9865\n",
      "Epoch 1016/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9901 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 1017/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.0638 - val_accuracy: 0.9828\n",
      "Epoch 1018/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.0546 - val_accuracy: 0.9818\n",
      "Epoch 1019/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0265 - accuracy: 0.9924 - val_loss: 0.0517 - val_accuracy: 0.9851\n",
      "Epoch 1020/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.0409 - val_accuracy: 0.9879\n",
      "Epoch 1021/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9924 - val_loss: 0.0426 - val_accuracy: 0.9883\n",
      "Epoch 1022/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.0426 - val_accuracy: 0.9883\n",
      "Epoch 1023/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0403 - val_accuracy: 0.9883\n",
      "Epoch 1024/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 0.0484 - val_accuracy: 0.9846\n",
      "Epoch 1025/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.0521 - val_accuracy: 0.9841\n",
      "Epoch 1026/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0252 - accuracy: 0.9929 - val_loss: 0.0480 - val_accuracy: 0.9855\n",
      "Epoch 1027/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.0399 - val_accuracy: 0.9883\n",
      "Epoch 1028/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.0528 - val_accuracy: 0.9851\n",
      "Epoch 1029/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 0.0439 - val_accuracy: 0.9869\n",
      "Epoch 1030/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 0.0424 - val_accuracy: 0.9865\n",
      "Epoch 1031/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 0.0448 - val_accuracy: 0.9874\n",
      "Epoch 1032/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9929 - val_loss: 0.0413 - val_accuracy: 0.9879\n",
      "Epoch 1033/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.0429 - val_accuracy: 0.9874\n",
      "Epoch 1034/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.0403 - val_accuracy: 0.9883\n",
      "Epoch 1035/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 0.9929 - val_loss: 0.0432 - val_accuracy: 0.9879\n",
      "Epoch 1036/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.0410 - val_accuracy: 0.9888\n",
      "Epoch 1037/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 0.9931 - val_loss: 0.0455 - val_accuracy: 0.9855\n",
      "Epoch 1038/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9922 - val_loss: 0.0590 - val_accuracy: 0.9818\n",
      "Epoch 1039/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.0469 - val_accuracy: 0.9865\n",
      "Epoch 1040/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 0.0499 - val_accuracy: 0.9851\n",
      "Epoch 1041/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9938 - val_loss: 0.0411 - val_accuracy: 0.9874\n",
      "Epoch 1042/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9931 - val_loss: 0.0421 - val_accuracy: 0.9874\n",
      "Epoch 1043/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0409 - val_accuracy: 0.9879\n",
      "Epoch 1044/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.0422 - val_accuracy: 0.9879\n",
      "Epoch 1045/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0416 - val_accuracy: 0.9883\n",
      "Epoch 1046/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0252 - accuracy: 0.9931 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1047/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.0423 - val_accuracy: 0.9865\n",
      "Epoch 1048/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 0.0407 - val_accuracy: 0.9879\n",
      "Epoch 1049/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 0.9922 - val_loss: 0.0429 - val_accuracy: 0.9879\n",
      "Epoch 1050/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0274 - accuracy: 0.9929 - val_loss: 0.0458 - val_accuracy: 0.9855\n",
      "Epoch 1051/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.0477 - val_accuracy: 0.9851\n",
      "Epoch 1052/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 0.0641 - val_accuracy: 0.9795\n",
      "Epoch 1053/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0610 - val_accuracy: 0.9832\n",
      "Epoch 1054/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 1055/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0329 - accuracy: 0.9913 - val_loss: 0.0467 - val_accuracy: 0.9869\n",
      "Epoch 1056/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0296 - accuracy: 0.9913 - val_loss: 0.0410 - val_accuracy: 0.9883\n",
      "Epoch 1057/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 0.0529 - val_accuracy: 0.9841\n",
      "Epoch 1058/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0299 - accuracy: 0.9910 - val_loss: 0.0414 - val_accuracy: 0.9869\n",
      "Epoch 1059/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0284 - accuracy: 0.9913 - val_loss: 0.0462 - val_accuracy: 0.9851\n",
      "Epoch 1060/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9929 - val_loss: 0.0417 - val_accuracy: 0.9874\n",
      "Epoch 1061/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9926 - val_loss: 0.0417 - val_accuracy: 0.9874\n",
      "Epoch 1062/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.0538 - val_accuracy: 0.9846\n",
      "Epoch 1063/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9929 - val_loss: 0.0441 - val_accuracy: 0.9874\n",
      "Epoch 1064/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.0420 - val_accuracy: 0.9879\n",
      "Epoch 1065/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0252 - accuracy: 0.9936 - val_loss: 0.0496 - val_accuracy: 0.9855\n",
      "Epoch 1066/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0534 - val_accuracy: 0.9846\n",
      "Epoch 1067/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0418 - val_accuracy: 0.9874\n",
      "Epoch 1068/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.0425 - val_accuracy: 0.9879\n",
      "Epoch 1069/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0520 - val_accuracy: 0.9851\n",
      "Epoch 1070/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.0507 - val_accuracy: 0.9846\n",
      "Epoch 1071/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.0463 - val_accuracy: 0.9855\n",
      "Epoch 1072/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.0423 - val_accuracy: 0.9874\n",
      "Epoch 1073/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9929 - val_loss: 0.0437 - val_accuracy: 0.9869\n",
      "Epoch 1074/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9931 - val_loss: 0.0513 - val_accuracy: 0.9841\n",
      "Epoch 1075/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.0541 - val_accuracy: 0.9846\n",
      "Epoch 1076/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 0.0473 - val_accuracy: 0.9855\n",
      "Epoch 1077/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9920 - val_loss: 0.0414 - val_accuracy: 0.9874\n",
      "Epoch 1078/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.0430 - val_accuracy: 0.9874\n",
      "Epoch 1079/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0423 - val_accuracy: 0.9860\n",
      "Epoch 1080/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0451 - val_accuracy: 0.9869\n",
      "Epoch 1081/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.0466 - val_accuracy: 0.9874\n",
      "Epoch 1082/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0506 - val_accuracy: 0.9851\n",
      "Epoch 1083/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9929 - val_loss: 0.0483 - val_accuracy: 0.9851\n",
      "Epoch 1084/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0521 - val_accuracy: 0.9841\n",
      "Epoch 1085/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0550 - val_accuracy: 0.9841\n",
      "Epoch 1086/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 0.0552 - val_accuracy: 0.9832\n",
      "Epoch 1087/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0266 - accuracy: 0.9924 - val_loss: 0.0510 - val_accuracy: 0.9860\n",
      "Epoch 1088/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0421 - val_accuracy: 0.9879\n",
      "Epoch 1089/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.0427 - val_accuracy: 0.9879\n",
      "Epoch 1090/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0257 - accuracy: 0.9929 - val_loss: 0.0410 - val_accuracy: 0.9883\n",
      "Epoch 1091/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9917 - val_loss: 0.0408 - val_accuracy: 0.9879\n",
      "Epoch 1092/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.0431 - val_accuracy: 0.9874\n",
      "Epoch 1093/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0408 - val_accuracy: 0.9879\n",
      "Epoch 1094/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0419 - val_accuracy: 0.9874\n",
      "Epoch 1095/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9931 - val_loss: 0.0524 - val_accuracy: 0.9841\n",
      "Epoch 1096/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0425 - val_accuracy: 0.9874\n",
      "Epoch 1097/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1098/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.0513 - val_accuracy: 0.9841\n",
      "Epoch 1099/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.0445 - val_accuracy: 0.9851\n",
      "Epoch 1100/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.0438 - val_accuracy: 0.9869\n",
      "Epoch 1101/3500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.0419 - val_accuracy: 0.9888\n",
      "Epoch 1102/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9926 - val_loss: 0.0415 - val_accuracy: 0.9879\n",
      "Epoch 1103/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0464 - val_accuracy: 0.9855\n",
      "Epoch 1104/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 0.0435 - val_accuracy: 0.9874\n",
      "Epoch 1105/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0461 - val_accuracy: 0.9865\n",
      "Epoch 1106/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 0.0432 - val_accuracy: 0.9879\n",
      "Epoch 1107/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0426 - val_accuracy: 0.9869\n",
      "Epoch 1108/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0426 - val_accuracy: 0.9883\n",
      "Epoch 1109/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9940 - val_loss: 0.0412 - val_accuracy: 0.9879\n",
      "Epoch 1110/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.0424 - val_accuracy: 0.9869\n",
      "Epoch 1111/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.0439 - val_accuracy: 0.9874\n",
      "Epoch 1112/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.0461 - val_accuracy: 0.9869\n",
      "Epoch 1113/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0514 - val_accuracy: 0.9860\n",
      "Epoch 1114/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.0443 - val_accuracy: 0.9879\n",
      "Epoch 1115/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0443 - val_accuracy: 0.9860\n",
      "Epoch 1116/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.0414 - val_accuracy: 0.9883\n",
      "Epoch 1117/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.0503 - val_accuracy: 0.9860\n",
      "Epoch 1118/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 0.0468 - val_accuracy: 0.9860\n",
      "Epoch 1119/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 0.0426 - val_accuracy: 0.9879\n",
      "Epoch 1120/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0284 - accuracy: 0.9910 - val_loss: 0.0434 - val_accuracy: 0.9874\n",
      "Epoch 1121/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.0424 - val_accuracy: 0.9869\n",
      "Epoch 1122/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9917 - val_loss: 0.0414 - val_accuracy: 0.9879\n",
      "Epoch 1123/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 1124/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.0422 - val_accuracy: 0.9883\n",
      "Epoch 1125/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9913 - val_loss: 0.0422 - val_accuracy: 0.9879\n",
      "Epoch 1126/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0492 - val_accuracy: 0.9851\n",
      "Epoch 1127/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0450 - val_accuracy: 0.9869\n",
      "Epoch 1128/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9924 - val_loss: 0.0413 - val_accuracy: 0.9869\n",
      "Epoch 1129/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0491 - val_accuracy: 0.9869\n",
      "Epoch 1130/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1131/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0438 - val_accuracy: 0.9869\n",
      "Epoch 1132/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.0422 - val_accuracy: 0.9879\n",
      "Epoch 1133/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.0453 - val_accuracy: 0.9860\n",
      "Epoch 1134/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.0423 - val_accuracy: 0.9879\n",
      "Epoch 1135/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0419 - val_accuracy: 0.9869\n",
      "Epoch 1136/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.0454 - val_accuracy: 0.9869\n",
      "Epoch 1137/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.0412 - val_accuracy: 0.9888\n",
      "Epoch 1138/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 0.9931 - val_loss: 0.0432 - val_accuracy: 0.9860\n",
      "Epoch 1139/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.0467 - val_accuracy: 0.9855\n",
      "Epoch 1140/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0394 - val_accuracy: 0.9879\n",
      "Epoch 1141/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.0403 - val_accuracy: 0.9883\n",
      "Epoch 1142/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.0419 - val_accuracy: 0.9874\n",
      "Epoch 1143/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0448 - val_accuracy: 0.9860\n",
      "Epoch 1144/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.0415 - val_accuracy: 0.9879\n",
      "Epoch 1145/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0485 - val_accuracy: 0.9855\n",
      "Epoch 1146/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0443 - val_accuracy: 0.9855\n",
      "Epoch 1147/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.9917 - val_loss: 0.0430 - val_accuracy: 0.9865\n",
      "Epoch 1148/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.0405 - val_accuracy: 0.9893\n",
      "Epoch 1149/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.0415 - val_accuracy: 0.9879\n",
      "Epoch 1150/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0421 - val_accuracy: 0.9865\n",
      "Epoch 1151/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.0441 - val_accuracy: 0.9879\n",
      "Epoch 1152/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0505 - val_accuracy: 0.9832\n",
      "Epoch 1153/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.0500 - val_accuracy: 0.9851\n",
      "Epoch 1154/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0463 - val_accuracy: 0.9865\n",
      "Epoch 1155/3500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.0437 - val_accuracy: 0.9879\n",
      "Epoch 1156/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.0579 - val_accuracy: 0.9841\n",
      "Epoch 1157/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0225 - accuracy: 0.9945 - val_loss: 0.0428 - val_accuracy: 0.9874\n",
      "Epoch 1158/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 0.0444 - val_accuracy: 0.9865\n",
      "Epoch 1159/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9929 - val_loss: 0.0424 - val_accuracy: 0.9879\n",
      "Epoch 1160/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0447 - val_accuracy: 0.9869\n",
      "Epoch 1161/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0439 - val_accuracy: 0.9869\n",
      "Epoch 1162/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0226 - accuracy: 0.9936 - val_loss: 0.0438 - val_accuracy: 0.9869\n",
      "Epoch 1163/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.0448 - val_accuracy: 0.9869\n",
      "Epoch 1164/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 0.0405 - val_accuracy: 0.9883\n",
      "Epoch 1165/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0228 - accuracy: 0.9943 - val_loss: 0.0410 - val_accuracy: 0.9883\n",
      "Epoch 1166/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.0530 - val_accuracy: 0.9846\n",
      "Epoch 1167/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.0564 - val_accuracy: 0.9818\n",
      "Epoch 1168/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 0.0560 - val_accuracy: 0.9837\n",
      "Epoch 1169/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0249 - accuracy: 0.9908 - val_loss: 0.0450 - val_accuracy: 0.9879\n",
      "Epoch 1170/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.0413 - val_accuracy: 0.9883\n",
      "Epoch 1171/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.0456 - val_accuracy: 0.9879\n",
      "Epoch 1172/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.0427 - val_accuracy: 0.9869\n",
      "Epoch 1173/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 0.0444 - val_accuracy: 0.9879\n",
      "Epoch 1174/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 0.0408 - val_accuracy: 0.9879\n",
      "Epoch 1175/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9929 - val_loss: 0.0432 - val_accuracy: 0.9879\n",
      "Epoch 1176/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0268 - accuracy: 0.9910 - val_loss: 0.0447 - val_accuracy: 0.9860\n",
      "Epoch 1177/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.0530 - val_accuracy: 0.9841\n",
      "Epoch 1178/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.0507 - val_accuracy: 0.9851\n",
      "Epoch 1179/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0239 - accuracy: 0.9938 - val_loss: 0.0462 - val_accuracy: 0.9865\n",
      "Epoch 1180/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0436 - val_accuracy: 0.9869\n",
      "Epoch 1181/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.0422 - val_accuracy: 0.9869\n",
      "Epoch 1182/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.0434 - val_accuracy: 0.9869\n",
      "Epoch 1183/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9940 - val_loss: 0.0449 - val_accuracy: 0.9860\n",
      "Epoch 1184/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0449 - val_accuracy: 0.9855\n",
      "Epoch 1185/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 0.0421 - val_accuracy: 0.9874\n",
      "Epoch 1186/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0422 - val_accuracy: 0.9883\n",
      "Epoch 1187/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.0436 - val_accuracy: 0.9869\n",
      "Epoch 1188/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 0.0428 - val_accuracy: 0.9869\n",
      "Epoch 1189/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.9922 - val_loss: 0.0447 - val_accuracy: 0.9869\n",
      "Epoch 1190/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0249 - accuracy: 0.9929 - val_loss: 0.0413 - val_accuracy: 0.9883\n",
      "Epoch 1191/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0472 - val_accuracy: 0.9860\n",
      "Epoch 1192/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0459 - val_accuracy: 0.9865\n",
      "Epoch 1193/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0551 - val_accuracy: 0.9837\n",
      "Epoch 1194/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.0525 - val_accuracy: 0.9846\n",
      "Epoch 1195/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0441 - val_accuracy: 0.9869\n",
      "Epoch 1196/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.0424 - val_accuracy: 0.9874\n",
      "Epoch 1197/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 1198/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0412 - val_accuracy: 0.9883\n",
      "Epoch 1199/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.9926 - val_loss: 0.0450 - val_accuracy: 0.9865\n",
      "Epoch 1200/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0281 - accuracy: 0.9917 - val_loss: 0.0476 - val_accuracy: 0.9860\n",
      "Epoch 1201/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 0.0444 - val_accuracy: 0.9865\n",
      "Epoch 1202/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.0424 - val_accuracy: 0.9874\n",
      "Epoch 1203/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1204/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9940 - val_loss: 0.0419 - val_accuracy: 0.9883\n",
      "Epoch 1205/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.0410 - val_accuracy: 0.9883\n",
      "Epoch 1206/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.0421 - val_accuracy: 0.9883\n",
      "Epoch 1207/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.0441 - val_accuracy: 0.9860\n",
      "Epoch 1208/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0430 - val_accuracy: 0.9874\n",
      "Epoch 1209/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.0419 - val_accuracy: 0.9874\n",
      "Epoch 1210/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0458 - val_accuracy: 0.9865\n",
      "Epoch 1211/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9913 - val_loss: 0.0495 - val_accuracy: 0.9865\n",
      "Epoch 1212/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.0551 - val_accuracy: 0.9837\n",
      "Epoch 1213/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 0.9924 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
      "Epoch 1214/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.0430 - val_accuracy: 0.9865\n",
      "Epoch 1215/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0289 - accuracy: 0.9920 - val_loss: 0.0501 - val_accuracy: 0.9865\n",
      "Epoch 1216/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0289 - accuracy: 0.9897 - val_loss: 0.0435 - val_accuracy: 0.9865\n",
      "Epoch 1217/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0240 - accuracy: 0.9947 - val_loss: 0.0425 - val_accuracy: 0.9879\n",
      "Epoch 1218/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0478 - val_accuracy: 0.9869\n",
      "Epoch 1219/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.0410 - val_accuracy: 0.9874\n",
      "Epoch 1220/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.0433 - val_accuracy: 0.9888\n",
      "Epoch 1221/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 0.0418 - val_accuracy: 0.9883\n",
      "Epoch 1222/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.0444 - val_accuracy: 0.9865\n",
      "Epoch 1223/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0440 - val_accuracy: 0.9869\n",
      "Epoch 1224/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9940 - val_loss: 0.0438 - val_accuracy: 0.9874\n",
      "Epoch 1225/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 0.0445 - val_accuracy: 0.9865\n",
      "Epoch 1226/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0423 - val_accuracy: 0.9874\n",
      "Epoch 1227/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.0434 - val_accuracy: 0.9883\n",
      "Epoch 1228/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 0.0409 - val_accuracy: 0.9883\n",
      "Epoch 1229/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9931 - val_loss: 0.0459 - val_accuracy: 0.9860\n",
      "Epoch 1230/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.0416 - val_accuracy: 0.9883\n",
      "Epoch 1231/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0412 - val_accuracy: 0.9883\n",
      "Epoch 1232/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 0.0434 - val_accuracy: 0.9869\n",
      "Epoch 1233/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0463 - val_accuracy: 0.9855\n",
      "Epoch 1234/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.0525 - val_accuracy: 0.9851\n",
      "Epoch 1235/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0551 - val_accuracy: 0.9818\n",
      "Epoch 1236/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0467 - val_accuracy: 0.9855\n",
      "Epoch 1237/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0424 - val_accuracy: 0.9879\n",
      "Epoch 1238/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0510 - val_accuracy: 0.9851\n",
      "Epoch 1239/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0465 - val_accuracy: 0.9869\n",
      "Epoch 1240/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0218 - accuracy: 0.9940 - val_loss: 0.0417 - val_accuracy: 0.9879\n",
      "Epoch 1241/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9922 - val_loss: 0.0453 - val_accuracy: 0.9869\n",
      "Epoch 1242/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.0438 - val_accuracy: 0.9874\n",
      "Epoch 1243/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9920 - val_loss: 0.0444 - val_accuracy: 0.9874\n",
      "Epoch 1244/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 1245/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.0553 - val_accuracy: 0.9828\n",
      "Epoch 1246/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.0474 - val_accuracy: 0.9869\n",
      "Epoch 1247/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0453 - val_accuracy: 0.9865\n",
      "Epoch 1248/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0259 - accuracy: 0.9922 - val_loss: 0.0467 - val_accuracy: 0.9865\n",
      "Epoch 1249/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0264 - accuracy: 0.9917 - val_loss: 0.0422 - val_accuracy: 0.9879\n",
      "Epoch 1250/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0295 - accuracy: 0.9892 - val_loss: 0.0500 - val_accuracy: 0.9855\n",
      "Epoch 1251/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 0.0453 - val_accuracy: 0.9874\n",
      "Epoch 1252/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.0483 - val_accuracy: 0.9860\n",
      "Epoch 1253/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.0507 - val_accuracy: 0.9855\n",
      "Epoch 1254/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0471 - val_accuracy: 0.9879\n",
      "Epoch 1255/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9943 - val_loss: 0.0455 - val_accuracy: 0.9874\n",
      "Epoch 1256/3500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
      "Epoch 1257/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0233 - accuracy: 0.9931 - val_loss: 0.0512 - val_accuracy: 0.9846\n",
      "Epoch 1258/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0513 - val_accuracy: 0.9851\n",
      "Epoch 1259/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 0.0514 - val_accuracy: 0.9855\n",
      "Epoch 1260/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0417 - val_accuracy: 0.9888\n",
      "Epoch 1261/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0533 - val_accuracy: 0.9855\n",
      "Epoch 1262/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 0.0673 - val_accuracy: 0.9804\n",
      "Epoch 1263/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0280 - accuracy: 0.9901 - val_loss: 0.0525 - val_accuracy: 0.9846\n",
      "Epoch 1264/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0256 - accuracy: 0.9924 - val_loss: 0.0426 - val_accuracy: 0.9879\n",
      "Epoch 1265/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.0451 - val_accuracy: 0.9860\n",
      "Epoch 1266/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.0479 - val_accuracy: 0.9865\n",
      "Epoch 1267/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 0.9922 - val_loss: 0.0404 - val_accuracy: 0.9888\n",
      "Epoch 1268/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 0.0553 - val_accuracy: 0.9846\n",
      "Epoch 1269/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0464 - val_accuracy: 0.9855\n",
      "Epoch 1270/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9943 - val_loss: 0.0406 - val_accuracy: 0.9883\n",
      "Epoch 1271/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.0436 - val_accuracy: 0.9888\n",
      "Epoch 1272/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0428 - val_accuracy: 0.9879\n",
      "Epoch 1273/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.0468 - val_accuracy: 0.9860\n",
      "Epoch 1274/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.0448 - val_accuracy: 0.9869\n",
      "Epoch 1275/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0439 - val_accuracy: 0.9869\n",
      "Epoch 1276/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0464 - val_accuracy: 0.9869\n",
      "Epoch 1277/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0443 - val_accuracy: 0.9879\n",
      "Epoch 1278/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.0407 - val_accuracy: 0.9883\n",
      "Epoch 1279/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9938 - val_loss: 0.0515 - val_accuracy: 0.9855\n",
      "Epoch 1280/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0435 - val_accuracy: 0.9879\n",
      "Epoch 1281/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.0434 - val_accuracy: 0.9883\n",
      "Epoch 1282/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0433 - val_accuracy: 0.9879\n",
      "Epoch 1283/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 0.0615 - val_accuracy: 0.9823\n",
      "Epoch 1284/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 0.0488 - val_accuracy: 0.9860\n",
      "Epoch 1285/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.0492 - val_accuracy: 0.9865\n",
      "Epoch 1286/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.0420 - val_accuracy: 0.9888\n",
      "Epoch 1287/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0419 - val_accuracy: 0.9883\n",
      "Epoch 1288/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 0.0481 - val_accuracy: 0.9865\n",
      "Epoch 1289/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0546 - val_accuracy: 0.9841\n",
      "Epoch 1290/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.0481 - val_accuracy: 0.9860\n",
      "Epoch 1291/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 0.0461 - val_accuracy: 0.9860\n",
      "Epoch 1292/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.0419 - val_accuracy: 0.9888\n",
      "Epoch 1293/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.0426 - val_accuracy: 0.9883\n",
      "Epoch 1294/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 0.0403 - val_accuracy: 0.9879\n",
      "Epoch 1295/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.0702 - val_accuracy: 0.9809\n",
      "Epoch 1296/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0326 - accuracy: 0.9892 - val_loss: 0.0627 - val_accuracy: 0.9795\n",
      "Epoch 1297/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 0.0476 - val_accuracy: 0.9869\n",
      "Epoch 1298/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.0406 - val_accuracy: 0.9893\n",
      "Epoch 1299/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0443 - val_accuracy: 0.9874\n",
      "Epoch 1300/3500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 0.0473 - val_accuracy: 0.9865\n",
      "Epoch 1301/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.0551 - val_accuracy: 0.9832\n",
      "Epoch 1302/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0472 - val_accuracy: 0.9855\n",
      "Epoch 1303/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0442 - val_accuracy: 0.9879\n",
      "Epoch 1304/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9922 - val_loss: 0.0419 - val_accuracy: 0.9888\n",
      "Epoch 1305/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0453 - val_accuracy: 0.9874\n",
      "Epoch 1306/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0436 - val_accuracy: 0.9879\n",
      "Epoch 1307/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0420 - val_accuracy: 0.9888\n",
      "Epoch 1308/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.0423 - val_accuracy: 0.9879\n",
      "Epoch 1309/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9924 - val_loss: 0.0438 - val_accuracy: 0.9865\n",
      "Epoch 1310/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0486 - val_accuracy: 0.9869\n",
      "Epoch 1311/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0503 - val_accuracy: 0.9865\n",
      "Epoch 1312/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.0412 - val_accuracy: 0.9879\n",
      "Epoch 1313/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.0422 - val_accuracy: 0.9883\n",
      "Epoch 1314/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.0430 - val_accuracy: 0.9879\n",
      "Epoch 1315/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0562 - val_accuracy: 0.9841\n",
      "Epoch 1316/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0479 - val_accuracy: 0.9855\n",
      "Epoch 1317/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.0426 - val_accuracy: 0.9883\n",
      "Epoch 1318/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.0447 - val_accuracy: 0.9893\n",
      "Epoch 1319/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.0522 - val_accuracy: 0.9841\n",
      "Epoch 1320/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0533 - val_accuracy: 0.9837\n",
      "Epoch 1321/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.0512 - val_accuracy: 0.9865\n",
      "Epoch 1322/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 0.0440 - val_accuracy: 0.9893\n",
      "Epoch 1323/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.0456 - val_accuracy: 0.9874\n",
      "Epoch 1324/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9943 - val_loss: 0.0415 - val_accuracy: 0.9883\n",
      "Epoch 1325/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 0.0447 - val_accuracy: 0.9874\n",
      "Epoch 1326/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0422 - val_accuracy: 0.9874\n",
      "Epoch 1327/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9879\n",
      "Epoch 1328/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 0.0420 - val_accuracy: 0.9893\n",
      "Epoch 1329/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0459 - val_accuracy: 0.9879\n",
      "Epoch 1330/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0510 - val_accuracy: 0.9865\n",
      "Epoch 1331/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0649 - val_accuracy: 0.9809\n",
      "Epoch 1332/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0313 - accuracy: 0.9899 - val_loss: 0.0740 - val_accuracy: 0.9776\n",
      "Epoch 1333/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.0437 - val_accuracy: 0.9883\n",
      "Epoch 1334/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.0408 - val_accuracy: 0.9888\n",
      "Epoch 1335/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.0433 - val_accuracy: 0.9874\n",
      "Epoch 1336/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1337/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 0.0434 - val_accuracy: 0.9883\n",
      "Epoch 1338/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0437 - val_accuracy: 0.9874\n",
      "Epoch 1339/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0633 - val_accuracy: 0.9804\n",
      "Epoch 1340/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9922 - val_loss: 0.0648 - val_accuracy: 0.9828\n",
      "Epoch 1341/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.0463 - val_accuracy: 0.9865\n",
      "Epoch 1342/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0486 - val_accuracy: 0.9865\n",
      "Epoch 1343/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.0428 - val_accuracy: 0.9879\n",
      "Epoch 1344/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0412 - val_accuracy: 0.9879\n",
      "Epoch 1345/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0461 - val_accuracy: 0.9883\n",
      "Epoch 1346/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.0408 - val_accuracy: 0.9879\n",
      "Epoch 1347/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0420 - val_accuracy: 0.9874\n",
      "Epoch 1348/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.0437 - val_accuracy: 0.9883\n",
      "Epoch 1349/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0450 - val_accuracy: 0.9883\n",
      "Epoch 1350/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0530 - val_accuracy: 0.9851\n",
      "Epoch 1351/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.0503 - val_accuracy: 0.9855\n",
      "Epoch 1352/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9943 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 1353/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0473 - val_accuracy: 0.9879\n",
      "Epoch 1354/3500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0574 - val_accuracy: 0.9846\n",
      "Epoch 1355/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0531 - val_accuracy: 0.9846\n",
      "Epoch 1356/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0230 - accuracy: 0.9940 - val_loss: 0.0469 - val_accuracy: 0.9865\n",
      "Epoch 1357/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.0471 - val_accuracy: 0.9865\n",
      "Epoch 1358/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0440 - val_accuracy: 0.9883\n",
      "Epoch 1359/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9943 - val_loss: 0.0427 - val_accuracy: 0.9874\n",
      "Epoch 1360/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 1361/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 0.0420 - val_accuracy: 0.9883\n",
      "Epoch 1362/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0442 - val_accuracy: 0.9888\n",
      "Epoch 1363/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0424 - val_accuracy: 0.9874\n",
      "Epoch 1364/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0430 - val_accuracy: 0.9879\n",
      "Epoch 1365/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.0474 - val_accuracy: 0.9874\n",
      "Epoch 1366/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0496 - val_accuracy: 0.9855\n",
      "Epoch 1367/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0690 - val_accuracy: 0.9804\n",
      "Epoch 1368/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0420 - val_accuracy: 0.9893\n",
      "Epoch 1369/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.0527 - val_accuracy: 0.9860\n",
      "Epoch 1370/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.0423 - val_accuracy: 0.9879\n",
      "Epoch 1371/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0493 - val_accuracy: 0.9851\n",
      "Epoch 1372/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0281 - accuracy: 0.9910 - val_loss: 0.0519 - val_accuracy: 0.9869\n",
      "Epoch 1373/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 0.0430 - val_accuracy: 0.9883\n",
      "Epoch 1374/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.0457 - val_accuracy: 0.9874\n",
      "Epoch 1375/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 0.0692 - val_accuracy: 0.9804\n",
      "Epoch 1376/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.0594 - val_accuracy: 0.9832\n",
      "Epoch 1377/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.0513 - val_accuracy: 0.9865\n",
      "Epoch 1378/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9938 - val_loss: 0.0454 - val_accuracy: 0.9879\n",
      "Epoch 1379/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0448 - val_accuracy: 0.9883\n",
      "Epoch 1380/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 0.0452 - val_accuracy: 0.9883\n",
      "Epoch 1381/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.0430 - val_accuracy: 0.9879\n",
      "Epoch 1382/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0475 - val_accuracy: 0.9869\n",
      "Epoch 1383/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.0546 - val_accuracy: 0.9837\n",
      "Epoch 1384/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 0.0586 - val_accuracy: 0.9846\n",
      "Epoch 1385/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0431 - val_accuracy: 0.9883\n",
      "Epoch 1386/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0423 - val_accuracy: 0.9888\n",
      "Epoch 1387/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.0454 - val_accuracy: 0.9869\n",
      "Epoch 1388/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.0428 - val_accuracy: 0.9874\n",
      "Epoch 1389/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.0473 - val_accuracy: 0.9855\n",
      "Epoch 1390/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.0418 - val_accuracy: 0.9869\n",
      "Epoch 1391/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.0454 - val_accuracy: 0.9879\n",
      "Epoch 1392/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.0492 - val_accuracy: 0.9869\n",
      "Epoch 1393/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.0555 - val_accuracy: 0.9828\n",
      "Epoch 1394/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0432 - val_accuracy: 0.9888\n",
      "Epoch 1395/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.0524 - val_accuracy: 0.9851\n",
      "Epoch 1396/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0441 - val_accuracy: 0.9888\n",
      "Epoch 1397/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.0417 - val_accuracy: 0.9879\n",
      "Epoch 1398/3500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0556 - val_accuracy: 0.9860\n",
      "Epoch 1399/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0440 - val_accuracy: 0.9883\n",
      "Epoch 1400/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0607 - val_accuracy: 0.9823\n",
      "Epoch 1401/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
      "Epoch 1402/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0311 - accuracy: 0.9894 - val_loss: 0.0538 - val_accuracy: 0.9860\n",
      "Epoch 1403/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0317 - accuracy: 0.9897 - val_loss: 0.0585 - val_accuracy: 0.9814\n",
      "Epoch 1404/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.0479 - val_accuracy: 0.9874\n",
      "Epoch 1405/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.0432 - val_accuracy: 0.9869\n",
      "Epoch 1406/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.0441 - val_accuracy: 0.9869\n",
      "Epoch 1407/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.0421 - val_accuracy: 0.9888\n",
      "Epoch 1408/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0421 - val_accuracy: 0.9883\n",
      "Epoch 1409/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0465 - val_accuracy: 0.9879\n",
      "Epoch 1410/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9940 - val_loss: 0.0417 - val_accuracy: 0.9883\n",
      "Epoch 1411/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 1412/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.0429 - val_accuracy: 0.9888\n",
      "Epoch 1413/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9901 - val_loss: 0.0480 - val_accuracy: 0.9869\n",
      "Epoch 1414/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 0.0667 - val_accuracy: 0.9818\n",
      "Epoch 1415/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0419 - val_accuracy: 0.9897\n",
      "Epoch 1416/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.0514 - val_accuracy: 0.9860\n",
      "Epoch 1417/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 0.0460 - val_accuracy: 0.9883\n",
      "Epoch 1418/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.0418 - val_accuracy: 0.9893\n",
      "Epoch 1419/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0445 - val_accuracy: 0.9888\n",
      "Epoch 1420/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.0537 - val_accuracy: 0.9851\n",
      "Epoch 1421/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9940 - val_loss: 0.0431 - val_accuracy: 0.9893\n",
      "Epoch 1422/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0520 - val_accuracy: 0.9865\n",
      "Epoch 1423/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0525 - val_accuracy: 0.9846\n",
      "Epoch 1424/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9931 - val_loss: 0.0546 - val_accuracy: 0.9837\n",
      "Epoch 1425/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.0591 - val_accuracy: 0.9841\n",
      "Epoch 1426/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.0449 - val_accuracy: 0.9879\n",
      "Epoch 1427/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.0423 - val_accuracy: 0.9879\n",
      "Epoch 1428/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 0.0480 - val_accuracy: 0.9855\n",
      "Epoch 1429/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0448 - val_accuracy: 0.9879\n",
      "Epoch 1430/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 0.0482 - val_accuracy: 0.9860\n",
      "Epoch 1431/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 0.0456 - val_accuracy: 0.9888\n",
      "Epoch 1432/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.0495 - val_accuracy: 0.9874\n",
      "Epoch 1433/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 0.0614 - val_accuracy: 0.9828\n",
      "Epoch 1434/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.0473 - val_accuracy: 0.9874\n",
      "Epoch 1435/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0471 - val_accuracy: 0.9879\n",
      "Epoch 1436/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0417 - val_accuracy: 0.9879\n",
      "Epoch 1437/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0579 - val_accuracy: 0.9832\n",
      "Epoch 1438/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0437 - val_accuracy: 0.9874\n",
      "Epoch 1439/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 0.0411 - val_accuracy: 0.9888\n",
      "Epoch 1440/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 0.0455 - val_accuracy: 0.9888\n",
      "Epoch 1441/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0749 - val_accuracy: 0.9800\n",
      "Epoch 1442/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 0.0765 - val_accuracy: 0.9786\n",
      "Epoch 1443/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.0433 - val_accuracy: 0.9883\n",
      "Epoch 1444/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.0443 - val_accuracy: 0.9865\n",
      "Epoch 1445/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0452 - val_accuracy: 0.9874\n",
      "Epoch 1446/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0471 - val_accuracy: 0.9893\n",
      "Epoch 1447/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 0.0459 - val_accuracy: 0.9874\n",
      "Epoch 1448/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0425 - val_accuracy: 0.9888\n",
      "Epoch 1449/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0497 - val_accuracy: 0.9865\n",
      "Epoch 1450/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0427 - val_accuracy: 0.9883\n",
      "Epoch 1451/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 1452/3500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0211 - accuracy: 0.9940 - val_loss: 0.0437 - val_accuracy: 0.9893\n",
      "Epoch 1453/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9943 - val_loss: 0.0458 - val_accuracy: 0.9879\n",
      "Epoch 1454/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 0.0490 - val_accuracy: 0.9874\n",
      "Epoch 1455/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.0506 - val_accuracy: 0.9855\n",
      "Epoch 1456/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.0414 - val_accuracy: 0.9883\n",
      "Epoch 1457/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.0468 - val_accuracy: 0.9869\n",
      "Epoch 1458/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.0444 - val_accuracy: 0.9893\n",
      "Epoch 1459/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0469 - val_accuracy: 0.9879\n",
      "Epoch 1460/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9929 - val_loss: 0.0463 - val_accuracy: 0.9879\n",
      "Epoch 1461/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.0499 - val_accuracy: 0.9855\n",
      "Epoch 1462/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0570 - val_accuracy: 0.9860\n",
      "Epoch 1463/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.0465 - val_accuracy: 0.9879\n",
      "Epoch 1464/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0503 - val_accuracy: 0.9874\n",
      "Epoch 1465/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0469 - val_accuracy: 0.9879\n",
      "Epoch 1466/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0460 - val_accuracy: 0.9883\n",
      "Epoch 1467/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9938 - val_loss: 0.0435 - val_accuracy: 0.9888\n",
      "Epoch 1468/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.0468 - val_accuracy: 0.9879\n",
      "Epoch 1469/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0565 - val_accuracy: 0.9837\n",
      "Epoch 1470/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0578 - val_accuracy: 0.9841\n",
      "Epoch 1471/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9910 - val_loss: 0.0711 - val_accuracy: 0.9814\n",
      "Epoch 1472/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 0.0594 - val_accuracy: 0.9814\n",
      "Epoch 1473/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 0.0529 - val_accuracy: 0.9860\n",
      "Epoch 1474/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0463 - val_accuracy: 0.9883\n",
      "Epoch 1475/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.0440 - val_accuracy: 0.9874\n",
      "Epoch 1476/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.0441 - val_accuracy: 0.9883\n",
      "Epoch 1477/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.0503 - val_accuracy: 0.9865\n",
      "Epoch 1478/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0472 - val_accuracy: 0.9879\n",
      "Epoch 1479/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.0548 - val_accuracy: 0.9846\n",
      "Epoch 1480/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 0.9931 - val_loss: 0.0470 - val_accuracy: 0.9879\n",
      "Epoch 1481/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0458 - val_accuracy: 0.9893\n",
      "Epoch 1482/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0400 - val_accuracy: 0.9888\n",
      "Epoch 1483/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0498 - val_accuracy: 0.9874\n",
      "Epoch 1484/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.0604 - val_accuracy: 0.9841\n",
      "Epoch 1485/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.0457 - val_accuracy: 0.9888\n",
      "Epoch 1486/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.0416 - val_accuracy: 0.9879\n",
      "Epoch 1487/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9924 - val_loss: 0.0489 - val_accuracy: 0.9855\n",
      "Epoch 1488/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0435 - val_accuracy: 0.9883\n",
      "Epoch 1489/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0453 - val_accuracy: 0.9893\n",
      "Epoch 1490/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0579 - val_accuracy: 0.9855\n",
      "Epoch 1491/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0429 - val_accuracy: 0.9888\n",
      "Epoch 1492/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.0445 - val_accuracy: 0.9883\n",
      "Epoch 1493/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0539 - val_accuracy: 0.9851\n",
      "Epoch 1494/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.0461 - val_accuracy: 0.9879\n",
      "Epoch 1495/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.0419 - val_accuracy: 0.9888\n",
      "Epoch 1496/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0463 - val_accuracy: 0.9879\n",
      "Epoch 1497/3500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0510 - val_accuracy: 0.9879\n",
      "Epoch 1498/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
      "Epoch 1499/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.0419 - val_accuracy: 0.9883\n",
      "Epoch 1500/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0474 - val_accuracy: 0.9888\n",
      "Epoch 1501/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0452 - val_accuracy: 0.9879\n",
      "Epoch 1502/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 1503/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0510 - val_accuracy: 0.9865\n",
      "Epoch 1504/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.0536 - val_accuracy: 0.9851\n",
      "Epoch 1505/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0590 - val_accuracy: 0.9832\n",
      "Epoch 1506/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.0432 - val_accuracy: 0.9883\n",
      "Epoch 1507/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.0439 - val_accuracy: 0.9888\n",
      "Epoch 1508/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0438 - val_accuracy: 0.9883\n",
      "Epoch 1509/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 0.0399 - val_accuracy: 0.9897\n",
      "Epoch 1510/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0484 - val_accuracy: 0.9879\n",
      "Epoch 1511/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0212 - accuracy: 0.9940 - val_loss: 0.0430 - val_accuracy: 0.9888\n",
      "Epoch 1512/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0425 - val_accuracy: 0.9879\n",
      "Epoch 1513/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.0424 - val_accuracy: 0.9888\n",
      "Epoch 1514/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 0.0463 - val_accuracy: 0.9883\n",
      "Epoch 1515/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
      "Epoch 1516/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0531 - val_accuracy: 0.9855\n",
      "Epoch 1517/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 0.0508 - val_accuracy: 0.9865\n",
      "Epoch 1518/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.0629 - val_accuracy: 0.9823\n",
      "Epoch 1519/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0458 - val_accuracy: 0.9883\n",
      "Epoch 1520/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0462 - val_accuracy: 0.9879\n",
      "Epoch 1521/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0448 - val_accuracy: 0.9893\n",
      "Epoch 1522/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0510 - val_accuracy: 0.9869\n",
      "Epoch 1523/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.0506 - val_accuracy: 0.9846\n",
      "Epoch 1524/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.0449 - val_accuracy: 0.9883\n",
      "Epoch 1525/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.0424 - val_accuracy: 0.9879\n",
      "Epoch 1526/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9929 - val_loss: 0.0543 - val_accuracy: 0.9860\n",
      "Epoch 1527/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.0476 - val_accuracy: 0.9874\n",
      "Epoch 1528/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.0464 - val_accuracy: 0.9883\n",
      "Epoch 1529/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0418 - val_accuracy: 0.9897\n",
      "Epoch 1530/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0518 - val_accuracy: 0.9874\n",
      "Epoch 1531/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.0486 - val_accuracy: 0.9879\n",
      "Epoch 1532/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 0.0508 - val_accuracy: 0.9860\n",
      "Epoch 1533/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.0462 - val_accuracy: 0.9874\n",
      "Epoch 1534/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0434 - val_accuracy: 0.9879\n",
      "Epoch 1535/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0519 - val_accuracy: 0.9860\n",
      "Epoch 1536/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0502 - val_accuracy: 0.9874\n",
      "Epoch 1537/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 0.0442 - val_accuracy: 0.9893\n",
      "Epoch 1538/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.0433 - val_accuracy: 0.9879\n",
      "Epoch 1539/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9924 - val_loss: 0.0435 - val_accuracy: 0.9883\n",
      "Epoch 1540/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0439 - val_accuracy: 0.9888\n",
      "Epoch 1541/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.0479 - val_accuracy: 0.9888\n",
      "Epoch 1542/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0485 - val_accuracy: 0.9865\n",
      "Epoch 1543/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.0556 - val_accuracy: 0.9865\n",
      "Epoch 1544/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.0435 - val_accuracy: 0.9893\n",
      "Epoch 1545/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.0429 - val_accuracy: 0.9888\n",
      "Epoch 1546/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.0483 - val_accuracy: 0.9869\n",
      "Epoch 1547/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 0.0626 - val_accuracy: 0.9823\n",
      "Epoch 1548/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.0486 - val_accuracy: 0.9874\n",
      "Epoch 1549/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.0593 - val_accuracy: 0.9837\n",
      "Epoch 1550/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9920 - val_loss: 0.0479 - val_accuracy: 0.9874\n",
      "Epoch 1551/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.0466 - val_accuracy: 0.9879\n",
      "Epoch 1552/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0417 - val_accuracy: 0.9879\n",
      "Epoch 1553/3500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0226 - accuracy: 0.9936 - val_loss: 0.0489 - val_accuracy: 0.9874\n",
      "Epoch 1554/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.0439 - val_accuracy: 0.9888\n",
      "Epoch 1555/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 0.0493 - val_accuracy: 0.9879\n",
      "Epoch 1556/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.0443 - val_accuracy: 0.9879\n",
      "Epoch 1557/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.0434 - val_accuracy: 0.9874\n",
      "Epoch 1558/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0438 - val_accuracy: 0.9883\n",
      "Epoch 1559/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.0454 - val_accuracy: 0.9893\n",
      "Epoch 1560/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0442 - val_accuracy: 0.9893\n",
      "Epoch 1561/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0491 - val_accuracy: 0.9869\n",
      "Epoch 1562/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0521 - val_accuracy: 0.9869\n",
      "Epoch 1563/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0467 - val_accuracy: 0.9888\n",
      "Epoch 1564/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0414 - val_accuracy: 0.9893\n",
      "Epoch 1565/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0469 - val_accuracy: 0.9879\n",
      "Epoch 1566/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 0.0425 - val_accuracy: 0.9874\n",
      "Epoch 1567/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9949 - val_loss: 0.0459 - val_accuracy: 0.9883\n",
      "Epoch 1568/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0498 - val_accuracy: 0.9869\n",
      "Epoch 1569/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0487 - val_accuracy: 0.9869\n",
      "Epoch 1570/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 1571/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0473 - val_accuracy: 0.9879\n",
      "Epoch 1572/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.0544 - val_accuracy: 0.9851\n",
      "Epoch 1573/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0466 - val_accuracy: 0.9883\n",
      "Epoch 1574/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0435 - val_accuracy: 0.9874\n",
      "Epoch 1575/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.0457 - val_accuracy: 0.9883\n",
      "Epoch 1576/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 0.0548 - val_accuracy: 0.9860\n",
      "Epoch 1577/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.0585 - val_accuracy: 0.9846\n",
      "Epoch 1578/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.0654 - val_accuracy: 0.9814\n",
      "Epoch 1579/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9938 - val_loss: 0.0564 - val_accuracy: 0.9841\n",
      "Epoch 1580/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0604 - val_accuracy: 0.9855\n",
      "Epoch 1581/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0477 - val_accuracy: 0.9874\n",
      "Epoch 1582/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0276 - accuracy: 0.9903 - val_loss: 0.0432 - val_accuracy: 0.9883\n",
      "Epoch 1583/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0435 - val_accuracy: 0.9874\n",
      "Epoch 1584/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.0429 - val_accuracy: 0.9879\n",
      "Epoch 1585/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0483 - val_accuracy: 0.9874\n",
      "Epoch 1586/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0446 - val_accuracy: 0.9883\n",
      "Epoch 1587/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0451 - val_accuracy: 0.9879\n",
      "Epoch 1588/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0436 - val_accuracy: 0.9883\n",
      "Epoch 1589/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0460 - val_accuracy: 0.9893\n",
      "Epoch 1590/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.0437 - val_accuracy: 0.9888\n",
      "Epoch 1591/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.0453 - val_accuracy: 0.9869\n",
      "Epoch 1592/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.0448 - val_accuracy: 0.9883\n",
      "Epoch 1593/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 0.0463 - val_accuracy: 0.9879\n",
      "Epoch 1594/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0473 - val_accuracy: 0.9883\n",
      "Epoch 1595/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 0.9910 - val_loss: 0.0419 - val_accuracy: 0.9874\n",
      "Epoch 1596/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.0477 - val_accuracy: 0.9883\n",
      "Epoch 1597/3500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.0426 - val_accuracy: 0.9888\n",
      "Epoch 1598/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0426 - val_accuracy: 0.9893\n",
      "Epoch 1599/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0519 - val_accuracy: 0.9869\n",
      "Epoch 1600/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0505 - val_accuracy: 0.9874\n",
      "Epoch 1601/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.0443 - val_accuracy: 0.9888\n",
      "Epoch 1602/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0421 - val_accuracy: 0.9888\n",
      "Epoch 1603/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9931 - val_loss: 0.0493 - val_accuracy: 0.9860\n",
      "Epoch 1604/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.9926 - val_loss: 0.0483 - val_accuracy: 0.9869\n",
      "Epoch 1605/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.0446 - val_accuracy: 0.9865\n",
      "Epoch 1606/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0535 - val_accuracy: 0.9869\n",
      "Epoch 1607/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.0629 - val_accuracy: 0.9837\n",
      "Epoch 1608/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0523 - val_accuracy: 0.9869\n",
      "Epoch 1609/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 0.0452 - val_accuracy: 0.9888\n",
      "Epoch 1610/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.0509 - val_accuracy: 0.9860\n",
      "Epoch 1611/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.0447 - val_accuracy: 0.9888\n",
      "Epoch 1612/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0489 - val_accuracy: 0.9888\n",
      "Epoch 1613/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0489 - val_accuracy: 0.9883\n",
      "Epoch 1614/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.0460 - val_accuracy: 0.9879\n",
      "Epoch 1615/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 0.0650 - val_accuracy: 0.9828\n",
      "Epoch 1616/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.0627 - val_accuracy: 0.9832\n",
      "Epoch 1617/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9913 - val_loss: 0.0605 - val_accuracy: 0.9846\n",
      "Epoch 1618/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.0479 - val_accuracy: 0.9874\n",
      "Epoch 1619/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 0.0464 - val_accuracy: 0.9879\n",
      "Epoch 1620/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0429 - val_accuracy: 0.9883\n",
      "Epoch 1621/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.0509 - val_accuracy: 0.9869\n",
      "Epoch 1622/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0500 - val_accuracy: 0.9869\n",
      "Epoch 1623/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0502 - val_accuracy: 0.9869\n",
      "Epoch 1624/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.0455 - val_accuracy: 0.9883\n",
      "Epoch 1625/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0498 - val_accuracy: 0.9869\n",
      "Epoch 1626/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0511 - val_accuracy: 0.9874\n",
      "Epoch 1627/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.0440 - val_accuracy: 0.9888\n",
      "Epoch 1628/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0484 - val_accuracy: 0.9883\n",
      "Epoch 1629/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0533 - val_accuracy: 0.9855\n",
      "Epoch 1630/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9929 - val_loss: 0.0564 - val_accuracy: 0.9832\n",
      "Epoch 1631/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.0593 - val_accuracy: 0.9860\n",
      "Epoch 1632/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 0.0480 - val_accuracy: 0.9883\n",
      "Epoch 1633/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.0452 - val_accuracy: 0.9869\n",
      "Epoch 1634/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.0447 - val_accuracy: 0.9888\n",
      "Epoch 1635/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0446 - val_accuracy: 0.9883\n",
      "Epoch 1636/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.0486 - val_accuracy: 0.9869\n",
      "Epoch 1637/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 0.9938 - val_loss: 0.0598 - val_accuracy: 0.9823\n",
      "Epoch 1638/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.0732 - val_accuracy: 0.9809\n",
      "Epoch 1639/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.0514 - val_accuracy: 0.9841\n",
      "Epoch 1640/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0526 - val_accuracy: 0.9874\n",
      "Epoch 1641/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0474 - val_accuracy: 0.9874\n",
      "Epoch 1642/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0446 - val_accuracy: 0.9897\n",
      "Epoch 1643/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.0437 - val_accuracy: 0.9883\n",
      "Epoch 1644/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.0485 - val_accuracy: 0.9865\n",
      "Epoch 1645/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.0430 - val_accuracy: 0.9883\n",
      "Epoch 1646/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.0454 - val_accuracy: 0.9869\n",
      "Epoch 1647/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 0.0451 - val_accuracy: 0.9888\n",
      "Epoch 1648/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0507 - val_accuracy: 0.9874\n",
      "Epoch 1649/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.0544 - val_accuracy: 0.9837\n",
      "Epoch 1650/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0517 - val_accuracy: 0.9869\n",
      "Epoch 1651/3500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.0439 - val_accuracy: 0.9893\n",
      "Epoch 1652/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0533 - val_accuracy: 0.9879\n",
      "Epoch 1653/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0403 - val_accuracy: 0.9888\n",
      "Epoch 1654/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.0481 - val_accuracy: 0.9883\n",
      "Epoch 1655/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0421 - val_accuracy: 0.9893\n",
      "Epoch 1656/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0458 - val_accuracy: 0.9897\n",
      "Epoch 1657/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.0477 - val_accuracy: 0.9888\n",
      "Epoch 1658/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 0.0464 - val_accuracy: 0.9874\n",
      "Epoch 1659/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0427 - val_accuracy: 0.9888\n",
      "Epoch 1660/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9922 - val_loss: 0.0465 - val_accuracy: 0.9888\n",
      "Epoch 1661/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0447 - val_accuracy: 0.9883\n",
      "Epoch 1662/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.0437 - val_accuracy: 0.9893\n",
      "Epoch 1663/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.0432 - val_accuracy: 0.9879\n",
      "Epoch 1664/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.0440 - val_accuracy: 0.9893\n",
      "Epoch 1665/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0474 - val_accuracy: 0.9888\n",
      "Epoch 1666/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0506 - val_accuracy: 0.9865\n",
      "Epoch 1667/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.0549 - val_accuracy: 0.9855\n",
      "Epoch 1668/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.0451 - val_accuracy: 0.9893\n",
      "Epoch 1669/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0436 - val_accuracy: 0.9888\n",
      "Epoch 1670/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0551 - val_accuracy: 0.9855\n",
      "Epoch 1671/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0497 - val_accuracy: 0.9883\n",
      "Epoch 1672/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0546 - val_accuracy: 0.9865\n",
      "Epoch 1673/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9943 - val_loss: 0.0436 - val_accuracy: 0.9888\n",
      "Epoch 1674/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.0488 - val_accuracy: 0.9879\n",
      "Epoch 1675/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0480 - val_accuracy: 0.9879\n",
      "Epoch 1676/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.0520 - val_accuracy: 0.9855\n",
      "Epoch 1677/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0516 - val_accuracy: 0.9860\n",
      "Epoch 1678/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.0562 - val_accuracy: 0.9841\n",
      "Epoch 1679/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0527 - val_accuracy: 0.9865\n",
      "Epoch 1680/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0188 - accuracy: 0.9931 - val_loss: 0.0477 - val_accuracy: 0.9883\n",
      "Epoch 1681/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.0446 - val_accuracy: 0.9893\n",
      "Epoch 1682/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0438 - val_accuracy: 0.9897\n",
      "Epoch 1683/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.0448 - val_accuracy: 0.9883\n",
      "Epoch 1684/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.0461 - val_accuracy: 0.9865\n",
      "Epoch 1685/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.0467 - val_accuracy: 0.9888\n",
      "Epoch 1686/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.0423 - val_accuracy: 0.9879\n",
      "Epoch 1687/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0543 - val_accuracy: 0.9860\n",
      "Epoch 1688/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 0.0490 - val_accuracy: 0.9888\n",
      "Epoch 1689/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0510 - val_accuracy: 0.9855\n",
      "Epoch 1690/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0490 - val_accuracy: 0.9879\n",
      "Epoch 1691/3500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0508 - val_accuracy: 0.9869\n",
      "Epoch 1692/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.0532 - val_accuracy: 0.9855\n",
      "Epoch 1693/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0527 - val_accuracy: 0.9874\n",
      "Epoch 1694/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0561 - val_accuracy: 0.9846\n",
      "Epoch 1695/3500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.0454 - val_accuracy: 0.9874\n",
      "Epoch 1696/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.0474 - val_accuracy: 0.9879\n",
      "Epoch 1697/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0194 - accuracy: 0.9929 - val_loss: 0.0586 - val_accuracy: 0.9851\n",
      "Epoch 1698/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0602 - val_accuracy: 0.9828\n",
      "Epoch 1699/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0524 - val_accuracy: 0.9855\n",
      "Epoch 1700/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 0.0480 - val_accuracy: 0.9883\n",
      "Epoch 1701/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0452 - val_accuracy: 0.9888\n",
      "Epoch 1702/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.0441 - val_accuracy: 0.9879\n",
      "Epoch 1703/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0529 - val_accuracy: 0.9860\n",
      "Epoch 1704/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0307 - accuracy: 0.9892 - val_loss: 0.0517 - val_accuracy: 0.9860\n",
      "Epoch 1705/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9922 - val_loss: 0.0444 - val_accuracy: 0.9879\n",
      "Epoch 1706/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9931 - val_loss: 0.0479 - val_accuracy: 0.9879\n",
      "Epoch 1707/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0587 - val_accuracy: 0.9851\n",
      "Epoch 1708/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.0469 - val_accuracy: 0.9893\n",
      "Epoch 1709/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 0.0434 - val_accuracy: 0.9883\n",
      "Epoch 1710/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0200 - accuracy: 0.9926 - val_loss: 0.0454 - val_accuracy: 0.9883\n",
      "Epoch 1711/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0465 - val_accuracy: 0.9893\n",
      "Epoch 1712/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 1713/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0435 - val_accuracy: 0.9879\n",
      "Epoch 1714/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.0452 - val_accuracy: 0.9888\n",
      "Epoch 1715/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.0486 - val_accuracy: 0.9869\n",
      "Epoch 1716/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0484 - val_accuracy: 0.9869\n",
      "Epoch 1717/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.0470 - val_accuracy: 0.9874\n",
      "Epoch 1718/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.0487 - val_accuracy: 0.9888\n",
      "Epoch 1719/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0453 - val_accuracy: 0.9893\n",
      "Epoch 1720/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.0471 - val_accuracy: 0.9893\n",
      "Epoch 1721/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 0.0468 - val_accuracy: 0.9874\n",
      "Epoch 1722/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0507 - val_accuracy: 0.9874\n",
      "Epoch 1723/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.0530 - val_accuracy: 0.9865\n",
      "Epoch 1724/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0581 - val_accuracy: 0.9846\n",
      "Epoch 1725/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0480 - val_accuracy: 0.9874\n",
      "Epoch 1726/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 0.0442 - val_accuracy: 0.9888\n",
      "Epoch 1727/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.0501 - val_accuracy: 0.9874\n",
      "Epoch 1728/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.0580 - val_accuracy: 0.9855\n",
      "Epoch 1729/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9929 - val_loss: 0.0510 - val_accuracy: 0.9869\n",
      "Epoch 1730/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.0466 - val_accuracy: 0.9888\n",
      "Epoch 1731/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0470 - val_accuracy: 0.9888\n",
      "Epoch 1732/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.0503 - val_accuracy: 0.9874\n",
      "Epoch 1733/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0474 - val_accuracy: 0.9883\n",
      "Epoch 1734/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 1735/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.0446 - val_accuracy: 0.9883\n",
      "Epoch 1736/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.0466 - val_accuracy: 0.9883\n",
      "Epoch 1737/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.0463 - val_accuracy: 0.9888\n",
      "Epoch 1738/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0441 - val_accuracy: 0.9888\n",
      "Epoch 1739/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.0455 - val_accuracy: 0.9879\n",
      "Epoch 1740/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9943 - val_loss: 0.0449 - val_accuracy: 0.9879\n",
      "Epoch 1741/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0452 - val_accuracy: 0.9883\n",
      "Epoch 1742/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0446 - val_accuracy: 0.9888\n",
      "Epoch 1743/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.0526 - val_accuracy: 0.9869\n",
      "Epoch 1744/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0498 - val_accuracy: 0.9879\n",
      "Epoch 1745/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0495 - val_accuracy: 0.9883\n",
      "Epoch 1746/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0564 - val_accuracy: 0.9855\n",
      "Epoch 1747/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0508 - val_accuracy: 0.9879\n",
      "Epoch 1748/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.0479 - val_accuracy: 0.9883\n",
      "Epoch 1749/3500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 1750/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0463 - val_accuracy: 0.9888\n",
      "Epoch 1751/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0450 - val_accuracy: 0.9869\n",
      "Epoch 1752/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9920 - val_loss: 0.0453 - val_accuracy: 0.9874\n",
      "Epoch 1753/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0561 - val_accuracy: 0.9860\n",
      "Epoch 1754/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 0.0530 - val_accuracy: 0.9851\n",
      "Epoch 1755/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.0513 - val_accuracy: 0.9865\n",
      "Epoch 1756/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0462 - val_accuracy: 0.9879\n",
      "Epoch 1757/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0500 - val_accuracy: 0.9879\n",
      "Epoch 1758/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.0554 - val_accuracy: 0.9841\n",
      "Epoch 1759/3500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0223 - accuracy: 0.9924 - val_loss: 0.0557 - val_accuracy: 0.9855\n",
      "Epoch 1760/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9926 - val_loss: 0.0471 - val_accuracy: 0.9883\n",
      "Epoch 1761/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.0459 - val_accuracy: 0.9893\n",
      "Epoch 1762/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0554 - val_accuracy: 0.9837\n",
      "Epoch 1763/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 0.0666 - val_accuracy: 0.9818\n",
      "Epoch 1764/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.0571 - val_accuracy: 0.9841\n",
      "Epoch 1765/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0489 - val_accuracy: 0.9888\n",
      "Epoch 1766/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 1767/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.0460 - val_accuracy: 0.9879\n",
      "Epoch 1768/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.0447 - val_accuracy: 0.9883\n",
      "Epoch 1769/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 1770/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0457 - val_accuracy: 0.9879\n",
      "Epoch 1771/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0481 - val_accuracy: 0.9865\n",
      "Epoch 1772/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0221 - accuracy: 0.9943 - val_loss: 0.0465 - val_accuracy: 0.9879\n",
      "Epoch 1773/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.0485 - val_accuracy: 0.9869\n",
      "Epoch 1774/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 1775/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0447 - val_accuracy: 0.9893\n",
      "Epoch 1776/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.0446 - val_accuracy: 0.9893\n",
      "Epoch 1777/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0458 - val_accuracy: 0.9879\n",
      "Epoch 1778/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 0.0433 - val_accuracy: 0.9883\n",
      "Epoch 1779/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0441 - val_accuracy: 0.9874\n",
      "Epoch 1780/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.0510 - val_accuracy: 0.9865\n",
      "Epoch 1781/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0518 - val_accuracy: 0.9865\n",
      "Epoch 1782/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0537 - val_accuracy: 0.9869\n",
      "Epoch 1783/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0430 - val_accuracy: 0.9888\n",
      "Epoch 1784/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.0510 - val_accuracy: 0.9874\n",
      "Epoch 1785/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0468 - val_accuracy: 0.9879\n",
      "Epoch 1786/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0532 - val_accuracy: 0.9860\n",
      "Epoch 1787/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0458 - val_accuracy: 0.9883\n",
      "Epoch 1788/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0487 - val_accuracy: 0.9869\n",
      "Epoch 1789/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.0501 - val_accuracy: 0.9869\n",
      "Epoch 1790/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0521 - val_accuracy: 0.9865\n",
      "Epoch 1791/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0569 - val_accuracy: 0.9851\n",
      "Epoch 1792/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0628 - val_accuracy: 0.9832\n",
      "Epoch 1793/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0555 - val_accuracy: 0.9865\n",
      "Epoch 1794/3500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0472 - val_accuracy: 0.9883\n",
      "Epoch 1795/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0466 - val_accuracy: 0.9869\n",
      "Epoch 1796/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.0469 - val_accuracy: 0.9869\n",
      "Epoch 1797/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0468 - val_accuracy: 0.9888\n",
      "Epoch 1798/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9929 - val_loss: 0.0461 - val_accuracy: 0.9883\n",
      "Epoch 1799/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.0555 - val_accuracy: 0.9846\n",
      "Epoch 1800/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0738 - val_accuracy: 0.9809\n",
      "Epoch 1801/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.0621 - val_accuracy: 0.9837\n",
      "Epoch 1802/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0493 - val_accuracy: 0.9879\n",
      "Epoch 1803/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.0457 - val_accuracy: 0.9865\n",
      "Epoch 1804/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0434 - val_accuracy: 0.9883\n",
      "Epoch 1805/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 1806/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0441 - val_accuracy: 0.9888\n",
      "Epoch 1807/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0516 - val_accuracy: 0.9883\n",
      "Epoch 1808/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.0544 - val_accuracy: 0.9865\n",
      "Epoch 1809/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0489 - val_accuracy: 0.9883\n",
      "Epoch 1810/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0444 - val_accuracy: 0.9879\n",
      "Epoch 1811/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9931 - val_loss: 0.0490 - val_accuracy: 0.9869\n",
      "Epoch 1812/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
      "Epoch 1813/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.0644 - val_accuracy: 0.9828\n",
      "Epoch 1814/3500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0223 - accuracy: 0.9917 - val_loss: 0.0590 - val_accuracy: 0.9851\n",
      "Epoch 1815/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0521 - val_accuracy: 0.9869\n",
      "Epoch 1816/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0463 - val_accuracy: 0.9893\n",
      "Epoch 1817/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0271 - accuracy: 0.9910 - val_loss: 0.0435 - val_accuracy: 0.9879\n",
      "Epoch 1818/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0472 - val_accuracy: 0.9869\n",
      "Epoch 1819/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.0439 - val_accuracy: 0.9879\n",
      "Epoch 1820/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0469 - val_accuracy: 0.9893\n",
      "Epoch 1821/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0422 - val_accuracy: 0.9893\n",
      "Epoch 1822/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.0438 - val_accuracy: 0.9883\n",
      "Epoch 1823/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.0476 - val_accuracy: 0.9888\n",
      "Epoch 1824/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0211 - accuracy: 0.9940 - val_loss: 0.0445 - val_accuracy: 0.9879\n",
      "Epoch 1825/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 0.0503 - val_accuracy: 0.9869\n",
      "Epoch 1826/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0524 - val_accuracy: 0.9860\n",
      "Epoch 1827/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0557 - val_accuracy: 0.9860\n",
      "Epoch 1828/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0448 - val_accuracy: 0.9888\n",
      "Epoch 1829/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0548 - val_accuracy: 0.9869\n",
      "Epoch 1830/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.0502 - val_accuracy: 0.9883\n",
      "Epoch 1831/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0468 - val_accuracy: 0.9888\n",
      "Epoch 1832/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.0447 - val_accuracy: 0.9879\n",
      "Epoch 1833/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.0431 - val_accuracy: 0.9888\n",
      "Epoch 1834/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0241 - accuracy: 0.9910 - val_loss: 0.0477 - val_accuracy: 0.9883\n",
      "Epoch 1835/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.0594 - val_accuracy: 0.9860\n",
      "Epoch 1836/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0497 - val_accuracy: 0.9888\n",
      "Epoch 1837/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.0487 - val_accuracy: 0.9888\n",
      "Epoch 1838/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.0472 - val_accuracy: 0.9883\n",
      "Epoch 1839/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0565 - val_accuracy: 0.9860\n",
      "Epoch 1840/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.0555 - val_accuracy: 0.9879\n",
      "Epoch 1841/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0533 - val_accuracy: 0.9869\n",
      "Epoch 1842/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.0482 - val_accuracy: 0.9879\n",
      "Epoch 1843/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.0448 - val_accuracy: 0.9893\n",
      "Epoch 1844/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 0.0483 - val_accuracy: 0.9874\n",
      "Epoch 1845/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0495 - val_accuracy: 0.9893\n",
      "Epoch 1846/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0461 - val_accuracy: 0.9888\n",
      "Epoch 1847/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0538 - val_accuracy: 0.9869\n",
      "Epoch 1848/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.0504 - val_accuracy: 0.9883\n",
      "Epoch 1849/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0531 - val_accuracy: 0.9874\n",
      "Epoch 1850/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0619 - val_accuracy: 0.9823\n",
      "Epoch 1851/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9938 - val_loss: 0.0611 - val_accuracy: 0.9846\n",
      "Epoch 1852/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0525 - val_accuracy: 0.9874\n",
      "Epoch 1853/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 0.0455 - val_accuracy: 0.9883\n",
      "Epoch 1854/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 0.0474 - val_accuracy: 0.9893\n",
      "Epoch 1855/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.0466 - val_accuracy: 0.9883\n",
      "Epoch 1856/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0458 - val_accuracy: 0.9883\n",
      "Epoch 1857/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.0469 - val_accuracy: 0.9869\n",
      "Epoch 1858/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0633 - val_accuracy: 0.9851\n",
      "Epoch 1859/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0544 - val_accuracy: 0.9851\n",
      "Epoch 1860/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0566 - val_accuracy: 0.9860\n",
      "Epoch 1861/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0665 - val_accuracy: 0.9823\n",
      "Epoch 1862/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9903 - val_loss: 0.0851 - val_accuracy: 0.9772\n",
      "Epoch 1863/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 0.0733 - val_accuracy: 0.9800\n",
      "Epoch 1864/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 0.0609 - val_accuracy: 0.9832\n",
      "Epoch 1865/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.0536 - val_accuracy: 0.9851\n",
      "Epoch 1866/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.0546 - val_accuracy: 0.9874\n",
      "Epoch 1867/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0504 - val_accuracy: 0.9883\n",
      "Epoch 1868/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.0489 - val_accuracy: 0.9888\n",
      "Epoch 1869/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0215 - accuracy: 0.9943 - val_loss: 0.0465 - val_accuracy: 0.9879\n",
      "Epoch 1870/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0433 - val_accuracy: 0.9902\n",
      "Epoch 1871/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0469 - val_accuracy: 0.9888\n",
      "Epoch 1872/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.0578 - val_accuracy: 0.9851\n",
      "Epoch 1873/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9931 - val_loss: 0.0564 - val_accuracy: 0.9855\n",
      "Epoch 1874/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.9959 - val_loss: 0.0462 - val_accuracy: 0.9888\n",
      "Epoch 1875/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.0436 - val_accuracy: 0.9883\n",
      "Epoch 1876/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.0475 - val_accuracy: 0.9874\n",
      "Epoch 1877/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0454 - val_accuracy: 0.9879\n",
      "Epoch 1878/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0418 - val_accuracy: 0.9893\n",
      "Epoch 1879/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
      "Epoch 1880/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 1881/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.0663 - val_accuracy: 0.9828\n",
      "Epoch 1882/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0524 - val_accuracy: 0.9860\n",
      "Epoch 1883/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.0482 - val_accuracy: 0.9865\n",
      "Epoch 1884/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0452 - val_accuracy: 0.9874\n",
      "Epoch 1885/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.0446 - val_accuracy: 0.9888\n",
      "Epoch 1886/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0494 - val_accuracy: 0.9865\n",
      "Epoch 1887/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.0445 - val_accuracy: 0.9883\n",
      "Epoch 1888/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.0494 - val_accuracy: 0.9893\n",
      "Epoch 1889/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.0453 - val_accuracy: 0.9888\n",
      "Epoch 1890/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0571 - val_accuracy: 0.9860\n",
      "Epoch 1891/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0489 - val_accuracy: 0.9879\n",
      "Epoch 1892/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0526 - val_accuracy: 0.9879\n",
      "Epoch 1893/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.0437 - val_accuracy: 0.9879\n",
      "Epoch 1894/3500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0476 - val_accuracy: 0.9879\n",
      "Epoch 1895/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 0.0447 - val_accuracy: 0.9883\n",
      "Epoch 1896/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 1897/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0518 - val_accuracy: 0.9869\n",
      "Epoch 1898/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0553 - val_accuracy: 0.9855\n",
      "Epoch 1899/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.0500 - val_accuracy: 0.9879\n",
      "Epoch 1900/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0475 - val_accuracy: 0.9883\n",
      "Epoch 1901/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0442 - val_accuracy: 0.9879\n",
      "Epoch 1902/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.0515 - val_accuracy: 0.9865\n",
      "Epoch 1903/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.0468 - val_accuracy: 0.9879\n",
      "Epoch 1904/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.0456 - val_accuracy: 0.9879\n",
      "Epoch 1905/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.0475 - val_accuracy: 0.9893\n",
      "Epoch 1906/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.0479 - val_accuracy: 0.9883\n",
      "Epoch 1907/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0438 - val_accuracy: 0.9883\n",
      "Epoch 1908/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9943 - val_loss: 0.0453 - val_accuracy: 0.9869\n",
      "Epoch 1909/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.0506 - val_accuracy: 0.9865\n",
      "Epoch 1910/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0469 - val_accuracy: 0.9893\n",
      "Epoch 1911/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.0447 - val_accuracy: 0.9893\n",
      "Epoch 1912/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.0457 - val_accuracy: 0.9888\n",
      "Epoch 1913/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0472 - val_accuracy: 0.9874\n",
      "Epoch 1914/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0560 - val_accuracy: 0.9855\n",
      "Epoch 1915/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0516 - val_accuracy: 0.9860\n",
      "Epoch 1916/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0518 - val_accuracy: 0.9869\n",
      "Epoch 1917/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0441 - val_accuracy: 0.9888\n",
      "Epoch 1918/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9931 - val_loss: 0.0485 - val_accuracy: 0.9874\n",
      "Epoch 1919/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.0482 - val_accuracy: 0.9883\n",
      "Epoch 1920/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0476 - val_accuracy: 0.9888\n",
      "Epoch 1921/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0445 - val_accuracy: 0.9888\n",
      "Epoch 1922/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.0540 - val_accuracy: 0.9865\n",
      "Epoch 1923/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0453 - val_accuracy: 0.9883\n",
      "Epoch 1924/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 1925/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0598 - val_accuracy: 0.9846\n",
      "Epoch 1926/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0605 - val_accuracy: 0.9846\n",
      "Epoch 1927/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0460 - val_accuracy: 0.9879\n",
      "Epoch 1928/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 0.0462 - val_accuracy: 0.9869\n",
      "Epoch 1929/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0452 - val_accuracy: 0.9897\n",
      "Epoch 1930/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0476 - val_accuracy: 0.9888\n",
      "Epoch 1931/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0550 - val_accuracy: 0.9865\n",
      "Epoch 1932/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0471 - val_accuracy: 0.9888\n",
      "Epoch 1933/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0550 - val_accuracy: 0.9869\n",
      "Epoch 1934/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.0555 - val_accuracy: 0.9860\n",
      "Epoch 1935/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.0475 - val_accuracy: 0.9869\n",
      "Epoch 1936/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0536 - val_accuracy: 0.9865\n",
      "Epoch 1937/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0542 - val_accuracy: 0.9865\n",
      "Epoch 1938/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.0624 - val_accuracy: 0.9832\n",
      "Epoch 1939/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0619 - val_accuracy: 0.9851\n",
      "Epoch 1940/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.0446 - val_accuracy: 0.9883\n",
      "Epoch 1941/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0582 - val_accuracy: 0.9860\n",
      "Epoch 1942/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 0.0682 - val_accuracy: 0.9823\n",
      "Epoch 1943/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9924 - val_loss: 0.0613 - val_accuracy: 0.9841\n",
      "Epoch 1944/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0628 - val_accuracy: 0.9832\n",
      "Epoch 1945/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 0.0552 - val_accuracy: 0.9865\n",
      "Epoch 1946/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0445 - val_accuracy: 0.9897\n",
      "Epoch 1947/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0456 - val_accuracy: 0.9888\n",
      "Epoch 1948/3500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.0465 - val_accuracy: 0.9869\n",
      "Epoch 1949/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0444 - val_accuracy: 0.9879\n",
      "Epoch 1950/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.0458 - val_accuracy: 0.9888\n",
      "Epoch 1951/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.0467 - val_accuracy: 0.9893\n",
      "Epoch 1952/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.0492 - val_accuracy: 0.9888\n",
      "Epoch 1953/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0591 - val_accuracy: 0.9846\n",
      "Epoch 1954/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.0533 - val_accuracy: 0.9874\n",
      "Epoch 1955/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.0454 - val_accuracy: 0.9883\n",
      "Epoch 1956/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.0486 - val_accuracy: 0.9869\n",
      "Epoch 1957/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 0.0502 - val_accuracy: 0.9869\n",
      "Epoch 1958/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
      "Epoch 1959/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.0518 - val_accuracy: 0.9869\n",
      "Epoch 1960/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0491 - val_accuracy: 0.9879\n",
      "Epoch 1961/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 0.0494 - val_accuracy: 0.9888\n",
      "Epoch 1962/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 0.0476 - val_accuracy: 0.9888\n",
      "Epoch 1963/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0446 - val_accuracy: 0.9879\n",
      "Epoch 1964/3500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0521 - val_accuracy: 0.9865\n",
      "Epoch 1965/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0426 - val_accuracy: 0.9893\n",
      "Epoch 1966/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0571 - val_accuracy: 0.9855\n",
      "Epoch 1967/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0689 - val_accuracy: 0.9818\n",
      "Epoch 1968/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.0462 - val_accuracy: 0.9888\n",
      "Epoch 1969/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.0504 - val_accuracy: 0.9869\n",
      "Epoch 1970/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0551 - val_accuracy: 0.9869\n",
      "Epoch 1971/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.0530 - val_accuracy: 0.9860\n",
      "Epoch 1972/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0510 - val_accuracy: 0.9869\n",
      "Epoch 1973/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0494 - val_accuracy: 0.9883\n",
      "Epoch 1974/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0521 - val_accuracy: 0.9869\n",
      "Epoch 1975/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0581 - val_accuracy: 0.9855\n",
      "Epoch 1976/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0746 - val_accuracy: 0.9818\n",
      "Epoch 1977/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.0547 - val_accuracy: 0.9865\n",
      "Epoch 1978/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.0447 - val_accuracy: 0.9883\n",
      "Epoch 1979/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0493 - val_accuracy: 0.9869\n",
      "Epoch 1980/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.0465 - val_accuracy: 0.9869\n",
      "Epoch 1981/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9917 - val_loss: 0.0489 - val_accuracy: 0.9883\n",
      "Epoch 1982/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 1983/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0466 - val_accuracy: 0.9902\n",
      "Epoch 1984/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.0506 - val_accuracy: 0.9879\n",
      "Epoch 1985/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0500 - val_accuracy: 0.9874\n",
      "Epoch 1986/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.0574 - val_accuracy: 0.9851\n",
      "Epoch 1987/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.0498 - val_accuracy: 0.9883\n",
      "Epoch 1988/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0240 - accuracy: 0.9910 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
      "Epoch 1989/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 0.0449 - val_accuracy: 0.9883\n",
      "Epoch 1990/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0532 - val_accuracy: 0.9865\n",
      "Epoch 1991/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0499 - val_accuracy: 0.9888\n",
      "Epoch 1992/3500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0524 - val_accuracy: 0.9879\n",
      "Epoch 1993/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0546 - val_accuracy: 0.9860\n",
      "Epoch 1994/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
      "Epoch 1995/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9943 - val_loss: 0.0468 - val_accuracy: 0.9879\n",
      "Epoch 1996/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0542 - val_accuracy: 0.9869\n",
      "Epoch 1997/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.0462 - val_accuracy: 0.9879\n",
      "Epoch 1998/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0514 - val_accuracy: 0.9888\n",
      "Epoch 1999/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.0488 - val_accuracy: 0.9888\n",
      "Epoch 2000/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0464 - val_accuracy: 0.9883\n",
      "Epoch 2001/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0461 - val_accuracy: 0.9902\n",
      "Epoch 2002/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.0448 - val_accuracy: 0.9883\n",
      "Epoch 2003/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.0466 - val_accuracy: 0.9874\n",
      "Epoch 2004/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.0488 - val_accuracy: 0.9888\n",
      "Epoch 2005/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0428 - val_accuracy: 0.9883\n",
      "Epoch 2006/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.0477 - val_accuracy: 0.9874\n",
      "Epoch 2007/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.0505 - val_accuracy: 0.9893\n",
      "Epoch 2008/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0473 - val_accuracy: 0.9883\n",
      "Epoch 2009/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.0473 - val_accuracy: 0.9883\n",
      "Epoch 2010/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.0504 - val_accuracy: 0.9879\n",
      "Epoch 2011/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.0586 - val_accuracy: 0.9855\n",
      "Epoch 2012/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.0456 - val_accuracy: 0.9865\n",
      "Epoch 2013/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.0503 - val_accuracy: 0.9883\n",
      "Epoch 2014/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.0486 - val_accuracy: 0.9888\n",
      "Epoch 2015/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 0.0572 - val_accuracy: 0.9860\n",
      "Epoch 2016/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.0514 - val_accuracy: 0.9879\n",
      "Epoch 2017/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0448 - val_accuracy: 0.9883\n",
      "Epoch 2018/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0452 - val_accuracy: 0.9883\n",
      "Epoch 2019/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.0510 - val_accuracy: 0.9865\n",
      "Epoch 2020/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.0469 - val_accuracy: 0.9879\n",
      "Epoch 2021/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0469 - val_accuracy: 0.9893\n",
      "Epoch 2022/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.0488 - val_accuracy: 0.9869\n",
      "Epoch 2023/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.0499 - val_accuracy: 0.9883\n",
      "Epoch 2024/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0596 - val_accuracy: 0.9832\n",
      "Epoch 2025/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 0.0523 - val_accuracy: 0.9869\n",
      "Epoch 2026/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0513 - val_accuracy: 0.9869\n",
      "Epoch 2027/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 0.0504 - val_accuracy: 0.9879\n",
      "Epoch 2028/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.0447 - val_accuracy: 0.9883\n",
      "Epoch 2029/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0427 - val_accuracy: 0.9888\n",
      "Epoch 2030/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 0.0470 - val_accuracy: 0.9879\n",
      "Epoch 2031/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.0483 - val_accuracy: 0.9869\n",
      "Epoch 2032/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.0458 - val_accuracy: 0.9874\n",
      "Epoch 2033/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9917 - val_loss: 0.0443 - val_accuracy: 0.9874\n",
      "Epoch 2034/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.0490 - val_accuracy: 0.9888\n",
      "Epoch 2035/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0526 - val_accuracy: 0.9869\n",
      "Epoch 2036/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0452 - val_accuracy: 0.9883\n",
      "Epoch 2037/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0616 - val_accuracy: 0.9837\n",
      "Epoch 2038/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0231 - accuracy: 0.9917 - val_loss: 0.0744 - val_accuracy: 0.9818\n",
      "Epoch 2039/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0507 - val_accuracy: 0.9883\n",
      "Epoch 2040/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 2041/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.0457 - val_accuracy: 0.9879\n",
      "Epoch 2042/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.0519 - val_accuracy: 0.9874\n",
      "Epoch 2043/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0443 - val_accuracy: 0.9883\n",
      "Epoch 2044/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 0.0541 - val_accuracy: 0.9869\n",
      "Epoch 2045/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0457 - val_accuracy: 0.9874\n",
      "Epoch 2046/3500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0476 - val_accuracy: 0.9888\n",
      "Epoch 2047/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0461 - val_accuracy: 0.9879\n",
      "Epoch 2048/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0500 - val_accuracy: 0.9888\n",
      "Epoch 2049/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0606 - val_accuracy: 0.9837\n",
      "Epoch 2050/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.0515 - val_accuracy: 0.9879\n",
      "Epoch 2051/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9952 - val_loss: 0.0431 - val_accuracy: 0.9888\n",
      "Epoch 2052/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0602 - val_accuracy: 0.9855\n",
      "Epoch 2053/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.0476 - val_accuracy: 0.9879\n",
      "Epoch 2054/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.0556 - val_accuracy: 0.9860\n",
      "Epoch 2055/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0545 - val_accuracy: 0.9860\n",
      "Epoch 2056/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.0516 - val_accuracy: 0.9879\n",
      "Epoch 2057/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0488 - val_accuracy: 0.9874\n",
      "Epoch 2058/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0525 - val_accuracy: 0.9865\n",
      "Epoch 2059/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.0473 - val_accuracy: 0.9888\n",
      "Epoch 2060/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0544 - val_accuracy: 0.9860\n",
      "Epoch 2061/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0523 - val_accuracy: 0.9879\n",
      "Epoch 2062/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 0.0426 - val_accuracy: 0.9897\n",
      "Epoch 2063/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.0483 - val_accuracy: 0.9893\n",
      "Epoch 2064/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.0465 - val_accuracy: 0.9888\n",
      "Epoch 2065/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0509 - val_accuracy: 0.9879\n",
      "Epoch 2066/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0490 - val_accuracy: 0.9883\n",
      "Epoch 2067/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 2068/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0467 - val_accuracy: 0.9888\n",
      "Epoch 2069/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0489 - val_accuracy: 0.9883\n",
      "Epoch 2070/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.0665 - val_accuracy: 0.9841\n",
      "Epoch 2071/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0535 - val_accuracy: 0.9865\n",
      "Epoch 2072/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.0463 - val_accuracy: 0.9897\n",
      "Epoch 2073/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 0.0459 - val_accuracy: 0.9893\n",
      "Epoch 2074/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.0557 - val_accuracy: 0.9865\n",
      "Epoch 2075/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.0653 - val_accuracy: 0.9809\n",
      "Epoch 2076/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.0563 - val_accuracy: 0.9860\n",
      "Epoch 2077/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.0455 - val_accuracy: 0.9869\n",
      "Epoch 2078/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.0519 - val_accuracy: 0.9888\n",
      "Epoch 2079/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.0507 - val_accuracy: 0.9883\n",
      "Epoch 2080/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0485 - val_accuracy: 0.9888\n",
      "Epoch 2081/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0470 - val_accuracy: 0.9879\n",
      "Epoch 2082/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 0.0463 - val_accuracy: 0.9888\n",
      "Epoch 2083/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0477 - val_accuracy: 0.9883\n",
      "Epoch 2084/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.0497 - val_accuracy: 0.9888\n",
      "Epoch 2085/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0507 - val_accuracy: 0.9883\n",
      "Epoch 2086/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.0523 - val_accuracy: 0.9874\n",
      "Epoch 2087/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0464 - val_accuracy: 0.9883\n",
      "Epoch 2088/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0466 - val_accuracy: 0.9879\n",
      "Epoch 2089/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 0.0484 - val_accuracy: 0.9883\n",
      "Epoch 2090/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0527 - val_accuracy: 0.9865\n",
      "Epoch 2091/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.0605 - val_accuracy: 0.9846\n",
      "Epoch 2092/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.0572 - val_accuracy: 0.9851\n",
      "Epoch 2093/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.0538 - val_accuracy: 0.9860\n",
      "Epoch 2094/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0231 - accuracy: 0.9917 - val_loss: 0.0442 - val_accuracy: 0.9879\n",
      "Epoch 2095/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
      "Epoch 2096/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0515 - val_accuracy: 0.9883\n",
      "Epoch 2097/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0528 - val_accuracy: 0.9874\n",
      "Epoch 2098/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 0.0476 - val_accuracy: 0.9883\n",
      "Epoch 2099/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0486 - val_accuracy: 0.9888\n",
      "Epoch 2100/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0463 - val_accuracy: 0.9888\n",
      "Epoch 2101/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.0461 - val_accuracy: 0.9893\n",
      "Epoch 2102/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9936 - val_loss: 0.0635 - val_accuracy: 0.9837\n",
      "Epoch 2103/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.0615 - val_accuracy: 0.9841\n",
      "Epoch 2104/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0492 - val_accuracy: 0.9883\n",
      "Epoch 2105/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9901 - val_loss: 0.0499 - val_accuracy: 0.9879\n",
      "Epoch 2106/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.0452 - val_accuracy: 0.9897\n",
      "Epoch 2107/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.0526 - val_accuracy: 0.9869\n",
      "Epoch 2108/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 0.0569 - val_accuracy: 0.9860\n",
      "Epoch 2109/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0474 - val_accuracy: 0.9879\n",
      "Epoch 2110/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0436 - val_accuracy: 0.9902\n",
      "Epoch 2111/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0616 - val_accuracy: 0.9851\n",
      "Epoch 2112/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.0514 - val_accuracy: 0.9874\n",
      "Epoch 2113/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0175 - accuracy: 0.9936 - val_loss: 0.0459 - val_accuracy: 0.9893\n",
      "Epoch 2114/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.0485 - val_accuracy: 0.9879\n",
      "Epoch 2115/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 0.0459 - val_accuracy: 0.9874\n",
      "Epoch 2116/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
      "Epoch 2117/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0690 - val_accuracy: 0.9828\n",
      "Epoch 2118/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0522 - val_accuracy: 0.9879\n",
      "Epoch 2119/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 2120/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 0.9922 - val_loss: 0.0611 - val_accuracy: 0.9828\n",
      "Epoch 2121/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 0.0622 - val_accuracy: 0.9841\n",
      "Epoch 2122/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.0550 - val_accuracy: 0.9869\n",
      "Epoch 2123/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.0519 - val_accuracy: 0.9883\n",
      "Epoch 2124/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.0487 - val_accuracy: 0.9879\n",
      "Epoch 2125/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0588 - val_accuracy: 0.9855\n",
      "Epoch 2126/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0492 - val_accuracy: 0.9883\n",
      "Epoch 2127/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.0494 - val_accuracy: 0.9874\n",
      "Epoch 2128/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0480 - val_accuracy: 0.9869\n",
      "Epoch 2129/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.0523 - val_accuracy: 0.9874\n",
      "Epoch 2130/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.0455 - val_accuracy: 0.9897\n",
      "Epoch 2131/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0226 - accuracy: 0.9913 - val_loss: 0.0494 - val_accuracy: 0.9888\n",
      "Epoch 2132/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.0588 - val_accuracy: 0.9846\n",
      "Epoch 2133/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 0.0716 - val_accuracy: 0.9814\n",
      "Epoch 2134/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.0589 - val_accuracy: 0.9841\n",
      "Epoch 2135/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0499 - val_accuracy: 0.9888\n",
      "Epoch 2136/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.0476 - val_accuracy: 0.9869\n",
      "Epoch 2137/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 2138/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.0511 - val_accuracy: 0.9879\n",
      "Epoch 2139/3500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0193 - accuracy: 0.9929 - val_loss: 0.0508 - val_accuracy: 0.9874\n",
      "Epoch 2140/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0642 - val_accuracy: 0.9832\n",
      "Epoch 2141/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.0582 - val_accuracy: 0.9855\n",
      "Epoch 2142/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.0608 - val_accuracy: 0.9846\n",
      "Epoch 2143/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.0518 - val_accuracy: 0.9888\n",
      "Epoch 2144/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.0456 - val_accuracy: 0.9888\n",
      "Epoch 2145/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0487 - val_accuracy: 0.9855\n",
      "Epoch 2146/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0586 - val_accuracy: 0.9860\n",
      "Epoch 2147/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.0559 - val_accuracy: 0.9851\n",
      "Epoch 2148/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.0614 - val_accuracy: 0.9818\n",
      "Epoch 2149/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.0493 - val_accuracy: 0.9874\n",
      "Epoch 2150/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.0474 - val_accuracy: 0.9879\n",
      "Epoch 2151/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 0.0472 - val_accuracy: 0.9869\n",
      "Epoch 2152/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.0520 - val_accuracy: 0.9888\n",
      "Epoch 2153/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9924 - val_loss: 0.0546 - val_accuracy: 0.9869\n",
      "Epoch 2154/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9926 - val_loss: 0.0559 - val_accuracy: 0.9855\n",
      "Epoch 2155/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0527 - val_accuracy: 0.9869\n",
      "Epoch 2156/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.0542 - val_accuracy: 0.9860\n",
      "Epoch 2157/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9956 - val_loss: 0.0486 - val_accuracy: 0.9874\n",
      "Epoch 2158/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 0.0447 - val_accuracy: 0.9893\n",
      "Epoch 2159/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.0475 - val_accuracy: 0.9874\n",
      "Epoch 2160/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0266 - accuracy: 0.9908 - val_loss: 0.0443 - val_accuracy: 0.9888\n",
      "Epoch 2161/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.0647 - val_accuracy: 0.9828\n",
      "Epoch 2162/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0526 - val_accuracy: 0.9855\n",
      "Epoch 2163/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0461 - val_accuracy: 0.9888\n",
      "Epoch 2164/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9940 - val_loss: 0.0563 - val_accuracy: 0.9865\n",
      "Epoch 2165/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.0613 - val_accuracy: 0.9851\n",
      "Epoch 2166/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.0492 - val_accuracy: 0.9888\n",
      "Epoch 2167/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.0451 - val_accuracy: 0.9869\n",
      "Epoch 2168/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0531 - val_accuracy: 0.9865\n",
      "Epoch 2169/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0472 - val_accuracy: 0.9888\n",
      "Epoch 2170/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0470 - val_accuracy: 0.9869\n",
      "Epoch 2171/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.0509 - val_accuracy: 0.9869\n",
      "Epoch 2172/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0585 - val_accuracy: 0.9860\n",
      "Epoch 2173/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0559 - val_accuracy: 0.9851\n",
      "Epoch 2174/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.0510 - val_accuracy: 0.9860\n",
      "Epoch 2175/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.0452 - val_accuracy: 0.9869\n",
      "Epoch 2176/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0512 - val_accuracy: 0.9879\n",
      "Epoch 2177/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.0488 - val_accuracy: 0.9883\n",
      "Epoch 2178/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0465 - val_accuracy: 0.9869\n",
      "Epoch 2179/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0466 - val_accuracy: 0.9869\n",
      "Epoch 2180/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.0486 - val_accuracy: 0.9865\n",
      "Epoch 2181/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0614 - val_accuracy: 0.9841\n",
      "Epoch 2182/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0659 - val_accuracy: 0.9841\n",
      "Epoch 2183/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0484 - val_accuracy: 0.9883\n",
      "Epoch 2184/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9938 - val_loss: 0.0449 - val_accuracy: 0.9865\n",
      "Epoch 2185/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0503 - val_accuracy: 0.9883\n",
      "Epoch 2186/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.0513 - val_accuracy: 0.9869\n",
      "Epoch 2187/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0506 - val_accuracy: 0.9888\n",
      "Epoch 2188/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0461 - val_accuracy: 0.9874\n",
      "Epoch 2189/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0530 - val_accuracy: 0.9860\n",
      "Epoch 2190/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0604 - val_accuracy: 0.9846\n",
      "Epoch 2191/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0177 - accuracy: 0.9952 - val_loss: 0.0479 - val_accuracy: 0.9874\n",
      "Epoch 2192/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 0.0476 - val_accuracy: 0.9883\n",
      "Epoch 2193/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0472 - val_accuracy: 0.9874\n",
      "Epoch 2194/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
      "Epoch 2195/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.0449 - val_accuracy: 0.9879\n",
      "Epoch 2196/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0531 - val_accuracy: 0.9888\n",
      "Epoch 2197/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0569 - val_accuracy: 0.9846\n",
      "Epoch 2198/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0556 - val_accuracy: 0.9855\n",
      "Epoch 2199/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0479 - val_accuracy: 0.9879\n",
      "Epoch 2200/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0502 - val_accuracy: 0.9860\n",
      "Epoch 2201/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0491 - val_accuracy: 0.9888\n",
      "Epoch 2202/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0563 - val_accuracy: 0.9855\n",
      "Epoch 2203/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0503 - val_accuracy: 0.9874\n",
      "Epoch 2204/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.0513 - val_accuracy: 0.9879\n",
      "Epoch 2205/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0472 - val_accuracy: 0.9869\n",
      "Epoch 2206/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.0565 - val_accuracy: 0.9860\n",
      "Epoch 2207/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0599 - val_accuracy: 0.9837\n",
      "Epoch 2208/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0551 - val_accuracy: 0.9855\n",
      "Epoch 2209/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0466 - val_accuracy: 0.9869\n",
      "Epoch 2210/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0493 - val_accuracy: 0.9874\n",
      "Epoch 2211/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0534 - val_accuracy: 0.9865\n",
      "Epoch 2212/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0592 - val_accuracy: 0.9855\n",
      "Epoch 2213/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0578 - val_accuracy: 0.9841\n",
      "Epoch 2214/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.0585 - val_accuracy: 0.9846\n",
      "Epoch 2215/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0491 - val_accuracy: 0.9865\n",
      "Epoch 2216/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0510 - val_accuracy: 0.9879\n",
      "Epoch 2217/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.0560 - val_accuracy: 0.9855\n",
      "Epoch 2218/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0547 - val_accuracy: 0.9860\n",
      "Epoch 2219/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0509 - val_accuracy: 0.9869\n",
      "Epoch 2220/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.0496 - val_accuracy: 0.9865\n",
      "Epoch 2221/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0677 - val_accuracy: 0.9828\n",
      "Epoch 2222/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.0497 - val_accuracy: 0.9888\n",
      "Epoch 2223/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.0479 - val_accuracy: 0.9893\n",
      "Epoch 2224/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.0637 - val_accuracy: 0.9837\n",
      "Epoch 2225/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0671 - val_accuracy: 0.9841\n",
      "Epoch 2226/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0501 - val_accuracy: 0.9879\n",
      "Epoch 2227/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.0459 - val_accuracy: 0.9879\n",
      "Epoch 2228/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0468 - val_accuracy: 0.9869\n",
      "Epoch 2229/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0507 - val_accuracy: 0.9874\n",
      "Epoch 2230/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.0477 - val_accuracy: 0.9865\n",
      "Epoch 2231/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0507 - val_accuracy: 0.9879\n",
      "Epoch 2232/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0443 - val_accuracy: 0.9893\n",
      "Epoch 2233/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0559 - val_accuracy: 0.9860\n",
      "Epoch 2234/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0543 - val_accuracy: 0.9851\n",
      "Epoch 2235/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0498 - val_accuracy: 0.9879\n",
      "Epoch 2236/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0487 - val_accuracy: 0.9865\n",
      "Epoch 2237/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0533 - val_accuracy: 0.9883\n",
      "Epoch 2238/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.0547 - val_accuracy: 0.9851\n",
      "Epoch 2239/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0518 - val_accuracy: 0.9860\n",
      "Epoch 2240/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.0595 - val_accuracy: 0.9851\n",
      "Epoch 2241/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0605 - val_accuracy: 0.9879\n",
      "Epoch 2242/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.0480 - val_accuracy: 0.9874\n",
      "Epoch 2243/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0555 - val_accuracy: 0.9869\n",
      "Epoch 2244/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0492 - val_accuracy: 0.9883\n",
      "Epoch 2245/3500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0498 - val_accuracy: 0.9883\n",
      "Epoch 2246/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.0476 - val_accuracy: 0.9874\n",
      "Epoch 2247/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0548 - val_accuracy: 0.9865\n",
      "Epoch 2248/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0506 - val_accuracy: 0.9869\n",
      "Epoch 2249/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.0460 - val_accuracy: 0.9874\n",
      "Epoch 2250/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
      "Epoch 2251/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0503 - val_accuracy: 0.9869\n",
      "Epoch 2252/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0548 - val_accuracy: 0.9846\n",
      "Epoch 2253/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0623 - val_accuracy: 0.9841\n",
      "Epoch 2254/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0739 - val_accuracy: 0.9823\n",
      "Epoch 2255/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.0472 - val_accuracy: 0.9869\n",
      "Epoch 2256/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.0532 - val_accuracy: 0.9879\n",
      "Epoch 2257/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0495 - val_accuracy: 0.9879\n",
      "Epoch 2258/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0660 - val_accuracy: 0.9837\n",
      "Epoch 2259/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0639 - val_accuracy: 0.9846\n",
      "Epoch 2260/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9924 - val_loss: 0.0588 - val_accuracy: 0.9855\n",
      "Epoch 2261/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
      "Epoch 2262/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0537 - val_accuracy: 0.9879\n",
      "Epoch 2263/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0543 - val_accuracy: 0.9865\n",
      "Epoch 2264/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0571 - val_accuracy: 0.9851\n",
      "Epoch 2265/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0507 - val_accuracy: 0.9865\n",
      "Epoch 2266/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.0503 - val_accuracy: 0.9883\n",
      "Epoch 2267/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0472 - val_accuracy: 0.9865\n",
      "Epoch 2268/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.0492 - val_accuracy: 0.9893\n",
      "Epoch 2269/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9952 - val_loss: 0.0502 - val_accuracy: 0.9888\n",
      "Epoch 2270/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0524 - val_accuracy: 0.9865\n",
      "Epoch 2271/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0538 - val_accuracy: 0.9879\n",
      "Epoch 2272/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0474 - val_accuracy: 0.9869\n",
      "Epoch 2273/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.0496 - val_accuracy: 0.9874\n",
      "Epoch 2274/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.0503 - val_accuracy: 0.9869\n",
      "Epoch 2275/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0569 - val_accuracy: 0.9860\n",
      "Epoch 2276/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0529 - val_accuracy: 0.9883\n",
      "Epoch 2277/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.0461 - val_accuracy: 0.9874\n",
      "Epoch 2278/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.0509 - val_accuracy: 0.9865\n",
      "Epoch 2279/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0563 - val_accuracy: 0.9865\n",
      "Epoch 2280/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 0.9913 - val_loss: 0.0481 - val_accuracy: 0.9865\n",
      "Epoch 2281/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0815 - val_accuracy: 0.9809\n",
      "Epoch 2282/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0228 - accuracy: 0.9917 - val_loss: 0.0673 - val_accuracy: 0.9828\n",
      "Epoch 2283/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.0520 - val_accuracy: 0.9860\n",
      "Epoch 2284/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0541 - val_accuracy: 0.9874\n",
      "Epoch 2285/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0683 - val_accuracy: 0.9818\n",
      "Epoch 2286/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.0621 - val_accuracy: 0.9851\n",
      "Epoch 2287/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0538 - val_accuracy: 0.9865\n",
      "Epoch 2288/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0173 - accuracy: 0.9936 - val_loss: 0.0448 - val_accuracy: 0.9883\n",
      "Epoch 2289/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0619 - val_accuracy: 0.9846\n",
      "Epoch 2290/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0461 - val_accuracy: 0.9879\n",
      "Epoch 2291/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0490 - val_accuracy: 0.9874\n",
      "Epoch 2292/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0495 - val_accuracy: 0.9869\n",
      "Epoch 2293/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.0482 - val_accuracy: 0.9879\n",
      "Epoch 2294/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0568 - val_accuracy: 0.9860\n",
      "Epoch 2295/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0579 - val_accuracy: 0.9855\n",
      "Epoch 2296/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0543 - val_accuracy: 0.9879\n",
      "Epoch 2297/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 0.0477 - val_accuracy: 0.9874\n",
      "Epoch 2298/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.0483 - val_accuracy: 0.9874\n",
      "Epoch 2299/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 0.9952 - val_loss: 0.0499 - val_accuracy: 0.9883\n",
      "Epoch 2300/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.0604 - val_accuracy: 0.9855\n",
      "Epoch 2301/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0580 - val_accuracy: 0.9855\n",
      "Epoch 2302/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0452 - val_accuracy: 0.9874\n",
      "Epoch 2303/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9952 - val_loss: 0.0465 - val_accuracy: 0.9893\n",
      "Epoch 2304/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0594 - val_accuracy: 0.9851\n",
      "Epoch 2305/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.0511 - val_accuracy: 0.9874\n",
      "Epoch 2306/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.0559 - val_accuracy: 0.9860\n",
      "Epoch 2307/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 0.0536 - val_accuracy: 0.9855\n",
      "Epoch 2308/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0585 - val_accuracy: 0.9851\n",
      "Epoch 2309/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0490 - val_accuracy: 0.9879\n",
      "Epoch 2310/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0559 - val_accuracy: 0.9865\n",
      "Epoch 2311/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0589 - val_accuracy: 0.9860\n",
      "Epoch 2312/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0611 - val_accuracy: 0.9841\n",
      "Epoch 2313/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0525 - val_accuracy: 0.9874\n",
      "Epoch 2314/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.0546 - val_accuracy: 0.9874\n",
      "Epoch 2315/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0649 - val_accuracy: 0.9841\n",
      "Epoch 2316/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0514 - val_accuracy: 0.9869\n",
      "Epoch 2317/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0557 - val_accuracy: 0.9860\n",
      "Epoch 2318/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.0524 - val_accuracy: 0.9874\n",
      "Epoch 2319/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.0612 - val_accuracy: 0.9851\n",
      "Epoch 2320/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.0961 - val_accuracy: 0.9776\n",
      "Epoch 2321/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9892 - val_loss: 0.1082 - val_accuracy: 0.9702\n",
      "Epoch 2322/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0351 - accuracy: 0.9874 - val_loss: 0.0672 - val_accuracy: 0.9846\n",
      "Epoch 2323/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0468 - val_accuracy: 0.9893\n",
      "Epoch 2324/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0502 - val_accuracy: 0.9855\n",
      "Epoch 2325/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.0533 - val_accuracy: 0.9888\n",
      "Epoch 2326/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.0712 - val_accuracy: 0.9823\n",
      "Epoch 2327/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.0624 - val_accuracy: 0.9837\n",
      "Epoch 2328/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.0545 - val_accuracy: 0.9865\n",
      "Epoch 2329/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.0509 - val_accuracy: 0.9874\n",
      "Epoch 2330/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0479 - val_accuracy: 0.9874\n",
      "Epoch 2331/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0697 - val_accuracy: 0.9841\n",
      "Epoch 2332/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 0.0555 - val_accuracy: 0.9855\n",
      "Epoch 2333/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 0.0520 - val_accuracy: 0.9879\n",
      "Epoch 2334/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0588 - val_accuracy: 0.9855\n",
      "Epoch 2335/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.0505 - val_accuracy: 0.9883\n",
      "Epoch 2336/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0624 - val_accuracy: 0.9841\n",
      "Epoch 2337/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.0593 - val_accuracy: 0.9846\n",
      "Epoch 2338/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.0499 - val_accuracy: 0.9879\n",
      "Epoch 2339/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.0539 - val_accuracy: 0.9869\n",
      "Epoch 2340/3500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.0487 - val_accuracy: 0.9865\n",
      "Epoch 2341/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.0556 - val_accuracy: 0.9879\n",
      "Epoch 2342/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0669 - val_accuracy: 0.9846\n",
      "Epoch 2343/3500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0587 - val_accuracy: 0.9846\n",
      "Epoch 2344/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.0499 - val_accuracy: 0.9883\n",
      "Epoch 2345/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0538 - val_accuracy: 0.9865\n",
      "Epoch 2346/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0519 - val_accuracy: 0.9874\n",
      "Epoch 2347/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0499 - val_accuracy: 0.9869\n",
      "Epoch 2348/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0497 - val_accuracy: 0.9869\n",
      "Epoch 2349/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0531 - val_accuracy: 0.9874\n",
      "Epoch 2350/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.0516 - val_accuracy: 0.9865\n",
      "Epoch 2351/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0509 - val_accuracy: 0.9879\n",
      "Epoch 2352/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0504 - val_accuracy: 0.9865\n",
      "Epoch 2353/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0558 - val_accuracy: 0.9860\n",
      "Epoch 2354/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.0519 - val_accuracy: 0.9865\n",
      "Epoch 2355/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.0676 - val_accuracy: 0.9841\n",
      "Epoch 2356/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0528 - val_accuracy: 0.9855\n",
      "Epoch 2357/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9956 - val_loss: 0.0482 - val_accuracy: 0.9860\n",
      "Epoch 2358/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0593 - val_accuracy: 0.9865\n",
      "Epoch 2359/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.0575 - val_accuracy: 0.9860\n",
      "Epoch 2360/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.0608 - val_accuracy: 0.9846\n",
      "Epoch 2361/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0168 - accuracy: 0.9938 - val_loss: 0.0547 - val_accuracy: 0.9865\n",
      "Epoch 2362/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.0484 - val_accuracy: 0.9883\n",
      "Epoch 2363/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.0566 - val_accuracy: 0.9869\n",
      "Epoch 2364/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.0529 - val_accuracy: 0.9874\n",
      "Epoch 2365/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 0.0498 - val_accuracy: 0.9869\n",
      "Epoch 2366/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0584 - val_accuracy: 0.9865\n",
      "Epoch 2367/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0519 - val_accuracy: 0.9865\n",
      "Epoch 2368/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0622 - val_accuracy: 0.9851\n",
      "Epoch 2369/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0560 - val_accuracy: 0.9879\n",
      "Epoch 2370/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.0592 - val_accuracy: 0.9846\n",
      "Epoch 2371/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.0545 - val_accuracy: 0.9879\n",
      "Epoch 2372/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9952 - val_loss: 0.0470 - val_accuracy: 0.9879\n",
      "Epoch 2373/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0553 - val_accuracy: 0.9860\n",
      "Epoch 2374/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0652 - val_accuracy: 0.9841\n",
      "Epoch 2375/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0497 - val_accuracy: 0.9879\n",
      "Epoch 2376/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0527 - val_accuracy: 0.9855\n",
      "Epoch 2377/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0502 - val_accuracy: 0.9879\n",
      "Epoch 2378/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0510 - val_accuracy: 0.9879\n",
      "Epoch 2379/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0654 - val_accuracy: 0.9837\n",
      "Epoch 2380/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9938 - val_loss: 0.0512 - val_accuracy: 0.9869\n",
      "Epoch 2381/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0464 - val_accuracy: 0.9888\n",
      "Epoch 2382/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9959 - val_loss: 0.0528 - val_accuracy: 0.9883\n",
      "Epoch 2383/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0520 - val_accuracy: 0.9855\n",
      "Epoch 2384/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0507 - val_accuracy: 0.9879\n",
      "Epoch 2385/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0692 - val_accuracy: 0.9841\n",
      "Epoch 2386/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0543 - val_accuracy: 0.9869\n",
      "Epoch 2387/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0500 - val_accuracy: 0.9869\n",
      "Epoch 2388/3500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.0563 - val_accuracy: 0.9865\n",
      "Epoch 2389/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0546 - val_accuracy: 0.9874\n",
      "Epoch 2390/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.0488 - val_accuracy: 0.9874\n",
      "Epoch 2391/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.0679 - val_accuracy: 0.9832\n",
      "Epoch 2392/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0658 - val_accuracy: 0.9841\n",
      "Epoch 2393/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.0523 - val_accuracy: 0.9869\n",
      "Epoch 2394/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9952 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
      "Epoch 2395/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 0.0524 - val_accuracy: 0.9860\n",
      "Epoch 2396/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0215 - accuracy: 0.9924 - val_loss: 0.0595 - val_accuracy: 0.9851\n",
      "Epoch 2397/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0540 - val_accuracy: 0.9865\n",
      "Epoch 2398/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0630 - val_accuracy: 0.9846\n",
      "Epoch 2399/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.0535 - val_accuracy: 0.9869\n",
      "Epoch 2400/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0524 - val_accuracy: 0.9860\n",
      "Epoch 2401/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0497 - val_accuracy: 0.9883\n",
      "Epoch 2402/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0536 - val_accuracy: 0.9874\n",
      "Epoch 2403/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.0568 - val_accuracy: 0.9855\n",
      "Epoch 2404/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0580 - val_accuracy: 0.9874\n",
      "Epoch 2405/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0489 - val_accuracy: 0.9879\n",
      "Epoch 2406/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0571 - val_accuracy: 0.9869\n",
      "Epoch 2407/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
      "Epoch 2408/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.0489 - val_accuracy: 0.9879\n",
      "Epoch 2409/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.0592 - val_accuracy: 0.9846\n",
      "Epoch 2410/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0510 - val_accuracy: 0.9869\n",
      "Epoch 2411/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0715 - val_accuracy: 0.9823\n",
      "Epoch 2412/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.0635 - val_accuracy: 0.9841\n",
      "Epoch 2413/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0520 - val_accuracy: 0.9874\n",
      "Epoch 2414/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.0507 - val_accuracy: 0.9883\n",
      "Epoch 2415/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 0.0568 - val_accuracy: 0.9874\n",
      "Epoch 2416/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.0564 - val_accuracy: 0.9860\n",
      "Epoch 2417/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0548 - val_accuracy: 0.9865\n",
      "Epoch 2418/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0497 - val_accuracy: 0.9869\n",
      "Epoch 2419/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.0605 - val_accuracy: 0.9851\n",
      "Epoch 2420/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.0503 - val_accuracy: 0.9888\n",
      "Epoch 2421/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.0589 - val_accuracy: 0.9855\n",
      "Epoch 2422/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0500 - val_accuracy: 0.9869\n",
      "Epoch 2423/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 0.0639 - val_accuracy: 0.9851\n",
      "Epoch 2424/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0676 - val_accuracy: 0.9841\n",
      "Epoch 2425/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0747 - val_accuracy: 0.9837\n",
      "Epoch 2426/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0556 - val_accuracy: 0.9855\n",
      "Epoch 2427/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0499 - val_accuracy: 0.9888\n",
      "Epoch 2428/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0574 - val_accuracy: 0.9865\n",
      "Epoch 2429/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0576 - val_accuracy: 0.9869\n",
      "Epoch 2430/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 0.0507 - val_accuracy: 0.9869\n",
      "Epoch 2431/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0538 - val_accuracy: 0.9860\n",
      "Epoch 2432/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.0516 - val_accuracy: 0.9874\n",
      "Epoch 2433/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0584 - val_accuracy: 0.9860\n",
      "Epoch 2434/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 0.0557 - val_accuracy: 0.9869\n",
      "Epoch 2435/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0504 - val_accuracy: 0.9879\n",
      "Epoch 2436/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.0522 - val_accuracy: 0.9860\n",
      "Epoch 2437/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.0506 - val_accuracy: 0.9865\n",
      "Epoch 2438/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.0600 - val_accuracy: 0.9846\n",
      "Epoch 2439/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0620 - val_accuracy: 0.9846\n",
      "Epoch 2440/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.0538 - val_accuracy: 0.9865\n",
      "Epoch 2441/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0505 - val_accuracy: 0.9865\n",
      "Epoch 2442/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.0511 - val_accuracy: 0.9869\n",
      "Epoch 2443/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0188 - accuracy: 0.9929 - val_loss: 0.0601 - val_accuracy: 0.9851\n",
      "Epoch 2444/3500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 0.0476 - val_accuracy: 0.9874\n",
      "Epoch 2445/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0539 - val_accuracy: 0.9874\n",
      "Epoch 2446/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0691 - val_accuracy: 0.9846\n",
      "Epoch 2447/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0658 - val_accuracy: 0.9846\n",
      "Epoch 2448/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.0517 - val_accuracy: 0.9869\n",
      "Epoch 2449/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 0.0494 - val_accuracy: 0.9874\n",
      "Epoch 2450/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0170 - accuracy: 0.9936 - val_loss: 0.0698 - val_accuracy: 0.9855\n",
      "Epoch 2451/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0643 - val_accuracy: 0.9837\n",
      "Epoch 2452/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0562 - val_accuracy: 0.9869\n",
      "Epoch 2453/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 0.0544 - val_accuracy: 0.9869\n",
      "Epoch 2454/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0147 - accuracy: 0.9966 - val_loss: 0.0540 - val_accuracy: 0.9869\n",
      "Epoch 2455/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0609 - val_accuracy: 0.9855\n",
      "Epoch 2456/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.0553 - val_accuracy: 0.9869\n",
      "Epoch 2457/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.0508 - val_accuracy: 0.9879\n",
      "Epoch 2458/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: 0.0508 - val_accuracy: 0.9874\n",
      "Epoch 2459/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.0539 - val_accuracy: 0.9883\n",
      "Epoch 2460/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.0529 - val_accuracy: 0.9855\n",
      "Epoch 2461/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0531 - val_accuracy: 0.9883\n",
      "Epoch 2462/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.0533 - val_accuracy: 0.9879\n",
      "Epoch 2463/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.0532 - val_accuracy: 0.9869\n",
      "Epoch 2464/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0551 - val_accuracy: 0.9865\n",
      "Epoch 2465/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 0.0580 - val_accuracy: 0.9846\n",
      "Epoch 2466/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 0.0551 - val_accuracy: 0.9874\n",
      "Epoch 2467/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.0521 - val_accuracy: 0.9874\n",
      "Epoch 2468/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0526 - val_accuracy: 0.9874\n",
      "Epoch 2469/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0539 - val_accuracy: 0.9860\n",
      "Epoch 2470/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0502 - val_accuracy: 0.9874\n",
      "Epoch 2471/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0533 - val_accuracy: 0.9869\n",
      "Epoch 2472/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0514 - val_accuracy: 0.9888\n",
      "Epoch 2473/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0590 - val_accuracy: 0.9841\n",
      "Epoch 2474/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0572 - val_accuracy: 0.9860\n",
      "Epoch 2475/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0558 - val_accuracy: 0.9865\n",
      "Epoch 2476/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0505 - val_accuracy: 0.9883\n",
      "Epoch 2477/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9956 - val_loss: 0.0516 - val_accuracy: 0.9865\n",
      "Epoch 2478/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0526 - val_accuracy: 0.9869\n",
      "Epoch 2479/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.0495 - val_accuracy: 0.9865\n",
      "Epoch 2480/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 0.0581 - val_accuracy: 0.9860\n",
      "Epoch 2481/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0635 - val_accuracy: 0.9841\n",
      "Epoch 2482/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0567 - val_accuracy: 0.9860\n",
      "Epoch 2483/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.0536 - val_accuracy: 0.9846\n",
      "Epoch 2484/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0518 - val_accuracy: 0.9874\n",
      "Epoch 2485/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.0547 - val_accuracy: 0.9879\n",
      "Epoch 2486/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0570 - val_accuracy: 0.9869\n",
      "Epoch 2487/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.0499 - val_accuracy: 0.9888\n",
      "Epoch 2488/3500\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0598 - val_accuracy: 0.9846\n",
      "Epoch 2489/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.0554 - val_accuracy: 0.9860\n",
      "Epoch 2490/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0638 - val_accuracy: 0.9846\n",
      "Epoch 2491/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0587 - val_accuracy: 0.9846\n",
      "Epoch 2492/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0538 - val_accuracy: 0.9883\n",
      "Epoch 2493/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 0.0516 - val_accuracy: 0.9874\n",
      "Epoch 2494/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0540 - val_accuracy: 0.9869\n",
      "Epoch 2495/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.0510 - val_accuracy: 0.9879\n",
      "Epoch 2496/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0596 - val_accuracy: 0.9832\n",
      "Epoch 2497/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.0575 - val_accuracy: 0.9855\n",
      "Epoch 2498/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0512 - val_accuracy: 0.9883\n",
      "Epoch 2499/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0603 - val_accuracy: 0.9841\n",
      "Epoch 2500/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0632 - val_accuracy: 0.9855\n",
      "Epoch 2501/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0665 - val_accuracy: 0.9841\n",
      "Epoch 2502/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0535 - val_accuracy: 0.9865\n",
      "Epoch 2503/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0588 - val_accuracy: 0.9855\n",
      "Epoch 2504/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.0509 - val_accuracy: 0.9874\n",
      "Epoch 2505/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0512 - val_accuracy: 0.9888\n",
      "Epoch 2506/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0551 - val_accuracy: 0.9879\n",
      "Epoch 2507/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0715 - val_accuracy: 0.9841\n",
      "Epoch 2508/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0479 - val_accuracy: 0.9879\n",
      "Epoch 2509/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0555 - val_accuracy: 0.9851\n",
      "Epoch 2510/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.0551 - val_accuracy: 0.9855\n",
      "Epoch 2511/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.0524 - val_accuracy: 0.9865\n",
      "Epoch 2512/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0643 - val_accuracy: 0.9851\n",
      "Epoch 2513/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0544 - val_accuracy: 0.9860\n",
      "Epoch 2514/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.0472 - val_accuracy: 0.9879\n",
      "Epoch 2515/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0535 - val_accuracy: 0.9869\n",
      "Epoch 2516/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0563 - val_accuracy: 0.9860\n",
      "Epoch 2517/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0671 - val_accuracy: 0.9841\n",
      "Epoch 2518/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.0539 - val_accuracy: 0.9874\n",
      "Epoch 2519/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0134 - accuracy: 0.9966 - val_loss: 0.0522 - val_accuracy: 0.9869\n",
      "Epoch 2520/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0632 - val_accuracy: 0.9846\n",
      "Epoch 2521/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0154 - accuracy: 0.9943 - val_loss: 0.0728 - val_accuracy: 0.9841\n",
      "Epoch 2522/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0491 - val_accuracy: 0.9879\n",
      "Epoch 2523/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0590 - val_accuracy: 0.9869\n",
      "Epoch 2524/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.0624 - val_accuracy: 0.9837\n",
      "Epoch 2525/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0612 - val_accuracy: 0.9851\n",
      "Epoch 2526/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0498 - val_accuracy: 0.9855\n",
      "Epoch 2527/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0542 - val_accuracy: 0.9869\n",
      "Epoch 2528/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0139 - accuracy: 0.9966 - val_loss: 0.0546 - val_accuracy: 0.9879\n",
      "Epoch 2529/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.0480 - val_accuracy: 0.9888\n",
      "Epoch 2530/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.0590 - val_accuracy: 0.9860\n",
      "Epoch 2531/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0574 - val_accuracy: 0.9865\n",
      "Epoch 2532/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0564 - val_accuracy: 0.9860\n",
      "Epoch 2533/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.0522 - val_accuracy: 0.9888\n",
      "Epoch 2534/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0542 - val_accuracy: 0.9869\n",
      "Epoch 2535/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.0529 - val_accuracy: 0.9874\n",
      "Epoch 2536/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0543 - val_accuracy: 0.9874\n",
      "Epoch 2537/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0502 - val_accuracy: 0.9879\n",
      "Epoch 2538/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0493 - val_accuracy: 0.9874\n",
      "Epoch 2539/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.0559 - val_accuracy: 0.9860\n",
      "Epoch 2540/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0510 - val_accuracy: 0.9879\n",
      "Epoch 2541/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0520 - val_accuracy: 0.9879\n",
      "Epoch 2542/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0585 - val_accuracy: 0.9851\n",
      "Epoch 2543/3500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.0568 - val_accuracy: 0.9874\n",
      "Epoch 2544/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.0534 - val_accuracy: 0.9874\n",
      "Epoch 2545/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0608 - val_accuracy: 0.9841\n",
      "Epoch 2546/3500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0616 - val_accuracy: 0.9855\n",
      "Epoch 2547/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9931 - val_loss: 0.0508 - val_accuracy: 0.9874\n",
      "Epoch 2548/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0590 - val_accuracy: 0.9855\n",
      "Epoch 2549/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0572 - val_accuracy: 0.9860\n",
      "Epoch 2550/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.0638 - val_accuracy: 0.9837\n",
      "Epoch 2551/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0584 - val_accuracy: 0.9865\n",
      "Epoch 2552/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.0555 - val_accuracy: 0.9874\n",
      "Epoch 2553/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.0508 - val_accuracy: 0.9879\n",
      "Epoch 2554/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0583 - val_accuracy: 0.9860\n",
      "Epoch 2555/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0539 - val_accuracy: 0.9874\n",
      "Epoch 2556/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.0662 - val_accuracy: 0.9846\n",
      "Epoch 2557/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0536 - val_accuracy: 0.9874\n",
      "Epoch 2558/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.0490 - val_accuracy: 0.9888\n",
      "Epoch 2559/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0545 - val_accuracy: 0.9860\n",
      "Epoch 2560/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.0491 - val_accuracy: 0.9874\n",
      "Epoch 2561/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0618 - val_accuracy: 0.9855\n",
      "Epoch 2562/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0524 - val_accuracy: 0.9869\n",
      "Epoch 2563/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9968 - val_loss: 0.0655 - val_accuracy: 0.9851\n",
      "Epoch 2564/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0751 - val_accuracy: 0.9809\n",
      "Epoch 2565/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9926 - val_loss: 0.0625 - val_accuracy: 0.9851\n",
      "Epoch 2566/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.0577 - val_accuracy: 0.9860\n",
      "Epoch 2567/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9931 - val_loss: 0.0628 - val_accuracy: 0.9841\n",
      "Epoch 2568/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0162 - accuracy: 0.9943 - val_loss: 0.0518 - val_accuracy: 0.9883\n",
      "Epoch 2569/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.0533 - val_accuracy: 0.9869\n",
      "Epoch 2570/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0543 - val_accuracy: 0.9879\n",
      "Epoch 2571/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.0548 - val_accuracy: 0.9874\n",
      "Epoch 2572/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0572 - val_accuracy: 0.9865\n",
      "Epoch 2573/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
      "Epoch 2574/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 0.0615 - val_accuracy: 0.9874\n",
      "Epoch 2575/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.0536 - val_accuracy: 0.9874\n",
      "Epoch 2576/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.0552 - val_accuracy: 0.9869\n",
      "Epoch 2577/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0550 - val_accuracy: 0.9874\n",
      "Epoch 2578/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.0640 - val_accuracy: 0.9851\n",
      "Epoch 2579/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0759 - val_accuracy: 0.9841\n",
      "Epoch 2580/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0502 - val_accuracy: 0.9883\n",
      "Epoch 2581/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0526 - val_accuracy: 0.9879\n",
      "Epoch 2582/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0575 - val_accuracy: 0.9869\n",
      "Epoch 2583/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0570 - val_accuracy: 0.9865\n",
      "Epoch 2584/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0546 - val_accuracy: 0.9865\n",
      "Epoch 2585/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.0598 - val_accuracy: 0.9846\n",
      "Epoch 2586/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.0732 - val_accuracy: 0.9832\n",
      "Epoch 2587/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.0519 - val_accuracy: 0.9874\n",
      "Epoch 2588/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0592 - val_accuracy: 0.9855\n",
      "Epoch 2589/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9938 - val_loss: 0.0560 - val_accuracy: 0.9860\n",
      "Epoch 2590/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0508 - val_accuracy: 0.9869\n",
      "Epoch 2591/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0684 - val_accuracy: 0.9837\n",
      "Epoch 2592/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0627 - val_accuracy: 0.9846\n",
      "Epoch 2593/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.0564 - val_accuracy: 0.9865\n",
      "Epoch 2594/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0518 - val_accuracy: 0.9879\n",
      "Epoch 2595/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.0595 - val_accuracy: 0.9874\n",
      "Epoch 2596/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.0669 - val_accuracy: 0.9841\n",
      "Epoch 2597/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.0726 - val_accuracy: 0.9823\n",
      "Epoch 2598/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 0.0645 - val_accuracy: 0.9832\n",
      "Epoch 2599/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.0590 - val_accuracy: 0.9865\n",
      "Epoch 2600/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.0491 - val_accuracy: 0.9860\n",
      "Epoch 2601/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.0604 - val_accuracy: 0.9865\n",
      "Epoch 2602/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.0520 - val_accuracy: 0.9874\n",
      "Epoch 2603/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.0543 - val_accuracy: 0.9865\n",
      "Epoch 2604/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.0517 - val_accuracy: 0.9860\n",
      "Epoch 2605/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.0576 - val_accuracy: 0.9865\n",
      "Epoch 2606/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0548 - val_accuracy: 0.9874\n",
      "Epoch 2607/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.0614 - val_accuracy: 0.9855\n",
      "Epoch 2608/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.0629 - val_accuracy: 0.9846\n",
      "Epoch 2609/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.0514 - val_accuracy: 0.9874\n",
      "Epoch 2610/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0539 - val_accuracy: 0.9860\n",
      "Epoch 2611/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 0.0524 - val_accuracy: 0.9883\n",
      "Epoch 2612/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.0602 - val_accuracy: 0.9855\n",
      "Epoch 2613/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0672 - val_accuracy: 0.9837\n",
      "Epoch 2614/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0535 - val_accuracy: 0.9869\n",
      "Epoch 2615/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 0.0528 - val_accuracy: 0.9860\n",
      "Epoch 2616/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0549 - val_accuracy: 0.9860\n",
      "Epoch 2617/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.0543 - val_accuracy: 0.9874\n",
      "Epoch 2618/3500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.0626 - val_accuracy: 0.9855\n",
      "Epoch 2619/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0573 - val_accuracy: 0.9855\n",
      "Epoch 2620/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.9943 - val_loss: 0.0703 - val_accuracy: 0.9832\n",
      "Epoch 2621/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0683 - val_accuracy: 0.9841\n",
      "Epoch 2622/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0547 - val_accuracy: 0.9874\n",
      "Epoch 2623/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.0520 - val_accuracy: 0.9879\n",
      "Epoch 2624/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0556 - val_accuracy: 0.9879\n",
      "Epoch 2625/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.0563 - val_accuracy: 0.9869\n",
      "Epoch 2626/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0588 - val_accuracy: 0.9869\n",
      "Epoch 2627/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0649 - val_accuracy: 0.9851\n",
      "Epoch 2628/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0148 - accuracy: 0.9945 - val_loss: 0.0606 - val_accuracy: 0.9851\n",
      "Epoch 2629/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0565 - val_accuracy: 0.9865\n",
      "Epoch 2630/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9959 - val_loss: 0.0593 - val_accuracy: 0.9865\n",
      "Epoch 2631/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.0604 - val_accuracy: 0.9851\n",
      "Epoch 2632/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.0588 - val_accuracy: 0.9879\n",
      "Epoch 2633/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0589 - val_accuracy: 0.9879\n",
      "Epoch 2634/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.0568 - val_accuracy: 0.9869\n",
      "Epoch 2635/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9933 - val_loss: 0.0726 - val_accuracy: 0.9846\n",
      "Epoch 2636/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.0662 - val_accuracy: 0.9851\n",
      "Epoch 2637/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0635 - val_accuracy: 0.9846\n",
      "Epoch 2638/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.0707 - val_accuracy: 0.9828\n",
      "Epoch 2639/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.0590 - val_accuracy: 0.9855\n",
      "Epoch 2640/3500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0547 - val_accuracy: 0.9874\n",
      "Epoch 2641/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 0.0517 - val_accuracy: 0.9879\n",
      "Epoch 2642/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0547 - val_accuracy: 0.9860\n",
      "Epoch 2643/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.0515 - val_accuracy: 0.9874\n",
      "Epoch 2644/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.0507 - val_accuracy: 0.9874\n",
      "Epoch 2645/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.0544 - val_accuracy: 0.9865\n",
      "Epoch 2646/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0658 - val_accuracy: 0.9846\n",
      "Epoch 2647/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9936 - val_loss: 0.0711 - val_accuracy: 0.9828\n",
      "Epoch 2648/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0649 - val_accuracy: 0.9846\n",
      "Epoch 2649/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0570 - val_accuracy: 0.9860\n",
      "Epoch 2650/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0528 - val_accuracy: 0.9879\n",
      "Epoch 2651/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0552 - val_accuracy: 0.9879\n",
      "Epoch 2652/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.0552 - val_accuracy: 0.9869\n",
      "Epoch 2653/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0511 - val_accuracy: 0.9879\n",
      "Epoch 2654/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0575 - val_accuracy: 0.9865\n",
      "Epoch 2655/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0566 - val_accuracy: 0.9869\n",
      "Epoch 2656/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0554 - val_accuracy: 0.9874\n",
      "Epoch 2657/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0534 - val_accuracy: 0.9879\n",
      "Epoch 2658/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0573 - val_accuracy: 0.9879\n",
      "Epoch 2659/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.0655 - val_accuracy: 0.9841\n",
      "Epoch 2660/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0552 - val_accuracy: 0.9869\n",
      "Epoch 2661/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.0545 - val_accuracy: 0.9879\n",
      "Epoch 2662/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.0584 - val_accuracy: 0.9865\n",
      "Epoch 2663/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.0563 - val_accuracy: 0.9860\n",
      "Epoch 2664/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 0.0583 - val_accuracy: 0.9865\n",
      "Epoch 2665/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0697 - val_accuracy: 0.9860\n",
      "Epoch 2666/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0509 - val_accuracy: 0.9883\n",
      "Epoch 2667/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0542 - val_accuracy: 0.9879\n",
      "Epoch 2668/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.0564 - val_accuracy: 0.9874\n",
      "Epoch 2669/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.0561 - val_accuracy: 0.9869\n",
      "Epoch 2670/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.0494 - val_accuracy: 0.9865\n",
      "Epoch 2671/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.0514 - val_accuracy: 0.9883\n",
      "Epoch 2672/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0495 - val_accuracy: 0.9869\n",
      "Epoch 2673/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9933 - val_loss: 0.0638 - val_accuracy: 0.9860\n",
      "Epoch 2674/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0715 - val_accuracy: 0.9828\n",
      "Epoch 2675/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.0623 - val_accuracy: 0.9860\n",
      "Epoch 2676/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0535 - val_accuracy: 0.9883\n",
      "Epoch 2677/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0614 - val_accuracy: 0.9869\n",
      "Epoch 2678/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0552 - val_accuracy: 0.9865\n",
      "Epoch 2679/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0569 - val_accuracy: 0.9874\n",
      "Epoch 2680/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0589 - val_accuracy: 0.9874\n",
      "Epoch 2681/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0634 - val_accuracy: 0.9855\n",
      "Epoch 2682/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0587 - val_accuracy: 0.9869\n",
      "Epoch 2683/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0490 - val_accuracy: 0.9879\n",
      "Epoch 2684/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.0588 - val_accuracy: 0.9883\n",
      "Epoch 2685/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.0623 - val_accuracy: 0.9860\n",
      "Epoch 2686/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.0466 - val_accuracy: 0.9883\n",
      "Epoch 2687/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.0578 - val_accuracy: 0.9879\n",
      "Epoch 2688/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0600 - val_accuracy: 0.9855\n",
      "Epoch 2689/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0675 - val_accuracy: 0.9851\n",
      "Epoch 2690/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0573 - val_accuracy: 0.9860\n",
      "Epoch 2691/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0577 - val_accuracy: 0.9874\n",
      "Epoch 2692/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0494 - val_accuracy: 0.9883\n",
      "Epoch 2693/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.0517 - val_accuracy: 0.9869\n",
      "Epoch 2694/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.0601 - val_accuracy: 0.9860\n",
      "Epoch 2695/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0684 - val_accuracy: 0.9855\n",
      "Epoch 2696/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0513 - val_accuracy: 0.9893\n",
      "Epoch 2697/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.0531 - val_accuracy: 0.9879\n",
      "Epoch 2698/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.0501 - val_accuracy: 0.9879\n",
      "Epoch 2699/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.0493 - val_accuracy: 0.9888\n",
      "Epoch 2700/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.0669 - val_accuracy: 0.9851\n",
      "Epoch 2701/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0491 - val_accuracy: 0.9869\n",
      "Epoch 2702/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.0509 - val_accuracy: 0.9865\n",
      "Epoch 2703/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0570 - val_accuracy: 0.9874\n",
      "Epoch 2704/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0600 - val_accuracy: 0.9865\n",
      "Epoch 2705/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.0526 - val_accuracy: 0.9879\n",
      "Epoch 2706/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.0525 - val_accuracy: 0.9865\n",
      "Epoch 2707/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.0654 - val_accuracy: 0.9851\n",
      "Epoch 2708/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0543 - val_accuracy: 0.9888\n",
      "Epoch 2709/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.0526 - val_accuracy: 0.9893\n",
      "Epoch 2710/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0524 - val_accuracy: 0.9874\n",
      "Epoch 2711/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
      "Epoch 2712/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9943 - val_loss: 0.0576 - val_accuracy: 0.9874\n",
      "Epoch 2713/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.0553 - val_accuracy: 0.9883\n",
      "Epoch 2714/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.0511 - val_accuracy: 0.9888\n",
      "Epoch 2715/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0650 - val_accuracy: 0.9851\n",
      "Epoch 2716/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.0541 - val_accuracy: 0.9869\n",
      "Epoch 2717/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.0508 - val_accuracy: 0.9883\n",
      "Epoch 2718/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0503 - val_accuracy: 0.9879\n",
      "Epoch 2719/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.0518 - val_accuracy: 0.9874\n",
      "Epoch 2720/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9943 - val_loss: 0.0485 - val_accuracy: 0.9874\n",
      "Epoch 2721/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.0485 - val_accuracy: 0.9879\n",
      "Epoch 2722/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.0551 - val_accuracy: 0.9883\n",
      "Epoch 2723/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0794 - val_accuracy: 0.9809\n",
      "Epoch 2724/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9936 - val_loss: 0.0601 - val_accuracy: 0.9860\n",
      "Epoch 2725/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.0519 - val_accuracy: 0.9888\n",
      "Epoch 2726/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.0465 - val_accuracy: 0.9888\n",
      "Epoch 2727/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0582 - val_accuracy: 0.9865\n",
      "Epoch 2728/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.0610 - val_accuracy: 0.9869\n",
      "Epoch 2729/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.0562 - val_accuracy: 0.9879\n",
      "Epoch 2730/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0519 - val_accuracy: 0.9869\n",
      "Epoch 2731/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0517 - val_accuracy: 0.9874\n",
      "Epoch 2732/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.0501 - val_accuracy: 0.9893\n",
      "Epoch 2733/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0563 - val_accuracy: 0.9865\n",
      "Epoch 2734/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0541 - val_accuracy: 0.9888\n",
      "Epoch 2735/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0697 - val_accuracy: 0.9841\n",
      "Epoch 2736/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0613 - val_accuracy: 0.9851\n",
      "Epoch 2737/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0579 - val_accuracy: 0.9869\n",
      "Epoch 2738/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0498 - val_accuracy: 0.9883\n",
      "Epoch 2739/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0560 - val_accuracy: 0.9865\n",
      "Epoch 2740/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.0531 - val_accuracy: 0.9874\n",
      "Epoch 2741/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.0650 - val_accuracy: 0.9855\n",
      "Epoch 2742/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0721 - val_accuracy: 0.9837\n",
      "Epoch 2743/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9929 - val_loss: 0.0783 - val_accuracy: 0.9832\n",
      "Epoch 2744/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0653 - val_accuracy: 0.9837\n",
      "Epoch 2745/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0627 - val_accuracy: 0.9865\n",
      "Epoch 2746/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.0520 - val_accuracy: 0.9893\n",
      "Epoch 2747/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0555 - val_accuracy: 0.9869\n",
      "Epoch 2748/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.0527 - val_accuracy: 0.9874\n",
      "Epoch 2749/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.0596 - val_accuracy: 0.9869\n",
      "Epoch 2750/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.0576 - val_accuracy: 0.9869\n",
      "Epoch 2751/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0498 - val_accuracy: 0.9883\n",
      "Epoch 2752/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0632 - val_accuracy: 0.9860\n",
      "Epoch 2753/3500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.0580 - val_accuracy: 0.9869\n",
      "Epoch 2754/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0590 - val_accuracy: 0.9865\n",
      "Epoch 2755/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0620 - val_accuracy: 0.9855\n",
      "Epoch 2756/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.0536 - val_accuracy: 0.9883\n",
      "Epoch 2757/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0503 - val_accuracy: 0.9888\n",
      "Epoch 2758/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0594 - val_accuracy: 0.9860\n",
      "Epoch 2759/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.0527 - val_accuracy: 0.9883\n",
      "Epoch 2760/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.0572 - val_accuracy: 0.9883\n",
      "Epoch 2761/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.0570 - val_accuracy: 0.9855\n",
      "Epoch 2762/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0559 - val_accuracy: 0.9883\n",
      "Epoch 2763/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0573 - val_accuracy: 0.9865\n",
      "Epoch 2764/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.0506 - val_accuracy: 0.9865\n",
      "Epoch 2765/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0479 - val_accuracy: 0.9869\n",
      "Epoch 2766/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.0732 - val_accuracy: 0.9851\n",
      "Epoch 2767/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.0675 - val_accuracy: 0.9846\n",
      "Epoch 2768/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0769 - val_accuracy: 0.9837\n",
      "Epoch 2769/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 0.0642 - val_accuracy: 0.9846\n",
      "Epoch 2770/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0523 - val_accuracy: 0.9883\n",
      "Epoch 2771/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.0476 - val_accuracy: 0.9879\n",
      "Epoch 2772/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0595 - val_accuracy: 0.9865\n",
      "Epoch 2773/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0619 - val_accuracy: 0.9860\n",
      "Epoch 2774/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.0563 - val_accuracy: 0.9865\n",
      "Epoch 2775/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0572 - val_accuracy: 0.9869\n",
      "Epoch 2776/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0546 - val_accuracy: 0.9869\n",
      "Epoch 2777/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.0521 - val_accuracy: 0.9879\n",
      "Epoch 2778/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0576 - val_accuracy: 0.9865\n",
      "Epoch 2779/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.0518 - val_accuracy: 0.9865\n",
      "Epoch 2780/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.0543 - val_accuracy: 0.9874\n",
      "Epoch 2781/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.0534 - val_accuracy: 0.9883\n",
      "Epoch 2782/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.0522 - val_accuracy: 0.9874\n",
      "Epoch 2783/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0510 - val_accuracy: 0.9883\n",
      "Epoch 2784/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0545 - val_accuracy: 0.9874\n",
      "Epoch 2785/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0705 - val_accuracy: 0.9841\n",
      "Epoch 2786/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.0650 - val_accuracy: 0.9855\n",
      "Epoch 2787/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.0564 - val_accuracy: 0.9874\n",
      "Epoch 2788/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 0.0500 - val_accuracy: 0.9869\n",
      "Epoch 2789/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.0525 - val_accuracy: 0.9883\n",
      "Epoch 2790/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0503 - val_accuracy: 0.9874\n",
      "Epoch 2791/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.0548 - val_accuracy: 0.9879\n",
      "Epoch 2792/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.0557 - val_accuracy: 0.9869\n",
      "Epoch 2793/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0610 - val_accuracy: 0.9865\n",
      "Epoch 2794/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0577 - val_accuracy: 0.9865\n",
      "Epoch 2795/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0511 - val_accuracy: 0.9879\n",
      "Epoch 2796/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0547 - val_accuracy: 0.9888\n",
      "Epoch 2797/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0610 - val_accuracy: 0.9855\n",
      "Epoch 2798/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0719 - val_accuracy: 0.9855\n",
      "Epoch 2799/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0521 - val_accuracy: 0.9865\n",
      "Epoch 2800/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.0486 - val_accuracy: 0.9874\n",
      "Epoch 2801/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0647 - val_accuracy: 0.9855\n",
      "Epoch 2802/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.0574 - val_accuracy: 0.9865\n",
      "Epoch 2803/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0583 - val_accuracy: 0.9865\n",
      "Epoch 2804/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0610 - val_accuracy: 0.9860\n",
      "Epoch 2805/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.0536 - val_accuracy: 0.9865\n",
      "Epoch 2806/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0533 - val_accuracy: 0.9869\n",
      "Epoch 2807/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.0615 - val_accuracy: 0.9874\n",
      "Epoch 2808/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0500 - val_accuracy: 0.9888\n",
      "Epoch 2809/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9933 - val_loss: 0.0525 - val_accuracy: 0.9879\n",
      "Epoch 2810/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0485 - val_accuracy: 0.9883\n",
      "Epoch 2811/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9940 - val_loss: 0.0539 - val_accuracy: 0.9883\n",
      "Epoch 2812/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 0.0617 - val_accuracy: 0.9851\n",
      "Epoch 2813/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.0539 - val_accuracy: 0.9865\n",
      "Epoch 2814/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.0511 - val_accuracy: 0.9897\n",
      "Epoch 2815/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0517 - val_accuracy: 0.9897\n",
      "Epoch 2816/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0593 - val_accuracy: 0.9860\n",
      "Epoch 2817/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0578 - val_accuracy: 0.9874\n",
      "Epoch 2818/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.0503 - val_accuracy: 0.9893\n",
      "Epoch 2819/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0521 - val_accuracy: 0.9874\n",
      "Epoch 2820/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.0513 - val_accuracy: 0.9883\n",
      "Epoch 2821/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0529 - val_accuracy: 0.9879\n",
      "Epoch 2822/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.0619 - val_accuracy: 0.9865\n",
      "Epoch 2823/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.0590 - val_accuracy: 0.9879\n",
      "Epoch 2824/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0588 - val_accuracy: 0.9865\n",
      "Epoch 2825/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9940 - val_loss: 0.0628 - val_accuracy: 0.9865\n",
      "Epoch 2826/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.0589 - val_accuracy: 0.9869\n",
      "Epoch 2827/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0600 - val_accuracy: 0.9865\n",
      "Epoch 2828/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0518 - val_accuracy: 0.9883\n",
      "Epoch 2829/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0572 - val_accuracy: 0.9869\n",
      "Epoch 2830/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0467 - val_accuracy: 0.9902\n",
      "Epoch 2831/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 0.0581 - val_accuracy: 0.9879\n",
      "Epoch 2832/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0470 - val_accuracy: 0.9883\n",
      "Epoch 2833/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0553 - val_accuracy: 0.9874\n",
      "Epoch 2834/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0537 - val_accuracy: 0.9879\n",
      "Epoch 2835/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.0491 - val_accuracy: 0.9883\n",
      "Epoch 2836/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 0.0581 - val_accuracy: 0.9874\n",
      "Epoch 2837/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.0539 - val_accuracy: 0.9893\n",
      "Epoch 2838/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0544 - val_accuracy: 0.9874\n",
      "Epoch 2839/3500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.0549 - val_accuracy: 0.9888\n",
      "Epoch 2840/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.0558 - val_accuracy: 0.9869\n",
      "Epoch 2841/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0490 - val_accuracy: 0.9897\n",
      "Epoch 2842/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0566 - val_accuracy: 0.9869\n",
      "Epoch 2843/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0503 - val_accuracy: 0.9888\n",
      "Epoch 2844/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0596 - val_accuracy: 0.9869\n",
      "Epoch 2845/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.0503 - val_accuracy: 0.9869\n",
      "Epoch 2846/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0534 - val_accuracy: 0.9879\n",
      "Epoch 2847/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.0592 - val_accuracy: 0.9855\n",
      "Epoch 2848/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0673 - val_accuracy: 0.9855\n",
      "Epoch 2849/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0732 - val_accuracy: 0.9823\n",
      "Epoch 2850/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0557 - val_accuracy: 0.9883\n",
      "Epoch 2851/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0605 - val_accuracy: 0.9865\n",
      "Epoch 2852/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 0.0556 - val_accuracy: 0.9874\n",
      "Epoch 2853/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.0522 - val_accuracy: 0.9874\n",
      "Epoch 2854/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
      "Epoch 2855/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0553 - val_accuracy: 0.9874\n",
      "Epoch 2856/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.0538 - val_accuracy: 0.9879\n",
      "Epoch 2857/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.0573 - val_accuracy: 0.9865\n",
      "Epoch 2858/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.0571 - val_accuracy: 0.9865\n",
      "Epoch 2859/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0534 - val_accuracy: 0.9879\n",
      "Epoch 2860/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0539 - val_accuracy: 0.9879\n",
      "Epoch 2861/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0552 - val_accuracy: 0.9879\n",
      "Epoch 2862/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0579 - val_accuracy: 0.9879\n",
      "Epoch 2863/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0525 - val_accuracy: 0.9888\n",
      "Epoch 2864/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.0515 - val_accuracy: 0.9865\n",
      "Epoch 2865/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0552 - val_accuracy: 0.9874\n",
      "Epoch 2866/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0657 - val_accuracy: 0.9851\n",
      "Epoch 2867/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.0598 - val_accuracy: 0.9860\n",
      "Epoch 2868/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0599 - val_accuracy: 0.9869\n",
      "Epoch 2869/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.0635 - val_accuracy: 0.9846\n",
      "Epoch 2870/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0529 - val_accuracy: 0.9879\n",
      "Epoch 2871/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0503 - val_accuracy: 0.9874\n",
      "Epoch 2872/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.0617 - val_accuracy: 0.9869\n",
      "Epoch 2873/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0515 - val_accuracy: 0.9888\n",
      "Epoch 2874/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0566 - val_accuracy: 0.9874\n",
      "Epoch 2875/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 0.0503 - val_accuracy: 0.9883\n",
      "Epoch 2876/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0566 - val_accuracy: 0.9865\n",
      "Epoch 2877/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 0.0492 - val_accuracy: 0.9893\n",
      "Epoch 2878/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0629 - val_accuracy: 0.9865\n",
      "Epoch 2879/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0853 - val_accuracy: 0.9809\n",
      "Epoch 2880/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
      "Epoch 2881/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0621 - val_accuracy: 0.9855\n",
      "Epoch 2882/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0601 - val_accuracy: 0.9860\n",
      "Epoch 2883/3500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0644 - val_accuracy: 0.9841\n",
      "Epoch 2884/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0530 - val_accuracy: 0.9874\n",
      "Epoch 2885/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.0517 - val_accuracy: 0.9874\n",
      "Epoch 2886/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0562 - val_accuracy: 0.9865\n",
      "Epoch 2887/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9940 - val_loss: 0.0522 - val_accuracy: 0.9879\n",
      "Epoch 2888/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0526 - val_accuracy: 0.9883\n",
      "Epoch 2889/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9938 - val_loss: 0.0581 - val_accuracy: 0.9874\n",
      "Epoch 2890/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.0511 - val_accuracy: 0.9874\n",
      "Epoch 2891/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0590 - val_accuracy: 0.9869\n",
      "Epoch 2892/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0597 - val_accuracy: 0.9860\n",
      "Epoch 2893/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.0640 - val_accuracy: 0.9860\n",
      "Epoch 2894/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0657 - val_accuracy: 0.9855\n",
      "Epoch 2895/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.0546 - val_accuracy: 0.9874\n",
      "Epoch 2896/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0582 - val_accuracy: 0.9883\n",
      "Epoch 2897/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0495 - val_accuracy: 0.9883\n",
      "Epoch 2898/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.0524 - val_accuracy: 0.9883\n",
      "Epoch 2899/3500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0537 - val_accuracy: 0.9893\n",
      "Epoch 2900/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0496 - val_accuracy: 0.9879\n",
      "Epoch 2901/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0679 - val_accuracy: 0.9851\n",
      "Epoch 2902/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0579 - val_accuracy: 0.9883\n",
      "Epoch 2903/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0724 - val_accuracy: 0.9846\n",
      "Epoch 2904/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.0623 - val_accuracy: 0.9865\n",
      "Epoch 2905/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.0601 - val_accuracy: 0.9855\n",
      "Epoch 2906/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0501 - val_accuracy: 0.9893\n",
      "Epoch 2907/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0582 - val_accuracy: 0.9865\n",
      "Epoch 2908/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0507 - val_accuracy: 0.9888\n",
      "Epoch 2909/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0606 - val_accuracy: 0.9869\n",
      "Epoch 2910/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0624 - val_accuracy: 0.9879\n",
      "Epoch 2911/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.0597 - val_accuracy: 0.9879\n",
      "Epoch 2912/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0551 - val_accuracy: 0.9888\n",
      "Epoch 2913/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0613 - val_accuracy: 0.9855\n",
      "Epoch 2914/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.0537 - val_accuracy: 0.9888\n",
      "Epoch 2915/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.0541 - val_accuracy: 0.9879\n",
      "Epoch 2916/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.0503 - val_accuracy: 0.9888\n",
      "Epoch 2917/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.0554 - val_accuracy: 0.9879\n",
      "Epoch 2918/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0513 - val_accuracy: 0.9888\n",
      "Epoch 2919/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0556 - val_accuracy: 0.9883\n",
      "Epoch 2920/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0619 - val_accuracy: 0.9865\n",
      "Epoch 2921/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.0540 - val_accuracy: 0.9874\n",
      "Epoch 2922/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0655 - val_accuracy: 0.9855\n",
      "Epoch 2923/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0556 - val_accuracy: 0.9883\n",
      "Epoch 2924/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.0505 - val_accuracy: 0.9869\n",
      "Epoch 2925/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0550 - val_accuracy: 0.9869\n",
      "Epoch 2926/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0537 - val_accuracy: 0.9893\n",
      "Epoch 2927/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0518 - val_accuracy: 0.9865\n",
      "Epoch 2928/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.0536 - val_accuracy: 0.9893\n",
      "Epoch 2929/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0605 - val_accuracy: 0.9865\n",
      "Epoch 2930/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0562 - val_accuracy: 0.9879\n",
      "Epoch 2931/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0577 - val_accuracy: 0.9869\n",
      "Epoch 2932/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.0524 - val_accuracy: 0.9888\n",
      "Epoch 2933/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0623 - val_accuracy: 0.9869\n",
      "Epoch 2934/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0669 - val_accuracy: 0.9837\n",
      "Epoch 2935/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0705 - val_accuracy: 0.9846\n",
      "Epoch 2936/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0667 - val_accuracy: 0.9851\n",
      "Epoch 2937/3500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0627 - val_accuracy: 0.9869\n",
      "Epoch 2938/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0639 - val_accuracy: 0.9841\n",
      "Epoch 2939/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0553 - val_accuracy: 0.9860\n",
      "Epoch 2940/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0603 - val_accuracy: 0.9879\n",
      "Epoch 2941/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.0556 - val_accuracy: 0.9874\n",
      "Epoch 2942/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.0532 - val_accuracy: 0.9897\n",
      "Epoch 2943/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.0514 - val_accuracy: 0.9888\n",
      "Epoch 2944/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.0639 - val_accuracy: 0.9855\n",
      "Epoch 2945/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0564 - val_accuracy: 0.9869\n",
      "Epoch 2946/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0555 - val_accuracy: 0.9874\n",
      "Epoch 2947/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0536 - val_accuracy: 0.9879\n",
      "Epoch 2948/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0553 - val_accuracy: 0.9888\n",
      "Epoch 2949/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0750 - val_accuracy: 0.9823\n",
      "Epoch 2950/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0711 - val_accuracy: 0.9841\n",
      "Epoch 2951/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.0633 - val_accuracy: 0.9855\n",
      "Epoch 2952/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0500 - val_accuracy: 0.9897\n",
      "Epoch 2953/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0597 - val_accuracy: 0.9855\n",
      "Epoch 2954/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 0.0501 - val_accuracy: 0.9883\n",
      "Epoch 2955/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.0605 - val_accuracy: 0.9879\n",
      "Epoch 2956/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0586 - val_accuracy: 0.9883\n",
      "Epoch 2957/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0532 - val_accuracy: 0.9865\n",
      "Epoch 2958/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0556 - val_accuracy: 0.9869\n",
      "Epoch 2959/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.0508 - val_accuracy: 0.9888\n",
      "Epoch 2960/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0682 - val_accuracy: 0.9869\n",
      "Epoch 2961/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.0709 - val_accuracy: 0.9841\n",
      "Epoch 2962/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0545 - val_accuracy: 0.9897\n",
      "Epoch 2963/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.0532 - val_accuracy: 0.9869\n",
      "Epoch 2964/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.0516 - val_accuracy: 0.9874\n",
      "Epoch 2965/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9940 - val_loss: 0.0559 - val_accuracy: 0.9865\n",
      "Epoch 2966/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0557 - val_accuracy: 0.9883\n",
      "Epoch 2967/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0759 - val_accuracy: 0.9828\n",
      "Epoch 2968/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0547 - val_accuracy: 0.9893\n",
      "Epoch 2969/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0526 - val_accuracy: 0.9874\n",
      "Epoch 2970/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0536 - val_accuracy: 0.9888\n",
      "Epoch 2971/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0536 - val_accuracy: 0.9897\n",
      "Epoch 2972/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0576 - val_accuracy: 0.9869\n",
      "Epoch 2973/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0527 - val_accuracy: 0.9883\n",
      "Epoch 2974/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.0580 - val_accuracy: 0.9879\n",
      "Epoch 2975/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0541 - val_accuracy: 0.9883\n",
      "Epoch 2976/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0524 - val_accuracy: 0.9897\n",
      "Epoch 2977/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0517 - val_accuracy: 0.9888\n",
      "Epoch 2978/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0581 - val_accuracy: 0.9869\n",
      "Epoch 2979/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0563 - val_accuracy: 0.9874\n",
      "Epoch 2980/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0601 - val_accuracy: 0.9865\n",
      "Epoch 2981/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.0647 - val_accuracy: 0.9855\n",
      "Epoch 2982/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0570 - val_accuracy: 0.9879\n",
      "Epoch 2983/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0573 - val_accuracy: 0.9879\n",
      "Epoch 2984/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 0.0628 - val_accuracy: 0.9851\n",
      "Epoch 2985/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0589 - val_accuracy: 0.9879\n",
      "Epoch 2986/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.0522 - val_accuracy: 0.9879\n",
      "Epoch 2987/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.0548 - val_accuracy: 0.9883\n",
      "Epoch 2988/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.0656 - val_accuracy: 0.9841\n",
      "Epoch 2989/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.0554 - val_accuracy: 0.9879\n",
      "Epoch 2990/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.0586 - val_accuracy: 0.9869\n",
      "Epoch 2991/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0666 - val_accuracy: 0.9860\n",
      "Epoch 2992/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0551 - val_accuracy: 0.9874\n",
      "Epoch 2993/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.0755 - val_accuracy: 0.9841\n",
      "Epoch 2994/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0608 - val_accuracy: 0.9860\n",
      "Epoch 2995/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0610 - val_accuracy: 0.9879\n",
      "Epoch 2996/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0493 - val_accuracy: 0.9879\n",
      "Epoch 2997/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0598 - val_accuracy: 0.9883\n",
      "Epoch 2998/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0487 - val_accuracy: 0.9879\n",
      "Epoch 2999/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.0563 - val_accuracy: 0.9869\n",
      "Epoch 3000/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.0510 - val_accuracy: 0.9888\n",
      "Epoch 3001/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.0673 - val_accuracy: 0.9869\n",
      "Epoch 3002/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0568 - val_accuracy: 0.9874\n",
      "Epoch 3003/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0541 - val_accuracy: 0.9865\n",
      "Epoch 3004/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.0553 - val_accuracy: 0.9879\n",
      "Epoch 3005/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.0545 - val_accuracy: 0.9883\n",
      "Epoch 3006/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.0578 - val_accuracy: 0.9879\n",
      "Epoch 3007/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0625 - val_accuracy: 0.9860\n",
      "Epoch 3008/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.0547 - val_accuracy: 0.9874\n",
      "Epoch 3009/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0539 - val_accuracy: 0.9869\n",
      "Epoch 3010/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.0591 - val_accuracy: 0.9865\n",
      "Epoch 3011/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.0584 - val_accuracy: 0.9883\n",
      "Epoch 3012/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0546 - val_accuracy: 0.9893\n",
      "Epoch 3013/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.0567 - val_accuracy: 0.9865\n",
      "Epoch 3014/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0544 - val_accuracy: 0.9883\n",
      "Epoch 3015/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.0628 - val_accuracy: 0.9874\n",
      "Epoch 3016/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0524 - val_accuracy: 0.9888\n",
      "Epoch 3017/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0588 - val_accuracy: 0.9860\n",
      "Epoch 3018/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.0570 - val_accuracy: 0.9883\n",
      "Epoch 3019/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0599 - val_accuracy: 0.9879\n",
      "Epoch 3020/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.0541 - val_accuracy: 0.9879\n",
      "Epoch 3021/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.0517 - val_accuracy: 0.9888\n",
      "Epoch 3022/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0599 - val_accuracy: 0.9869\n",
      "Epoch 3023/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0745 - val_accuracy: 0.9846\n",
      "Epoch 3024/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.0563 - val_accuracy: 0.9869\n",
      "Epoch 3025/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0577 - val_accuracy: 0.9879\n",
      "Epoch 3026/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0590 - val_accuracy: 0.9869\n",
      "Epoch 3027/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.0545 - val_accuracy: 0.9869\n",
      "Epoch 3028/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0590 - val_accuracy: 0.9883\n",
      "Epoch 3029/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.0510 - val_accuracy: 0.9879\n",
      "Epoch 3030/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.0572 - val_accuracy: 0.9869\n",
      "Epoch 3031/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0539 - val_accuracy: 0.9874\n",
      "Epoch 3032/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0558 - val_accuracy: 0.9883\n",
      "Epoch 3033/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0586 - val_accuracy: 0.9865\n",
      "Epoch 3034/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0810 - val_accuracy: 0.9841\n",
      "Epoch 3035/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0540 - val_accuracy: 0.9860\n",
      "Epoch 3036/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.0550 - val_accuracy: 0.9874\n",
      "Epoch 3037/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0575 - val_accuracy: 0.9874\n",
      "Epoch 3038/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0522 - val_accuracy: 0.9888\n",
      "Epoch 3039/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0690 - val_accuracy: 0.9851\n",
      "Epoch 3040/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.0608 - val_accuracy: 0.9865\n",
      "Epoch 3041/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0603 - val_accuracy: 0.9865\n",
      "Epoch 3042/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0580 - val_accuracy: 0.9883\n",
      "Epoch 3043/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0557 - val_accuracy: 0.9869\n",
      "Epoch 3044/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.0539 - val_accuracy: 0.9888\n",
      "Epoch 3045/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.0521 - val_accuracy: 0.9869\n",
      "Epoch 3046/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.0526 - val_accuracy: 0.9888\n",
      "Epoch 3047/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0566 - val_accuracy: 0.9865\n",
      "Epoch 3048/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0569 - val_accuracy: 0.9879\n",
      "Epoch 3049/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.0650 - val_accuracy: 0.9851\n",
      "Epoch 3050/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0725 - val_accuracy: 0.9841\n",
      "Epoch 3051/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0764 - val_accuracy: 0.9841\n",
      "Epoch 3052/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9940 - val_loss: 0.0691 - val_accuracy: 0.9851\n",
      "Epoch 3053/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.0761 - val_accuracy: 0.9832\n",
      "Epoch 3054/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0753 - val_accuracy: 0.9837\n",
      "Epoch 3055/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 0.0741 - val_accuracy: 0.9841\n",
      "Epoch 3056/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.0577 - val_accuracy: 0.9883\n",
      "Epoch 3057/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0637 - val_accuracy: 0.9874\n",
      "Epoch 3058/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0536 - val_accuracy: 0.9888\n",
      "Epoch 3059/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.0530 - val_accuracy: 0.9874\n",
      "Epoch 3060/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.0597 - val_accuracy: 0.9846\n",
      "Epoch 3061/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0560 - val_accuracy: 0.9874\n",
      "Epoch 3062/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.0619 - val_accuracy: 0.9888\n",
      "Epoch 3063/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.0541 - val_accuracy: 0.9893\n",
      "Epoch 3064/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9917 - val_loss: 0.0558 - val_accuracy: 0.9860\n",
      "Epoch 3065/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.0714 - val_accuracy: 0.9851\n",
      "Epoch 3066/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.0619 - val_accuracy: 0.9851\n",
      "Epoch 3067/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0699 - val_accuracy: 0.9860\n",
      "Epoch 3068/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0548 - val_accuracy: 0.9879\n",
      "Epoch 3069/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0563 - val_accuracy: 0.9874\n",
      "Epoch 3070/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9943 - val_loss: 0.0579 - val_accuracy: 0.9883\n",
      "Epoch 3071/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0557 - val_accuracy: 0.9888\n",
      "Epoch 3072/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0564 - val_accuracy: 0.9874\n",
      "Epoch 3073/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.0578 - val_accuracy: 0.9883\n",
      "Epoch 3074/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.0630 - val_accuracy: 0.9874\n",
      "Epoch 3075/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0670 - val_accuracy: 0.9855\n",
      "Epoch 3076/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.0692 - val_accuracy: 0.9841\n",
      "Epoch 3077/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0622 - val_accuracy: 0.9888\n",
      "Epoch 3078/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.0533 - val_accuracy: 0.9883\n",
      "Epoch 3079/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0604 - val_accuracy: 0.9883\n",
      "Epoch 3080/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0667 - val_accuracy: 0.9879\n",
      "Epoch 3081/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0639 - val_accuracy: 0.9874\n",
      "Epoch 3082/3500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0583 - val_accuracy: 0.9879\n",
      "Epoch 3083/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.0577 - val_accuracy: 0.9883\n",
      "Epoch 3084/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.0707 - val_accuracy: 0.9874\n",
      "Epoch 3085/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0567 - val_accuracy: 0.9888\n",
      "Epoch 3086/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0595 - val_accuracy: 0.9879\n",
      "Epoch 3087/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0716 - val_accuracy: 0.9860\n",
      "Epoch 3088/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0650 - val_accuracy: 0.9855\n",
      "Epoch 3089/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0643 - val_accuracy: 0.9860\n",
      "Epoch 3090/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0553 - val_accuracy: 0.9888\n",
      "Epoch 3091/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0648 - val_accuracy: 0.9865\n",
      "Epoch 3092/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0535 - val_accuracy: 0.9879\n",
      "Epoch 3093/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0580 - val_accuracy: 0.9883\n",
      "Epoch 3094/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0606 - val_accuracy: 0.9888\n",
      "Epoch 3095/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0532 - val_accuracy: 0.9888\n",
      "Epoch 3096/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0735 - val_accuracy: 0.9851\n",
      "Epoch 3097/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0596 - val_accuracy: 0.9883\n",
      "Epoch 3098/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0598 - val_accuracy: 0.9883\n",
      "Epoch 3099/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0583 - val_accuracy: 0.9879\n",
      "Epoch 3100/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0570 - val_accuracy: 0.9883\n",
      "Epoch 3101/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0573 - val_accuracy: 0.9860\n",
      "Epoch 3102/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0550 - val_accuracy: 0.9869\n",
      "Epoch 3103/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 0.9943 - val_loss: 0.0630 - val_accuracy: 0.9874\n",
      "Epoch 3104/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.0611 - val_accuracy: 0.9874\n",
      "Epoch 3105/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.0568 - val_accuracy: 0.9888\n",
      "Epoch 3106/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0553 - val_accuracy: 0.9879\n",
      "Epoch 3107/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0572 - val_accuracy: 0.9883\n",
      "Epoch 3108/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.0605 - val_accuracy: 0.9883\n",
      "Epoch 3109/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.0618 - val_accuracy: 0.9883\n",
      "Epoch 3110/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0565 - val_accuracy: 0.9888\n",
      "Epoch 3111/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0550 - val_accuracy: 0.9874\n",
      "Epoch 3112/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0544 - val_accuracy: 0.9874\n",
      "Epoch 3113/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.0565 - val_accuracy: 0.9874\n",
      "Epoch 3114/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 0.0549 - val_accuracy: 0.9865\n",
      "Epoch 3115/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0204 - accuracy: 0.9922 - val_loss: 0.0613 - val_accuracy: 0.9865\n",
      "Epoch 3116/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0824 - val_accuracy: 0.9832\n",
      "Epoch 3117/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.0611 - val_accuracy: 0.9865\n",
      "Epoch 3118/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 0.0605 - val_accuracy: 0.9874\n",
      "Epoch 3119/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.0560 - val_accuracy: 0.9865\n",
      "Epoch 3120/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.0661 - val_accuracy: 0.9869\n",
      "Epoch 3121/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0510 - val_accuracy: 0.9902\n",
      "Epoch 3122/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.0543 - val_accuracy: 0.9860\n",
      "Epoch 3123/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0599 - val_accuracy: 0.9879\n",
      "Epoch 3124/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0534 - val_accuracy: 0.9883\n",
      "Epoch 3125/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0696 - val_accuracy: 0.9855\n",
      "Epoch 3126/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 0.0536 - val_accuracy: 0.9883\n",
      "Epoch 3127/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0544 - val_accuracy: 0.9869\n",
      "Epoch 3128/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.0507 - val_accuracy: 0.9893\n",
      "Epoch 3129/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0522 - val_accuracy: 0.9883\n",
      "Epoch 3130/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.0596 - val_accuracy: 0.9879\n",
      "Epoch 3131/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9938 - val_loss: 0.0614 - val_accuracy: 0.9865\n",
      "Epoch 3132/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0625 - val_accuracy: 0.9851\n",
      "Epoch 3133/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0565 - val_accuracy: 0.9883\n",
      "Epoch 3134/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0540 - val_accuracy: 0.9869\n",
      "Epoch 3135/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.0532 - val_accuracy: 0.9893\n",
      "Epoch 3136/3500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0698 - val_accuracy: 0.9846\n",
      "Epoch 3137/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0613 - val_accuracy: 0.9846\n",
      "Epoch 3138/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0549 - val_accuracy: 0.9888\n",
      "Epoch 3139/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0584 - val_accuracy: 0.9888\n",
      "Epoch 3140/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.0638 - val_accuracy: 0.9879\n",
      "Epoch 3141/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0611 - val_accuracy: 0.9888\n",
      "Epoch 3142/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.0630 - val_accuracy: 0.9869\n",
      "Epoch 3143/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0590 - val_accuracy: 0.9865\n",
      "Epoch 3144/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0495 - val_accuracy: 0.9893\n",
      "Epoch 3145/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0540 - val_accuracy: 0.9883\n",
      "Epoch 3146/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.0579 - val_accuracy: 0.9869\n",
      "Epoch 3147/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0564 - val_accuracy: 0.9869\n",
      "Epoch 3148/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.0586 - val_accuracy: 0.9874\n",
      "Epoch 3149/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0510 - val_accuracy: 0.9888\n",
      "Epoch 3150/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0627 - val_accuracy: 0.9860\n",
      "Epoch 3151/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0617 - val_accuracy: 0.9865\n",
      "Epoch 3152/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0569 - val_accuracy: 0.9879\n",
      "Epoch 3153/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0569 - val_accuracy: 0.9869\n",
      "Epoch 3154/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0564 - val_accuracy: 0.9865\n",
      "Epoch 3155/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.0544 - val_accuracy: 0.9869\n",
      "Epoch 3156/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0611 - val_accuracy: 0.9865\n",
      "Epoch 3157/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.0531 - val_accuracy: 0.9893\n",
      "Epoch 3158/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0591 - val_accuracy: 0.9879\n",
      "Epoch 3159/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.0544 - val_accuracy: 0.9883\n",
      "Epoch 3160/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.0503 - val_accuracy: 0.9893\n",
      "Epoch 3161/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0618 - val_accuracy: 0.9869\n",
      "Epoch 3162/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0620 - val_accuracy: 0.9869\n",
      "Epoch 3163/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0567 - val_accuracy: 0.9865\n",
      "Epoch 3164/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.0576 - val_accuracy: 0.9860\n",
      "Epoch 3165/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.0515 - val_accuracy: 0.9874\n",
      "Epoch 3166/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.0571 - val_accuracy: 0.9865\n",
      "Epoch 3167/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0531 - val_accuracy: 0.9860\n",
      "Epoch 3168/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0559 - val_accuracy: 0.9874\n",
      "Epoch 3169/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.0567 - val_accuracy: 0.9874\n",
      "Epoch 3170/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0545 - val_accuracy: 0.9865\n",
      "Epoch 3171/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0529 - val_accuracy: 0.9879\n",
      "Epoch 3172/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.0554 - val_accuracy: 0.9860\n",
      "Epoch 3173/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0652 - val_accuracy: 0.9855\n",
      "Epoch 3174/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.0573 - val_accuracy: 0.9860\n",
      "Epoch 3175/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0531 - val_accuracy: 0.9879\n",
      "Epoch 3176/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0639 - val_accuracy: 0.9865\n",
      "Epoch 3177/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0507 - val_accuracy: 0.9874\n",
      "Epoch 3178/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.0593 - val_accuracy: 0.9860\n",
      "Epoch 3179/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0536 - val_accuracy: 0.9879\n",
      "Epoch 3180/3500\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0571 - val_accuracy: 0.9865\n",
      "Epoch 3181/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0619 - val_accuracy: 0.9860\n",
      "Epoch 3182/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.0645 - val_accuracy: 0.9851\n",
      "Epoch 3183/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 0.0624 - val_accuracy: 0.9865\n",
      "Epoch 3184/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0526 - val_accuracy: 0.9883\n",
      "Epoch 3185/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.0644 - val_accuracy: 0.9855\n",
      "Epoch 3186/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0686 - val_accuracy: 0.9869\n",
      "Epoch 3187/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.0573 - val_accuracy: 0.9855\n",
      "Epoch 3188/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0546 - val_accuracy: 0.9869\n",
      "Epoch 3189/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0553 - val_accuracy: 0.9865\n",
      "Epoch 3190/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.0714 - val_accuracy: 0.9846\n",
      "Epoch 3191/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0554 - val_accuracy: 0.9860\n",
      "Epoch 3192/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0613 - val_accuracy: 0.9883\n",
      "Epoch 3193/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0519 - val_accuracy: 0.9893\n",
      "Epoch 3194/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 0.0582 - val_accuracy: 0.9865\n",
      "Epoch 3195/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0525 - val_accuracy: 0.9893\n",
      "Epoch 3196/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0562 - val_accuracy: 0.9874\n",
      "Epoch 3197/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0571 - val_accuracy: 0.9869\n",
      "Epoch 3198/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0753 - val_accuracy: 0.9851\n",
      "Epoch 3199/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0601 - val_accuracy: 0.9869\n",
      "Epoch 3200/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0606 - val_accuracy: 0.9860\n",
      "Epoch 3201/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.0611 - val_accuracy: 0.9874\n",
      "Epoch 3202/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0653 - val_accuracy: 0.9865\n",
      "Epoch 3203/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.0758 - val_accuracy: 0.9828\n",
      "Epoch 3204/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0568 - val_accuracy: 0.9869\n",
      "Epoch 3205/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
      "Epoch 3206/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0658 - val_accuracy: 0.9860\n",
      "Epoch 3207/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0580 - val_accuracy: 0.9865\n",
      "Epoch 3208/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0601 - val_accuracy: 0.9860\n",
      "Epoch 3209/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0600 - val_accuracy: 0.9860\n",
      "Epoch 3210/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.0577 - val_accuracy: 0.9855\n",
      "Epoch 3211/3500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0587 - val_accuracy: 0.9865\n",
      "Epoch 3212/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0543 - val_accuracy: 0.9879\n",
      "Epoch 3213/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0575 - val_accuracy: 0.9865\n",
      "Epoch 3214/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.0541 - val_accuracy: 0.9865\n",
      "Epoch 3215/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0591 - val_accuracy: 0.9865\n",
      "Epoch 3216/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.0583 - val_accuracy: 0.9874\n",
      "Epoch 3217/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0544 - val_accuracy: 0.9865\n",
      "Epoch 3218/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0601 - val_accuracy: 0.9869\n",
      "Epoch 3219/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0714 - val_accuracy: 0.9851\n",
      "Epoch 3220/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0544 - val_accuracy: 0.9888\n",
      "Epoch 3221/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0625 - val_accuracy: 0.9846\n",
      "Epoch 3222/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0678 - val_accuracy: 0.9846\n",
      "Epoch 3223/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0591 - val_accuracy: 0.9855\n",
      "Epoch 3224/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.0542 - val_accuracy: 0.9869\n",
      "Epoch 3225/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0556 - val_accuracy: 0.9869\n",
      "Epoch 3226/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.0644 - val_accuracy: 0.9855\n",
      "Epoch 3227/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0634 - val_accuracy: 0.9860\n",
      "Epoch 3228/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.0553 - val_accuracy: 0.9869\n",
      "Epoch 3229/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0544 - val_accuracy: 0.9883\n",
      "Epoch 3230/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0561 - val_accuracy: 0.9888\n",
      "Epoch 3231/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.0583 - val_accuracy: 0.9855\n",
      "Epoch 3232/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.0597 - val_accuracy: 0.9869\n",
      "Epoch 3233/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0574 - val_accuracy: 0.9869\n",
      "Epoch 3234/3500\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0572 - val_accuracy: 0.9860\n",
      "Epoch 3235/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0627 - val_accuracy: 0.9860\n",
      "Epoch 3236/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0635 - val_accuracy: 0.9855\n",
      "Epoch 3237/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0602 - val_accuracy: 0.9869\n",
      "Epoch 3238/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.0544 - val_accuracy: 0.9869\n",
      "Epoch 3239/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.0640 - val_accuracy: 0.9855\n",
      "Epoch 3240/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0578 - val_accuracy: 0.9865\n",
      "Epoch 3241/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.0551 - val_accuracy: 0.9879\n",
      "Epoch 3242/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0536 - val_accuracy: 0.9883\n",
      "Epoch 3243/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.0692 - val_accuracy: 0.9860\n",
      "Epoch 3244/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0562 - val_accuracy: 0.9893\n",
      "Epoch 3245/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0565 - val_accuracy: 0.9883\n",
      "Epoch 3246/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.0560 - val_accuracy: 0.9869\n",
      "Epoch 3247/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0583 - val_accuracy: 0.9879\n",
      "Epoch 3248/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0603 - val_accuracy: 0.9879\n",
      "Epoch 3249/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.0563 - val_accuracy: 0.9860\n",
      "Epoch 3250/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0569 - val_accuracy: 0.9869\n",
      "Epoch 3251/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0568 - val_accuracy: 0.9874\n",
      "Epoch 3252/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0645 - val_accuracy: 0.9869\n",
      "Epoch 3253/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0558 - val_accuracy: 0.9883\n",
      "Epoch 3254/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0565 - val_accuracy: 0.9865\n",
      "Epoch 3255/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0584 - val_accuracy: 0.9851\n",
      "Epoch 3256/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.0629 - val_accuracy: 0.9865\n",
      "Epoch 3257/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0669 - val_accuracy: 0.9865\n",
      "Epoch 3258/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.0573 - val_accuracy: 0.9869\n",
      "Epoch 3259/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0562 - val_accuracy: 0.9879\n",
      "Epoch 3260/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0599 - val_accuracy: 0.9888\n",
      "Epoch 3261/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0575 - val_accuracy: 0.9865\n",
      "Epoch 3262/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0562 - val_accuracy: 0.9874\n",
      "Epoch 3263/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0541 - val_accuracy: 0.9883\n",
      "Epoch 3264/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0563 - val_accuracy: 0.9879\n",
      "Epoch 3265/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0653 - val_accuracy: 0.9860\n",
      "Epoch 3266/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0554 - val_accuracy: 0.9860\n",
      "Epoch 3267/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0555 - val_accuracy: 0.9874\n",
      "Epoch 3268/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0671 - val_accuracy: 0.9841\n",
      "Epoch 3269/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.9952 - val_loss: 0.0711 - val_accuracy: 0.9851\n",
      "Epoch 3270/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0541 - val_accuracy: 0.9888\n",
      "Epoch 3271/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0616 - val_accuracy: 0.9860\n",
      "Epoch 3272/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0530 - val_accuracy: 0.9893\n",
      "Epoch 3273/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0561 - val_accuracy: 0.9879\n",
      "Epoch 3274/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0545 - val_accuracy: 0.9893\n",
      "Epoch 3275/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0602 - val_accuracy: 0.9860\n",
      "Epoch 3276/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.0576 - val_accuracy: 0.9869\n",
      "Epoch 3277/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0543 - val_accuracy: 0.9874\n",
      "Epoch 3278/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0600 - val_accuracy: 0.9883\n",
      "Epoch 3279/3500\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0620 - val_accuracy: 0.9860\n",
      "Epoch 3280/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.0574 - val_accuracy: 0.9883\n",
      "Epoch 3281/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0668 - val_accuracy: 0.9860\n",
      "Epoch 3282/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0541 - val_accuracy: 0.9874\n",
      "Epoch 3283/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0608 - val_accuracy: 0.9860\n",
      "Epoch 3284/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0568 - val_accuracy: 0.9893\n",
      "Epoch 3285/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0544 - val_accuracy: 0.9879\n",
      "Epoch 3286/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0552 - val_accuracy: 0.9865\n",
      "Epoch 3287/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.0569 - val_accuracy: 0.9874\n",
      "Epoch 3288/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.0568 - val_accuracy: 0.9888\n",
      "Epoch 3289/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0666 - val_accuracy: 0.9865\n",
      "Epoch 3290/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.0562 - val_accuracy: 0.9883\n",
      "Epoch 3291/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0621 - val_accuracy: 0.9879\n",
      "Epoch 3292/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0575 - val_accuracy: 0.9860\n",
      "Epoch 3293/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 0.0555 - val_accuracy: 0.9883\n",
      "Epoch 3294/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0578 - val_accuracy: 0.9874\n",
      "Epoch 3295/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0572 - val_accuracy: 0.9879\n",
      "Epoch 3296/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.0559 - val_accuracy: 0.9869\n",
      "Epoch 3297/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0645 - val_accuracy: 0.9865\n",
      "Epoch 3298/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.0544 - val_accuracy: 0.9874\n",
      "Epoch 3299/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0569 - val_accuracy: 0.9869\n",
      "Epoch 3300/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0737 - val_accuracy: 0.9846\n",
      "Epoch 3301/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0614 - val_accuracy: 0.9865\n",
      "Epoch 3302/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0596 - val_accuracy: 0.9869\n",
      "Epoch 3303/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0551 - val_accuracy: 0.9888\n",
      "Epoch 3304/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0592 - val_accuracy: 0.9883\n",
      "Epoch 3305/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0588 - val_accuracy: 0.9879\n",
      "Epoch 3306/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0596 - val_accuracy: 0.9865\n",
      "Epoch 3307/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0607 - val_accuracy: 0.9860\n",
      "Epoch 3308/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0577 - val_accuracy: 0.9874\n",
      "Epoch 3309/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0579 - val_accuracy: 0.9888\n",
      "Epoch 3310/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 0.0590 - val_accuracy: 0.9869\n",
      "Epoch 3311/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0586 - val_accuracy: 0.9874\n",
      "Epoch 3312/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0640 - val_accuracy: 0.9865\n",
      "Epoch 3313/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0550 - val_accuracy: 0.9879\n",
      "Epoch 3314/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0558 - val_accuracy: 0.9879\n",
      "Epoch 3315/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0568 - val_accuracy: 0.9869\n",
      "Epoch 3316/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0623 - val_accuracy: 0.9860\n",
      "Epoch 3317/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.0574 - val_accuracy: 0.9883\n",
      "Epoch 3318/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0609 - val_accuracy: 0.9874\n",
      "Epoch 3319/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0655 - val_accuracy: 0.9860\n",
      "Epoch 3320/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0707 - val_accuracy: 0.9855\n",
      "Epoch 3321/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0601 - val_accuracy: 0.9883\n",
      "Epoch 3322/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.0591 - val_accuracy: 0.9865\n",
      "Epoch 3323/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0565 - val_accuracy: 0.9865\n",
      "Epoch 3324/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0559 - val_accuracy: 0.9879\n",
      "Epoch 3325/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.0563 - val_accuracy: 0.9865\n",
      "Epoch 3326/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.0540 - val_accuracy: 0.9883\n",
      "Epoch 3327/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0505 - val_accuracy: 0.9879\n",
      "Epoch 3328/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.0536 - val_accuracy: 0.9888\n",
      "Epoch 3329/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0649 - val_accuracy: 0.9869\n",
      "Epoch 3330/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.0558 - val_accuracy: 0.9869\n",
      "Epoch 3331/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0524 - val_accuracy: 0.9897\n",
      "Epoch 3332/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0643 - val_accuracy: 0.9860\n",
      "Epoch 3333/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9949 - val_loss: 0.0599 - val_accuracy: 0.9879\n",
      "Epoch 3334/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0668 - val_accuracy: 0.9860\n",
      "Epoch 3335/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0777 - val_accuracy: 0.9841\n",
      "Epoch 3336/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0666 - val_accuracy: 0.9851\n",
      "Epoch 3337/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0616 - val_accuracy: 0.9874\n",
      "Epoch 3338/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.0668 - val_accuracy: 0.9860\n",
      "Epoch 3339/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.0631 - val_accuracy: 0.9869\n",
      "Epoch 3340/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.0628 - val_accuracy: 0.9879\n",
      "Epoch 3341/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.0653 - val_accuracy: 0.9865\n",
      "Epoch 3342/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.0597 - val_accuracy: 0.9855\n",
      "Epoch 3343/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9938 - val_loss: 0.0628 - val_accuracy: 0.9865\n",
      "Epoch 3344/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.0668 - val_accuracy: 0.9841\n",
      "Epoch 3345/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0624 - val_accuracy: 0.9883\n",
      "Epoch 3346/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0622 - val_accuracy: 0.9874\n",
      "Epoch 3347/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0696 - val_accuracy: 0.9837\n",
      "Epoch 3348/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.0719 - val_accuracy: 0.9865\n",
      "Epoch 3349/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0599 - val_accuracy: 0.9860\n",
      "Epoch 3350/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.0617 - val_accuracy: 0.9865\n",
      "Epoch 3351/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.0605 - val_accuracy: 0.9874\n",
      "Epoch 3352/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0565 - val_accuracy: 0.9883\n",
      "Epoch 3353/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0588 - val_accuracy: 0.9874\n",
      "Epoch 3354/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.0587 - val_accuracy: 0.9888\n",
      "Epoch 3355/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0575 - val_accuracy: 0.9874\n",
      "Epoch 3356/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.0616 - val_accuracy: 0.9869\n",
      "Epoch 3357/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0618 - val_accuracy: 0.9865\n",
      "Epoch 3358/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0590 - val_accuracy: 0.9879\n",
      "Epoch 3359/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0621 - val_accuracy: 0.9860\n",
      "Epoch 3360/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0618 - val_accuracy: 0.9865\n",
      "Epoch 3361/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0598 - val_accuracy: 0.9865\n",
      "Epoch 3362/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0657 - val_accuracy: 0.9865\n",
      "Epoch 3363/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.0570 - val_accuracy: 0.9869\n",
      "Epoch 3364/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0615 - val_accuracy: 0.9860\n",
      "Epoch 3365/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.0610 - val_accuracy: 0.9879\n",
      "Epoch 3366/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.0613 - val_accuracy: 0.9869\n",
      "Epoch 3367/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.0651 - val_accuracy: 0.9874\n",
      "Epoch 3368/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0606 - val_accuracy: 0.9855\n",
      "Epoch 3369/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0681 - val_accuracy: 0.9860\n",
      "Epoch 3370/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.0622 - val_accuracy: 0.9855\n",
      "Epoch 3371/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0626 - val_accuracy: 0.9865\n",
      "Epoch 3372/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.0562 - val_accuracy: 0.9869\n",
      "Epoch 3373/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0608 - val_accuracy: 0.9874\n",
      "Epoch 3374/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.0571 - val_accuracy: 0.9879\n",
      "Epoch 3375/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0635 - val_accuracy: 0.9865\n",
      "Epoch 3376/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0587 - val_accuracy: 0.9883\n",
      "Epoch 3377/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0626 - val_accuracy: 0.9860\n",
      "Epoch 3378/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.0628 - val_accuracy: 0.9851\n",
      "Epoch 3379/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.0610 - val_accuracy: 0.9883\n",
      "Epoch 3380/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0570 - val_accuracy: 0.9874\n",
      "Epoch 3381/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.0625 - val_accuracy: 0.9865\n",
      "Epoch 3382/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0613 - val_accuracy: 0.9883\n",
      "Epoch 3383/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0584 - val_accuracy: 0.9869\n",
      "Epoch 3384/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 0.0577 - val_accuracy: 0.9883\n",
      "Epoch 3385/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0593 - val_accuracy: 0.9874\n",
      "Epoch 3386/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0612 - val_accuracy: 0.9883\n",
      "Epoch 3387/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.0591 - val_accuracy: 0.9874\n",
      "Epoch 3388/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.0721 - val_accuracy: 0.9855\n",
      "Epoch 3389/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0631 - val_accuracy: 0.9869\n",
      "Epoch 3390/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0571 - val_accuracy: 0.9883\n",
      "Epoch 3391/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0593 - val_accuracy: 0.9865\n",
      "Epoch 3392/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0605 - val_accuracy: 0.9869\n",
      "Epoch 3393/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0625 - val_accuracy: 0.9865\n",
      "Epoch 3394/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0608 - val_accuracy: 0.9869\n",
      "Epoch 3395/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.0703 - val_accuracy: 0.9851\n",
      "Epoch 3396/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0582 - val_accuracy: 0.9879\n",
      "Epoch 3397/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0591 - val_accuracy: 0.9874\n",
      "Epoch 3398/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0619 - val_accuracy: 0.9869\n",
      "Epoch 3399/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0616 - val_accuracy: 0.9869\n",
      "Epoch 3400/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.0584 - val_accuracy: 0.9883\n",
      "Epoch 3401/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.0641 - val_accuracy: 0.9851\n",
      "Epoch 3402/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0602 - val_accuracy: 0.9865\n",
      "Epoch 3403/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.0621 - val_accuracy: 0.9879\n",
      "Epoch 3404/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.0613 - val_accuracy: 0.9874\n",
      "Epoch 3405/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.0588 - val_accuracy: 0.9865\n",
      "Epoch 3406/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0625 - val_accuracy: 0.9874\n",
      "Epoch 3407/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0596 - val_accuracy: 0.9869\n",
      "Epoch 3408/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.0588 - val_accuracy: 0.9879\n",
      "Epoch 3409/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.0574 - val_accuracy: 0.9879\n",
      "Epoch 3410/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0646 - val_accuracy: 0.9860\n",
      "Epoch 3411/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.0589 - val_accuracy: 0.9865\n",
      "Epoch 3412/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0664 - val_accuracy: 0.9860\n",
      "Epoch 3413/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9917 - val_loss: 0.0852 - val_accuracy: 0.9823\n",
      "Epoch 3414/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9929 - val_loss: 0.0631 - val_accuracy: 0.9879\n",
      "Epoch 3415/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0148 - accuracy: 0.9943 - val_loss: 0.0600 - val_accuracy: 0.9879\n",
      "Epoch 3416/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.0477 - val_accuracy: 0.9897\n",
      "Epoch 3417/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0750 - val_accuracy: 0.9879\n",
      "Epoch 3418/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0616 - val_accuracy: 0.9855\n",
      "Epoch 3419/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0680 - val_accuracy: 0.9869\n",
      "Epoch 3420/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0737 - val_accuracy: 0.9837\n",
      "Epoch 3421/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0551 - val_accuracy: 0.9888\n",
      "Epoch 3422/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0541 - val_accuracy: 0.9888\n",
      "Epoch 3423/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0654 - val_accuracy: 0.9865\n",
      "Epoch 3424/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0621 - val_accuracy: 0.9860\n",
      "Epoch 3425/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0568 - val_accuracy: 0.9879\n",
      "Epoch 3426/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.0554 - val_accuracy: 0.9883\n",
      "Epoch 3427/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.0608 - val_accuracy: 0.9879\n",
      "Epoch 3428/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.0588 - val_accuracy: 0.9869\n",
      "Epoch 3429/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0569 - val_accuracy: 0.9883\n",
      "Epoch 3430/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0564 - val_accuracy: 0.9874\n",
      "Epoch 3431/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0614 - val_accuracy: 0.9883\n",
      "Epoch 3432/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0644 - val_accuracy: 0.9855\n",
      "Epoch 3433/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0619 - val_accuracy: 0.9874\n",
      "Epoch 3434/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.0645 - val_accuracy: 0.9869\n",
      "Epoch 3435/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0550 - val_accuracy: 0.9879\n",
      "Epoch 3436/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0553 - val_accuracy: 0.9874\n",
      "Epoch 3437/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0541 - val_accuracy: 0.9888\n",
      "Epoch 3438/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0618 - val_accuracy: 0.9860\n",
      "Epoch 3439/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.0574 - val_accuracy: 0.9888\n",
      "Epoch 3440/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0578 - val_accuracy: 0.9879\n",
      "Epoch 3441/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0627 - val_accuracy: 0.9869\n",
      "Epoch 3442/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0579 - val_accuracy: 0.9883\n",
      "Epoch 3443/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.0626 - val_accuracy: 0.9879\n",
      "Epoch 3444/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0612 - val_accuracy: 0.9860\n",
      "Epoch 3445/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0764 - val_accuracy: 0.9841\n",
      "Epoch 3446/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9924 - val_loss: 0.0859 - val_accuracy: 0.9855\n",
      "Epoch 3447/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9901 - val_loss: 0.0687 - val_accuracy: 0.9841\n",
      "Epoch 3448/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9917 - val_loss: 0.0651 - val_accuracy: 0.9893\n",
      "Epoch 3449/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0571 - val_accuracy: 0.9874\n",
      "Epoch 3450/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.0616 - val_accuracy: 0.9855\n",
      "Epoch 3451/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.0570 - val_accuracy: 0.9883\n",
      "Epoch 3452/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.0832 - val_accuracy: 0.9841\n",
      "Epoch 3453/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9952 - val_loss: 0.0637 - val_accuracy: 0.9874\n",
      "Epoch 3454/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0613 - val_accuracy: 0.9874\n",
      "Epoch 3455/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.0539 - val_accuracy: 0.9893\n",
      "Epoch 3456/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0759 - val_accuracy: 0.9851\n",
      "Epoch 3457/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0560 - val_accuracy: 0.9897\n",
      "Epoch 3458/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0629 - val_accuracy: 0.9883\n",
      "Epoch 3459/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.0634 - val_accuracy: 0.9874\n",
      "Epoch 3460/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0613 - val_accuracy: 0.9869\n",
      "Epoch 3461/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0594 - val_accuracy: 0.9874\n",
      "Epoch 3462/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0665 - val_accuracy: 0.9865\n",
      "Epoch 3463/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0538 - val_accuracy: 0.9883\n",
      "Epoch 3464/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0572 - val_accuracy: 0.9883\n",
      "Epoch 3465/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0604 - val_accuracy: 0.9874\n",
      "Epoch 3466/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.0619 - val_accuracy: 0.9865\n",
      "Epoch 3467/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0761 - val_accuracy: 0.9832\n",
      "Epoch 3468/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9945 - val_loss: 0.0587 - val_accuracy: 0.9897\n",
      "Epoch 3469/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0551 - val_accuracy: 0.9865\n",
      "Epoch 3470/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0581 - val_accuracy: 0.9883\n",
      "Epoch 3471/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0580 - val_accuracy: 0.9883\n",
      "Epoch 3472/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0599 - val_accuracy: 0.9879\n",
      "Epoch 3473/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0629 - val_accuracy: 0.9888\n",
      "Epoch 3474/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0574 - val_accuracy: 0.9888\n",
      "Epoch 3475/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0582 - val_accuracy: 0.9883\n",
      "Epoch 3476/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0655 - val_accuracy: 0.9874\n",
      "Epoch 3477/3500\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0590 - val_accuracy: 0.9879\n",
      "Epoch 3478/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0580 - val_accuracy: 0.9865\n",
      "Epoch 3479/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.0580 - val_accuracy: 0.9883\n",
      "Epoch 3480/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.0665 - val_accuracy: 0.9860\n",
      "Epoch 3481/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0637 - val_accuracy: 0.9869\n",
      "Epoch 3482/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.0580 - val_accuracy: 0.9893\n",
      "Epoch 3483/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.0563 - val_accuracy: 0.9888\n",
      "Epoch 3484/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0614 - val_accuracy: 0.9879\n",
      "Epoch 3485/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.0621 - val_accuracy: 0.9865\n",
      "Epoch 3486/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.0645 - val_accuracy: 0.9869\n",
      "Epoch 3487/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0570 - val_accuracy: 0.9879\n",
      "Epoch 3488/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.0596 - val_accuracy: 0.9874\n",
      "Epoch 3489/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.0596 - val_accuracy: 0.9888\n",
      "Epoch 3490/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.0574 - val_accuracy: 0.9888\n",
      "Epoch 3491/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0616 - val_accuracy: 0.9869\n",
      "Epoch 3492/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.0710 - val_accuracy: 0.9855\n",
      "Epoch 3493/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0592 - val_accuracy: 0.9860\n",
      "Epoch 3494/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0615 - val_accuracy: 0.9883\n",
      "Epoch 3495/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0556 - val_accuracy: 0.9883\n",
      "Epoch 3496/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.0659 - val_accuracy: 0.9874\n",
      "Epoch 3497/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0632 - val_accuracy: 0.9869\n",
      "Epoch 3498/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0550 - val_accuracy: 0.9893\n",
      "Epoch 3499/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0618 - val_accuracy: 0.9874\n",
      "Epoch 3500/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.0806 - val_accuracy: 0.9837\n"
     ]
    }
   ],
   "source": [
    "# 그래프로 확인키위해 저장한 예측정확도를 변수에 저장\n",
    "df = df_pre.sample(frac = 0.15)\n",
    "history = model.fit(X, Y, validation_split=.33 , epochs=3500, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhWd0wOu6Ljv",
    "outputId": "8defac46-f3b8-48ec-a1c5-cb246c9f1051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss [0.043241944164037704, 0.0425618477165699, 0.04130805656313896, 0.04167474806308746, 0.04398937150835991, 0.04491792246699333, 0.0406486913561821, 0.04292851313948631, 0.04406024143099785, 0.048478756099939346, 0.04112214595079422, 0.04092991352081299, 0.040483810007572174, 0.04141620174050331, 0.03994433954358101, 0.04117366671562195, 0.0442604161798954, 0.04253679886460304, 0.04061147943139076, 0.04005296900868416, 0.03961919620633125, 0.039935313165187836, 0.04024115204811096, 0.04036198556423187, 0.040223900228738785, 0.04181281477212906, 0.04061058908700943, 0.04447762668132782, 0.04083404317498207, 0.042608100920915604, 0.04141728952527046, 0.04076360538601875, 0.041025515645742416, 0.03928264603018761, 0.03934195637702942, 0.039861347526311874, 0.040285129100084305, 0.04019032046198845, 0.039147865027189255, 0.041466355323791504, 0.04060205817222595, 0.03974175080657005, 0.03938081115484238, 0.03902676701545715, 0.03960946947336197, 0.03902541473507881, 0.04055159538984299, 0.03984394669532776, 0.04494921863079071, 0.042237456887960434, 0.042213186621665955, 0.04555296152830124, 0.04560404643416405, 0.04129170626401901, 0.04084925726056099, 0.041339557617902756, 0.04109986498951912, 0.04217320308089256, 0.04064879193902016, 0.0406930111348629, 0.04047894850373268, 0.04053772985935211, 0.040018003433942795, 0.03929318115115166, 0.04062087833881378, 0.03979774937033653, 0.039553191512823105, 0.03818879649043083, 0.03838063403964043, 0.038529716432094574, 0.038205523043870926, 0.038748741149902344, 0.03863251954317093, 0.03974457085132599, 0.0424385592341423, 0.040518470108509064, 0.040626268833875656, 0.04103931784629822, 0.03857850283384323, 0.03849607706069946, 0.039784159511327744, 0.041198570281267166, 0.03957066684961319, 0.0380142480134964, 0.03767530620098114, 0.03931650519371033, 0.03919031471014023, 0.0387209877371788, 0.038182564079761505, 0.03984388709068298, 0.03967270255088806, 0.04475843906402588, 0.0423164926469326, 0.040011927485466, 0.04100106656551361, 0.03762522339820862, 0.03785434365272522, 0.03763163089752197, 0.04168973118066788, 0.038195524364709854, 0.037721190601587296, 0.037372034043073654, 0.03775075450539589, 0.03785773366689682, 0.037967223674058914, 0.03704720363020897, 0.03777863457798958, 0.039916034787893295, 0.03942999988794327, 0.043060995638370514, 0.04038209095597267, 0.038853563368320465, 0.03705554082989693, 0.03717765212059021, 0.04041953384876251, 0.0440078042447567, 0.03788226842880249, 0.037495583295822144, 0.03716914728283882, 0.03805596008896828, 0.03719555214047432, 0.03764258697628975, 0.03720672428607941, 0.0369340255856514, 0.0381828173995018, 0.043149616569280624, 0.040614429861307144, 0.03773203119635582, 0.039013780653476715, 0.036760155111551285, 0.03921045362949371, 0.036339808255434036, 0.03815634176135063, 0.03787361457943916, 0.03972676396369934, 0.03729581460356712, 0.03670818358659744, 0.03691789507865906, 0.03705206140875816, 0.03666337579488754, 0.03741953894495964, 0.0397065207362175, 0.03977315127849579, 0.03792742267251015, 0.04065096005797386, 0.039223119616508484, 0.04073551297187805, 0.0372106209397316, 0.04021831974387169, 0.04090212285518646, 0.04516632482409477, 0.041640754789114, 0.03942444920539856, 0.03754069283604622, 0.03679459169507027, 0.0362401120364666, 0.03650032728910446, 0.03663879260420799, 0.03786666691303253, 0.03643333911895752, 0.036864690482616425, 0.037435952574014664, 0.03910313546657562, 0.04136001691222191, 0.03872028738260269, 0.037995774298906326, 0.039296410977840424, 0.03894687816500664, 0.040057357400655746, 0.04525056108832359, 0.04491254314780235, 0.04357835650444031, 0.037313539534807205, 0.03607121482491493, 0.03777735307812691, 0.03803131356835365, 0.03975948691368103, 0.036126941442489624, 0.03659605607390404, 0.037671200931072235, 0.039167147129774094, 0.03752363473176956, 0.037716612219810486, 0.03725622966885567, 0.03842054307460785, 0.03849739208817482, 0.0379534475505352, 0.036989327520132065, 0.0355537086725235, 0.03590290620923042, 0.035366471856832504, 0.03536127135157585, 0.03508279472589493, 0.036298397928476334, 0.036286186426877975, 0.03802609443664551, 0.03940696641802788, 0.03628009557723999, 0.037170492112636566, 0.03515329957008362, 0.036013711243867874, 0.035642221570014954, 0.03619991987943649, 0.03528376296162605, 0.036732275038957596, 0.04256083816289902, 0.04067787155508995, 0.038694996386766434, 0.03607742488384247, 0.03550801798701286, 0.03822994977235794, 0.03897504881024361, 0.035647980868816376, 0.03854118287563324, 0.03977072238922119, 0.03668937087059021, 0.04409421607851982, 0.038928717374801636, 0.037842221558094025, 0.035200055688619614, 0.034973084926605225, 0.036041438579559326, 0.03574034571647644, 0.034906722605228424, 0.03537362813949585, 0.03488883748650551, 0.03591054677963257, 0.03533535823225975, 0.03564479202032089, 0.037868060171604156, 0.037978336215019226, 0.03565377742052078, 0.036242131143808365, 0.034906286746263504, 0.03447487950325012, 0.036215316504240036, 0.03545234352350235, 0.03612079471349716, 0.03491906449198723, 0.03455289080739021, 0.03570108488202095, 0.03559691086411476, 0.03548680990934372, 0.04233274981379509, 0.03984495624899864, 0.03671877086162567, 0.03518567606806755, 0.03438631445169449, 0.03487441688776016, 0.03568892553448677, 0.03372778743505478, 0.0340864360332489, 0.03419387713074684, 0.03396889194846153, 0.03512657806277275, 0.034394022077322006, 0.03419176861643791, 0.03615786135196686, 0.040327876806259155, 0.034126728773117065, 0.03400284796953201, 0.03579410910606384, 0.035210419446229935, 0.03683518245816231, 0.03498699516057968, 0.03919548541307449, 0.03901619091629982, 0.0351296104490757, 0.03463667258620262, 0.03663359209895134, 0.03409804776310921, 0.035371631383895874, 0.03650526702404022, 0.03690582886338234, 0.03462081775069237, 0.034098997712135315, 0.033807720988988876, 0.03497784957289696, 0.03699520230293274, 0.036313608288764954, 0.03567016124725342, 0.0341951809823513, 0.03511827066540718, 0.03614761680364609, 0.03389040753245354, 0.03462493047118187, 0.03598758205771446, 0.0339832529425621, 0.03753587231040001, 0.03742918372154236, 0.03529425337910652, 0.03561227768659592, 0.0341169498860836, 0.03460732474923134, 0.036755017936229706, 0.03772296383976936, 0.034845270216464996, 0.03781110793352127, 0.037184715270996094, 0.035774555057287216, 0.03690171614289284, 0.034112852066755295, 0.0349116250872612, 0.033654119819402695, 0.03444555401802063, 0.034282609820365906, 0.03307628631591797, 0.03290193900465965, 0.03284021094441414, 0.03465985506772995, 0.03680017590522766, 0.033253613859415054, 0.03341500833630562, 0.033515315502882004, 0.03298385441303253, 0.03321228176355362, 0.03353456035256386, 0.03463229537010193, 0.0337502546608448, 0.03478092700242996, 0.03420281782746315, 0.03564943000674248, 0.03471044450998306, 0.03918776661157608, 0.03662542998790741, 0.035277109593153, 0.03288782387971878, 0.033391907811164856, 0.03326965495944023, 0.03328387066721916, 0.03329300507903099, 0.03221656754612923, 0.03299768269062042, 0.03279798850417137, 0.032072070986032486, 0.03218964487314224, 0.035709358751773834, 0.034242112189531326, 0.03345617279410362, 0.03454384207725525, 0.036156028509140015, 0.038476042449474335, 0.0330878309905529, 0.03355107083916664, 0.034136317670345306, 0.0323287770152092, 0.032021671533584595, 0.03192926198244095, 0.03357833996415138, 0.03217524290084839, 0.0323004387319088, 0.03177265450358391, 0.03238900378346443, 0.033597856760025024, 0.03296206519007683, 0.032769277691841125, 0.04077178239822388, 0.047958821058273315, 0.03919157385826111, 0.04216853529214859, 0.04198621213436127, 0.04209854453802109, 0.03525393828749657, 0.03210034966468811, 0.0322997123003006, 0.032310809940099716, 0.033689986914396286, 0.03377506509423256, 0.035585060715675354, 0.032795120030641556, 0.034368377178907394, 0.03343404084444046, 0.031989503651857376, 0.03195161744952202, 0.03193766996264458, 0.03225625306367874, 0.03159298002719879, 0.03312120959162712, 0.033086907118558884, 0.03236003220081329, 0.0346577987074852, 0.032610371708869934, 0.034501343965530396, 0.033386021852493286, 0.031636156141757965, 0.03204789757728577, 0.03367308899760246, 0.03794394060969353, 0.03121449053287506, 0.03143404796719551, 0.03115089423954487, 0.03164753317832947, 0.03177735209465027, 0.03206548094749451, 0.03272353857755661, 0.030955325812101364, 0.03239778056740761, 0.03264722228050232, 0.032669249922037125, 0.033189818263053894, 0.03479233384132385, 0.03319956734776497, 0.0373481884598732, 0.031547583639621735, 0.031228594481945038, 0.03166033327579498, 0.0313374288380146, 0.03163987398147583, 0.031166652217507362, 0.031795017421245575, 0.03482726588845253, 0.0406162291765213, 0.036110665649175644, 0.03546145558357239, 0.03278207778930664, 0.035737864673137665, 0.03141359984874725, 0.031196339055895805, 0.030937282368540764, 0.03254863619804382, 0.03225785493850708, 0.030847696587443352, 0.030813876539468765, 0.03002011775970459, 0.033428117632865906, 0.031495243310928345, 0.03398248553276062, 0.03238333389163017, 0.03132756054401398, 0.031467825174331665, 0.03134153410792351, 0.03565683960914612, 0.035135019570589066, 0.03326117992401123, 0.030343802645802498, 0.032848797738552094, 0.03590734302997589, 0.032022032886743546, 0.03125525638461113, 0.030857471749186516, 0.030769748613238335, 0.03135288506746292, 0.03185691311955452, 0.030088134109973907, 0.0318169891834259, 0.03306106850504875, 0.03171241655945778, 0.03289862349629402, 0.03564578667283058, 0.031533777713775635, 0.030031248927116394, 0.032174285501241684, 0.03057669848203659, 0.030954256653785706, 0.03039706125855446, 0.03318551182746887, 0.03601003810763359, 0.03422798588871956, 0.037155088037252426, 0.03916435316205025, 0.03232201188802719, 0.03131312504410744, 0.03009902685880661, 0.03125777468085289, 0.03205794841051102, 0.032966893166303635, 0.03209689259529114, 0.031238004565238953, 0.03389451652765274, 0.03420218825340271, 0.03142188489437103, 0.030415460467338562, 0.03001978062093258, 0.030594591051340103, 0.032572876662015915, 0.02951875887811184, 0.030670639127492905, 0.030394911766052246, 0.03047059290111065, 0.030188048258423805, 0.030289247632026672, 0.02979966439306736, 0.03221506252884865, 0.030434057116508484, 0.03180909529328346, 0.031236806884407997, 0.03351208195090294, 0.030699828639626503, 0.032057080417871475, 0.036503635346889496, 0.031094690784811974, 0.030510853976011276, 0.031770795583724976, 0.0343191958963871, 0.03263358771800995, 0.030916687101125717, 0.034728024154901505, 0.03158443048596382, 0.029562480747699738, 0.029473714530467987, 0.032138824462890625, 0.03721478953957558, 0.03079598769545555, 0.029495656490325928, 0.02963688038289547, 0.03263600915670395, 0.0307528767734766, 0.03280504420399666, 0.032345592975616455, 0.030124317854642868, 0.03052472323179245, 0.029647139832377434, 0.029550595209002495, 0.029314609244465828, 0.029428822919726372, 0.029052482917904854, 0.02974151447415352, 0.029489966109395027, 0.03007383644580841, 0.029896482825279236, 0.032922469079494476, 0.02984616719186306, 0.03090612031519413, 0.0298017468303442, 0.03021560050547123, 0.02999396249651909, 0.0310648363083601, 0.03483965992927551, 0.035326529294252396, 0.029816003516316414, 0.02992592751979828, 0.028870463371276855, 0.02876271866261959, 0.02866537682712078, 0.029030950739979744, 0.030913598835468292, 0.02984631434082985, 0.028971955180168152, 0.02854551002383232, 0.030249519273638725, 0.03030870296061039, 0.03305913880467415, 0.03697989508509636, 0.03303257003426552, 0.030194608494639397, 0.030893364921212196, 0.030161861330270767, 0.0314180813729763, 0.0295890960842371, 0.029599424451589584, 0.03019852563738823, 0.028604768216609955, 0.028947511687874794, 0.029253598302602768, 0.0314028337597847, 0.031220948323607445, 0.028673803433775902, 0.028873294591903687, 0.02888631634414196, 0.02875743806362152, 0.029714833945035934, 0.0292261503636837, 0.029461296275258064, 0.029497532173991203, 0.030238214880228043, 0.02952447347342968, 0.02986535243690014, 0.030362717807292938, 0.0295255184173584, 0.028789153322577477, 0.028958404436707497, 0.030511872842907906, 0.0290240328758955, 0.02957172319293022, 0.028915883973240852, 0.028421955183148384, 0.028244953602552414, 0.028552010655403137, 0.028771650046110153, 0.028347646817564964, 0.02793116867542267, 0.02944226749241352, 0.028437180444598198, 0.028212396427989006, 0.028060896322131157, 0.031252242624759674, 0.029146207496523857, 0.03038780763745308, 0.028713837265968323, 0.03336235508322716, 0.033910300582647324, 0.028588293120265007, 0.028631940484046936, 0.029957449063658714, 0.029229069128632545, 0.02989991195499897, 0.02940097264945507, 0.028660371899604797, 0.028962310403585434, 0.028187815099954605, 0.029307138174772263, 0.0312919020652771, 0.03121044673025608, 0.030081462115049362, 0.027892496436834335, 0.028083432465791702, 0.029184328392148018, 0.030669288709759712, 0.029146241024136543, 0.03091384656727314, 0.029572412371635437, 0.030906565487384796, 0.029028987511992455, 0.02838336117565632, 0.028132416307926178, 0.02830582857131958, 0.028370704501867294, 0.03149190917611122, 0.03208071365952492, 0.0323287695646286, 0.03127017617225647, 0.029113657772541046, 0.028277738019824028, 0.02964583970606327, 0.029763543978333473, 0.03192935138940811, 0.029569264501333237, 0.028653567656874657, 0.028287533670663834, 0.02836330235004425, 0.032070789486169815, 0.031146053224802017, 0.03429955989122391, 0.030516238883137703, 0.02836555801331997, 0.028306225314736366, 0.028313539922237396, 0.0285255778580904, 0.029765931889414787, 0.02987956628203392, 0.028392568230628967, 0.027501221746206284, 0.030482428148388863, 0.030919035896658897, 0.029761258512735367, 0.028354182839393616, 0.030721982941031456, 0.02900237962603569, 0.028481975197792053, 0.028841692954301834, 0.032357193529605865, 0.031002890318632126, 0.02823379822075367, 0.028906207531690598, 0.02881903201341629, 0.028199441730976105, 0.029309913516044617, 0.029675673693418503, 0.029933810234069824, 0.028209520503878593, 0.029806680977344513, 0.02874089777469635, 0.029370516538619995, 0.028906073421239853, 0.027300987392663956, 0.027599504217505455, 0.027417819947004318, 0.028323465958237648, 0.027728214859962463, 0.027354732155799866, 0.02749912068247795, 0.03139050304889679, 0.031037000939249992, 0.029183655977249146, 0.028721479699015617, 0.027245644479990005, 0.02770933136343956, 0.02996380254626274, 0.028839847072958946, 0.030522899702191353, 0.03070448338985443, 0.03526756912469864, 0.030141424387693405, 0.028802191838622093, 0.031081410124897957, 0.03732996806502342, 0.033051878213882446, 0.028948456048965454, 0.030294926837086678, 0.027625955641269684, 0.02787553146481514, 0.02752985991537571, 0.02908695861697197, 0.02750476449728012, 0.02821465954184532, 0.029085474088788033, 0.027659179642796516, 0.027016349136829376, 0.027091488242149353, 0.027823736891150475, 0.02694445475935936, 0.0273978840559721, 0.02723759412765503, 0.028011474758386612, 0.02740292251110077, 0.027239592745900154, 0.027739394456148148, 0.02833331562578678, 0.028381558135151863, 0.026648759841918945, 0.026927689090371132, 0.026953302323818207, 0.026868239045143127, 0.028868399560451508, 0.02823329158127308, 0.029669295996427536, 0.030768653377890587, 0.030064599588513374, 0.029321100562810898, 0.028277313336730003, 0.028361914679408073, 0.029026329517364502, 0.029137374833226204, 0.03102252446115017, 0.028052188456058502, 0.027499454095959663, 0.028028909116983414, 0.028031950816512108, 0.0302426740527153, 0.02840099297463894, 0.026809200644493103, 0.0283893384039402, 0.029061762616038322, 0.02756851725280285, 0.02739216387271881, 0.028289763256907463, 0.027309594675898552, 0.026389047503471375, 0.02774069644510746, 0.027645284309983253, 0.027366632595658302, 0.02694513648748398, 0.027353573590517044, 0.02819242887198925, 0.028384361416101456, 0.027191942557692528, 0.02881830371916294, 0.0267181396484375, 0.02739662677049637, 0.027901452034711838, 0.027351148426532745, 0.027641257271170616, 0.02665657177567482, 0.027238713577389717, 0.026636291295289993, 0.02730259671807289, 0.026990875601768494, 0.027081483975052834, 0.02726271003484726, 0.02706427499651909, 0.027168050408363342, 0.02923234924674034, 0.0333971232175827, 0.028021840378642082, 0.02890707738697529, 0.027470484375953674, 0.026512889191508293, 0.02897724322974682, 0.027822932228446007, 0.030839398503303528, 0.026922481134533882, 0.032602209597826004, 0.029220206663012505, 0.027124710381031036, 0.02843845635652542, 0.02668345347046852, 0.0276455357670784, 0.02713826298713684, 0.026716060936450958, 0.026324525475502014, 0.026749495416879654, 0.02643740549683571, 0.02724349871277809, 0.026664048433303833, 0.027568090707063675, 0.028551800176501274, 0.026637759059667587, 0.02786884270608425, 0.02605406939983368, 0.026489291340112686, 0.026881176978349686, 0.026531033217906952, 0.0314176119863987, 0.02868620492517948, 0.026465529575943947, 0.027028121054172516, 0.027459803968667984, 0.02746168151497841, 0.026472600176930428, 0.026812702417373657, 0.026645705103874207, 0.02566804550588131, 0.028067782521247864, 0.027766350656747818, 0.02670779637992382, 0.029021115973591805, 0.0285404771566391, 0.033236704766750336, 0.02882934734225273, 0.027559272944927216, 0.026233654469251633, 0.025865845382213593, 0.02852463163435459, 0.03210948035120964, 0.03056725300848484, 0.027683425694704056, 0.02684096060693264, 0.02667246200144291, 0.028226057067513466, 0.029903391376137733, 0.02906239777803421, 0.027880001813173294, 0.02961568906903267, 0.028874797746539116, 0.027087600901722908, 0.030476108193397522, 0.03082161396741867, 0.028347821906208992, 0.0269077867269516, 0.02746567688882351, 0.027759553864598274, 0.026332082226872444, 0.026124030351638794, 0.026081766933202744, 0.02740781009197235, 0.02630256675183773, 0.02704397775232792, 0.026772551238536835, 0.026731211692094803, 0.028209157288074493, 0.029055651277303696, 0.02609337866306305, 0.026327820494771004, 0.02755572646856308, 0.02605189010500908, 0.026083387434482574, 0.0256207175552845, 0.029378706589341164, 0.026507537811994553, 0.026484355330467224, 0.026144858449697495, 0.027240389958024025, 0.027787543833255768, 0.026058020070195198, 0.026237888261675835, 0.02590004913508892, 0.025923162698745728, 0.02512449584901333, 0.025663573294878006, 0.03177911415696144, 0.0363420695066452, 0.03090023249387741, 0.029814355075359344, 0.029006365686655045, 0.030042847618460655, 0.028672317042946815, 0.02981429547071457, 0.03015824221074581, 0.031706321984529495, 0.03539317101240158, 0.037110548466444016, 0.027588913217186928, 0.0270864125341177, 0.028637656942009926, 0.030861318111419678, 0.028994834050536156, 0.02760227583348751, 0.027557622641324997, 0.0302905160933733, 0.029289504513144493, 0.028981268405914307, 0.02707783505320549, 0.030441300943493843, 0.027027921751141548, 0.028264811262488365, 0.02896254137158394, 0.026762492954730988, 0.026766952127218246, 0.026076575741171837, 0.02610594779253006, 0.027361225336790085, 0.026367133483290672, 0.02596159465610981, 0.025680676102638245, 0.025528941303491592, 0.025087563320994377, 0.02531374990940094, 0.02747366391122341, 0.026314036920666695, 0.028251711279153824, 0.025505244731903076, 0.025526322424411774, 0.027449771761894226, 0.02614925056695938, 0.026184335350990295, 0.02654842473566532, 0.02703678607940674, 0.025684334337711334, 0.025326287373900414, 0.026567872613668442, 0.027407517656683922, 0.027439910918474197, 0.026798201724886894, 0.025766676291823387, 0.025599928572773933, 0.025619808584451675, 0.026103775948286057, 0.02626745216548443, 0.027758384123444557, 0.028991851955652237, 0.02723929099738598, 0.025544216856360435, 0.026077494025230408, 0.024797912687063217, 0.025057736784219742, 0.027330506592988968, 0.02758697047829628, 0.02822733484208584, 0.024963174015283585, 0.0249289833009243, 0.02620561420917511, 0.02520635724067688, 0.02451787143945694, 0.03128442168235779, 0.02880999818444252, 0.033149220049381256, 0.030699344351887703, 0.02855333499610424, 0.027170661836862564, 0.026712145656347275, 0.025309354066848755, 0.025329114869236946, 0.025339879095554352, 0.02485491894185543, 0.02554251253604889, 0.025827335193753242, 0.02804982103407383, 0.02612137980759144, 0.025201275944709778, 0.024993129074573517, 0.025525826960802078, 0.026084430515766144, 0.025279410183429718, 0.025514980778098106, 0.02556501515209675, 0.027214601635932922, 0.025711199268698692, 0.027484603226184845, 0.026009323075413704, 0.024837655946612358, 0.025513697415590286, 0.026080414652824402, 0.026545947417616844, 0.026400502771139145, 0.02680031582713127, 0.024925699457526207, 0.027838803827762604, 0.02501203492283821, 0.024299755692481995, 0.024347158148884773, 0.025393586605787277, 0.025277020409703255, 0.024479864165186882, 0.028241248801350594, 0.027686353772878647, 0.027207445353269577, 0.023961789906024933, 0.025220319628715515, 0.024526922032237053, 0.023784803226590157, 0.025047127157449722, 0.02558966912329197, 0.026934653520584106, 0.026259401813149452, 0.027283819392323494, 0.027916019782423973, 0.025608249008655548, 0.025123413652181625, 0.028200363740324974, 0.02571553736925125, 0.025173207744956017, 0.024164224043488503, 0.025511514395475388, 0.02414572238922119, 0.024490294978022575, 0.02665676176548004, 0.026129385456442833, 0.02494552731513977, 0.02400176413357258, 0.026655888184905052, 0.025612253695726395, 0.02478855289518833, 0.029528992250561714, 0.026392469182610512, 0.023537639528512955, 0.024045659229159355, 0.02402360551059246, 0.02681480161845684, 0.02901252545416355, 0.02885272353887558, 0.02646356076002121, 0.024689899757504463, 0.026192229241132736, 0.03010966069996357, 0.03043201006948948, 0.03000636398792267, 0.0298099797219038, 0.027403051033616066, 0.026548519730567932, 0.024461563676595688, 0.026106970384716988, 0.024686213582754135, 0.025400232523679733, 0.02412264049053192, 0.02449224889278412, 0.025177553296089172, 0.024515366181731224, 0.023933567106723785, 0.024973228573799133, 0.02410963550209999, 0.02488306723535061, 0.02553214691579342, 0.02517174929380417, 0.02497827634215355, 0.024633044376969337, 0.023819051682949066, 0.025168700143694878, 0.025012051686644554, 0.031100785359740257, 0.027313992381095886, 0.025345636531710625, 0.025115543976426125, 0.024415310472249985, 0.024363147094845772, 0.024137884378433228, 0.02515716850757599, 0.028278902173042297, 0.025547800585627556, 0.02677817828953266, 0.02736268937587738, 0.024854183197021484, 0.025000598281621933, 0.028571842238307, 0.029710881412029266, 0.032930802553892136, 0.029618442058563232, 0.03255866467952728, 0.029912510886788368, 0.028440231457352638, 0.028014449402689934, 0.02546876110136509, 0.024198325350880623, 0.025154156610369682, 0.023669449612498283, 0.025164708495140076, 0.023783857002854347, 0.024168210104107857, 0.023538589477539062, 0.024156272411346436, 0.024424578994512558, 0.0248119980096817, 0.023665718734264374, 0.023786447942256927, 0.023930560797452927, 0.024758310988545418, 0.02715534158051014, 0.027854718267917633, 0.024826694279909134, 0.025495056062936783, 0.02346017211675644, 0.024491433054208755, 0.024532213807106018, 0.026355482637882233, 0.02542736753821373, 0.025397317484021187, 0.02607913129031658, 0.02661440148949623, 0.02343110181391239, 0.023391222581267357, 0.025693606585264206, 0.025741983205080032, 0.023845499381422997, 0.02369542419910431, 0.023171328008174896, 0.02390468120574951, 0.02309231460094452, 0.02388426475226879, 0.02349613606929779, 0.0248174536973238, 0.024277733638882637, 0.02316431887447834, 0.02550150267779827, 0.024647217243909836, 0.024699077010154724, 0.023407116532325745, 0.0231271181255579, 0.023540128022432327, 0.023425359278917313, 0.022668980062007904, 0.02320961095392704, 0.023546895012259483, 0.024998558685183525, 0.023413537070155144, 0.02318737283349037, 0.02438676916062832, 0.02518598921597004, 0.02324453555047512, 0.03507622703909874, 0.035276323556900024, 0.028358647599816322, 0.025487124919891357, 0.026195315644145012, 0.02600787580013275, 0.025990083813667297, 0.0278580691665411, 0.023805424571037292, 0.023147566244006157, 0.027691522613167763, 0.025595393031835556, 0.02423226274549961, 0.02384028024971485, 0.02359836734831333, 0.023850910365581512, 0.023063264787197113, 0.022789904847741127, 0.02289927750825882, 0.02315022423863411, 0.02514585293829441, 0.022745030000805855, 0.022577114403247833, 0.02338487282395363, 0.024084804579615593, 0.02314792573451996, 0.022395983338356018, 0.021971283480525017, 0.022059185430407524, 0.026398442685604095, 0.025846222415566444, 0.02378641813993454, 0.022768331691622734, 0.024070188403129578, 0.02311345562338829, 0.02508656121790409, 0.02256651222705841, 0.023004421964287758, 0.023935958743095398, 0.022509491071105003, 0.02477593719959259, 0.02554444782435894, 0.02402782067656517, 0.022819673642516136, 0.02259100042283535, 0.022909771651029587, 0.023560624569654465, 0.02275882102549076, 0.022171514108777046, 0.023517342284321785, 0.02570297382771969, 0.024928078055381775, 0.028235124424099922, 0.024767626076936722, 0.02458847314119339, 0.02755923569202423, 0.02427617833018303, 0.023290691897273064, 0.026830656453967094, 0.02285490557551384, 0.024103453382849693, 0.023911574855446815, 0.02373928390443325, 0.022743646055459976, 0.022675925865769386, 0.02291116863489151, 0.024158667773008347, 0.027162674814462662, 0.024382008239626884, 0.024308064952492714, 0.02375732734799385, 0.02500523068010807, 0.02490101382136345, 0.024483075365424156, 0.02344256266951561, 0.022818783298134804, 0.024731745943427086, 0.02436468005180359, 0.023905716836452484, 0.023255642503499985, 0.02265375293791294, 0.025910766795277596, 0.028056912124156952, 0.03046835958957672, 0.0234305951744318, 0.02232597954571247, 0.022259898483753204, 0.02314121276140213, 0.024914458394050598, 0.02526937611401081, 0.023683026432991028, 0.022333985194563866, 0.02330605685710907, 0.025452177971601486, 0.02273007482290268, 0.024610204622149467, 0.025048986077308655, 0.028919408097863197, 0.02890850603580475, 0.02396260015666485, 0.022631004452705383, 0.02224542200565338, 0.022364208474755287, 0.021981636062264442, 0.022887198254466057, 0.021553149446845055, 0.02286195009946823, 0.0222610030323267, 0.02249731682240963, 0.02508411929011345, 0.022842343896627426, 0.02295217290520668, 0.02327660284936428, 0.02383205108344555, 0.025009341537952423, 0.02226259745657444, 0.02249683439731598, 0.023052092641592026, 0.02349790558218956, 0.021873565390706062, 0.021633295342326164, 0.022413993254303932, 0.021838882938027382, 0.022990193217992783, 0.021701976656913757, 0.02658330462872982, 0.02453659474849701, 0.024257680401206017, 0.024102644994854927, 0.024052539840340614, 0.025871025398373604, 0.026399977505207062, 0.029520118609070778, 0.035409800708293915, 0.026006732136011124, 0.022891413420438766, 0.0233077984303236, 0.021762151271104813, 0.02241462841629982, 0.02327292412519455, 0.023275261744856834, 0.026861973106861115, 0.022809069603681564, 0.021575525403022766, 0.024323755875229836, 0.02796592377126217, 0.025587182492017746, 0.02268373966217041, 0.029364805668592453, 0.026004234328866005, 0.021640904247760773, 0.021788055077195168, 0.022322937846183777, 0.021991046145558357, 0.022136839106678963, 0.022985296323895454, 0.02173769474029541, 0.021368635818362236, 0.021060558035969734, 0.021363286301493645, 0.022109005600214005, 0.021356061100959778, 0.021636785939335823, 0.02133769355714321, 0.022080035880208015, 0.020540611818432808, 0.02373037301003933, 0.024910787120461464, 0.02499556355178356, 0.022025980055332184, 0.020774254575371742, 0.02258908748626709, 0.02469184808433056, 0.023138783872127533, 0.022949954494833946, 0.023814797401428223, 0.02402571588754654, 0.02103389799594879, 0.03256053850054741, 0.02427827939391136, 0.02314843237400055, 0.023907607421278954, 0.023989785462617874, 0.02425745502114296, 0.02389761619269848, 0.025447748601436615, 0.025793330743908882, 0.023432118818163872, 0.022615477442741394, 0.02249743789434433, 0.02241898700594902, 0.02190585620701313, 0.022950677201151848, 0.022175118327140808, 0.022125350311398506, 0.022164061665534973, 0.02149207331240177, 0.020599329844117165, 0.02271522581577301, 0.02155323140323162, 0.02056497521698475, 0.02290049009025097, 0.021703824400901794, 0.024419385939836502, 0.02282211184501648, 0.02247641049325466, 0.022137269377708435, 0.02194087952375412, 0.02105318009853363, 0.02138187363743782, 0.021933920681476593, 0.0231159795075655, 0.028033435344696045, 0.025361109524965286, 0.03133931756019592, 0.02376238815486431, 0.024046992883086205, 0.02352447435259819, 0.02592584490776062, 0.02676020748913288, 0.023114077746868134, 0.023425232619047165, 0.026354797184467316, 0.024727053940296173, 0.025435183197259903, 0.02357243001461029, 0.022202732041478157, 0.021617118269205093, 0.024387918412685394, 0.022042246535420418, 0.02216094732284546, 0.021096395328640938, 0.022608987987041473, 0.023544088006019592, 0.021544909104704857, 0.020630165934562683, 0.022294558584690094, 0.02271975576877594, 0.023049823939800262, 0.021484525874257088, 0.021579066291451454, 0.021024473011493683, 0.02165128104388714, 0.020865030586719513, 0.021832231432199478, 0.02111363410949707, 0.021433541551232338, 0.021017244085669518, 0.022481044754385948, 0.02550812065601349, 0.02115301415324211, 0.020762920379638672, 0.021316906437277794, 0.023928795009851456, 0.02812153287231922, 0.02841256931424141, 0.03027932718396187, 0.031882502138614655, 0.029023192822933197, 0.0236970242112875, 0.0217749010771513, 0.022057225927710533, 0.02174929715692997, 0.022389933466911316, 0.023394644260406494, 0.023538287729024887, 0.021874956786632538, 0.02179519645869732, 0.021098002791404724, 0.020103013142943382, 0.02114846743643284, 0.02254934050142765, 0.024344081059098244, 0.02037823386490345, 0.021792206913232803, 0.021020766347646713, 0.022027408704161644, 0.025794869288802147, 0.02347484417259693, 0.02285517007112503, 0.02179599553346634, 0.02209066040813923, 0.021745167672634125, 0.028495943173766136, 0.03110860288143158, 0.031745657324790955, 0.025788437575101852, 0.02266215905547142, 0.025228526443243027, 0.02219078503549099, 0.023274634033441544, 0.022175177931785583, 0.02215675637125969, 0.021853232756257057, 0.028302142396569252, 0.02752665802836418, 0.02520854026079178, 0.023642918094992638, 0.02137940749526024, 0.0209769569337368, 0.020153310149908066, 0.02079230360686779, 0.020651625469326973, 0.0228760726749897, 0.020534509792923927, 0.02258448116481304, 0.0239119715988636, 0.022119984030723572, 0.02385924756526947, 0.021860413253307343, 0.0233550276607275, 0.022531595081090927, 0.02419937402009964, 0.02482973039150238, 0.023183586075901985, 0.022697947919368744, 0.023251235485076904, 0.02195844054222107, 0.020319221541285515, 0.0200054831802845, 0.0220381710678339, 0.020442869514226913, 0.023691322654485703, 0.02449888363480568, 0.027720371261239052, 0.02225973643362522, 0.023577500134706497, 0.025135617703199387, 0.02160295471549034, 0.02041475474834442, 0.021273458376526833, 0.021846704185009003, 0.020631039515137672, 0.023818399757146835, 0.02108369953930378, 0.021621858701109886, 0.02292366325855255, 0.021290145814418793, 0.020726516842842102, 0.023528195917606354, 0.021020693704485893, 0.021337183192372322, 0.023347236216068268, 0.021326977759599686, 0.021054020151495934, 0.022461574524641037, 0.022130431607365608, 0.020527023822069168, 0.021575314924120903, 0.02181616611778736, 0.021264933049678802, 0.023875826969742775, 0.022231921553611755, 0.02516287937760353, 0.02693571336567402, 0.023728303611278534, 0.021274732425808907, 0.020241811871528625, 0.02100306563079357, 0.02004976198077202, 0.020591840147972107, 0.02058619260787964, 0.022391289472579956, 0.02258528769016266, 0.02136867493391037, 0.02003319188952446, 0.020655637606978416, 0.020952707156538963, 0.020180489867925644, 0.02124137431383133, 0.02435077540576458, 0.02197677455842495, 0.01993865892291069, 0.020616920664906502, 0.020154878497123718, 0.02180318534374237, 0.019752660766243935, 0.020298244431614876, 0.02107383869588375, 0.02060537226498127, 0.023368656635284424, 0.020309502258896828, 0.02050192840397358, 0.02059580385684967, 0.02190384827554226, 0.021938607096672058, 0.020156724378466606, 0.02280854620039463, 0.022763028740882874, 0.02102435939013958, 0.023352675139904022, 0.02227560244500637, 0.019537702202796936, 0.02121766470372677, 0.025128187611699104, 0.026145339012145996, 0.0258199330419302, 0.020883021876215935, 0.021063275635242462, 0.02049729786813259, 0.021350698545575142, 0.021703511476516724, 0.020755700767040253, 0.02068929374217987, 0.02155645191669464, 0.02167089655995369, 0.02321353182196617, 0.022735046222805977, 0.020527128130197525, 0.021025247871875763, 0.020389841869473457, 0.021349279209971428, 0.020056691020727158, 0.01999712362885475, 0.020072484388947487, 0.02035575918853283, 0.0213025975972414, 0.019362129271030426, 0.02190013974905014, 0.02048966847360134, 0.019785994663834572, 0.022207513451576233, 0.02216908149421215, 0.0210107509046793, 0.019839942455291748, 0.021145446226000786, 0.019902793690562248, 0.01978774555027485, 0.02065456658601761, 0.020452305674552917, 0.022304609417915344, 0.02002989873290062, 0.021180814132094383, 0.021020343527197838, 0.02091672271490097, 0.02260197326540947, 0.022196486592292786, 0.020852576941251755, 0.01914862170815468, 0.023173710331320763, 0.020818106830120087, 0.020235564559698105, 0.01979738287627697, 0.019435111433267593, 0.020618559792637825, 0.021631574258208275, 0.022198036313056946, 0.0227209385484457, 0.021970922127366066, 0.01943427138030529, 0.01979646272957325, 0.019876735284924507, 0.019241558387875557, 0.01980784349143505, 0.020010244101285934, 0.02054586075246334, 0.020567046478390694, 0.023069094866514206, 0.02187971957027912, 0.02280988171696663, 0.023480074480175972, 0.021704884245991707, 0.02314854972064495, 0.022604184225201607, 0.02756878361105919, 0.02211526408791542, 0.021526312455534935, 0.02121259644627571, 0.01886008493602276, 0.0194686446338892, 0.019902342930436134, 0.01935846172273159, 0.01894320175051689, 0.021053040400147438, 0.022189315408468246, 0.023289786651730537, 0.023117223754525185, 0.026014119386672974, 0.02397710457444191, 0.02293657884001732, 0.02196541056036949, 0.02034759148955345, 0.019789936020970345, 0.021024079993367195, 0.021296599879860878, 0.022383883595466614, 0.02588295005261898, 0.02557762712240219, 0.023379040881991386, 0.020555054768919945, 0.022076502442359924, 0.020487476140260696, 0.019770577549934387, 0.020294349640607834, 0.01998821273446083, 0.02179891988635063, 0.021694600582122803, 0.02272341214120388, 0.023566221818327904, 0.023572929203510284, 0.02253909595310688, 0.019583238288760185, 0.019405435770750046, 0.019383057951927185, 0.019717682152986526, 0.019839627668261528, 0.019835729151964188, 0.019361838698387146, 0.021051524206995964, 0.02019691839814186, 0.019469497725367546, 0.02161436714231968, 0.02433134615421295, 0.022181706503033638, 0.020833779126405716, 0.02054564282298088, 0.020978203043341637, 0.020767677575349808, 0.021168677136301994, 0.021727552637457848, 0.02285490371286869, 0.022879913449287415, 0.023410169407725334, 0.02087835967540741, 0.0193987637758255, 0.02025863714516163, 0.020874295383691788, 0.022077331319451332, 0.021049562841653824, 0.025260185822844505, 0.022764578461647034, 0.021006019786000252, 0.020346418023109436, 0.021306447684764862, 0.02144613303244114, 0.022240694612264633, 0.02054719626903534, 0.02324729412794113, 0.02128114551305771, 0.021103249862790108, 0.020185884088277817, 0.020544132217764854, 0.022282367572188377, 0.02214622125029564, 0.019157826900482178, 0.02038845419883728, 0.02019677124917507, 0.019380049780011177, 0.01855943538248539, 0.01908262073993683, 0.020060792565345764, 0.018419861793518066, 0.018727725371718407, 0.01941612735390663, 0.01985299214720726, 0.01972617208957672, 0.018572483211755753, 0.018984174355864525, 0.019133225083351135, 0.019425775855779648, 0.019637173041701317, 0.021266771480441093, 0.018828248605132103, 0.01893210969865322, 0.01978176459670067, 0.023870432749390602, 0.022173285484313965, 0.020320387557148933, 0.018979515880346298, 0.018581584095954895, 0.019643548876047134, 0.018574103713035583, 0.019612856209278107, 0.01982589066028595, 0.02055494301021099, 0.02251393161714077, 0.025196613743901253, 0.02291090041399002, 0.021057697013020515, 0.019409537315368652, 0.021299954503774643, 0.02084251493215561, 0.020428631454706192, 0.018970565870404243, 0.021869661286473274, 0.023748070001602173, 0.03066689521074295, 0.026411518454551697, 0.02332366071641445, 0.0220708716660738, 0.02099316194653511, 0.019294479861855507, 0.0199811402708292, 0.021126078441739082, 0.019248085096478462, 0.019899819046258926, 0.021333858370780945, 0.024430911988019943, 0.023412063717842102, 0.020395556464791298, 0.020424433052539825, 0.018408991396427155, 0.019030459225177765, 0.0182881448417902, 0.020300550386309624, 0.0191631056368351, 0.020697375759482384, 0.0202557984739542, 0.019718773663043976, 0.01868046261370182, 0.020873907953500748, 0.020272180438041687, 0.020282885059714317, 0.018967682495713234, 0.01920023187994957, 0.01953258365392685, 0.019088901579380035, 0.019294176250696182, 0.020130719989538193, 0.019319932907819748, 0.01997409760951996, 0.01890329085290432, 0.0208660326898098, 0.021831290796399117, 0.02197025530040264, 0.019283542409539223, 0.019472116604447365, 0.017963513731956482, 0.01924099773168564, 0.018995074555277824, 0.02007524110376835, 0.020101021975278854, 0.01948317512869835, 0.019488707184791565, 0.021884538233280182, 0.022217389196157455, 0.020012184977531433, 0.02047891728579998, 0.018778102472424507, 0.020623434334993362, 0.019395487383008003, 0.022272620350122452, 0.02007824182510376, 0.018584895879030228, 0.01867518573999405, 0.02330142818391323, 0.024453578516840935, 0.022643720731139183, 0.020142225548624992, 0.020131820812821388, 0.02351173758506775, 0.02260122448205948, 0.01994975097477436, 0.02012334205210209, 0.022119728848338127, 0.025184087455272675, 0.021988824009895325, 0.01889563538134098, 0.0185784213244915, 0.02263732999563217, 0.0207817405462265, 0.020182017236948013, 0.019325921311974525, 0.020912332460284233, 0.021301470696926117, 0.02118707075715065, 0.02015826664865017, 0.01921013370156288, 0.018910571932792664, 0.01864822395145893, 0.019900565966963768, 0.018648209050297737, 0.019350070506334305, 0.019787687808275223, 0.019045952707529068, 0.022143058478832245, 0.0194842629134655, 0.021848948672413826, 0.019874615594744682, 0.01938617415726185, 0.01960800029337406, 0.020386500284075737, 0.021574851125478745, 0.022684555500745773, 0.022423896938562393, 0.02251351624727249, 0.02047475054860115, 0.01945696584880352, 0.018964635208249092, 0.019189676269888878, 0.02022186852991581, 0.020229196175932884, 0.022407226264476776, 0.019493039697408676, 0.01860981620848179, 0.02074473537504673, 0.02232714556157589, 0.02078155055642128, 0.021356845274567604, 0.027090545743703842, 0.02212033048272133, 0.02060459740459919, 0.01864161714911461, 0.01941639557480812, 0.01947101391851902, 0.020068779587745667, 0.02107871137559414, 0.019381560385227203, 0.01861962117254734, 0.018774349242448807, 0.018421068787574768, 0.017912331968545914, 0.018364325165748596, 0.01808111183345318, 0.020686689764261246, 0.024430202320218086, 0.02407524734735489, 0.020396502688527107, 0.01958942785859108, 0.018511740490794182, 0.019119838252663612, 0.021619444712996483, 0.02353067696094513, 0.022779271006584167, 0.020391695201396942, 0.021247152239084244, 0.018698327243328094, 0.0189017616212368, 0.019158514216542244, 0.018430521711707115, 0.018064329400658607, 0.01823415979743004, 0.01988670416176319, 0.021223537623882294, 0.020937476307153702, 0.01832675375044346, 0.01965472474694252, 0.01886935718357563, 0.019604429602622986, 0.019715119153261185, 0.019951393827795982, 0.020060526207089424, 0.020694591104984283, 0.019890371710062027, 0.025381114333868027, 0.03392401710152626, 0.023145271465182304, 0.022564606741070747, 0.020167803391814232, 0.02140391618013382, 0.021015996113419533, 0.021497897803783417, 0.019596735015511513, 0.01879715546965599, 0.018337005749344826, 0.01876976154744625, 0.01848757639527321, 0.020960733294487, 0.019698454067111015, 0.020642178133130074, 0.022576140239834785, 0.018606217578053474, 0.02096649818122387, 0.018886752426624298, 0.022219978272914886, 0.02407679706811905, 0.022320548072457314, 0.018662165850400925, 0.019000139087438583, 0.021031618118286133, 0.018993787467479706, 0.01794220507144928, 0.01729329489171505, 0.020312540233135223, 0.017945751547813416, 0.018274543806910515, 0.01866152696311474, 0.018313083797693253, 0.019130732864141464, 0.019758492708206177, 0.018887046724557877, 0.019828593358397484, 0.018478306010365486, 0.017426496371626854, 0.018449023365974426, 0.018591562286019325, 0.018046215176582336, 0.01780034601688385, 0.017559023573994637, 0.01840386353433132, 0.020336279645562172, 0.018513154238462448, 0.01906534470617771, 0.019154420122504234, 0.020310359075665474, 0.019179318100214005, 0.018590154126286507, 0.01984383538365364, 0.01894846372306347, 0.01763145625591278, 0.01899748295545578, 0.01888011023402214, 0.0178119707852602, 0.018878471106290817, 0.018209757283329964, 0.019941769540309906, 0.018672510981559753, 0.017207151278853416, 0.019831458106637, 0.019846711307764053, 0.017416344955563545, 0.021596789360046387, 0.018027670681476593, 0.018858270719647408, 0.01877698116004467, 0.018190771341323853, 0.01937352865934372, 0.01913745515048504, 0.018959471955895424, 0.019778624176979065, 0.021370714530348778, 0.020457176491618156, 0.020446622744202614, 0.020041611045598984, 0.02511684037744999, 0.021007969975471497, 0.023753968998789787, 0.020544353872537613, 0.01959272474050522, 0.018748370930552483, 0.020616156980395317, 0.02140078693628311, 0.020711123943328857, 0.018809253349900246, 0.022027231752872467, 0.019742662087082863, 0.020044898614287376, 0.020562658086419106, 0.01996620185673237, 0.018843114376068115, 0.02010318823158741, 0.019405873492360115, 0.01868334598839283, 0.019686562940478325, 0.018889807164669037, 0.019213933497667313, 0.020910467952489853, 0.020836761221289635, 0.019548626616597176, 0.023375244811177254, 0.020975634455680847, 0.019269660115242004, 0.019002974033355713, 0.018727919086813927, 0.01853819005191326, 0.019109085202217102, 0.018657049164175987, 0.018997542560100555, 0.019772160798311234, 0.02408367022871971, 0.019774027168750763, 0.019449159502983093, 0.017749957740306854, 0.02289915271103382, 0.0204336978495121, 0.017401648685336113, 0.01711202785372734, 0.018509916961193085, 0.02043384686112404, 0.022275252267718315, 0.024034028872847557, 0.018332576379179955, 0.018529808148741722, 0.018046962097287178, 0.018075019121170044, 0.018969304859638214, 0.018565770238637924, 0.019718822091817856, 0.017206769436597824, 0.018097173422574997, 0.018206464126706123, 0.01956004463136196, 0.017213717103004456, 0.017600344493985176, 0.019113784655928612, 0.018697472289204597, 0.01759498380124569, 0.020075121894478798, 0.022330129519104958, 0.020964419469237328, 0.019371116533875465, 0.019532933831214905, 0.019789138808846474, 0.01880023628473282, 0.019541027024388313, 0.02022242173552513, 0.01856161840260029, 0.01882539689540863, 0.01856110617518425, 0.018604321405291557, 0.01691446825861931, 0.018939629197120667, 0.017924731597304344, 0.019497757777571678, 0.01767849177122116, 0.019186612218618393, 0.019015716388821602, 0.019322942942380905, 0.019697904586791992, 0.022043094038963318, 0.025249294936656952, 0.02166668139398098, 0.01978885382413864, 0.019562436267733574, 0.021580353379249573, 0.022878482937812805, 0.022881073877215385, 0.018442921340465546, 0.017437083646655083, 0.01740414649248123, 0.023101825267076492, 0.020905129611492157, 0.017979854717850685, 0.01710672862827778, 0.018660828471183777, 0.018698766827583313, 0.019586456939578056, 0.018132220953702927, 0.019475262612104416, 0.018050173297524452, 0.01710381545126438, 0.01792292483150959, 0.02064576931297779, 0.01915339194238186, 0.017412612214684486, 0.017854146659374237, 0.018165916204452515, 0.018439777195453644, 0.01787782460451126, 0.017925899475812912, 0.017446786165237427, 0.01937563717365265, 0.017559923231601715, 0.01982642151415348, 0.018631311133503914, 0.019515261054039, 0.017824290320277214, 0.016876889392733574, 0.017458476126194, 0.017442356795072556, 0.01703548990190029, 0.017619680613279343, 0.018857760354876518, 0.022079303860664368, 0.017625592648983, 0.018762949854135513, 0.01784333772957325, 0.01982305757701397, 0.019485289230942726, 0.019894905388355255, 0.018444225192070007, 0.017938196659088135, 0.017912495881319046, 0.018179481849074364, 0.019640106707811356, 0.018572086468338966, 0.01815604791045189, 0.018602151423692703, 0.016848770901560783, 0.017200203612446785, 0.016940733417868614, 0.017767034471035004, 0.017405960708856583, 0.018282607197761536, 0.020553817972540855, 0.02316698059439659, 0.023147281259298325, 0.02004714123904705, 0.018649224191904068, 0.018521621823310852, 0.019602889195084572, 0.02162029594182968, 0.018351493403315544, 0.019778534770011902, 0.018369944766163826, 0.018410637974739075, 0.019906625151634216, 0.02623005583882332, 0.020084965974092484, 0.019825521856546402, 0.02011743187904358, 0.017005696892738342, 0.018498383462429047, 0.01759868487715721, 0.01776929758489132, 0.01747201383113861, 0.01726234331727028, 0.01925787329673767, 0.019311318174004555, 0.018765512853860855, 0.02063763327896595, 0.01902642846107483, 0.021018974483013153, 0.020965278148651123, 0.018306836485862732, 0.0187296774238348, 0.018108373507857323, 0.017542392015457153, 0.018363850191235542, 0.017521800473332405, 0.02000485360622406, 0.022061720490455627, 0.0190857145935297, 0.02256113663315773, 0.021314924582839012, 0.01971127837896347, 0.021205957978963852, 0.018604079261422157, 0.01928592287003994, 0.020008932799100876, 0.021097110584378242, 0.01934298872947693, 0.018481336534023285, 0.020718954503536224, 0.019462112337350845, 0.021288800984621048, 0.019549338147044182, 0.022398823872208595, 0.02129436656832695, 0.0258558951318264, 0.02072185091674328, 0.020108617842197418, 0.019076025113463402, 0.019728971645236015, 0.019045047461986542, 0.02107415720820427, 0.019487977027893066, 0.01630559004843235, 0.017945848405361176, 0.018159989267587662, 0.018768692389130592, 0.023033564910292625, 0.026614263653755188, 0.020602989941835403, 0.017592838034033775, 0.018237661570310593, 0.017130451276898384, 0.019709289073944092, 0.019782496616244316, 0.018380656838417053, 0.01648668386042118, 0.01737934537231922, 0.01739501953125, 0.01812778040766716, 0.01679079793393612, 0.018649091944098473, 0.020143277943134308, 0.01848706789314747, 0.01691998355090618, 0.016299381852149963, 0.01591222733259201, 0.02052629366517067, 0.02155761420726776, 0.018008224666118622, 0.018870875239372253, 0.02059989981353283, 0.021215129643678665, 0.017571711912751198, 0.018461836501955986, 0.016751080751419067, 0.016535857692360878, 0.019392501562833786, 0.0177474282681942, 0.01766146346926689, 0.01748950593173504, 0.017156271263957024, 0.01785467006266117, 0.01740250177681446, 0.016430649906396866, 0.017268670722842216, 0.017047276720404625, 0.016415901482105255, 0.018098115921020508, 0.020586980506777763, 0.01726084016263485, 0.017583446577191353, 0.01569468155503273, 0.016236059367656708, 0.019237253814935684, 0.016468210145831108, 0.018939649686217308, 0.017481163144111633, 0.018084106966853142, 0.01693268120288849, 0.017200089991092682, 0.017381660640239716, 0.01786615140736103, 0.016825083643198013, 0.017589058727025986, 0.017954707145690918, 0.018472064286470413, 0.0174667090177536, 0.018335161730647087, 0.016023758798837662, 0.017232734709978104, 0.01636390946805477, 0.016904424875974655, 0.017992669716477394, 0.0201126616448164, 0.01719771884381771, 0.01634882390499115, 0.018712077289819717, 0.02125399373471737, 0.017773285508155823, 0.01654789038002491, 0.016051379963755608, 0.016355006024241447, 0.017212286591529846, 0.01607963629066944, 0.01710839942097664, 0.017779268324375153, 0.018373683094978333, 0.018723824992775917, 0.018556416034698486, 0.016792064532637596, 0.016461322084069252, 0.016533521935343742, 0.016787227243185043, 0.018257712945342064, 0.01760857179760933, 0.016483619809150696, 0.01714400202035904, 0.017039503902196884, 0.016107767820358276, 0.017258502542972565, 0.02046838216483593, 0.019852183759212494, 0.018459143117070198, 0.016879498958587646, 0.015522369183599949, 0.015836184844374657, 0.017516663298010826, 0.021656043827533722, 0.01755860261619091, 0.015840385109186172, 0.016588743776082993, 0.016809189692139626, 0.01612136699259281, 0.017750367522239685, 0.017405247315764427, 0.017591755837202072, 0.01766909472644329, 0.016557296738028526, 0.016421692445874214, 0.015614171512424946, 0.015318786725401878, 0.015715397894382477, 0.016171293333172798, 0.016308452934026718, 0.015399124473333359, 0.020913399755954742, 0.020304985344409943, 0.019534006714820862, 0.016421305015683174, 0.02281186357140541, 0.017375748604536057, 0.016317881643772125, 0.016053717583417892, 0.01910453289747238, 0.016109710559248924, 0.017270980402827263, 0.018281621858477592, 0.015488063916563988, 0.017865821719169617, 0.01607288420200348, 0.016577327623963356, 0.015344391576945782, 0.015285935252904892, 0.016557471826672554, 0.014862414449453354, 0.019978486001491547, 0.017677992582321167, 0.018078995868563652, 0.01563790626823902, 0.016008110716938972, 0.017415279522538185, 0.017450537532567978, 0.016663704067468643, 0.017747696489095688, 0.019271254539489746, 0.021435115486383438, 0.019432321190834045, 0.017367180436849594, 0.01581888645887375, 0.01657496578991413, 0.0159134604036808, 0.014393162913620472, 0.01635698974132538, 0.016458719968795776, 0.016713151708245277, 0.017251241952180862, 0.018154431134462357, 0.020861927419900894, 0.028401343151926994, 0.0350801944732666, 0.023889727890491486, 0.016787663102149963, 0.021207284182310104, 0.020968478173017502, 0.020667148754000664, 0.017250390723347664, 0.014905762858688831, 0.01814119517803192, 0.018618913367390633, 0.016538767144083977, 0.019270995631814003, 0.01924116536974907, 0.02082962915301323, 0.01870020106434822, 0.01686333864927292, 0.02073015086352825, 0.023587847128510475, 0.018282247707247734, 0.02287762425839901, 0.018151290714740753, 0.01748661696910858, 0.01634630374610424, 0.015984997153282166, 0.016491251066327095, 0.016360588371753693, 0.015823159366846085, 0.01578083634376526, 0.015083787962794304, 0.015756620094180107, 0.01606070250272751, 0.01615731418132782, 0.0163409486413002, 0.016192857176065445, 0.018103953450918198, 0.01681235246360302, 0.01965092308819294, 0.018956908956170082, 0.01652166247367859, 0.01684553176164627, 0.016607997938990593, 0.01601235941052437, 0.016403259709477425, 0.01570432074368, 0.01634117029607296, 0.016728295013308525, 0.016387619078159332, 0.017515886574983597, 0.01762417145073414, 0.018413744866847992, 0.017432155087590218, 0.017918871715664864, 0.016423020511865616, 0.015755724161863327, 0.01570095121860504, 0.016263986006379128, 0.016828475520014763, 0.015641557052731514, 0.016892286017537117, 0.019061729311943054, 0.0155861871317029, 0.015172746032476425, 0.015704616904258728, 0.016329394653439522, 0.01770651526749134, 0.015589090064167976, 0.014034740626811981, 0.014277704060077667, 0.015250434167683125, 0.014463571831583977, 0.01942584104835987, 0.01867239736020565, 0.018067263066768646, 0.018332762643694878, 0.021507494151592255, 0.018182575702667236, 0.016541024670004845, 0.01675765961408615, 0.016311563551425934, 0.018376778811216354, 0.017868272960186005, 0.01753728836774826, 0.016642561182379723, 0.016301849856972694, 0.015958232805132866, 0.014193065464496613, 0.015094852074980736, 0.015159126371145248, 0.014999954029917717, 0.014425700530409813, 0.0214796494692564, 0.01581927202641964, 0.015186332166194916, 0.015353002585470676, 0.0150879742577672, 0.015898698940873146, 0.018796933814883232, 0.024274202063679695, 0.018956109881401062, 0.014832887798547745, 0.015135204419493675, 0.01619715429842472, 0.015889042988419533, 0.018905850127339363, 0.017850792035460472, 0.01582295075058937, 0.015207312069833279, 0.015409141778945923, 0.015790430828928947, 0.017906099557876587, 0.019855275750160217, 0.017365915700793266, 0.015810411423444748, 0.01803448051214218, 0.01443756278604269, 0.014687104150652885, 0.01509289164096117, 0.014628646895289421, 0.015472622588276863, 0.016205204650759697, 0.016201943159103394, 0.01876566745340824, 0.020063025876879692, 0.01652100495994091, 0.017001770436763763, 0.01615854911506176, 0.015323642641305923, 0.015056473203003407, 0.01702558994293213, 0.018227236345410347, 0.01780843175947666, 0.014590309001505375, 0.014732285402715206, 0.014720006845891476, 0.014467673376202583, 0.0149000845849514, 0.01451794058084488, 0.014153044670820236, 0.01456359587609768, 0.01489943079650402, 0.014014051295816898, 0.013639513403177261, 0.013522381894290447, 0.014532755129039288, 0.015109964646399021, 0.013259815983474255, 0.014264932833611965, 0.016635293141007423, 0.014922527596354485, 0.013890497386455536, 0.01560830045491457, 0.017582252621650696, 0.015955287963151932, 0.014647204428911209, 0.016218360513448715, 0.01579534262418747, 0.015670618042349815, 0.017838072031736374, 0.015808500349521637, 0.01577611453831196, 0.015934273600578308, 0.018496917560696602, 0.017213372513651848, 0.01550356112420559, 0.0152816753834486, 0.015296111814677715, 0.014257887378334999, 0.01564817875623703, 0.014785516075789928, 0.014724710024893284, 0.014825694262981415, 0.01362302154302597, 0.01400685403496027, 0.013954518362879753, 0.014562476426362991, 0.015701061114668846, 0.015040232799947262, 0.015133132226765156, 0.017025234177708626, 0.0161521527916193, 0.017450712621212006, 0.016938531771302223, 0.019469182938337326, 0.015609895810484886, 0.015477947890758514, 0.014827110804617405, 0.016242241486907005, 0.018334781751036644, 0.01643010973930359, 0.015328796580433846, 0.014558829367160797, 0.01451085414737463, 0.015011205337941647, 0.017478398978710175, 0.016614826396107674, 0.01457819901406765, 0.014105536974966526, 0.013415639288723469, 0.01535616535693407, 0.015396400354802608, 0.015818029642105103, 0.013665932230651379, 0.01369486190378666, 0.014793626964092255, 0.013442721217870712, 0.014282871037721634, 0.013858413323760033, 0.013723035342991352, 0.015070565976202488, 0.016974613070487976, 0.015199277549982071, 0.013609618879854679, 0.01394577044993639, 0.014462541788816452, 0.013689609244465828, 0.014565924182534218, 0.014855356886982918, 0.013964137993752956, 0.013263851404190063, 0.013131490908563137, 0.01352628692984581, 0.013660667464137077, 0.013495749793946743, 0.016415931284427643, 0.017425546422600746, 0.019011396914720535, 0.016552738845348358, 0.015897927805781364, 0.013810554519295692, 0.015022452920675278, 0.01360334176570177, 0.01331861037760973, 0.017426911741495132, 0.01641937717795372, 0.016701072454452515, 0.015523580834269524, 0.014977686107158661, 0.014923546463251114, 0.013774026185274124, 0.012985127978026867, 0.014599879272282124, 0.014824762009084225, 0.01881120726466179, 0.020079849287867546, 0.019202912226319313, 0.01751026324927807, 0.016244955360889435, 0.01630101352930069, 0.014882026240229607, 0.01566028781235218, 0.014914731495082378, 0.014135670848190784, 0.01493524108082056, 0.014668463729321957, 0.014427253976464272, 0.014919305220246315, 0.016384748741984367, 0.01677870564162731, 0.014632400125265121, 0.014300627633929253, 0.015289626084268093, 0.015571719035506248, 0.01367693580687046, 0.013814426027238369, 0.013883838430047035, 0.0166192427277565, 0.016400432214140892, 0.017007196322083473, 0.01401505060493946, 0.014943843707442284, 0.014978354796767235, 0.015979943796992302, 0.014766647480428219, 0.015222188085317612, 0.01511397585272789, 0.01725972630083561, 0.018305137753486633, 0.016908394172787666, 0.0145340571179986, 0.012812814675271511, 0.013804912567138672, 0.013809950090944767, 0.016088033095002174, 0.01648225076496601, 0.013240321539342403, 0.01435994915664196, 0.014965665526688099, 0.016541652381420135, 0.014904365874826908, 0.015371950343251228, 0.013822130858898163, 0.014054079540073872, 0.014318074099719524, 0.012805474922060966, 0.015738433226943016, 0.014291205443441868, 0.013470366597175598, 0.013756396248936653, 0.015108292922377586, 0.01643363945186138, 0.01592782512307167, 0.015506351366639137, 0.014155956916511059, 0.013207913376390934, 0.014340681955218315, 0.013806530274450779, 0.014814629219472408, 0.017309602349996567, 0.015245535410940647, 0.01236841082572937, 0.014072657562792301, 0.017554113641381264, 0.018863985314965248, 0.01693013496696949, 0.0178762786090374, 0.015390234999358654, 0.017691511660814285, 0.01564284786581993, 0.01729782298207283, 0.016257479786872864, 0.015223085880279541, 0.017613040283322334, 0.01943572610616684, 0.01855175942182541, 0.014897994697093964, 0.017392229288816452, 0.01795656979084015, 0.01396770030260086, 0.014986760914325714, 0.013024536892771721, 0.013162277638912201, 0.012714502401649952, 0.013353480957448483, 0.01279470231384039, 0.013096091337502003, 0.01272501703351736, 0.013317861594259739, 0.012592463754117489, 0.013572759926319122, 0.01323448121547699, 0.013783315196633339, 0.013051855377852917, 0.014922026544809341, 0.016574254259467125, 0.014792424626648426, 0.016358468681573868, 0.01421438716351986, 0.015525766648352146, 0.015247730538249016, 0.015592150390148163, 0.01587500236928463, 0.01755118928849697, 0.01987970620393753, 0.021018823608756065, 0.01623476855456829, 0.013777934946119785, 0.014296017587184906, 0.014666562899947166, 0.014150832779705524, 0.015202929265797138, 0.013285026885569096, 0.012816266156733036, 0.014653068967163563, 0.013211790472269058, 0.013042060658335686, 0.01490187831223011, 0.014093930833041668, 0.013862245716154575, 0.01585990935564041, 0.01455647498369217, 0.01620171032845974, 0.014387262985110283, 0.013637796975672245, 0.014224308542907238, 0.013218807987868786, 0.012856433168053627, 0.014036272652447224, 0.013302638195455074, 0.012749167159199715, 0.013163657858967781, 0.01419607549905777, 0.01588667929172516, 0.01642405427992344, 0.01572495326399803, 0.012892433442175388, 0.014376659877598286, 0.013479983434081078, 0.012768692336976528, 0.013069565407931805, 0.01638166978955269, 0.01367463544011116, 0.012692786753177643, 0.012582624331116676, 0.012492728419601917, 0.013977518305182457, 0.012511191889643669, 0.01335959043353796, 0.013467060402035713, 0.014819464646279812, 0.013941085897386074, 0.018046008422970772, 0.012784899212419987, 0.016162320971488953, 0.01639881543815136, 0.012744713574647903, 0.014373917132616043, 0.014210770837962627, 0.012514728121459484, 0.012446639128029346, 0.013662979938089848, 0.015457204543054104, 0.014304338954389095, 0.014158395119011402, 0.013160777278244495, 0.015923811122775078, 0.014603344723582268, 0.012289612554013729, 0.017980482429265976, 0.01940160244703293, 0.016737865284085274, 0.01479768194258213, 0.019538864493370056, 0.017239540815353394, 0.016268927603960037, 0.015464761294424534, 0.014514002948999405, 0.013207455165684223, 0.013115932233631611, 0.013306527398526669, 0.012442858889698982, 0.013337485492229462, 0.013527431525290012, 0.012705033645033836, 0.012706450186669827, 0.011980249546468258, 0.012531133368611336, 0.012525332160294056, 0.012071462348103523, 0.011827527545392513, 0.014614023268222809, 0.01316662784665823, 0.013086349703371525, 0.013307152315974236, 0.013372346758842468, 0.01319997850805521, 0.01422867365181446, 0.016602972522377968, 0.01583676226437092, 0.01590362936258316, 0.013781766407191753, 0.014628969132900238, 0.013666745275259018, 0.013838005252182484, 0.01292899064719677, 0.013131653890013695, 0.01380174607038498, 0.01283440925180912, 0.012382998131215572, 0.01237411331385374, 0.012452707625925541, 0.012818360701203346, 0.014169654808938503, 0.015978680923581123, 0.014975816011428833, 0.01444811001420021, 0.013193321414291859, 0.012819156050682068, 0.013374123722314835, 0.013003788888454437, 0.0135477464646101, 0.01303788274526596, 0.012416870333254337, 0.013057863339781761, 0.013517051935195923, 0.015092169865965843, 0.015544225461781025, 0.013394070789217949, 0.012559251859784126, 0.01391854789108038, 0.016119392588734627, 0.01501991506665945, 0.012784590013325214, 0.013990752398967743, 0.013713986612856388, 0.014317008666694164, 0.013512350618839264, 0.014009659178555012, 0.018199466168880463, 0.019009483978152275, 0.01675652153789997, 0.015543677844107151, 0.014075180515646935, 0.014352075755596161, 0.012153537943959236, 0.013171718455851078, 0.012567357160151005, 0.012379717081785202, 0.012845486402511597, 0.014370467513799667, 0.01352199912071228, 0.015253315679728985, 0.016219306737184525, 0.017433704808354378, 0.016729502007365227, 0.015119768679141998, 0.014562156982719898, 0.0148087739944458, 0.01614285446703434, 0.015854550525546074, 0.013305068016052246, 0.013133509084582329, 0.015246236696839333, 0.014139852486550808, 0.013237593695521355, 0.011584010906517506, 0.01310345996171236, 0.01365035679191351, 0.012297175824642181, 0.012356549501419067, 0.01278145145624876, 0.014531874097883701, 0.013084165751934052, 0.011918083764612675, 0.012989141047000885, 0.012940973974764347, 0.012927857227623463, 0.01188686490058899, 0.014412978664040565, 0.01365789957344532, 0.013304618187248707, 0.012246467173099518, 0.011524504981935024, 0.012869549915194511, 0.012871749699115753, 0.012062551453709602, 0.011864177882671356, 0.011668344959616661, 0.011677026748657227, 0.012011435814201832, 0.01235839445143938, 0.011839471757411957, 0.01230188924819231, 0.01162052620202303, 0.01252933219075203, 0.011542157270014286, 0.011937691830098629, 0.013530601747334003, 0.013935553841292858, 0.013005416840314865, 0.01594715379178524, 0.014620386064052582, 0.012698334641754627, 0.012556401081383228, 0.01629592850804329, 0.013277539983391762, 0.012833035551011562, 0.012826060876250267, 0.01574908010661602, 0.016605718061327934, 0.013984635472297668, 0.015544959343969822, 0.01590869389474392, 0.014391747303307056, 0.012027215212583542, 0.013382683508098125, 0.01655065454542637, 0.016126390546560287, 0.014918754808604717, 0.014192597940564156, 0.013654968701303005, 0.012777889147400856, 0.014040162786841393, 0.014321215450763702, 0.014427361078560352, 0.01499010156840086, 0.01346847414970398, 0.015144147910177708, 0.015178193338215351, 0.015296244993805885, 0.014462738297879696, 0.012175490148365498, 0.012133563868701458, 0.014508705586194992, 0.014058754779398441, 0.012701408937573433, 0.013993958942592144, 0.016125513240695, 0.013588863424956799, 0.01381578017026186, 0.014225777238607407, 0.014460018835961819, 0.013572003692388535, 0.01416342705488205, 0.014274900779128075, 0.013100665993988514, 0.013923106715083122, 0.014356975443661213, 0.013580524362623692, 0.011766765266656876, 0.011931275017559528, 0.011860320344567299, 0.01241227611899376, 0.012681643478572369, 0.015507063828408718, 0.014712410978972912, 0.013288581743836403, 0.01510141883045435, 0.0124573465436697, 0.011570733040571213, 0.012996576726436615, 0.012752044014632702, 0.014757657423615456, 0.013387863524258137, 0.012880845926702023, 0.016002211719751358, 0.015533357858657837, 0.017364896833896637, 0.014817257411777973, 0.012435403652489185, 0.011655155569314957, 0.011536241509020329, 0.011911665089428425, 0.012124438770115376, 0.012695232406258583, 0.012793784029781818, 0.012911261059343815, 0.012236102484166622, 0.013467087410390377, 0.015614052303135395, 0.01820378005504608, 0.018165800720453262, 0.018720662221312523, 0.017380740493535995, 0.014442934654653072, 0.01220211572945118, 0.01155469287186861, 0.014135664328932762, 0.013759512454271317, 0.01364017091691494, 0.013251309283077717, 0.013448079116642475, 0.012136006727814674, 0.013081208802759647, 0.017075059935450554, 0.013703039847314358, 0.012216846458613873, 0.013207606971263885, 0.011671273037791252, 0.013641205616295338, 0.012814254499971867, 0.01161173265427351, 0.011738044209778309, 0.011260394006967545, 0.011196840554475784, 0.012288677506148815, 0.01189910713583231, 0.012590681202709675, 0.011879664845764637, 0.010762894526124, 0.012247316539287567, 0.012085095047950745, 0.012080108746886253, 0.017773184925317764, 0.015481016598641872, 0.0159574206918478, 0.011713474988937378, 0.014122722670435905, 0.012309468351304531, 0.012323189526796341, 0.01221293956041336, 0.012827644124627113, 0.012294167652726173, 0.014645271003246307, 0.013508704490959644, 0.013909230940043926, 0.01463388279080391, 0.014419841580092907, 0.018283803015947342, 0.01724122278392315, 0.01354213897138834, 0.013051818124949932, 0.01402696780860424, 0.013299998827278614, 0.012368005700409412, 0.01371038518846035, 0.013143478892743587, 0.01101953350007534, 0.0118224723264575, 0.011385055258870125, 0.012692911550402641, 0.011668204329907894, 0.01297670602798462, 0.014150443486869335, 0.01240033470094204, 0.011353354901075363, 0.011066635139286518, 0.01049868855625391, 0.010867233388125896, 0.011885975487530231, 0.011417653411626816, 0.011223767884075642, 0.011460847221314907, 0.01436622254550457, 0.013219043612480164, 0.015176840126514435, 0.014062384143471718, 0.011931540444493294, 0.01204768382012844, 0.013934536837041378, 0.012558724731206894, 0.013585998676717281, 0.011744693852961063, 0.01325972005724907, 0.014319771900773048, 0.012144006788730621, 0.013039903715252876, 0.012929998338222504, 0.013723879121243954, 0.020376259461045265, 0.01486506313085556, 0.011567012406885624, 0.012227076105773449, 0.014088262803852558, 0.013813138008117676, 0.01304357685148716, 0.011211837641894817, 0.011861530132591724, 0.012220548465847969, 0.015683626756072044, 0.016176633536815643, 0.022891458123922348, 0.023558806627988815, 0.02027082070708275, 0.021026089787483215, 0.021487383171916008, 0.023124298080801964, 0.018205532804131508, 0.017703639343380928, 0.016886679455637932, 0.02186526730656624, 0.018191248178482056, 0.017463183030486107, 0.02311055362224579, 0.023862384259700775, 0.01664721593260765, 0.02173745632171631, 0.018643934279680252, 0.01580766774713993, 0.015254694037139416, 0.014556007459759712, 0.015483004041016102, 0.017079517245292664, 0.014153342694044113, 0.01493253093212843, 0.018314417451620102, 0.017712250351905823, 0.01696285791695118, 0.016649307683110237, 0.016189225018024445, 0.01629430428147316, 0.015312785282731056, 0.014603495597839355, 0.014632835984230042, 0.015593337826430798, 0.014526494778692722, 0.015462510287761688, 0.015789350494742393, 0.01743992790579796, 0.01714562438428402, 0.016511043533682823, 0.018564609810709953, 0.02073557674884796, 0.015966609120368958, 0.014276562258601189, 0.015355052426457405, 0.016568349674344063, 0.015095027163624763, 0.014934820123016834, 0.01425414253026247, 0.014514234848320484, 0.017129017040133476, 0.016208777204155922, 0.015017316676676273, 0.01482303161174059, 0.014361917041242123, 0.016343360766768456, 0.01685045287013054, 0.01611683890223503, 0.01705489493906498, 0.01689489372074604, 0.017308160662651062, 0.020424148067831993, 0.021009447053074837, 0.020444700494408607, 0.019245706498622894, 0.018315389752388, 0.017887471243739128, 0.014440884813666344, 0.015965450555086136, 0.015167595818638802, 0.01596183329820633, 0.015869436785578728, 0.016571376472711563, 0.016210686415433884, 0.016705580055713654, 0.019801143556833267, 0.018589219078421593, 0.017997780814766884, 0.016889192163944244, 0.016006896272301674, 0.014968723058700562, 0.01616024598479271, 0.015890559181571007, 0.016595927998423576, 0.016663484275341034, 0.017556164413690567, 0.015044234693050385, 0.013983862474560738, 0.01373363845050335, 0.013644687831401825, 0.014290295541286469, 0.013541795313358307, 0.013036434538662434, 0.01331131998449564, 0.012267982587218285, 0.011820001527667046, 0.011916792020201683, 0.013016962446272373, 0.013273514807224274, 0.01577359065413475, 0.014555438421666622, 0.015998993068933487, 0.018031207844614983, 0.015371632762253284, 0.01404387503862381, 0.012906540185213089, 0.011797891929745674, 0.012404416687786579, 0.012034609913825989, 0.013031498529016972, 0.012910427525639534, 0.014279775321483612, 0.011754289269447327, 0.011701195500791073, 0.011627170257270336, 0.0117354616522789, 0.011696912348270416, 0.011223851703107357, 0.011234147474169731, 0.011656180024147034, 0.01237600389868021, 0.011968079954385757, 0.012733487412333488, 0.011120893992483616, 0.013102294877171516, 0.012350191362202168, 0.012250291183590889, 0.011365891434252262, 0.011729234829545021, 0.011403150856494904, 0.014611574821174145, 0.015472899191081524, 0.013272551819682121, 0.012339449487626553, 0.013087521307170391, 0.013739340007305145, 0.012867390178143978, 0.01292383298277855, 0.01488740835338831, 0.012368660420179367, 0.012690986506640911, 0.01257637981325388, 0.011638094671070576, 0.01470987405627966, 0.016165176406502724, 0.014388641342520714, 0.012428839690983295, 0.014634290710091591, 0.013055660761892796, 0.012445386499166489, 0.01370646059513092, 0.014931638725101948, 0.014833979308605194, 0.012643085792660713, 0.012731678783893585, 0.011631564237177372, 0.01159727480262518, 0.010858760215342045, 0.01205467153340578, 0.011445282027125359, 0.01656430773437023, 0.014141327701508999, 0.01349950022995472, 0.012605574913322926, 0.011224196292459965, 0.01103327888995409, 0.011905030347406864, 0.011565529741346836, 0.01046984177082777, 0.011123327538371086, 0.012458957731723785, 0.012589049525558949, 0.012166640721261501, 0.01201801747083664, 0.011250552721321583, 0.012768573127686977, 0.011800716631114483, 0.011045086197555065, 0.01114384364336729, 0.011149327270686626, 0.01047453097999096, 0.011030144989490509, 0.01129660103470087, 0.012266946025192738, 0.01255771704018116, 0.01112182717770338, 0.010910125449299812, 0.010385316796600819, 0.012514488771557808, 0.014068297110497952, 0.012606387957930565, 0.010315298102796078, 0.011302778497338295, 0.011047220788896084, 0.012853546999394894, 0.012153394520282745, 0.011364877223968506, 0.01226265449076891, 0.013642974197864532, 0.01217094250023365, 0.011604762636125088, 0.011409992352128029, 0.011625831946730614, 0.013148360885679722, 0.014500388875603676, 0.013327195309102535, 0.01417833287268877, 0.013021744787693024, 0.011238671839237213, 0.01190250925719738, 0.010893387719988823, 0.011226557195186615, 0.011801652610301971, 0.012971601448953152, 0.01200941950082779, 0.011386879719793797, 0.011461785063147545, 0.012490947730839252, 0.012026921845972538, 0.010936837643384933, 0.010973326861858368, 0.01403446402400732, 0.013372090645134449, 0.012842308729887009, 0.012090756557881832, 0.011734692379832268, 0.012991060502827168, 0.01190950721502304, 0.011017721146345139, 0.010679014027118683, 0.011199412867426872, 0.011647345498204231, 0.011427639052271843, 0.01099160686135292, 0.012060449458658695, 0.012163911014795303, 0.011269737035036087, 0.012550177052617073, 0.014377077110111713, 0.014384973794221878, 0.012707511894404888, 0.01155560277402401, 0.011522753164172173, 0.011945503763854504, 0.012847056612372398, 0.019397161900997162, 0.014505133032798767, 0.012565058656036854, 0.013463535346090794, 0.013420113362371922, 0.01331073883920908, 0.013347391039133072, 0.01133014913648367, 0.011115247383713722, 0.01120762899518013, 0.011071709915995598, 0.010573823936283588, 0.011226626113057137, 0.011620842851698399, 0.01092144101858139, 0.011369328945875168, 0.010728714987635612, 0.011727608740329742, 0.011864425614476204, 0.012161285616457462, 0.010998215526342392, 0.012733167968690395, 0.01254816260188818, 0.011754174716770649, 0.012115484103560448, 0.014359320513904095, 0.011592534370720387, 0.01289508305490017, 0.013232670724391937, 0.014695154502987862, 0.013587839901447296, 0.01388487033545971, 0.012887515127658844, 0.0118013396859169, 0.015268695540726185, 0.015277355909347534, 0.013839483261108398, 0.01405628677457571, 0.013565385714173317, 0.01356130838394165, 0.011442514136433601, 0.01029739435762167, 0.010735353454947472, 0.010651076212525368, 0.011947563849389553, 0.015561703592538834, 0.016321009024977684, 0.014049368910491467, 0.011430764570832253, 0.012699194252490997, 0.013089016079902649, 0.014664511196315289, 0.012559476308524609, 0.01216851081699133, 0.013967662118375301, 0.011637082323431969, 0.011280628852546215, 0.01150343008339405, 0.011536424979567528, 0.011962123215198517, 0.01088447030633688, 0.010952337644994259, 0.011917585507035255, 0.011161799542605877, 0.011894548311829567, 0.013098576106131077, 0.015101241879165173, 0.012752912938594818, 0.01667972095310688, 0.018877286463975906, 0.0166335329413414, 0.015416380017995834, 0.01409610453993082, 0.01492217741906643, 0.015183108858764172, 0.015134155750274658, 0.013329186476767063, 0.010849837213754654, 0.010348685085773468, 0.010003440082073212, 0.010305501520633698, 0.0118983443826437, 0.013920878991484642, 0.011761756613850594, 0.011688468046486378, 0.011705925688147545, 0.011872610077261925, 0.014314820989966393, 0.01165084633976221, 0.011829708702862263, 0.010652849450707436, 0.01053823996335268, 0.011621566489338875, 0.010847680270671844, 0.011418547481298447, 0.010857952758669853, 0.010842768475413322, 0.010153144598007202, 0.012652786448597908, 0.01360171940177679, 0.011236528865993023, 0.012782560661435127, 0.01108673308044672, 0.01057446375489235, 0.010444574989378452, 0.0111647704616189, 0.010529102757573128, 0.011635552160441875, 0.011642790399491787, 0.010882646776735783, 0.010809000581502914, 0.010086293332278728, 0.01027186494320631, 0.01094986591488123, 0.01046520471572876, 0.015335410833358765, 0.023185735568404198, 0.027754608541727066, 0.014813637360930443, 0.015557101927697659, 0.020080694928765297, 0.017382372170686722, 0.019306542351841927, 0.012606684118509293, 0.012020905502140522, 0.011116930283606052, 0.012021607719361782, 0.011043502017855644, 0.01037459447979927, 0.010755064897239208, 0.010421358048915863, 0.01057460531592369, 0.0107127008959651, 0.010620963759720325, 0.009861298836767673, 0.011628380045294762, 0.011598744429647923, 0.011329141445457935, 0.01343881618231535, 0.014021231792867184, 0.012173296883702278, 0.011435260996222496, 0.010253733024001122, 0.011245273053646088, 0.01189839094877243, 0.011041887104511261, 0.0118250148370862, 0.01195740606635809, 0.015732839703559875, 0.027786627411842346, 0.025508079677820206, 0.020910104736685753, 0.01896286942064762, 0.0161454975605011, 0.017079738900065422, 0.013381129130721092, 0.012996808625757694, 0.012292325496673584, 0.012383590452373028, 0.012580309994518757, 0.013323722407221794, 0.011128476820886135, 0.010812242515385151, 0.010759558528661728, 0.01157884020358324, 0.011436511762440205, 0.01155678741633892, 0.011538784019649029, 0.011051112785935402, 0.014385498128831387, 0.01325133815407753, 0.014798126183450222, 0.01630762219429016, 0.015309291891753674, 0.01244275737553835, 0.01144244521856308, 0.011433673091232777, 0.011067114770412445, 0.010380369611084461, 0.009894182905554771, 0.010792143642902374, 0.012168483808636665, 0.015459783375263214, 0.011850894428789616, 0.011094890534877777, 0.0102319847792387, 0.01021465566009283, 0.010326556861400604, 0.010495360009372234, 0.01097093615680933, 0.01045854203402996, 0.010294663719832897, 0.010346408002078533, 0.009653844870626926, 0.010813786648213863, 0.011111306957900524, 0.01144875306636095, 0.011357642710208893, 0.010753589682281017, 0.010985404253005981, 0.011946811340749264, 0.010478115640580654, 0.01082815881818533, 0.01041107065975666]\n",
      "accuracy [0.9885110259056091, 0.9889705777168274, 0.9880514740943909, 0.990349292755127, 0.9889705777168274, 0.9869025945663452, 0.9892003536224365, 0.9875919222831726, 0.9892003536224365, 0.9839154481887817, 0.9898896813392639, 0.9898896813392639, 0.9892003536224365, 0.9892003536224365, 0.9896599054336548, 0.990119457244873, 0.9875919222831726, 0.9887408018112183, 0.9889705777168274, 0.990119457244873, 0.9894301295280457, 0.9892003536224365, 0.9894301295280457, 0.9892003536224365, 0.990349292755127, 0.9887408018112183, 0.9885110259056091, 0.98828125, 0.9889705777168274, 0.9875919222831726, 0.9889705777168274, 0.9889705777168274, 0.9892003536224365, 0.9905790686607361, 0.9898896813392639, 0.990119457244873, 0.9908088445663452, 0.9887408018112183, 0.9898896813392639, 0.9894301295280457, 0.9887408018112183, 0.990119457244873, 0.990119457244873, 0.990349292755127, 0.9898896813392639, 0.990349292755127, 0.9894301295280457, 0.9908088445663452, 0.98828125, 0.9871323704719543, 0.9871323704719543, 0.9871323704719543, 0.9866728186607361, 0.9894301295280457, 0.9885110259056091, 0.9892003536224365, 0.9898896813392639, 0.9887408018112183, 0.9905790686607361, 0.9889705777168274, 0.9892003536224365, 0.9898896813392639, 0.9896599054336548, 0.9892003536224365, 0.9892003536224365, 0.9892003536224365, 0.9898896813392639, 0.990349292755127, 0.9908088445663452, 0.9894301295280457, 0.9905790686607361, 0.9910386204719543, 0.9896599054336548, 0.990119457244873, 0.9892003536224365, 0.9892003536224365, 0.9885110259056091, 0.9896599054336548, 0.9905790686607361, 0.990349292755127, 0.9896599054336548, 0.9898896813392639, 0.98828125, 0.990349292755127, 0.9898896813392639, 0.9892003536224365, 0.9894301295280457, 0.9896599054336548, 0.990119457244873, 0.9896599054336548, 0.9896599054336548, 0.9852941036224365, 0.98828125, 0.9894301295280457, 0.9889705777168274, 0.990349292755127, 0.9898896813392639, 0.9905790686607361, 0.9887408018112183, 0.990349292755127, 0.990119457244873, 0.9892003536224365, 0.9905790686607361, 0.990119457244873, 0.9910386204719543, 0.9912683963775635, 0.9905790686607361, 0.9889705777168274, 0.990119457244873, 0.9880514740943909, 0.9892003536224365, 0.990349292755127, 0.9898896813392639, 0.990119457244873, 0.9889705777168274, 0.9878216981887817, 0.9898896813392639, 0.9905790686607361, 0.9910386204719543, 0.9905790686607361, 0.990119457244873, 0.9905790686607361, 0.9917279481887817, 0.9910386204719543, 0.990349292755127, 0.98828125, 0.9898896813392639, 0.9908088445663452, 0.9894301295280457, 0.9908088445663452, 0.9894301295280457, 0.9905790686607361, 0.9908088445663452, 0.9905790686607361, 0.9905790686607361, 0.9905790686607361, 0.9914981722831726, 0.9910386204719543, 0.990349292755127, 0.990349292755127, 0.9905790686607361, 0.9889705777168274, 0.9894301295280457, 0.9892003536224365, 0.98828125, 0.9914981722831726, 0.9880514740943909, 0.990349292755127, 0.9889705777168274, 0.9892003536224365, 0.9878216981887817, 0.9892003536224365, 0.9887408018112183, 0.9892003536224365, 0.990119457244873, 0.9898896813392639, 0.9905790686607361, 0.9898896813392639, 0.9905790686607361, 0.9908088445663452, 0.990119457244873, 0.990119457244873, 0.9898896813392639, 0.9885110259056091, 0.990119457244873, 0.9894301295280457, 0.990119457244873, 0.9889705777168274, 0.9887408018112183, 0.98828125, 0.9869025945663452, 0.9880514740943909, 0.990349292755127, 0.990349292755127, 0.9898896813392639, 0.9898896813392639, 0.9892003536224365, 0.990349292755127, 0.9905790686607361, 0.9908088445663452, 0.9908088445663452, 0.990349292755127, 0.990349292755127, 0.9905790686607361, 0.9905790686607361, 0.9905790686607361, 0.9910386204719543, 0.9896599054336548, 0.9908088445663452, 0.9910386204719543, 0.9905790686607361, 0.990349292755127, 0.9908088445663452, 0.9898896813392639, 0.9908088445663452, 0.990349292755127, 0.9896599054336548, 0.990349292755127, 0.990119457244873, 0.990349292755127, 0.990349292755127, 0.9896599054336548, 0.9905790686607361, 0.9910386204719543, 0.9908088445663452, 0.9873621463775635, 0.9887408018112183, 0.9896599054336548, 0.9905790686607361, 0.990119457244873, 0.990119457244873, 0.9887408018112183, 0.9898896813392639, 0.990349292755127, 0.9894301295280457, 0.9898896813392639, 0.9878216981887817, 0.9894301295280457, 0.9896599054336548, 0.9898896813392639, 0.990349292755127, 0.9910386204719543, 0.9908088445663452, 0.9905790686607361, 0.9898896813392639, 0.9917279481887817, 0.9898896813392639, 0.990349292755127, 0.990119457244873, 0.9898896813392639, 0.9896599054336548, 0.9917279481887817, 0.9914981722831726, 0.9910386204719543, 0.9914981722831726, 0.990349292755127, 0.9905790686607361, 0.9898896813392639, 0.990349292755127, 0.9908088445663452, 0.9917279481887817, 0.9917279481887817, 0.9898896813392639, 0.9873621463775635, 0.9894301295280457, 0.9892003536224365, 0.9905790686607361, 0.990349292755127, 0.9919577240943909, 0.9908088445663452, 0.9914981722831726, 0.9910386204719543, 0.9905790686607361, 0.9908088445663452, 0.9905790686607361, 0.9914981722831726, 0.9919577240943909, 0.9898896813392639, 0.9894301295280457, 0.9914981722831726, 0.9898896813392639, 0.9905790686607361, 0.9898896813392639, 0.9898896813392639, 0.9910386204719543, 0.9889705777168274, 0.9898896813392639, 0.9898896813392639, 0.9912683963775635, 0.9898896813392639, 0.990349292755127, 0.9908088445663452, 0.990349292755127, 0.990119457244873, 0.9910386204719543, 0.9912683963775635, 0.9914981722831726, 0.990119457244873, 0.990119457244873, 0.990119457244873, 0.9908088445663452, 0.9914981722831726, 0.990349292755127, 0.9908088445663452, 0.990119457244873, 0.9905790686607361, 0.990349292755127, 0.9912683963775635, 0.9912683963775635, 0.990349292755127, 0.9894301295280457, 0.990349292755127, 0.9912683963775635, 0.990119457244873, 0.9898896813392639, 0.990119457244873, 0.9908088445663452, 0.9898896813392639, 0.9894301295280457, 0.9898896813392639, 0.990349292755127, 0.9917279481887817, 0.9910386204719543, 0.9908088445663452, 0.990119457244873, 0.9898896813392639, 0.9912683963775635, 0.990119457244873, 0.9905790686607361, 0.9898896813392639, 0.9887408018112183, 0.9912683963775635, 0.9908088445663452, 0.9912683963775635, 0.9917279481887817, 0.9917279481887817, 0.9905790686607361, 0.9912683963775635, 0.9912683963775635, 0.9896599054336548, 0.990119457244873, 0.9905790686607361, 0.9908088445663452, 0.990119457244873, 0.9892003536224365, 0.9905790686607361, 0.9914981722831726, 0.9914981722831726, 0.9910386204719543, 0.9914981722831726, 0.9917279481887817, 0.9914981722831726, 0.9905790686607361, 0.9910386204719543, 0.9917279481887817, 0.9912683963775635, 0.9889705777168274, 0.9910386204719543, 0.9910386204719543, 0.9908088445663452, 0.9892003536224365, 0.9898896813392639, 0.9917279481887817, 0.9917279481887817, 0.9908088445663452, 0.9921875, 0.9914981722831726, 0.9914981722831726, 0.990349292755127, 0.9917279481887817, 0.9919577240943909, 0.9919577240943909, 0.9910386204719543, 0.9908088445663452, 0.9924172759056091, 0.9908088445663452, 0.9878216981887817, 0.9859834313392639, 0.9892003536224365, 0.986443042755127, 0.9885110259056091, 0.9869025945663452, 0.9910386204719543, 0.9912683963775635, 0.9914981722831726, 0.9905790686607361, 0.9912683963775635, 0.990119457244873, 0.990349292755127, 0.9910386204719543, 0.9910386204719543, 0.9912683963775635, 0.9912683963775635, 0.9908088445663452, 0.9917279481887817, 0.9914981722831726, 0.9924172759056091, 0.9924172759056091, 0.9917279481887817, 0.9924172759056091, 0.9910386204719543, 0.990119457244873, 0.990119457244873, 0.9912683963775635, 0.9914981722831726, 0.9912683963775635, 0.9914981722831726, 0.990119457244873, 0.9926470518112183, 0.9912683963775635, 0.9919577240943909, 0.9912683963775635, 0.9910386204719543, 0.9908088445663452, 0.9912683963775635, 0.9917279481887817, 0.9917279481887817, 0.9905790686607361, 0.9910386204719543, 0.9908088445663452, 0.9896599054336548, 0.9917279481887817, 0.9894301295280457, 0.9908088445663452, 0.9912683963775635, 0.9914981722831726, 0.9908088445663452, 0.9914981722831726, 0.9917279481887817, 0.9919577240943909, 0.9894301295280457, 0.9894301295280457, 0.990349292755127, 0.990119457244873, 0.9896599054336548, 0.9898896813392639, 0.9912683963775635, 0.9910386204719543, 0.9919577240943909, 0.9919577240943909, 0.9908088445663452, 0.9914981722831726, 0.9914981722831726, 0.9924172759056091, 0.9908088445663452, 0.9910386204719543, 0.9914981722831726, 0.9917279481887817, 0.9910386204719543, 0.9917279481887817, 0.9910386204719543, 0.9892003536224365, 0.9905790686607361, 0.990349292755127, 0.9919577240943909, 0.9905790686607361, 0.9910386204719543, 0.9917279481887817, 0.9919577240943909, 0.9914981722831726, 0.9917279481887817, 0.9912683963775635, 0.9905790686607361, 0.9917279481887817, 0.9910386204719543, 0.9910386204719543, 0.9917279481887817, 0.990119457244873, 0.9889705777168274, 0.9912683963775635, 0.9919577240943909, 0.9921875, 0.9924172759056091, 0.9912683963775635, 0.9914981722831726, 0.990119457244873, 0.9910386204719543, 0.9910386204719543, 0.9894301295280457, 0.9887408018112183, 0.9914981722831726, 0.9924172759056091, 0.9919577240943909, 0.9912683963775635, 0.9912683963775635, 0.9914981722831726, 0.9912683963775635, 0.9912683963775635, 0.9908088445663452, 0.9896599054336548, 0.9914981722831726, 0.9912683963775635, 0.9912683963775635, 0.9914981722831726, 0.9912683963775635, 0.9917279481887817, 0.9924172759056091, 0.9919577240943909, 0.9910386204719543, 0.9921875, 0.9921875, 0.9919577240943909, 0.9905790686607361, 0.9914981722831726, 0.9912683963775635, 0.9914981722831726, 0.9905790686607361, 0.9912683963775635, 0.9910386204719543, 0.9892003536224365, 0.9912683963775635, 0.9921875, 0.9912683963775635, 0.990119457244873, 0.9912683963775635, 0.9910386204719543, 0.9905790686607361, 0.9908088445663452, 0.9910386204719543, 0.9919577240943909, 0.9912683963775635, 0.990119457244873, 0.9910386204719543, 0.9912683963775635, 0.9924172759056091, 0.9908088445663452, 0.9914981722831726, 0.9912683963775635, 0.9912683963775635, 0.9908088445663452, 0.9914981722831726, 0.9917279481887817, 0.9917279481887817, 0.9917279481887817, 0.9914981722831726, 0.9919577240943909, 0.9910386204719543, 0.9914981722831726, 0.9917279481887817, 0.9919577240943909, 0.9910386204719543, 0.9919577240943909, 0.9912683963775635, 0.9926470518112183, 0.9921875, 0.9924172759056091, 0.9912683963775635, 0.990349292755127, 0.9905790686607361, 0.9919577240943909, 0.9924172759056091, 0.9924172759056091, 0.9928768277168274, 0.9919577240943909, 0.9921875, 0.9912683963775635, 0.9921875, 0.9921875, 0.9917279481887817, 0.9908088445663452, 0.9919577240943909, 0.990349292755127, 0.9894301295280457, 0.9898896813392639, 0.9924172759056091, 0.9917279481887817, 0.9917279481887817, 0.9908088445663452, 0.9921875, 0.9921875, 0.9908088445663452, 0.9921875, 0.9921875, 0.9921875, 0.9924172759056091, 0.9908088445663452, 0.9926470518112183, 0.9912683963775635, 0.9919577240943909, 0.9917279481887817, 0.9917279481887817, 0.9919577240943909, 0.9928768277168274, 0.9914981722831726, 0.9914981722831726, 0.9914981722831726, 0.9912683963775635, 0.9917279481887817, 0.9921875, 0.9919577240943909, 0.9924172759056091, 0.9917279481887817, 0.9919577240943909, 0.9914981722831726, 0.9908088445663452, 0.9924172759056091, 0.9917279481887817, 0.9924172759056091, 0.9926470518112183, 0.9917279481887817, 0.9926470518112183, 0.9919577240943909, 0.9921875, 0.9926470518112183, 0.9917279481887817, 0.9924172759056091, 0.9931066036224365, 0.9914981722831726, 0.9926470518112183, 0.9912683963775635, 0.9898896813392639, 0.9917279481887817, 0.9928768277168274, 0.9926470518112183, 0.9926470518112183, 0.9914981722831726, 0.9921875, 0.9921875, 0.9912683963775635, 0.9924172759056091, 0.9917279481887817, 0.9910386204719543, 0.9917279481887817, 0.9912683963775635, 0.9919577240943909, 0.9924172759056091, 0.9914981722831726, 0.9921875, 0.9924172759056091, 0.9908088445663452, 0.9912683963775635, 0.9917279481887817, 0.9910386204719543, 0.9928768277168274, 0.9924172759056091, 0.9914981722831726, 0.9919577240943909, 0.9910386204719543, 0.9914981722831726, 0.9910386204719543, 0.9917279481887817, 0.9914981722831726, 0.9914981722831726, 0.9917279481887817, 0.9914981722831726, 0.9905790686607361, 0.9910386204719543, 0.9914981722831726, 0.9919577240943909, 0.9917279481887817, 0.9908088445663452, 0.9917279481887817, 0.9894301295280457, 0.9905790686607361, 0.9912683963775635, 0.9917279481887817, 0.9921875, 0.9917279481887817, 0.9914981722831726, 0.9919577240943909, 0.9919577240943909, 0.9924172759056091, 0.9917279481887817, 0.9910386204719543, 0.9917279481887817, 0.9926470518112183, 0.9912683963775635, 0.9928768277168274, 0.9924172759056091, 0.9919577240943909, 0.9919577240943909, 0.9919577240943909, 0.9924172759056091, 0.9917279481887817, 0.9917279481887817, 0.9914981722831726, 0.9921875, 0.9908088445663452, 0.9919577240943909, 0.9924172759056091, 0.9914981722831726, 0.9919577240943909, 0.9919577240943909, 0.9919577240943909, 0.9921875, 0.9933363795280457, 0.9919577240943909, 0.9921875, 0.9928768277168274, 0.9926470518112183, 0.9924172759056091, 0.9914981722831726, 0.990349292755127, 0.9928768277168274, 0.9917279481887817, 0.9924172759056091, 0.9924172759056091, 0.9914981722831726, 0.9926470518112183, 0.9908088445663452, 0.9926470518112183, 0.98828125, 0.9914981722831726, 0.9912683963775635, 0.9908088445663452, 0.9887408018112183, 0.990349292755127, 0.9917279481887817, 0.9921875, 0.9917279481887817, 0.9931066036224365, 0.9921875, 0.9908088445663452, 0.9928768277168274, 0.9924172759056091, 0.9914981722831726, 0.9921875, 0.9924172759056091, 0.9933363795280457, 0.9919577240943909, 0.9924172759056091, 0.9928768277168274, 0.9926470518112183, 0.9921875, 0.9921875, 0.9926470518112183, 0.9919577240943909, 0.9921875, 0.9914981722831726, 0.9926470518112183, 0.9926470518112183, 0.9928768277168274, 0.9921875, 0.9921875, 0.9926470518112183, 0.9910386204719543, 0.9896599054336548, 0.9919577240943909, 0.9912683963775635, 0.9917279481887817, 0.9924172759056091, 0.9921875, 0.9919577240943909, 0.9898896813392639, 0.9919577240943909, 0.9917279481887817, 0.9921875, 0.9924172759056091, 0.9908088445663452, 0.9914981722831726, 0.9924172759056091, 0.9919577240943909, 0.9921875, 0.9917279481887817, 0.9924172759056091, 0.9912683963775635, 0.9931066036224365, 0.9924172759056091, 0.9924172759056091, 0.9921875, 0.9921875, 0.9924172759056091, 0.9928768277168274, 0.9919577240943909, 0.9928768277168274, 0.9926470518112183, 0.9912683963775635, 0.9926470518112183, 0.9931066036224365, 0.9917279481887817, 0.9924172759056091, 0.9912683963775635, 0.9928768277168274, 0.9917279481887817, 0.9926470518112183, 0.9931066036224365, 0.9921875, 0.9924172759056091, 0.9924172759056091, 0.9926470518112183, 0.9926470518112183, 0.9919577240943909, 0.9905790686607361, 0.9924172759056091, 0.9921875, 0.9917279481887817, 0.9928768277168274, 0.990349292755127, 0.9919577240943909, 0.9910386204719543, 0.9931066036224365, 0.9896599054336548, 0.9924172759056091, 0.9917279481887817, 0.9921875, 0.9917279481887817, 0.9931066036224365, 0.9924172759056091, 0.9921875, 0.9924172759056091, 0.9926470518112183, 0.9919577240943909, 0.9924172759056091, 0.9921875, 0.9919577240943909, 0.9919577240943909, 0.9926470518112183, 0.9924172759056091, 0.9931066036224365, 0.9921875, 0.9924172759056091, 0.9926470518112183, 0.9914981722831726, 0.9914981722831726, 0.9933363795280457, 0.9919577240943909, 0.9931066036224365, 0.9917279481887817, 0.9926470518112183, 0.9921875, 0.9919577240943909, 0.9924172759056091, 0.9921875, 0.9914981722831726, 0.9926470518112183, 0.9914981722831726, 0.9917279481887817, 0.9905790686607361, 0.9921875, 0.9924172759056091, 0.9928768277168274, 0.9928768277168274, 0.9917279481887817, 0.9905790686607361, 0.9919577240943909, 0.9921875, 0.9917279481887817, 0.9926470518112183, 0.9928768277168274, 0.9919577240943909, 0.9924172759056091, 0.9921875, 0.9919577240943909, 0.9917279481887817, 0.9926470518112183, 0.990349292755127, 0.9917279481887817, 0.9919577240943909, 0.9926470518112183, 0.9914981722831726, 0.9931066036224365, 0.9928768277168274, 0.9928768277168274, 0.9933363795280457, 0.9928768277168274, 0.9928768277168274, 0.9921875, 0.9926470518112183, 0.9928768277168274, 0.9921875, 0.9917279481887817, 0.9921875, 0.9919577240943909, 0.9928768277168274, 0.9924172759056091, 0.9924172759056091, 0.9931066036224365, 0.9917279481887817, 0.9926470518112183, 0.9924172759056091, 0.9924172759056091, 0.9919577240943909, 0.9924172759056091, 0.9924172759056091, 0.9921875, 0.9924172759056091, 0.9924172759056091, 0.9928768277168274, 0.9933363795280457, 0.9908088445663452, 0.9885110259056091, 0.990349292755127, 0.9912683963775635, 0.9908088445663452, 0.990119457244873, 0.9912683963775635, 0.9917279481887817, 0.9912683963775635, 0.9914981722831726, 0.9892003536224365, 0.9871323704719543, 0.9921875, 0.9924172759056091, 0.9908088445663452, 0.990119457244873, 0.9921875, 0.9931066036224365, 0.9917279481887817, 0.990349292755127, 0.9910386204719543, 0.9917279481887817, 0.9926470518112183, 0.9910386204719543, 0.9926470518112183, 0.9919577240943909, 0.9917279481887817, 0.9928768277168274, 0.9926470518112183, 0.9921875, 0.9917279481887817, 0.9924172759056091, 0.9928768277168274, 0.9926470518112183, 0.9931066036224365, 0.9926470518112183, 0.9928768277168274, 0.9917279481887817, 0.9935661554336548, 0.9921875, 0.9921875, 0.9926470518112183, 0.9926470518112183, 0.9921875, 0.9917279481887817, 0.9928768277168274, 0.9924172759056091, 0.9931066036224365, 0.9926470518112183, 0.9935661554336548, 0.9926470518112183, 0.9921875, 0.9914981722831726, 0.9926470518112183, 0.9921875, 0.9924172759056091, 0.9928768277168274, 0.9921875, 0.9921875, 0.9919577240943909, 0.9917279481887817, 0.9921875, 0.9924172759056091, 0.9935661554336548, 0.9928768277168274, 0.9928768277168274, 0.9917279481887817, 0.9926470518112183, 0.9910386204719543, 0.9928768277168274, 0.994025707244873, 0.9926470518112183, 0.9928768277168274, 0.9928768277168274, 0.9912683963775635, 0.9912683963775635, 0.9898896813392639, 0.990349292755127, 0.9917279481887817, 0.9919577240943909, 0.9917279481887817, 0.9931066036224365, 0.9931066036224365, 0.9928768277168274, 0.9928768277168274, 0.9928768277168274, 0.9921875, 0.9921875, 0.9926470518112183, 0.9924172759056091, 0.9933363795280457, 0.9931066036224365, 0.9928768277168274, 0.9926470518112183, 0.9926470518112183, 0.9928768277168274, 0.9926470518112183, 0.9937959313392639, 0.9919577240943909, 0.9921875, 0.9931066036224365, 0.9933363795280457, 0.9921875, 0.9931066036224365, 0.9921875, 0.9924172759056091, 0.9926470518112183, 0.9921875, 0.9919577240943909, 0.9926470518112183, 0.9926470518112183, 0.9931066036224365, 0.9921875, 0.9931066036224365, 0.9917279481887817, 0.9914981722831726, 0.9921875, 0.9933363795280457, 0.9926470518112183, 0.9924172759056091, 0.9937959313392639, 0.9935661554336548, 0.9933363795280457, 0.9905790686607361, 0.9933363795280457, 0.9921875, 0.9914981722831726, 0.9921875, 0.9924172759056091, 0.990349292755127, 0.9931066036224365, 0.9926470518112183, 0.9933363795280457, 0.9937959313392639, 0.9933363795280457, 0.9937959313392639, 0.9921875, 0.9924172759056091, 0.9931066036224365, 0.9931066036224365, 0.9919577240943909, 0.9919577240943909, 0.9917279481887817, 0.9912683963775635, 0.9919577240943909, 0.9937959313392639, 0.9937959313392639, 0.9933363795280457, 0.9931066036224365, 0.9910386204719543, 0.9926470518112183, 0.9917279481887817, 0.9935661554336548, 0.9919577240943909, 0.9910386204719543, 0.9914981722831726, 0.990119457244873, 0.990349292755127, 0.9914981722831726, 0.9924172759056091, 0.9933363795280457, 0.9924172759056091, 0.9931066036224365, 0.9926470518112183, 0.9928768277168274, 0.9931066036224365, 0.9928768277168274, 0.9931066036224365, 0.9928768277168274, 0.9924172759056091, 0.9928768277168274, 0.9931066036224365, 0.9928768277168274, 0.9933363795280457, 0.9926470518112183, 0.9928768277168274, 0.9933363795280457, 0.9931066036224365, 0.9921875, 0.990349292755127, 0.9917279481887817, 0.9937959313392639, 0.9931066036224365, 0.9924172759056091, 0.9919577240943909, 0.9926470518112183, 0.9931066036224365, 0.9910386204719543, 0.9921875, 0.9921875, 0.9928768277168274, 0.9921875, 0.9924172759056091, 0.9912683963775635, 0.9914981722831726, 0.9912683963775635, 0.9912683963775635, 0.9887408018112183, 0.9910386204719543, 0.9912683963775635, 0.9928768277168274, 0.9926470518112183, 0.9917279481887817, 0.9928768277168274, 0.9928768277168274, 0.9935661554336548, 0.9926470518112183, 0.9926470518112183, 0.9933363795280457, 0.9926470518112183, 0.9926470518112183, 0.9924172759056091, 0.9933363795280457, 0.9928768277168274, 0.9931066036224365, 0.9928768277168274, 0.9910386204719543, 0.9919577240943909, 0.9928768277168274, 0.9917279481887817, 0.9937959313392639, 0.9931066036224365, 0.9924172759056091, 0.9928768277168274, 0.9926470518112183, 0.9926470518112183, 0.9917279481887817, 0.9924172759056091, 0.9928768277168274, 0.994025707244873, 0.9928768277168274, 0.9917279481887817, 0.9931066036224365, 0.9935661554336548, 0.9926470518112183, 0.9931066036224365, 0.9933363795280457, 0.9928768277168274, 0.9926470518112183, 0.9928768277168274, 0.9933363795280457, 0.9935661554336548, 0.9926470518112183, 0.9926470518112183, 0.9924172759056091, 0.9928768277168274, 0.9935661554336548, 0.9931066036224365, 0.9928768277168274, 0.994025707244873, 0.9937959313392639, 0.9926470518112183, 0.9926470518112183, 0.9935661554336548, 0.9937959313392639, 0.9935661554336548, 0.9924172759056091, 0.9935661554336548, 0.9887408018112183, 0.9894301295280457, 0.9910386204719543, 0.9914981722831726, 0.9917279481887817, 0.9919577240943909, 0.9917279481887817, 0.9912683963775635, 0.9926470518112183, 0.9931066036224365, 0.9924172759056091, 0.9914981722831726, 0.9926470518112183, 0.9926470518112183, 0.9933363795280457, 0.9928768277168274, 0.9937959313392639, 0.9931066036224365, 0.9933363795280457, 0.9937959313392639, 0.9931066036224365, 0.9935661554336548, 0.9931066036224365, 0.9933363795280457, 0.9933363795280457, 0.9931066036224365, 0.9937959313392639, 0.9937959313392639, 0.9928768277168274, 0.9917279481887817, 0.9917279481887817, 0.9931066036224365, 0.9937959313392639, 0.9931066036224365, 0.9931066036224365, 0.9926470518112183, 0.9931066036224365, 0.9928768277168274, 0.9926470518112183, 0.9944853186607361, 0.9931066036224365, 0.9928768277168274, 0.9935661554336548, 0.9931066036224365, 0.9935661554336548, 0.9931066036224365, 0.9931066036224365, 0.994255542755127, 0.9937959313392639, 0.9933363795280457, 0.9919577240943909, 0.9908088445663452, 0.990349292755127, 0.9924172759056091, 0.9937959313392639, 0.9905790686607361, 0.9931066036224365, 0.9928768277168274, 0.9910386204719543, 0.9935661554336548, 0.9921875, 0.9937959313392639, 0.9926470518112183, 0.9933363795280457, 0.9933363795280457, 0.994025707244873, 0.9926470518112183, 0.9912683963775635, 0.9935661554336548, 0.9919577240943909, 0.9937959313392639, 0.9921875, 0.9928768277168274, 0.9921875, 0.9926470518112183, 0.9937959313392639, 0.9921875, 0.9924172759056091, 0.9928768277168274, 0.9937959313392639, 0.9928768277168274, 0.9926470518112183, 0.9917279481887817, 0.990349292755127, 0.994025707244873, 0.9928768277168274, 0.994025707244873, 0.9926470518112183, 0.9926470518112183, 0.9921875, 0.9926470518112183, 0.9933363795280457, 0.9933363795280457, 0.9912683963775635, 0.9937959313392639, 0.9924172759056091, 0.9926470518112183, 0.9919577240943909, 0.9896599054336548, 0.9947150945663452, 0.9931066036224365, 0.9937959313392639, 0.9935661554336548, 0.994025707244873, 0.9928768277168274, 0.9935661554336548, 0.994025707244873, 0.9937959313392639, 0.9928768277168274, 0.9921875, 0.994025707244873, 0.9931066036224365, 0.9914981722831726, 0.9926470518112183, 0.9919577240943909, 0.9935661554336548, 0.9935661554336548, 0.9924172759056091, 0.9937959313392639, 0.9933363795280457, 0.9931066036224365, 0.9926470518112183, 0.994025707244873, 0.9921875, 0.9935661554336548, 0.9919577240943909, 0.9919577240943909, 0.9926470518112183, 0.9931066036224365, 0.9917279481887817, 0.9921875, 0.9917279481887817, 0.9892003536224365, 0.9894301295280457, 0.9917279481887817, 0.9924172759056091, 0.9926470518112183, 0.994255542755127, 0.9928768277168274, 0.9931066036224365, 0.9933363795280457, 0.9905790686607361, 0.9935661554336548, 0.9933363795280457, 0.9921875, 0.990119457244873, 0.9924172759056091, 0.9933363795280457, 0.990349292755127, 0.9921875, 0.994025707244873, 0.9931066036224365, 0.994255542755127, 0.9933363795280457, 0.9933363795280457, 0.9928768277168274, 0.9935661554336548, 0.9933363795280457, 0.9935661554336548, 0.9933363795280457, 0.9935661554336548, 0.9937959313392639, 0.9933363795280457, 0.994025707244873, 0.9933363795280457, 0.994255542755127, 0.9914981722831726, 0.9919577240943909, 0.9914981722831726, 0.9928768277168274, 0.994025707244873, 0.9933363795280457, 0.9919577240943909, 0.9935661554336548, 0.9931066036224365, 0.9931066036224365, 0.9924172759056091, 0.9935661554336548, 0.9892003536224365, 0.9917279481887817, 0.9928768277168274, 0.9919577240943909, 0.9931066036224365, 0.9926470518112183, 0.9933363795280457, 0.9926470518112183, 0.9921875, 0.9926470518112183, 0.9931066036224365, 0.9928768277168274, 0.9935661554336548, 0.9924172759056091, 0.9933363795280457, 0.9933363795280457, 0.9935661554336548, 0.9931066036224365, 0.9931066036224365, 0.9933363795280457, 0.9928768277168274, 0.9937959313392639, 0.9937959313392639, 0.9935661554336548, 0.9933363795280457, 0.9921875, 0.994025707244873, 0.9935661554336548, 0.994255542755127, 0.9937959313392639, 0.9935661554336548, 0.9944853186607361, 0.994025707244873, 0.9933363795280457, 0.9908088445663452, 0.9926470518112183, 0.9898896813392639, 0.9921875, 0.9933363795280457, 0.9928768277168274, 0.9917279481887817, 0.9914981722831726, 0.9924172759056091, 0.9924172759056091, 0.9921875, 0.9926470518112183, 0.9912683963775635, 0.9933363795280457, 0.9933363795280457, 0.9935661554336548, 0.9933363795280457, 0.9928768277168274, 0.9931066036224365, 0.9931066036224365, 0.9933363795280457, 0.9919577240943909, 0.994255542755127, 0.9933363795280457, 0.9935661554336548, 0.9926470518112183, 0.994025707244873, 0.9935661554336548, 0.9933363795280457, 0.994255542755127, 0.9931066036224365, 0.994025707244873, 0.9928768277168274, 0.9931066036224365, 0.9935661554336548, 0.9937959313392639, 0.9931066036224365, 0.9917279481887817, 0.9931066036224365, 0.9937959313392639, 0.9933363795280457, 0.9919577240943909, 0.9910386204719543, 0.9905790686607361, 0.9894301295280457, 0.9896599054336548, 0.990349292755127, 0.9928768277168274, 0.9937959313392639, 0.9937959313392639, 0.994255542755127, 0.9935661554336548, 0.9926470518112183, 0.9926470518112183, 0.994025707244873, 0.9935661554336548, 0.9931066036224365, 0.9937959313392639, 0.9937959313392639, 0.9933363795280457, 0.9919577240943909, 0.9937959313392639, 0.9926470518112183, 0.9933363795280457, 0.9931066036224365, 0.9919577240943909, 0.9921875, 0.9933363795280457, 0.9935661554336548, 0.9937959313392639, 0.9933363795280457, 0.9908088445663452, 0.9894301295280457, 0.9896599054336548, 0.9912683963775635, 0.9935661554336548, 0.9924172759056091, 0.9937959313392639, 0.9933363795280457, 0.9928768277168274, 0.994025707244873, 0.9933363795280457, 0.9910386204719543, 0.990119457244873, 0.9921875, 0.9924172759056091, 0.9931066036224365, 0.9926470518112183, 0.994255542755127, 0.9933363795280457, 0.9933363795280457, 0.994025707244873, 0.9933363795280457, 0.9933363795280457, 0.9931066036224365, 0.9931066036224365, 0.9928768277168274, 0.9931066036224365, 0.9931066036224365, 0.9928768277168274, 0.9921875, 0.9921875, 0.9921875, 0.9919577240943909, 0.9919577240943909, 0.9931066036224365, 0.994025707244873, 0.9935661554336548, 0.9928768277168274, 0.994255542755127, 0.9914981722831726, 0.9924172759056091, 0.9917279481887817, 0.9926470518112183, 0.9928768277168274, 0.9919577240943909, 0.9928768277168274, 0.994255542755127, 0.9937959313392639, 0.9935661554336548, 0.9933363795280457, 0.9933363795280457, 0.994025707244873, 0.994255542755127, 0.9919577240943909, 0.9931066036224365, 0.9949448704719543, 0.9933363795280457, 0.994025707244873, 0.9937959313392639, 0.9928768277168274, 0.994025707244873, 0.9933363795280457, 0.9933363795280457, 0.9933363795280457, 0.9937959313392639, 0.9931066036224365, 0.9937959313392639, 0.994025707244873, 0.9924172759056091, 0.9933363795280457, 0.9910386204719543, 0.9908088445663452, 0.9914981722831726, 0.9935661554336548, 0.994255542755127, 0.9935661554336548, 0.994025707244873, 0.9933363795280457, 0.9931066036224365, 0.9931066036224365, 0.9931066036224365, 0.9933363795280457, 0.9937959313392639, 0.9928768277168274, 0.9937959313392639, 0.994025707244873, 0.9924172759056091, 0.9924172759056091, 0.9928768277168274, 0.9937959313392639, 0.9935661554336548, 0.994025707244873, 0.9931066036224365, 0.9933363795280457, 0.9944853186607361, 0.9935661554336548, 0.9935661554336548, 0.9931066036224365, 0.9947150945663452, 0.9935661554336548, 0.9933363795280457, 0.9928768277168274, 0.9933363795280457, 0.9933363795280457, 0.9931066036224365, 0.9924172759056091, 0.994025707244873, 0.9928768277168274, 0.9928768277168274, 0.994025707244873, 0.994025707244873, 0.9919577240943909, 0.9912683963775635, 0.9926470518112183, 0.9928768277168274, 0.9933363795280457, 0.994025707244873, 0.994025707244873, 0.9931066036224365, 0.9935661554336548, 0.9935661554336548, 0.9931066036224365, 0.9928768277168274, 0.9919577240943909, 0.9933363795280457, 0.9928768277168274, 0.9931066036224365, 0.9935661554336548, 0.9937959313392639, 0.9935661554336548, 0.9933363795280457, 0.994025707244873, 0.994025707244873, 0.9935661554336548, 0.994255542755127, 0.9933363795280457, 0.994025707244873, 0.9944853186607361, 0.9924172759056091, 0.9933363795280457, 0.9935661554336548, 0.9937959313392639, 0.9937959313392639, 0.994025707244873, 0.9944853186607361, 0.9944853186607361, 0.994025707244873, 0.9926470518112183, 0.9933363795280457, 0.9919577240943909, 0.9944853186607361, 0.9931066036224365, 0.9935661554336548, 0.9931066036224365, 0.994025707244873, 0.994025707244873, 0.9928768277168274, 0.9935661554336548, 0.9935661554336548, 0.994025707244873, 0.9937959313392639, 0.9935661554336548, 0.9933363795280457, 0.9933363795280457, 0.9928768277168274, 0.994025707244873, 0.9949448704719543, 0.9935661554336548, 0.994255542755127, 0.9947150945663452, 0.9937959313392639, 0.994025707244873, 0.9937959313392639, 0.9933363795280457, 0.9926470518112183, 0.9937959313392639, 0.9924172759056091, 0.9924172759056091, 0.9937959313392639, 0.9924172759056091, 0.9931066036224365, 0.990349292755127, 0.9933363795280457, 0.9931066036224365, 0.9931066036224365, 0.994025707244873, 0.994255542755127, 0.9935661554336548, 0.9937959313392639, 0.9944853186607361, 0.9928768277168274, 0.9937959313392639, 0.9921875, 0.9924172759056091, 0.9910386204719543, 0.9937959313392639, 0.9931066036224365, 0.9928768277168274, 0.9935661554336548, 0.9935661554336548, 0.9935661554336548, 0.9935661554336548, 0.9931066036224365, 0.9926470518112183, 0.9917279481887817, 0.9919577240943909, 0.9931066036224365, 0.9937959313392639, 0.994255542755127, 0.9944853186607361, 0.9933363795280457, 0.9935661554336548, 0.9933363795280457, 0.9926470518112183, 0.9919577240943909, 0.9928768277168274, 0.9912683963775635, 0.9935661554336548, 0.994255542755127, 0.9937959313392639, 0.9933363795280457, 0.9935661554336548, 0.9937959313392639, 0.994255542755127, 0.9935661554336548, 0.9935661554336548, 0.9928768277168274, 0.994025707244873, 0.9935661554336548, 0.9928768277168274, 0.9914981722831726, 0.994025707244873, 0.9931066036224365, 0.9937959313392639, 0.9935661554336548, 0.9928768277168274, 0.9937959313392639, 0.9928768277168274, 0.9926470518112183, 0.9926470518112183, 0.9931066036224365, 0.994255542755127, 0.9944853186607361, 0.9937959313392639, 0.9924172759056091, 0.9937959313392639, 0.9924172759056091, 0.9928768277168274, 0.9931066036224365, 0.9931066036224365, 0.9926470518112183, 0.9928768277168274, 0.9926470518112183, 0.9944853186607361, 0.9931066036224365, 0.9935661554336548, 0.9928768277168274, 0.9931066036224365, 0.9937959313392639, 0.9921875, 0.9937959313392639, 0.9944853186607361, 0.9931066036224365, 0.994025707244873, 0.9937959313392639, 0.994025707244873, 0.994255542755127, 0.994255542755127, 0.9944853186607361, 0.994025707244873, 0.994255542755127, 0.9935661554336548, 0.994255542755127, 0.9935661554336548, 0.994025707244873, 0.994255542755127, 0.9937959313392639, 0.9937959313392639, 0.9935661554336548, 0.9931066036224365, 0.9944853186607361, 0.994025707244873, 0.9921875, 0.9931066036224365, 0.9937959313392639, 0.9947150945663452, 0.994255542755127, 0.994255542755127, 0.9947150945663452, 0.994025707244873, 0.9935661554336548, 0.9928768277168274, 0.9931066036224365, 0.9926470518112183, 0.9926470518112183, 0.9937959313392639, 0.9928768277168274, 0.9937959313392639, 0.9935661554336548, 0.994255542755127, 0.9944853186607361, 0.9935661554336548, 0.9926470518112183, 0.9892003536224365, 0.9921875, 0.9931066036224365, 0.9928768277168274, 0.9933363795280457, 0.9949448704719543, 0.9926470518112183, 0.9935661554336548, 0.9944853186607361, 0.994255542755127, 0.9931066036224365, 0.9919577240943909, 0.9928768277168274, 0.9926470518112183, 0.994025707244873, 0.9944853186607361, 0.994255542755127, 0.9951746463775635, 0.9935661554336548, 0.9944853186607361, 0.9935661554336548, 0.994025707244873, 0.9944853186607361, 0.9947150945663452, 0.9928768277168274, 0.9928768277168274, 0.9944853186607361, 0.9944853186607361, 0.9933363795280457, 0.994025707244873, 0.9944853186607361, 0.994255542755127, 0.9931066036224365, 0.9947150945663452, 0.9935661554336548, 0.9947150945663452, 0.994255542755127, 0.9928768277168274, 0.9931066036224365, 0.994255542755127, 0.994025707244873, 0.9947150945663452, 0.9935661554336548, 0.9937959313392639, 0.9944853186607361, 0.9935661554336548, 0.994025707244873, 0.994255542755127, 0.9919577240943909, 0.9933363795280457, 0.994255542755127, 0.9944853186607361, 0.994025707244873, 0.9935661554336548, 0.994025707244873, 0.9924172759056091, 0.9926470518112183, 0.9935661554336548, 0.994025707244873, 0.9921875, 0.9933363795280457, 0.9933363795280457, 0.994025707244873, 0.9944853186607361, 0.9928768277168274, 0.9933363795280457, 0.994255542755127, 0.9933363795280457, 0.994255542755127, 0.9914981722831726, 0.9933363795280457, 0.994255542755127, 0.9944853186607361, 0.9931066036224365, 0.994025707244873, 0.9937959313392639, 0.994255542755127, 0.9933363795280457, 0.9937959313392639, 0.9931066036224365, 0.994025707244873, 0.9935661554336548, 0.994025707244873, 0.9947150945663452, 0.9937959313392639, 0.9944853186607361, 0.9937959313392639, 0.9937959313392639, 0.994025707244873, 0.9928768277168274, 0.994025707244873, 0.9931066036224365, 0.9944853186607361, 0.994255542755127, 0.9928768277168274, 0.9931066036224365, 0.9928768277168274, 0.9935661554336548, 0.9926470518112183, 0.9933363795280457, 0.9937959313392639, 0.994255542755127, 0.994025707244873, 0.994025707244873, 0.9944853186607361, 0.9937959313392639, 0.9926470518112183, 0.9931066036224365, 0.994255542755127, 0.9933363795280457, 0.9917279481887817, 0.9933363795280457, 0.9935661554336548, 0.9910386204719543, 0.9928768277168274, 0.9937959313392639, 0.9947150945663452, 0.9937959313392639, 0.9935661554336548, 0.9937959313392639, 0.994025707244873, 0.9931066036224365, 0.9937959313392639, 0.9935661554336548, 0.994255542755127, 0.9944853186607361, 0.9949448704719543, 0.9947150945663452, 0.9937959313392639, 0.9912683963775635, 0.9910386204719543, 0.994025707244873, 0.994025707244873, 0.994255542755127, 0.9947150945663452, 0.9933363795280457, 0.9928768277168274, 0.9937959313392639, 0.994025707244873, 0.9935661554336548, 0.9949448704719543, 0.994025707244873, 0.994025707244873, 0.9944853186607361, 0.994025707244873, 0.994025707244873, 0.9937959313392639, 0.9937959313392639, 0.9935661554336548, 0.9951746463775635, 0.9931066036224365, 0.9944853186607361, 0.994025707244873, 0.9947150945663452, 0.9935661554336548, 0.9933363795280457, 0.9935661554336548, 0.994255542755127, 0.990349292755127, 0.9887408018112183, 0.9919577240943909, 0.9924172759056091, 0.994255542755127, 0.9928768277168274, 0.994025707244873, 0.994255542755127, 0.994025707244873, 0.994255542755127, 0.9949448704719543, 0.9931066036224365, 0.9958639740943909, 0.994025707244873, 0.9933363795280457, 0.9935661554336548, 0.9931066036224365, 0.9944853186607361, 0.9933363795280457, 0.9937959313392639, 0.9933363795280457, 0.9919577240943909, 0.9931066036224365, 0.9937959313392639, 0.994025707244873, 0.9933363795280457, 0.9935661554336548, 0.9947150945663452, 0.9947150945663452, 0.994025707244873, 0.9944853186607361, 0.9947150945663452, 0.994255542755127, 0.9951746463775635, 0.994025707244873, 0.994025707244873, 0.994025707244873, 0.9933363795280457, 0.994025707244873, 0.9944853186607361, 0.9937959313392639, 0.9949448704719543, 0.9949448704719543, 0.994025707244873, 0.9949448704719543, 0.994255542755127, 0.994255542755127, 0.9947150945663452, 0.9937959313392639, 0.9947150945663452, 0.9944853186607361, 0.9937959313392639, 0.9947150945663452, 0.9937959313392639, 0.994255542755127, 0.9947150945663452, 0.9931066036224365, 0.9933363795280457, 0.9947150945663452, 0.994255542755127, 0.9949448704719543, 0.9937959313392639, 0.994255542755127, 0.994255542755127, 0.9935661554336548, 0.9937959313392639, 0.9958639740943909, 0.9933363795280457, 0.994025707244873, 0.9935661554336548, 0.994255542755127, 0.9944853186607361, 0.9944853186607361, 0.994025707244873, 0.9944853186607361, 0.9937959313392639, 0.9921875, 0.9937959313392639, 0.9933363795280457, 0.9935661554336548, 0.9928768277168274, 0.9924172759056091, 0.9924172759056091, 0.994025707244873, 0.994025707244873, 0.994255542755127, 0.994025707244873, 0.9935661554336548, 0.9933363795280457, 0.9944853186607361, 0.9926470518112183, 0.9937959313392639, 0.9933363795280457, 0.9937959313392639, 0.994025707244873, 0.9949448704719543, 0.9931066036224365, 0.9944853186607361, 0.994255542755127, 0.9944853186607361, 0.9949448704719543, 0.9937959313392639, 0.9933363795280457, 0.9931066036224365, 0.994025707244873, 0.9926470518112183, 0.9933363795280457, 0.9933363795280457, 0.9937959313392639, 0.9937959313392639, 0.9944853186607361, 0.9937959313392639, 0.994255542755127, 0.9944853186607361, 0.9935661554336548, 0.9914981722831726, 0.994255542755127, 0.994255542755127, 0.9937959313392639, 0.9917279481887817, 0.9928768277168274, 0.9947150945663452, 0.9951746463775635, 0.9944853186607361, 0.9926470518112183, 0.9926470518112183, 0.9910386204719543, 0.9951746463775635, 0.9944853186607361, 0.9937959313392639, 0.9947150945663452, 0.994025707244873, 0.994255542755127, 0.994255542755127, 0.9949448704719543, 0.9935661554336548, 0.9944853186607361, 0.9935661554336548, 0.994255542755127, 0.994255542755127, 0.9935661554336548, 0.9937959313392639, 0.9949448704719543, 0.9935661554336548, 0.9933363795280457, 0.9935661554336548, 0.9935661554336548, 0.9944853186607361, 0.994255542755127, 0.9944853186607361, 0.9933363795280457, 0.9935661554336548, 0.9944853186607361, 0.9937959313392639, 0.9933363795280457, 0.9947150945663452, 0.9949448704719543, 0.9947150945663452, 0.9947150945663452, 0.994025707244873, 0.9937959313392639, 0.9949448704719543, 0.9937959313392639, 0.9944853186607361, 0.9935661554336548, 0.9924172759056091, 0.9908088445663452, 0.9933363795280457, 0.9931066036224365, 0.9933363795280457, 0.9926470518112183, 0.9917279481887817, 0.9935661554336548, 0.994255542755127, 0.9947150945663452, 0.994255542755127, 0.9917279481887817, 0.9931066036224365, 0.9947150945663452, 0.9949448704719543, 0.9947150945663452, 0.994255542755127, 0.9949448704719543, 0.9947150945663452, 0.9937959313392639, 0.9944853186607361, 0.9947150945663452, 0.994255542755127, 0.9937959313392639, 0.9951746463775635, 0.9944853186607361, 0.994025707244873, 0.9947150945663452, 0.9944853186607361, 0.9949448704719543, 0.9944853186607361, 0.9947150945663452, 0.994025707244873, 0.9944853186607361, 0.9937959313392639, 0.9954044222831726, 0.9935661554336548, 0.9944853186607361, 0.9949448704719543, 0.9949448704719543, 0.994255542755127, 0.9949448704719543, 0.994255542755127, 0.9944853186607361, 0.9933363795280457, 0.9949448704719543, 0.9947150945663452, 0.9944853186607361, 0.9933363795280457, 0.9949448704719543, 0.9931066036224365, 0.9947150945663452, 0.9949448704719543, 0.9944853186607361, 0.9944853186607361, 0.9931066036224365, 0.9937959313392639, 0.9949448704719543, 0.994025707244873, 0.994255542755127, 0.9947150945663452, 0.9947150945663452, 0.9937959313392639, 0.994255542755127, 0.9944853186607361, 0.9931066036224365, 0.9919577240943909, 0.9917279481887817, 0.9937959313392639, 0.9937959313392639, 0.9944853186607361, 0.994255542755127, 0.9931066036224365, 0.9944853186607361, 0.994255542755127, 0.9935661554336548, 0.9947150945663452, 0.9937959313392639, 0.990119457244873, 0.9937959313392639, 0.9944853186607361, 0.994025707244873, 0.9947150945663452, 0.9937959313392639, 0.9947150945663452, 0.9949448704719543, 0.9935661554336548, 0.9951746463775635, 0.994025707244873, 0.9935661554336548, 0.994255542755127, 0.9933363795280457, 0.9944853186607361, 0.9921875, 0.9926470518112183, 0.994025707244873, 0.9944853186607361, 0.994255542755127, 0.9947150945663452, 0.994025707244873, 0.9937959313392639, 0.9935661554336548, 0.9924172759056091, 0.9947150945663452, 0.9912683963775635, 0.9926470518112183, 0.9931066036224365, 0.9928768277168274, 0.994025707244873, 0.994255542755127, 0.9937959313392639, 0.9928768277168274, 0.9928768277168274, 0.994025707244873, 0.9931066036224365, 0.9944853186607361, 0.9931066036224365, 0.9944853186607361, 0.9926470518112183, 0.9935661554336548, 0.9919577240943909, 0.9937959313392639, 0.9937959313392639, 0.994255542755127, 0.9944853186607361, 0.994255542755127, 0.9924172759056091, 0.9926470518112183, 0.9954044222831726, 0.9947150945663452, 0.9956341981887817, 0.9947150945663452, 0.9914981722831726, 0.9908088445663452, 0.9928768277168274, 0.994255542755127, 0.994025707244873, 0.994025707244873, 0.9933363795280457, 0.994255542755127, 0.9947150945663452, 0.9951746463775635, 0.9944853186607361, 0.9947150945663452, 0.9935661554336548, 0.9947150945663452, 0.994255542755127, 0.9931066036224365, 0.9947150945663452, 0.9947150945663452, 0.9944853186607361, 0.9954044222831726, 0.9937959313392639, 0.9921875, 0.994025707244873, 0.994255542755127, 0.9933363795280457, 0.9937959313392639, 0.994255542755127, 0.994255542755127, 0.9947150945663452, 0.9951746463775635, 0.994255542755127, 0.994255542755127, 0.9951746463775635, 0.9951746463775635, 0.9949448704719543, 0.9947150945663452, 0.9956341981887817, 0.9947150945663452, 0.994255542755127, 0.994255542755127, 0.9949448704719543, 0.9947150945663452, 0.9933363795280457, 0.994255542755127, 0.9947150945663452, 0.9956341981887817, 0.9947150945663452, 0.9933363795280457, 0.9947150945663452, 0.9935661554336548, 0.9947150945663452, 0.9944853186607361, 0.9949448704719543, 0.9949448704719543, 0.994255542755127, 0.994025707244873, 0.9944853186607361, 0.9944853186607361, 0.9949448704719543, 0.9944853186607361, 0.9949448704719543, 0.9947150945663452, 0.9956341981887817, 0.9954044222831726, 0.9958639740943909, 0.9951746463775635, 0.9947150945663452, 0.9933363795280457, 0.9951746463775635, 0.9947150945663452, 0.994255542755127, 0.9931066036224365, 0.994255542755127, 0.9944853186607361, 0.9954044222831726, 0.9949448704719543, 0.9949448704719543, 0.9954044222831726, 0.9947150945663452, 0.9944853186607361, 0.994255542755127, 0.9947150945663452, 0.994255542755127, 0.9951746463775635, 0.9949448704719543, 0.9951746463775635, 0.9949448704719543, 0.9944853186607361, 0.9944853186607361, 0.9949448704719543, 0.9951746463775635, 0.994255542755127, 0.9951746463775635, 0.994255542755127, 0.9935661554336548, 0.9935661554336548, 0.9947150945663452, 0.9954044222831726, 0.9951746463775635, 0.9954044222831726, 0.994255542755127, 0.9924172759056091, 0.9947150945663452, 0.9954044222831726, 0.9951746463775635, 0.9944853186607361, 0.9947150945663452, 0.9954044222831726, 0.9944853186607361, 0.9949448704719543, 0.9951746463775635, 0.9944853186607361, 0.9954044222831726, 0.9956341981887817, 0.99609375, 0.99609375, 0.9947150945663452, 0.9949448704719543, 0.9963235259056091, 0.9926470518112183, 0.9935661554336548, 0.9912683963775635, 0.9944853186607361, 0.9917279481887817, 0.9949448704719543, 0.9947150945663452, 0.9947150945663452, 0.9933363795280457, 0.9954044222831726, 0.9935661554336548, 0.994255542755127, 0.9947150945663452, 0.9944853186607361, 0.9954044222831726, 0.9947150945663452, 0.9956341981887817, 0.9956341981887817, 0.9944853186607361, 0.99609375, 0.9933363795280457, 0.9951746463775635, 0.994255542755127, 0.9951746463775635, 0.9944853186607361, 0.9951746463775635, 0.9949448704719543, 0.9951746463775635, 0.9944853186607361, 0.9944853186607361, 0.9935661554336548, 0.994255542755127, 0.9947150945663452, 0.9951746463775635, 0.9951746463775635, 0.9954044222831726, 0.99609375, 0.9944853186607361, 0.9944853186607361, 0.9947150945663452, 0.9954044222831726, 0.9937959313392639, 0.9928768277168274, 0.9892003536224365, 0.9873621463775635, 0.9924172759056091, 0.9954044222831726, 0.9921875, 0.9931066036224365, 0.9933363795280457, 0.994025707244873, 0.9965533018112183, 0.9944853186607361, 0.994025707244873, 0.994025707244873, 0.9944853186607361, 0.9935661554336548, 0.9937959313392639, 0.994255542755127, 0.9944853186607361, 0.9928768277168274, 0.9919577240943909, 0.994025707244873, 0.9928768277168274, 0.994255542755127, 0.994255542755127, 0.9956341981887817, 0.9956341981887817, 0.9951746463775635, 0.9944853186607361, 0.9947150945663452, 0.9949448704719543, 0.9958639740943909, 0.9954044222831726, 0.9956341981887817, 0.9947150945663452, 0.9956341981887817, 0.9937959313392639, 0.9947150945663452, 0.9956341981887817, 0.9937959313392639, 0.9935661554336548, 0.994255542755127, 0.9937959313392639, 0.994255542755127, 0.9951746463775635, 0.9951746463775635, 0.9958639740943909, 0.9947150945663452, 0.9947150945663452, 0.9947150945663452, 0.9947150945663452, 0.9935661554336548, 0.9937959313392639, 0.9951746463775635, 0.994255542755127, 0.9944853186607361, 0.9954044222831726, 0.9951746463775635, 0.9954044222831726, 0.9949448704719543, 0.9954044222831726, 0.9937959313392639, 0.9937959313392639, 0.9958639740943909, 0.9951746463775635, 0.9951746463775635, 0.9947150945663452, 0.9947150945663452, 0.9956341981887817, 0.99609375, 0.9958639740943909, 0.9958639740943909, 0.9949448704719543, 0.994255542755127, 0.9935661554336548, 0.9951746463775635, 0.9933363795280457, 0.9924172759056091, 0.994025707244873, 0.9944853186607361, 0.9958639740943909, 0.9949448704719543, 0.994025707244873, 0.994255542755127, 0.994025707244873, 0.9944853186607361, 0.9947150945663452, 0.9944853186607361, 0.9963235259056091, 0.9956341981887817, 0.9965533018112183, 0.9954044222831726, 0.9956341981887817, 0.9928768277168274, 0.9954044222831726, 0.99609375, 0.99609375, 0.9954044222831726, 0.9947150945663452, 0.994255542755127, 0.9926470518112183, 0.9933363795280457, 0.9963235259056091, 0.9951746463775635, 0.9958639740943909, 0.9949448704719543, 0.994025707244873, 0.994255542755127, 0.9951746463775635, 0.9954044222831726, 0.9951746463775635, 0.9958639740943909, 0.9944853186607361, 0.994025707244873, 0.994025707244873, 0.9958639740943909, 0.9937959313392639, 0.9963235259056091, 0.9963235259056091, 0.9956341981887817, 0.9951746463775635, 0.99609375, 0.9944853186607361, 0.9951746463775635, 0.9928768277168274, 0.994025707244873, 0.9949448704719543, 0.9947150945663452, 0.9944853186607361, 0.9958639740943909, 0.99609375, 0.9935661554336548, 0.994025707244873, 0.9947150945663452, 0.9965533018112183, 0.9965533018112183, 0.9954044222831726, 0.9951746463775635, 0.9963235259056091, 0.99609375, 0.99609375, 0.9963235259056091, 0.9954044222831726, 0.9965533018112183, 0.9963235259056091, 0.9958639740943909, 0.9967830777168274, 0.99609375, 0.9963235259056091, 0.9958639740943909, 0.9944853186607361, 0.9958639740943909, 0.9963235259056091, 0.9951746463775635, 0.994255542755127, 0.9949448704719543, 0.9956341981887817, 0.9947150945663452, 0.9956341981887817, 0.9951746463775635, 0.9944853186607361, 0.994025707244873, 0.9949448704719543, 0.9954044222831726, 0.9947150945663452, 0.994255542755127, 0.99609375, 0.9947150945663452, 0.9958639740943909, 0.9958639740943909, 0.9947150945663452, 0.9951746463775635, 0.9956341981887817, 0.9956341981887817, 0.9965533018112183, 0.9956341981887817, 0.9967830777168274, 0.9958639740943909, 0.9944853186607361, 0.9951746463775635, 0.9951746463775635, 0.994255542755127, 0.9949448704719543, 0.9949448704719543, 0.9949448704719543, 0.9933363795280457, 0.9949448704719543, 0.9947150945663452, 0.9956341981887817, 0.9947150945663452, 0.994255542755127, 0.9951746463775635, 0.9958639740943909, 0.9951746463775635, 0.9956341981887817, 0.9944853186607361, 0.994255542755127, 0.9949448704719543, 0.9951746463775635, 0.99609375, 0.9965533018112183, 0.9947150945663452, 0.994255542755127, 0.9954044222831726, 0.9963235259056091, 0.9958639740943909, 0.9949448704719543, 0.9963235259056091, 0.9951746463775635, 0.9965533018112183, 0.9958639740943909, 0.9947150945663452, 0.9947150945663452, 0.9949448704719543, 0.9963235259056091, 0.9954044222831726, 0.9965533018112183, 0.9963235259056091, 0.9954044222831726, 0.9958639740943909, 0.99609375, 0.99609375, 0.9963235259056091, 0.9954044222831726, 0.9967830777168274, 0.9963235259056091, 0.9949448704719543, 0.994025707244873, 0.9931066036224365, 0.9951746463775635, 0.9947150945663452, 0.9965533018112183, 0.9949448704719543, 0.9963235259056091, 0.9963235259056091, 0.9944853186607361, 0.9947150945663452, 0.9951746463775635, 0.9951746463775635, 0.99609375, 0.9958639740943909, 0.9967830777168274, 0.9963235259056091, 0.9958639740943909, 0.9967830777168274, 0.9935661554336548, 0.9926470518112183, 0.9933363795280457, 0.9931066036224365, 0.994255542755127, 0.9956341981887817, 0.9958639740943909, 0.9944853186607361, 0.9949448704719543, 0.9958639740943909, 0.99609375, 0.9963235259056091, 0.99609375, 0.9954044222831726, 0.9951746463775635, 0.9947150945663452, 0.9954044222831726, 0.9958639740943909, 0.9947150945663452, 0.9951746463775635, 0.99609375, 0.9965533018112183, 0.9951746463775635, 0.9947150945663452, 0.9954044222831726, 0.9937959313392639, 0.9958639740943909, 0.9949448704719543, 0.9958639740943909, 0.9947150945663452, 0.9951746463775635, 0.9956341981887817, 0.9947150945663452, 0.9951746463775635, 0.9933363795280457, 0.9951746463775635, 0.9951746463775635, 0.9970128536224365, 0.9963235259056091, 0.9963235259056091, 0.9944853186607361, 0.9956341981887817, 0.9956341981887817, 0.99609375, 0.9944853186607361, 0.9954044222831726, 0.9954044222831726, 0.99609375, 0.99609375, 0.9954044222831726, 0.9958639740943909, 0.9965533018112183, 0.9954044222831726, 0.99609375, 0.9965533018112183, 0.9956341981887817, 0.994255542755127, 0.9947150945663452, 0.9947150945663452, 0.9956341981887817, 0.9954044222831726, 0.9970128536224365, 0.9956341981887817, 0.9956341981887817, 0.9944853186607361, 0.994255542755127, 0.9958639740943909, 0.9967830777168274, 0.9951746463775635, 0.994255542755127, 0.9933363795280457, 0.9933363795280457, 0.9935661554336548, 0.9949448704719543, 0.9937959313392639, 0.9947150945663452, 0.9944853186607361, 0.994025707244873, 0.9954044222831726, 0.994025707244873, 0.9933363795280457, 0.9935661554336548, 0.9949448704719543, 0.9935661554336548, 0.994255542755127, 0.9954044222831726, 0.9958639740943909, 0.9963235259056091, 0.9967830777168274, 0.9967830777168274, 0.9958639740943909, 0.99609375, 0.9963235259056091, 0.9963235259056091, 0.9958639740943909, 0.9967830777168274, 0.9958639740943909, 0.9967830777168274, 0.99609375, 0.9967830777168274, 0.99609375, 0.9949448704719543, 0.9956341981887817, 0.9947150945663452, 0.99609375, 0.9956341981887817, 0.99609375, 0.9947150945663452, 0.9949448704719543, 0.9933363795280457, 0.9935661554336548, 0.9928768277168274, 0.9949448704719543, 0.9956341981887817, 0.9958639740943909, 0.9954044222831726, 0.9956341981887817, 0.9947150945663452, 0.9958639740943909, 0.99609375, 0.9947150945663452, 0.9965533018112183, 0.9965533018112183, 0.9951746463775635, 0.9958639740943909, 0.9956341981887817, 0.9944853186607361, 0.9951746463775635, 0.9944853186607361, 0.99609375, 0.9947150945663452, 0.9956341981887817, 0.9958639740943909, 0.9970128536224365, 0.99609375, 0.9965533018112183, 0.9965533018112183, 0.9963235259056091, 0.9958639740943909, 0.9944853186607361, 0.9956341981887817, 0.9956341981887817, 0.9967830777168274, 0.9947150945663452, 0.9958639740943909, 0.9972426295280457, 0.9958639740943909, 0.9944853186607361, 0.994255542755127, 0.9965533018112183, 0.9967830777168274, 0.9963235259056091, 0.9947150945663452, 0.9967830777168274, 0.99609375, 0.9970128536224365, 0.994255542755127, 0.9958639740943909, 0.9935661554336548, 0.9956341981887817, 0.9935661554336548, 0.994255542755127, 0.99609375, 0.9956341981887817, 0.9958639740943909, 0.9967830777168274, 0.9963235259056091, 0.9963235259056091, 0.9958639740943909, 0.9951746463775635, 0.9954044222831726, 0.9958639740943909, 0.9949448704719543, 0.9951746463775635, 0.9963235259056091, 0.9937959313392639, 0.9933363795280457, 0.994255542755127, 0.9949448704719543, 0.9928768277168274, 0.9949448704719543, 0.9947150945663452, 0.99609375, 0.9956341981887817, 0.9965533018112183, 0.9965533018112183, 0.9965533018112183, 0.99609375, 0.99609375, 0.9963235259056091, 0.9963235259056091, 0.9967830777168274, 0.9970128536224365, 0.9958639740943909, 0.99609375, 0.9965533018112183, 0.9972426295280457, 0.99609375, 0.9963235259056091, 0.9963235259056091, 0.9970128536224365, 0.9954044222831726, 0.99609375, 0.9949448704719543, 0.9951746463775635, 0.994025707244873, 0.9951746463775635, 0.9963235259056091, 0.9956341981887817, 0.9956341981887817, 0.9963235259056091, 0.99609375, 0.99609375, 0.9958639740943909, 0.9956341981887817, 0.9970128536224365, 0.9967830777168274, 0.9965533018112183, 0.9967830777168274, 0.9956341981887817, 0.9949448704719543, 0.9949448704719543, 0.9958639740943909, 0.9970128536224365, 0.9965533018112183, 0.9970128536224365, 0.9954044222831726, 0.9967830777168274, 0.9958639740943909, 0.9963235259056091, 0.99609375, 0.9956341981887817, 0.9951746463775635, 0.9947150945663452, 0.99609375, 0.9965533018112183, 0.9951746463775635, 0.9954044222831726, 0.9956341981887817, 0.9963235259056091, 0.9958639740943909, 0.9958639740943909, 0.9956341981887817, 0.9963235259056091, 0.9956341981887817, 0.9933363795280457, 0.994025707244873, 0.994025707244873, 0.994255542755127, 0.99609375, 0.9951746463775635, 0.9967830777168274, 0.9956341981887817, 0.9963235259056091, 0.9965533018112183, 0.9956341981887817, 0.9963235259056091, 0.9954044222831726, 0.9963235259056091, 0.9954044222831726, 0.994255542755127, 0.994025707244873, 0.9954044222831726, 0.9954044222831726, 0.9949448704719543, 0.9956341981887817, 0.9947150945663452, 0.9967830777168274, 0.9963235259056091, 0.9951746463775635, 0.9958639740943909, 0.9965533018112183, 0.9972426295280457, 0.9970128536224365, 0.9963235259056091, 0.9970128536224365, 0.9965533018112183, 0.9963235259056091, 0.9956341981887817, 0.9963235259056091, 0.9967830777168274, 0.9970128536224365, 0.9963235259056091, 0.9965533018112183, 0.99609375, 0.9949448704719543, 0.99609375, 0.99609375, 0.9972426295280457, 0.9970128536224365, 0.9967830777168274, 0.99609375, 0.9965533018112183, 0.9970128536224365, 0.9970128536224365, 0.9967830777168274, 0.99609375, 0.9958639740943909, 0.9967830777168274, 0.9963235259056091, 0.9970128536224365, 0.9963235259056091, 0.99609375, 0.9965533018112183, 0.9956341981887817, 0.9951746463775635, 0.9963235259056091, 0.9949448704719543, 0.9949448704719543, 0.9967830777168274, 0.9965533018112183, 0.994025707244873, 0.99609375, 0.9965533018112183, 0.9963235259056091, 0.9954044222831726, 0.9951746463775635, 0.9954044222831726, 0.9947150945663452, 0.9947150945663452, 0.9956341981887817, 0.9970128536224365, 0.99609375, 0.994025707244873, 0.9947150945663452, 0.9937959313392639, 0.9958639740943909, 0.9963235259056091, 0.9963235259056091, 0.99609375, 0.9954044222831726, 0.9958639740943909, 0.9958639740943909, 0.9958639740943909, 0.9956341981887817, 0.9949448704719543, 0.9949448704719543, 0.9956341981887817, 0.9967830777168274, 0.99609375, 0.9949448704719543, 0.9947150945663452, 0.9963235259056091, 0.9949448704719543, 0.9951746463775635, 0.99609375, 0.9954044222831726, 0.9963235259056091, 0.9954044222831726, 0.99609375, 0.99609375, 0.9963235259056091, 0.9965533018112183, 0.9958639740943909, 0.9949448704719543, 0.99609375, 0.9967830777168274, 0.9965533018112183, 0.9967830777168274, 0.99609375, 0.9965533018112183, 0.9954044222831726, 0.9954044222831726, 0.9956341981887817, 0.9947150945663452, 0.99609375, 0.9967830777168274, 0.9956341981887817, 0.9967830777168274, 0.9956341981887817, 0.9958639740943909, 0.9956341981887817, 0.9944853186607361, 0.9947150945663452, 0.9947150945663452, 0.9949448704719543, 0.9963235259056091, 0.9970128536224365, 0.9972426295280457, 0.9970128536224365, 0.9965533018112183, 0.9963235259056091, 0.9963235259056091, 0.9963235259056091, 0.99609375, 0.99609375, 0.9949448704719543, 0.9937959313392639, 0.994255542755127, 0.994025707244873, 0.9937959313392639, 0.9951746463775635, 0.9967830777168274, 0.9967830777168274, 0.9956341981887817, 0.9958639740943909, 0.9954044222831726, 0.9949448704719543, 0.9956341981887817, 0.9970128536224365, 0.9951746463775635, 0.994025707244873, 0.9956341981887817, 0.99609375, 0.9956341981887817, 0.9967830777168274, 0.9958639740943909, 0.99609375, 0.9965533018112183, 0.9967830777168274, 0.9972426295280457, 0.9965533018112183, 0.9963235259056091, 0.9963235259056091, 0.9963235259056091, 0.9967830777168274, 0.9967830777168274, 0.9970128536224365, 0.99609375, 0.9958639740943909, 0.9937959313392639, 0.9949448704719543, 0.9947150945663452, 0.9965533018112183, 0.9949448704719543, 0.9967830777168274, 0.9965533018112183, 0.9963235259056091, 0.9963235259056091, 0.9970128536224365, 0.9954044222831726, 0.9956341981887817, 0.9963235259056091, 0.9954044222831726, 0.9956341981887817, 0.9944853186607361, 0.9944853186607361, 0.9963235259056091, 0.99609375, 0.9956341981887817, 0.9965533018112183, 0.9965533018112183, 0.9965533018112183, 0.99609375, 0.9970128536224365, 0.9967830777168274, 0.9972426295280457, 0.9965533018112183, 0.9967830777168274, 0.9958639740943909, 0.9954044222831726, 0.9967830777168274, 0.9967830777168274, 0.9970128536224365, 0.9970128536224365, 0.9970128536224365, 0.9970128536224365, 0.9972426295280457, 0.9967830777168274, 0.9963235259056091, 0.9951746463775635, 0.9956341981887817, 0.9951746463775635, 0.9970128536224365, 0.9963235259056091, 0.9970128536224365, 0.9958639740943909, 0.9965533018112183, 0.99609375, 0.9963235259056091, 0.9956341981887817, 0.9951746463775635, 0.9965533018112183, 0.9963235259056091, 0.9963235259056091, 0.99609375, 0.9928768277168274, 0.9949448704719543, 0.9967830777168274, 0.99609375, 0.9963235259056091, 0.9965533018112183, 0.9958639740943909, 0.9972426295280457, 0.9963235259056091, 0.9965533018112183, 0.9949448704719543, 0.9947150945663452, 0.994025707244873, 0.9921875, 0.9931066036224365, 0.9926470518112183, 0.9928768277168274, 0.9931066036224365, 0.994255542755127, 0.994025707244873, 0.9951746463775635, 0.9933363795280457, 0.9935661554336548, 0.9944853186607361, 0.9917279481887817, 0.9928768277168274, 0.994255542755127, 0.9933363795280457, 0.9937959313392639, 0.9954044222831726, 0.994255542755127, 0.9951746463775635, 0.9947150945663452, 0.9951746463775635, 0.9958639740943909, 0.9949448704719543, 0.994025707244873, 0.994255542755127, 0.9944853186607361, 0.9949448704719543, 0.9949448704719543, 0.9947150945663452, 0.9951746463775635, 0.9947150945663452, 0.9949448704719543, 0.9951746463775635, 0.9958639740943909, 0.9951746463775635, 0.9954044222831726, 0.9947150945663452, 0.9947150945663452, 0.9949448704719543, 0.994255542755127, 0.9935661554336548, 0.9944853186607361, 0.9956341981887817, 0.9951746463775635, 0.9944853186607361, 0.9951746463775635, 0.9954044222831726, 0.9951746463775635, 0.9956341981887817, 0.994255542755127, 0.994255542755127, 0.9956341981887817, 0.9947150945663452, 0.9956341981887817, 0.9947150945663452, 0.9951746463775635, 0.9944853186607361, 0.9944853186607361, 0.9949448704719543, 0.9944853186607361, 0.9937959313392639, 0.9926470518112183, 0.9921875, 0.994025707244873, 0.9949448704719543, 0.9937959313392639, 0.9963235259056091, 0.994255542755127, 0.9947150945663452, 0.9951746463775635, 0.9949448704719543, 0.9949448704719543, 0.9949448704719543, 0.9956341981887817, 0.9935661554336548, 0.9949448704719543, 0.9937959313392639, 0.994255542755127, 0.9937959313392639, 0.9949448704719543, 0.9944853186607361, 0.9949448704719543, 0.994255542755127, 0.9944853186607361, 0.994255542755127, 0.9958639740943909, 0.9958639740943909, 0.9958639740943909, 0.9958639740943909, 0.9965533018112183, 0.99609375, 0.9963235259056091, 0.99609375, 0.9967830777168274, 0.9967830777168274, 0.9970128536224365, 0.99609375, 0.9956341981887817, 0.9949448704719543, 0.9954044222831726, 0.9944853186607361, 0.994025707244873, 0.9956341981887817, 0.9954044222831726, 0.9965533018112183, 0.9967830777168274, 0.9965533018112183, 0.9967830777168274, 0.9954044222831726, 0.99609375, 0.9958639740943909, 0.9970128536224365, 0.9970128536224365, 0.9970128536224365, 0.9967830777168274, 0.9967830777168274, 0.9970128536224365, 0.9967830777168274, 0.9967830777168274, 0.9965533018112183, 0.9963235259056091, 0.9965533018112183, 0.9970128536224365, 0.9956341981887817, 0.9963235259056091, 0.9970128536224365, 0.9970128536224365, 0.9963235259056091, 0.9963235259056091, 0.9949448704719543, 0.994255542755127, 0.9958639740943909, 0.9965533018112183, 0.9963235259056091, 0.9951746463775635, 0.9963235259056091, 0.9963235259056091, 0.9951746463775635, 0.9956341981887817, 0.9967830777168274, 0.9963235259056091, 0.9972426295280457, 0.9956341981887817, 0.9949448704719543, 0.9954044222831726, 0.9963235259056091, 0.9954044222831726, 0.9963235259056091, 0.9967830777168274, 0.99609375, 0.9956341981887817, 0.9954044222831726, 0.9963235259056091, 0.9963235259056091, 0.9967830777168274, 0.9967830777168274, 0.9970128536224365, 0.9967830777168274, 0.9965533018112183, 0.9949448704719543, 0.9958639740943909, 0.9965533018112183, 0.9963235259056091, 0.9970128536224365, 0.9967830777168274, 0.9967830777168274, 0.9963235259056091, 0.9974724054336548, 0.9970128536224365, 0.9956341981887817, 0.9963235259056091, 0.9970128536224365, 0.9963235259056091, 0.9970128536224365, 0.99609375, 0.9970128536224365, 0.9965533018112183, 0.9970128536224365, 0.9972426295280457, 0.9972426295280457, 0.9965533018112183, 0.9963235259056091, 0.9963235259056091, 0.99609375, 0.9963235259056091, 0.9974724054336548, 0.9970128536224365, 0.9958639740943909, 0.9951746463775635, 0.9965533018112183, 0.9970128536224365, 0.9963235259056091, 0.9965533018112183, 0.9965533018112183, 0.9967830777168274, 0.9970128536224365, 0.9965533018112183, 0.9958639740943909, 0.9967830777168274, 0.9967830777168274, 0.9967830777168274, 0.9963235259056091, 0.9954044222831726, 0.9949448704719543, 0.9958639740943909, 0.99609375, 0.9956341981887817, 0.9967830777168274, 0.99609375, 0.9972426295280457, 0.9967830777168274, 0.9963235259056091, 0.9963235259056091, 0.9958639740943909, 0.9970128536224365, 0.9967830777168274, 0.9951746463775635, 0.9956341981887817, 0.9965533018112183, 0.9965533018112183, 0.9954044222831726, 0.9958639740943909, 0.9963235259056091, 0.9970128536224365, 0.9963235259056091, 0.9963235259056091, 0.9963235259056091, 0.9970128536224365, 0.9972426295280457, 0.9967830777168274, 0.9963235259056091, 0.9967830777168274, 0.9965533018112183, 0.9958639740943909, 0.9965533018112183, 0.9965533018112183, 0.9965533018112183, 0.9963235259056091, 0.9954044222831726, 0.9956341981887817, 0.9972426295280457, 0.9967830777168274, 0.9963235259056091, 0.9970128536224365, 0.9937959313392639, 0.9947150945663452, 0.9963235259056091, 0.99609375, 0.9963235259056091, 0.9956341981887817, 0.9956341981887817, 0.9963235259056091, 0.9965533018112183, 0.9965533018112183, 0.9970128536224365, 0.9967830777168274, 0.9963235259056091, 0.9972426295280457, 0.9963235259056091, 0.9965533018112183, 0.9972426295280457, 0.9958639740943909, 0.99609375, 0.9963235259056091, 0.9970128536224365, 0.9963235259056091, 0.99609375, 0.9958639740943909, 0.9956341981887817, 0.9958639740943909, 0.9967830777168274, 0.9963235259056091, 0.99609375, 0.99609375, 0.9949448704719543, 0.9947150945663452, 0.9956341981887817, 0.9965533018112183, 0.9956341981887817, 0.9954044222831726, 0.9949448704719543, 0.9958639740943909, 0.9954044222831726, 0.9951746463775635, 0.9970128536224365, 0.9974724054336548, 0.9970128536224365, 0.99609375, 0.9970128536224365, 0.994255542755127, 0.9937959313392639, 0.9947150945663452, 0.9970128536224365, 0.9954044222831726, 0.9954044222831726, 0.9963235259056091, 0.9956341981887817, 0.9970128536224365, 0.99609375, 0.9967830777168274, 0.9967830777168274, 0.9970128536224365, 0.9958639740943909, 0.9967830777168274, 0.9970128536224365, 0.9967830777168274, 0.9963235259056091, 0.9965533018112183, 0.99609375, 0.9958639740943909, 0.9947150945663452, 0.9963235259056091, 0.9951746463775635, 0.9947150945663452, 0.9947150945663452, 0.9954044222831726, 0.9956341981887817, 0.9956341981887817, 0.9951746463775635, 0.9954044222831726, 0.9958639740943909, 0.9970128536224365, 0.9972426295280457, 0.9972426295280457, 0.9972426295280457, 0.9965533018112183, 0.9958639740943909, 0.9963235259056091, 0.9970128536224365, 0.9963235259056091, 0.9963235259056091, 0.9944853186607361, 0.9963235259056091, 0.99609375, 0.9970128536224365, 0.9965533018112183, 0.9965533018112183, 0.9967830777168274, 0.9967830777168274, 0.9963235259056091, 0.9972426295280457, 0.9972426295280457, 0.9965533018112183, 0.9956341981887817, 0.9965533018112183, 0.99609375, 0.9967830777168274, 0.9965533018112183, 0.9970128536224365, 0.9967830777168274, 0.9965533018112183, 0.9970128536224365, 0.9970128536224365, 0.9965533018112183, 0.9965533018112183, 0.9970128536224365, 0.9970128536224365, 0.9967830777168274, 0.9977021813392639, 0.9949448704719543, 0.9917279481887817, 0.9928768277168274, 0.994255542755127, 0.9947150945663452, 0.9933363795280457, 0.994025707244873, 0.9937959313392639, 0.9965533018112183, 0.9963235259056091, 0.9963235259056091, 0.9963235259056091, 0.9963235259056091, 0.9967830777168274, 0.9970128536224365, 0.9970128536224365, 0.9965533018112183, 0.9967830777168274, 0.9967830777168274, 0.9972426295280457, 0.99609375, 0.9963235259056091, 0.9970128536224365, 0.9958639740943909, 0.9951746463775635, 0.9958639740943909, 0.9958639740943909, 0.99609375, 0.9965533018112183, 0.99609375, 0.9967830777168274, 0.9970128536224365, 0.9963235259056091, 0.9954044222831726, 0.9924172759056091, 0.990119457244873, 0.9917279481887817, 0.994025707244873, 0.994255542755127, 0.9949448704719543, 0.9951746463775635, 0.9951746463775635, 0.99609375, 0.9970128536224365, 0.99609375, 0.9958639740943909, 0.9967830777168274, 0.9970128536224365, 0.9967830777168274, 0.9967830777168274, 0.9965533018112183, 0.9965533018112183, 0.9965533018112183, 0.9970128536224365, 0.9947150945663452, 0.9956341981887817, 0.9944853186607361, 0.9949448704719543, 0.9947150945663452, 0.9963235259056091, 0.9965533018112183, 0.9967830777168274, 0.9963235259056091, 0.9972426295280457, 0.9972426295280457, 0.9965533018112183, 0.9967830777168274, 0.9944853186607361, 0.9956341981887817, 0.9965533018112183, 0.9970128536224365, 0.9974724054336548, 0.9972426295280457, 0.9970128536224365, 0.9970128536224365, 0.9963235259056091, 0.9970128536224365, 0.9970128536224365, 0.9974724054336548, 0.9967830777168274, 0.99609375, 0.99609375, 0.9965533018112183, 0.9972426295280457, 0.9972426295280457, 0.9963235259056091, 0.9967830777168274, 0.9967830777168274, 0.9970128536224365]\n",
      "val_loss [0.050129085779190063, 0.045550908893346786, 0.043914079666137695, 0.04275817424058914, 0.04623696208000183, 0.042811136692762375, 0.05401172861456871, 0.04403221234679222, 0.05591469630599022, 0.04453202337026596, 0.046918027102947235, 0.04301895201206207, 0.043184794485569, 0.04239044338464737, 0.04380721598863602, 0.0474613755941391, 0.04221147298812866, 0.043876536190509796, 0.043379925191402435, 0.0432838499546051, 0.04515070840716362, 0.04237797483801842, 0.04238641634583473, 0.04268219321966171, 0.04188154265284538, 0.04463541507720947, 0.0582723543047905, 0.04178859293460846, 0.0442802831530571, 0.042670927941799164, 0.041897062212228775, 0.0423906110227108, 0.042233906686306, 0.04345499351620674, 0.04216863214969635, 0.04298064857721329, 0.04225149005651474, 0.04293012619018555, 0.043008580803871155, 0.04280794411897659, 0.0423048660159111, 0.04201887547969818, 0.0420260950922966, 0.04500638693571091, 0.043873921036720276, 0.04241214692592621, 0.042490363121032715, 0.04533988982439041, 0.04472315311431885, 0.042742885649204254, 0.046697936952114105, 0.05166015774011612, 0.04877926781773567, 0.05357382819056511, 0.042938943952322006, 0.04215440899133682, 0.04901506006717682, 0.04250192642211914, 0.043454285711050034, 0.04265156760811806, 0.04243044555187225, 0.04195309057831764, 0.042062606662511826, 0.05018453299999237, 0.045853544026613235, 0.043872736394405365, 0.04185117408633232, 0.04256748408079147, 0.0447731576859951, 0.04255222529172897, 0.04168613627552986, 0.04219600930809975, 0.04927677661180496, 0.04989781603217125, 0.04169829934835434, 0.04351964592933655, 0.0424070730805397, 0.04226195067167282, 0.041739411652088165, 0.04220445454120636, 0.04347596317529678, 0.04163298010826111, 0.04753240570425987, 0.04208654537796974, 0.04855423793196678, 0.049044910818338394, 0.04567082226276398, 0.04293856397271156, 0.04179636016488075, 0.04347914829850197, 0.049576662480831146, 0.042652424424886703, 0.04260806366801262, 0.041818153113126755, 0.045444898307323456, 0.04195794835686684, 0.044825851917266846, 0.04188581556081772, 0.04262077063322067, 0.04226575791835785, 0.04194283112883568, 0.045729413628578186, 0.045019395649433136, 0.04205017909407616, 0.04429355263710022, 0.042113494127988815, 0.042602576315402985, 0.04168517142534256, 0.042239826172590256, 0.04176781326532364, 0.043801698833703995, 0.04281710460782051, 0.041815370321273804, 0.0466223880648613, 0.06904326379299164, 0.04686780273914337, 0.043333638459444046, 0.041744329035282135, 0.04423541948199272, 0.04336460307240486, 0.04486042261123657, 0.04527423158288002, 0.042690008878707886, 0.043682485818862915, 0.07044507563114166, 0.05328986421227455, 0.048765916377305984, 0.046204306185245514, 0.0438733845949173, 0.04907776042819023, 0.04580030217766762, 0.04281188175082207, 0.04292925447225571, 0.042017389088869095, 0.04462301731109619, 0.04235503077507019, 0.04363265633583069, 0.0460798516869545, 0.04299231246113777, 0.04232649505138397, 0.04459565505385399, 0.043899476528167725, 0.04430582374334335, 0.041804876178503036, 0.045025575906038284, 0.044088978320360184, 0.04213746637105942, 0.04336952790617943, 0.044112175703048706, 0.056909237056970596, 0.044830672442913055, 0.0443577878177166, 0.042872946709394455, 0.04455893859267235, 0.04524746164679527, 0.044508881866931915, 0.042871810495853424, 0.04184144735336304, 0.04444520175457001, 0.04944853484630585, 0.04370366409420967, 0.04231167957186699, 0.04234213009476662, 0.04193631932139397, 0.04318264499306679, 0.05082076042890549, 0.05318235605955124, 0.05487856641411781, 0.04790682718157768, 0.058210063725709915, 0.044180773198604584, 0.04190078377723694, 0.04263748601078987, 0.042515773326158524, 0.04299786686897278, 0.046943120658397675, 0.043092280626297, 0.04613347724080086, 0.04408607631921768, 0.05697169527411461, 0.04250939190387726, 0.04634740203619003, 0.04246285557746887, 0.043765436857938766, 0.04267861694097519, 0.042373787611722946, 0.04261649772524834, 0.04150823876261711, 0.04305797442793846, 0.04192042350769043, 0.043689802289009094, 0.04261616989970207, 0.04434283822774887, 0.04289907217025757, 0.043191663920879364, 0.044744472950696945, 0.04220172017812729, 0.04782874137163162, 0.042721912264823914, 0.04416900500655174, 0.04228906333446503, 0.04251126945018768, 0.04160400107502937, 0.04622527211904526, 0.044557541608810425, 0.0469537079334259, 0.05688256397843361, 0.04972202703356743, 0.043676286935806274, 0.043755706399679184, 0.04301369935274124, 0.04383796826004982, 0.044536057859659195, 0.04289358854293823, 0.04394541680812836, 0.045164816081523895, 0.04955252259969711, 0.04431911185383797, 0.042649831622838974, 0.045078787952661514, 0.05046134069561958, 0.042863816022872925, 0.043688852339982986, 0.04545005038380623, 0.047461602836847305, 0.04237501323223114, 0.042682912200689316, 0.04267260432243347, 0.042085856199264526, 0.04199928045272827, 0.0446782186627388, 0.042907360941171646, 0.041750237345695496, 0.04383713752031326, 0.04174448922276497, 0.043202079832553864, 0.04283034801483154, 0.043328866362571716, 0.043098676949739456, 0.042240921407938004, 0.04309910163283348, 0.04321242496371269, 0.0436333604156971, 0.05004386976361275, 0.04458894580602646, 0.04307836666703224, 0.043618835508823395, 0.042927518486976624, 0.059590134769678116, 0.044838935136795044, 0.0439692959189415, 0.04670790210366249, 0.04267276078462601, 0.04218230023980141, 0.043161358684301376, 0.04317615181207657, 0.042809512466192245, 0.047750819474458694, 0.043410904705524445, 0.043485164642333984, 0.04539477825164795, 0.04842190444469452, 0.0481695793569088, 0.04704457148909569, 0.041943494230508804, 0.04540465027093887, 0.042894147336483, 0.04302220419049263, 0.0431070476770401, 0.04374226927757263, 0.04279515519738197, 0.04211726039648056, 0.04532773420214653, 0.04247958958148956, 0.04249567165970802, 0.04251391813158989, 0.043526675552129745, 0.04310794919729233, 0.04332033172249794, 0.04177940636873245, 0.044094350188970566, 0.042739447206258774, 0.04239937290549278, 0.04675019532442093, 0.04178372025489807, 0.046971797943115234, 0.043171629309654236, 0.04253614693880081, 0.044324882328510284, 0.04171968623995781, 0.043435290455818176, 0.043045949190855026, 0.045935146510601044, 0.049477629363536835, 0.04389364272356033, 0.04259080812335014, 0.043527912348508835, 0.046226125210523605, 0.04558942839503288, 0.04411621019244194, 0.04245859384536743, 0.04865230619907379, 0.04526273161172867, 0.04984253644943237, 0.04846963286399841, 0.0422910638153553, 0.044402338564395905, 0.0441657193005085, 0.04783949628472328, 0.04604828357696533, 0.043333251029253006, 0.0434822253882885, 0.0452018678188324, 0.042891256511211395, 0.044071853160858154, 0.04429418966174126, 0.04591021314263344, 0.04423777759075165, 0.04291568696498871, 0.044539064168930054, 0.04327535256743431, 0.0432039350271225, 0.04513029381632805, 0.050580576062202454, 0.04679163172841072, 0.04265780746936798, 0.04927491769194603, 0.042459577322006226, 0.04393995180726051, 0.04288586974143982, 0.044352736324071884, 0.04494943469762802, 0.04287485405802727, 0.042154792696237564, 0.04493258148431778, 0.04541509225964546, 0.04377271234989166, 0.04248712956905365, 0.04316141456365585, 0.04420212283730507, 0.04651381075382233, 0.042157698422670364, 0.04301200434565544, 0.04318184405565262, 0.04195653274655342, 0.04325525090098381, 0.04218219593167305, 0.04286343231797218, 0.04398093372583389, 0.044946979731321335, 0.045114435255527496, 0.04342497140169144, 0.04373658820986748, 0.04841011017560959, 0.04335317015647888, 0.05275651440024376, 0.05453179031610489, 0.06112218648195267, 0.05518127605319023, 0.06274954229593277, 0.05348299443721771, 0.04694172739982605, 0.04730529710650444, 0.044305913150310516, 0.04209188371896744, 0.042407162487506866, 0.04349182918667793, 0.04761325567960739, 0.04284161701798439, 0.042702484875917435, 0.04279179126024246, 0.04512903094291687, 0.04442121461033821, 0.04346391186118126, 0.04234001785516739, 0.047147296369075775, 0.04420606419444084, 0.04349195584654808, 0.04288395494222641, 0.05345437675714493, 0.055363383144140244, 0.04714140668511391, 0.04251335933804512, 0.04418722912669182, 0.04351475462317467, 0.04310179874300957, 0.04505608603358269, 0.043148916214704514, 0.044809047132730484, 0.04774715006351471, 0.04268013313412666, 0.04377404600381851, 0.04321737214922905, 0.04309159889817238, 0.042901359498500824, 0.042766980826854706, 0.043614208698272705, 0.04223691672086716, 0.04332824423909187, 0.042538248002529144, 0.046838048845529556, 0.05693882331252098, 0.047456029802560806, 0.04294000193476677, 0.04267780855298042, 0.04766775295138359, 0.041649140417575836, 0.04258309304714203, 0.042087819427251816, 0.04258102551102638, 0.04232792183756828, 0.04326295480132103, 0.04410065338015556, 0.05428358167409897, 0.05369770899415016, 0.041967637836933136, 0.04155891016125679, 0.04429188743233681, 0.04273996129631996, 0.042099665850400925, 0.04300346225500107, 0.04309748113155365, 0.04622795805335045, 0.04276750236749649, 0.04343630373477936, 0.04381638765335083, 0.047167081385850906, 0.04814348369836807, 0.042545631527900696, 0.04453973099589348, 0.05011637136340141, 0.0488143227994442, 0.04287204146385193, 0.04356860741972923, 0.042713627219200134, 0.0430082269012928, 0.04493623226881027, 0.042336076498031616, 0.04601956158876419, 0.047035329043865204, 0.04270447418093681, 0.05037938803434372, 0.043674346059560776, 0.04597420245409012, 0.04526672512292862, 0.04673086851835251, 0.05700782313942909, 0.05935671553015709, 0.059270430356264114, 0.04294576495885849, 0.041501209139823914, 0.04190332069993019, 0.04209352284669876, 0.04191388562321663, 0.04298514500260353, 0.04228774830698967, 0.04270036891102791, 0.041630275547504425, 0.043595824390649796, 0.04259391129016876, 0.0412323884665966, 0.04679615795612335, 0.04372752457857132, 0.041498538106679916, 0.04160493612289429, 0.04308862239122391, 0.04194158688187599, 0.045222051441669464, 0.049999162554740906, 0.056996796280145645, 0.0439627468585968, 0.0446891263127327, 0.045649755746126175, 0.047184400260448456, 0.044361598789691925, 0.04391155391931534, 0.042015980929136276, 0.042215652763843536, 0.0421721525490284, 0.04227569326758385, 0.04181566834449768, 0.04189885035157204, 0.042096201330423355, 0.04881777614355087, 0.04816458374261856, 0.05289844796061516, 0.05144072324037552, 0.050979021936655045, 0.061516173183918, 0.04874413460493088, 0.04451260343194008, 0.04899786785244942, 0.05767858400940895, 0.05399731919169426, 0.04357553645968437, 0.04954897239804268, 0.04504529759287834, 0.04801648110151291, 0.04371308907866478, 0.044302500784397125, 0.057122644037008286, 0.05315018445253372, 0.04642593488097191, 0.04256591200828552, 0.04222254082560539, 0.04276607185602188, 0.0422557070851326, 0.0420953594148159, 0.04618688300251961, 0.050098519772291183, 0.04212595149874687, 0.04247235506772995, 0.042260367423295975, 0.04248529672622681, 0.0418301559984684, 0.04226142168045044, 0.04244200140237808, 0.0427473783493042, 0.0430818535387516, 0.04685862362384796, 0.042448755353689194, 0.04164762794971466, 0.04249364137649536, 0.04268926754593849, 0.042202699929475784, 0.04235147684812546, 0.04619138315320015, 0.044001463800668716, 0.04209217056632042, 0.04187034070491791, 0.04730720818042755, 0.041701339185237885, 0.041550323367118835, 0.04441479966044426, 0.04326767474412918, 0.04203799366950989, 0.041936855763196945, 0.041946567595005035, 0.0455646850168705, 0.05347174406051636, 0.055240001529455185, 0.04478015750646591, 0.05311591550707817, 0.051779698580503464, 0.04527668282389641, 0.0423361174762249, 0.04309550300240517, 0.042714107781648636, 0.041801027953624725, 0.04668804630637169, 0.050545673817396164, 0.042719800025224686, 0.0427008755505085, 0.04148970916867256, 0.042501043528318405, 0.041386671364307404, 0.042091503739356995, 0.04336506128311157, 0.042504388839006424, 0.04295441508293152, 0.04120289534330368, 0.047261931002140045, 0.049075666815042496, 0.05239681527018547, 0.04632401466369629, 0.0421438068151474, 0.04503834247589111, 0.04669271782040596, 0.04308006912469864, 0.04147540032863617, 0.04371120035648346, 0.04198595508933067, 0.04258200153708458, 0.04351341724395752, 0.04545041546225548, 0.04328329861164093, 0.04540431126952171, 0.045198339968919754, 0.042396754026412964, 0.04407542571425438, 0.04271853715181351, 0.04151523485779762, 0.04175478219985962, 0.04332903027534485, 0.04249387979507446, 0.04159500077366829, 0.04401414841413498, 0.043303608894348145, 0.043408699333667755, 0.053594790399074554, 0.04242474213242531, 0.043569471687078476, 0.049008555710315704, 0.04327321797609329, 0.04495934769511223, 0.04228772968053818, 0.04174823686480522, 0.043890099972486496, 0.04225727915763855, 0.044690392911434174, 0.05587295442819595, 0.05090593919157982, 0.04463924467563629, 0.044415295124053955, 0.04199034348130226, 0.04247041046619415, 0.05132431909441948, 0.04177094250917435, 0.042792513966560364, 0.0434456430375576, 0.05225175991654396, 0.044814158231019974, 0.04359256476163864, 0.046322859823703766, 0.04295343905687332, 0.04453035816550255, 0.04472131282091141, 0.04854906350374222, 0.054686203598976135, 0.05978599190711975, 0.04853742569684982, 0.043168019503355026, 0.041016604751348495, 0.04171619564294815, 0.045368365943431854, 0.042049162089824677, 0.044841524213552475, 0.045017555356025696, 0.04576638713479042, 0.04987963289022446, 0.04814238101243973, 0.05400294065475464, 0.04830557107925415, 0.04206480085849762, 0.04460082948207855, 0.04131479561328888, 0.04343892261385918, 0.05763084813952446, 0.060983747243881226, 0.04853203147649765, 0.04311344772577286, 0.04108184576034546, 0.04372001439332962, 0.04271410405635834, 0.045064568519592285, 0.04051753506064415, 0.04657464474439621, 0.04630016162991524, 0.04563247039914131, 0.04390876740217209, 0.04770263284444809, 0.04620548337697983, 0.045266058295965195, 0.04659184813499451, 0.042378250509500504, 0.04238525778055191, 0.048937421292066574, 0.051349785178899765, 0.04786092787981033, 0.04970686882734299, 0.049963321536779404, 0.04183346405625343, 0.044860340654850006, 0.04250238090753555, 0.04249555617570877, 0.044683173298835754, 0.04697105288505554, 0.048633377999067307, 0.04266379401087761, 0.043929096311330795, 0.053081512451171875, 0.05854160711169243, 0.05119550973176956, 0.04745836928486824, 0.045298103243112564, 0.04264549911022186, 0.04874810948967934, 0.05588015913963318, 0.043648604303598404, 0.043988823890686035, 0.042455583810806274, 0.042483434081077576, 0.04393917694687843, 0.04685990512371063, 0.04810396581888199, 0.054933253675699234, 0.0562460720539093, 0.05412871018052101, 0.049863915890455246, 0.045087143778800964, 0.0414230115711689, 0.04368697851896286, 0.042565565556287766, 0.042746640741825104, 0.04260497912764549, 0.04243526607751846, 0.04276691749691963, 0.04293115437030792, 0.044165872037410736, 0.047309502959251404, 0.04364194720983505, 0.04534139856696129, 0.04251754656434059, 0.04963315650820732, 0.04628182575106621, 0.044344011694192886, 0.05431005358695984, 0.0551355816423893, 0.04529733955860138, 0.04449958726763725, 0.04346713423728943, 0.04435764625668526, 0.04693521186709404, 0.04916675016283989, 0.04717275872826576, 0.061587296426296234, 0.04761514067649841, 0.057265836745500565, 0.05341746658086777, 0.04484932869672775, 0.04326387122273445, 0.04171891510486603, 0.04641564190387726, 0.04124456271529198, 0.04417800158262253, 0.04227853938937187, 0.049068138003349304, 0.056986693292856216, 0.050477199256420135, 0.04530009999871254, 0.04482891410589218, 0.04862600937485695, 0.044849943369627, 0.04410082474350929, 0.045581601560115814, 0.043461915105581284, 0.04352213069796562, 0.04453955218195915, 0.04869300499558449, 0.04595838487148285, 0.04383106157183647, 0.04470857232809067, 0.042893484234809875, 0.05282822623848915, 0.04165654629468918, 0.045964568853378296, 0.04085434973239899, 0.04394681006669998, 0.04324624687433243, 0.04200208932161331, 0.053428616374731064, 0.043928321450948715, 0.04425553232431412, 0.042300306260585785, 0.04150431230664253, 0.043814897537231445, 0.042244020849466324, 0.04229952394962311, 0.044159162789583206, 0.04194563627243042, 0.04269813746213913, 0.05322742462158203, 0.044305332005023956, 0.04407668858766556, 0.04254461079835892, 0.04364006593823433, 0.041589993983507156, 0.042171910405159, 0.04202556610107422, 0.0438891276717186, 0.042248476296663284, 0.04306376725435257, 0.042059481143951416, 0.04139662906527519, 0.044243693351745605, 0.04202735051512718, 0.04196607321500778, 0.04385719820857048, 0.04203245788812637, 0.04212481528520584, 0.04250779747962952, 0.04330996423959732, 0.045503370463848114, 0.04599766060709953, 0.04057201370596886, 0.04512842744588852, 0.04847978055477142, 0.043335627764463425, 0.044217947870492935, 0.0417029894888401, 0.04582604020833969, 0.04218398407101631, 0.04274967685341835, 0.04253625124692917, 0.04191753640770912, 0.04171684756875038, 0.04838596284389496, 0.04431331902742386, 0.041758377104997635, 0.04239712655544281, 0.043055761605501175, 0.043433234095573425, 0.042408403009176254, 0.041324879974126816, 0.04544672742486, 0.04621633142232895, 0.04503912106156349, 0.05365410074591637, 0.04361559823155403, 0.046166907995939255, 0.0425468347966671, 0.04165901243686676, 0.04452475905418396, 0.04179693013429642, 0.044172871857881546, 0.04691033437848091, 0.04496358707547188, 0.04290425032377243, 0.04128509759902954, 0.04426346346735954, 0.04121512919664383, 0.04079270362854004, 0.04342985525727272, 0.04049849510192871, 0.04315691441297531, 0.047257184982299805, 0.04571167007088661, 0.04075570032000542, 0.04212898761034012, 0.04158817231655121, 0.041149310767650604, 0.04292692616581917, 0.043202340602874756, 0.041960012167692184, 0.04087551683187485, 0.04248443990945816, 0.04358378052711487, 0.04149651527404785, 0.04244803264737129, 0.042104996740818024, 0.04110712558031082, 0.04222611337900162, 0.04117107018828392, 0.04059436172246933, 0.046598464250564575, 0.04244377836585045, 0.05132824555039406, 0.04462249577045441, 0.04331616684794426, 0.04269630089402199, 0.042865682393312454, 0.04144768789410591, 0.041440676897764206, 0.049540020525455475, 0.04126615822315216, 0.04148098826408386, 0.04369456693530083, 0.043090108782052994, 0.06720946729183197, 0.07620900869369507, 0.07209451496601105, 0.062153395265340805, 0.05922491103410721, 0.05224192142486572, 0.06231871619820595, 0.05316387116909027, 0.042255427688360214, 0.043866343796253204, 0.04602913558483124, 0.04778360575437546, 0.04492798075079918, 0.04223264753818512, 0.042452119290828705, 0.048156704753637314, 0.046886809170246124, 0.04113569110631943, 0.046948932111263275, 0.04203364998102188, 0.041775722056627274, 0.05052947998046875, 0.043364040553569794, 0.0662156268954277, 0.0527019277215004, 0.04818215221166611, 0.04329217970371246, 0.04672020673751831, 0.04317651689052582, 0.04546976834535599, 0.04640565812587738, 0.04512563720345497, 0.04246038198471069, 0.049920327961444855, 0.04090927541255951, 0.04960038885474205, 0.04571862146258354, 0.04472026228904724, 0.043031737208366394, 0.044966764748096466, 0.043941766023635864, 0.042951613664627075, 0.04551026225090027, 0.05306655168533325, 0.05529839172959328, 0.043432820588350296, 0.04156061261892319, 0.04383637011051178, 0.04224936664104462, 0.04999552667140961, 0.04290177300572395, 0.04317442327737808, 0.043483950197696686, 0.04209423437714577, 0.043074578046798706, 0.04491717368364334, 0.04393320530653, 0.05393415316939354, 0.05470453202724457, 0.04897027462720871, 0.04570178687572479, 0.04125409573316574, 0.049913667142391205, 0.04755712300539017, 0.04284793511033058, 0.04659926891326904, 0.0413907952606678, 0.04198470339179039, 0.041808657348155975, 0.04277550056576729, 0.04173220321536064, 0.045056939125061035, 0.0442214235663414, 0.04225865378975868, 0.04420783743262291, 0.045074500143527985, 0.0437002032995224, 0.04058877378702164, 0.041468024253845215, 0.042154110968112946, 0.04843517020344734, 0.04406140744686127, 0.0407637283205986, 0.042920440435409546, 0.04177932068705559, 0.04318585991859436, 0.04127394035458565, 0.04311918839812279, 0.040753040462732315, 0.041642606258392334, 0.04165780544281006, 0.04132895544171333, 0.044006552547216415, 0.050486285239458084, 0.050131432712078094, 0.04524076730012894, 0.05087089166045189, 0.045012738555669785, 0.05093717947602272, 0.044303685426712036, 0.043146148324012756, 0.04093453660607338, 0.042751722037792206, 0.041794195771217346, 0.04152336344122887, 0.043000224977731705, 0.0425526387989521, 0.045074742287397385, 0.04177876189351082, 0.044926661998033524, 0.04574162885546684, 0.04328380152583122, 0.048581384122371674, 0.04438284784555435, 0.047545481473207474, 0.043308988213539124, 0.04302658513188362, 0.04245446249842644, 0.04218778759241104, 0.04264451190829277, 0.04648371785879135, 0.042962852865457535, 0.04158741608262062, 0.04185973480343819, 0.042767055332660675, 0.041828375309705734, 0.04309214651584625, 0.04494430497288704, 0.04244818910956383, 0.04116695374250412, 0.04449177905917168, 0.04772738367319107, 0.04399295151233673, 0.04805486649274826, 0.04735565558075905, 0.04408494010567665, 0.04669192060828209, 0.050680018961429596, 0.047383684664964676, 0.04639444127678871, 0.041268929839134216, 0.041452743113040924, 0.040542762726545334, 0.05839545279741287, 0.05299114063382149, 0.052646394819021225, 0.04084557667374611, 0.04317779466509819, 0.04111500456929207, 0.043361272662878036, 0.04133268818259239, 0.045272402465343475, 0.04254939779639244, 0.04074147716164589, 0.04466727748513222, 0.04641618952155113, 0.04285074397921562, 0.04502016305923462, 0.0637814998626709, 0.05460573360323906, 0.05173709616065025, 0.04094000160694122, 0.04260372743010521, 0.042556360363960266, 0.0403115451335907, 0.04842863976955414, 0.0520678274333477, 0.04802635312080383, 0.0399007573723793, 0.0527803935110569, 0.04386422783136368, 0.04244072362780571, 0.044800709933042526, 0.04134912043809891, 0.04287486523389816, 0.04030297324061394, 0.043240126222372055, 0.04102882742881775, 0.04553816467523575, 0.059008046984672546, 0.046881213784217834, 0.04987245053052902, 0.04112594202160835, 0.04212203249335289, 0.04094519838690758, 0.04224482923746109, 0.041574981063604355, 0.04184330627322197, 0.04234219342470169, 0.040700387209653854, 0.04294031858444214, 0.04579731449484825, 0.04766606166958809, 0.06407006829977036, 0.06101144477725029, 0.04503681883215904, 0.04665164276957512, 0.040988124907016754, 0.052894558757543564, 0.04139428213238716, 0.04621661826968193, 0.04174597188830376, 0.04169250279664993, 0.053801313042640686, 0.04410673305392265, 0.04203788936138153, 0.049618370831012726, 0.05336185172200203, 0.0417887382209301, 0.04252520576119423, 0.052030302584171295, 0.05071813985705376, 0.04627009481191635, 0.04231858253479004, 0.04372795671224594, 0.05131847411394119, 0.054097749292850494, 0.047271352261304855, 0.04137364774942398, 0.042954351752996445, 0.04234164208173752, 0.04512510821223259, 0.04657062515616417, 0.05058711767196655, 0.048255160450935364, 0.05208102613687515, 0.054984353482723236, 0.05522812530398369, 0.050993699580430984, 0.04208848252892494, 0.042742010205984116, 0.04104876518249512, 0.04082365706562996, 0.04314232990145683, 0.040777187794446945, 0.04190617799758911, 0.05242818221449852, 0.042477741837501526, 0.041809696704149246, 0.0512932650744915, 0.04449961334466934, 0.043845001608133316, 0.04194725304841995, 0.04152148589491844, 0.04641586169600487, 0.043485455214977264, 0.04606488719582558, 0.04317087680101395, 0.04259748384356499, 0.04256455600261688, 0.04118763282895088, 0.042429037392139435, 0.043868113309144974, 0.04609034210443497, 0.05137047916650772, 0.04431416094303131, 0.044285085052251816, 0.04136175662279129, 0.05025843158364296, 0.046766456216573715, 0.04262670874595642, 0.04339416325092316, 0.04241134598851204, 0.04138271138072014, 0.04492085799574852, 0.042161665856838226, 0.042195580899715424, 0.04917445778846741, 0.04500440135598183, 0.04130938649177551, 0.04906923696398735, 0.04177841544151306, 0.0437946617603302, 0.042217180132865906, 0.04527384042739868, 0.0422908179461956, 0.041918687522411346, 0.045420680195093155, 0.04122146964073181, 0.04316312447190285, 0.04665779694914818, 0.03943973407149315, 0.04030408710241318, 0.04189079627394676, 0.04479290917515755, 0.04154464602470398, 0.048486895859241486, 0.0443253293633461, 0.04295767843723297, 0.04051458463072777, 0.04150395467877388, 0.042079754173755646, 0.044064708054065704, 0.05052653327584267, 0.05003087967634201, 0.04632831737399101, 0.043701957911252975, 0.057867612689733505, 0.04284282028675079, 0.04444652423262596, 0.04242859408259392, 0.04465398192405701, 0.043904341757297516, 0.04382523521780968, 0.04477659612894058, 0.04046390950679779, 0.0409579798579216, 0.053041644394397736, 0.05637536942958832, 0.05595354735851288, 0.04496069625020027, 0.041319720447063446, 0.04563577100634575, 0.04268058389425278, 0.04435081034898758, 0.0408039465546608, 0.04315671697258949, 0.044710177928209305, 0.053030069917440414, 0.05070263147354126, 0.04623451456427574, 0.04356325417757034, 0.04216712713241577, 0.04340590164065361, 0.04487369954586029, 0.044895075261592865, 0.04205729812383652, 0.04221043735742569, 0.043631892651319504, 0.0428113117814064, 0.04468745365738869, 0.04132566228508949, 0.047171395272016525, 0.045871540904045105, 0.05506257340312004, 0.052514877170324326, 0.04405103996396065, 0.04239097982645035, 0.04487912729382515, 0.04120637848973274, 0.045011527836322784, 0.047573547810316086, 0.04438740760087967, 0.04239438474178314, 0.04175809770822525, 0.04193730652332306, 0.041013769805431366, 0.04210401698946953, 0.04408688470721245, 0.04302553832530975, 0.041913360357284546, 0.04580487683415413, 0.04950299113988876, 0.055112093687057495, 0.04192345216870308, 0.04300461709499359, 0.05014178529381752, 0.04350070655345917, 0.0424986258149147, 0.047791291028261185, 0.04097890853881836, 0.0432693175971508, 0.04180384799838066, 0.044366590678691864, 0.044041842222213745, 0.043825507164001465, 0.04447731375694275, 0.04232688248157501, 0.043436985462903976, 0.04088063910603523, 0.045929230749607086, 0.04159001633524895, 0.04117054119706154, 0.04341236874461174, 0.04627641662955284, 0.05247652530670166, 0.05506515875458717, 0.04671259596943855, 0.04235970973968506, 0.05095795914530754, 0.04652915522456169, 0.04170646518468857, 0.04534511640667915, 0.04376186430454254, 0.04441536217927933, 0.04496588930487633, 0.055349402129650116, 0.04744533449411392, 0.045293983072042465, 0.04668669030070305, 0.04218422994017601, 0.04997219145298004, 0.04532169923186302, 0.048295244574546814, 0.05067644268274307, 0.047057200223207474, 0.04545879736542702, 0.0541888028383255, 0.0512385368347168, 0.051270876079797745, 0.051388971507549286, 0.04168768227100372, 0.05327548831701279, 0.06729795783758163, 0.05248912051320076, 0.04255232959985733, 0.0451451800763607, 0.04790820926427841, 0.040396254509687424, 0.05531897023320198, 0.0463792085647583, 0.040579088032245636, 0.04359043762087822, 0.04283804073929787, 0.04684959724545479, 0.04483563080430031, 0.043873969465494156, 0.04641938582062721, 0.04430446773767471, 0.040654003620147705, 0.05153518542647362, 0.04349822178483009, 0.04336769878864288, 0.04329247400164604, 0.06147510185837746, 0.04884295538067818, 0.04924929141998291, 0.0419754721224308, 0.04185258969664574, 0.048066187649965286, 0.054617542773485184, 0.04810498282313347, 0.04608720913529396, 0.0418538972735405, 0.04260539263486862, 0.040266603231430054, 0.07023114711046219, 0.06269603967666626, 0.04757648706436157, 0.04058537632226944, 0.04433312639594078, 0.04734761267900467, 0.055086273699998856, 0.047244396060705185, 0.04419909417629242, 0.0418860949575901, 0.045250482857227325, 0.043569158762693405, 0.04196044057607651, 0.0422985665500164, 0.04376411810517311, 0.04857136681675911, 0.05030667409300804, 0.04122165963053703, 0.042211055755615234, 0.043007753789424896, 0.05622375011444092, 0.04791344329714775, 0.04256931692361832, 0.04474123194813728, 0.0522204153239727, 0.053298987448215485, 0.05124524608254433, 0.04404284060001373, 0.04558809474110603, 0.04147448390722275, 0.04467838257551193, 0.04218462482094765, 0.044933367520570755, 0.041993170976638794, 0.04589961841702461, 0.050992947071790695, 0.06488727033138275, 0.07395978271961212, 0.043704550713300705, 0.040823016315698624, 0.043326620012521744, 0.041807226836681366, 0.043441615998744965, 0.0437229759991169, 0.06326072663068771, 0.06479983031749725, 0.0463312491774559, 0.0486254058778286, 0.04280370846390724, 0.04123526066541672, 0.04607832431793213, 0.040845178067684174, 0.04201894626021385, 0.04374774172902107, 0.045025572180747986, 0.0530143566429615, 0.05028412118554115, 0.045111283659935, 0.047345008701086044, 0.05735865980386734, 0.053108274936676025, 0.0469147227704525, 0.04709503799676895, 0.044031739234924316, 0.04267174005508423, 0.04493601247668266, 0.042031947523355484, 0.04421359673142433, 0.04235447943210602, 0.043020326644182205, 0.04743555188179016, 0.04956085979938507, 0.06904979795217514, 0.04197463393211365, 0.05269240587949753, 0.04226033762097359, 0.049336180090904236, 0.051940616220235825, 0.04298853129148483, 0.0457184836268425, 0.06919301301240921, 0.05938723310828209, 0.05132771283388138, 0.04537016525864601, 0.04482236132025719, 0.045228876173496246, 0.04295885190367699, 0.04749533161520958, 0.054578669369220734, 0.058551475405693054, 0.043095894157886505, 0.04225536808371544, 0.045360762625932693, 0.04280700907111168, 0.047254662960767746, 0.04176207631826401, 0.04540783539414406, 0.04918508604168892, 0.055501196533441544, 0.04320776090025902, 0.05239052698016167, 0.04405324161052704, 0.04167034849524498, 0.055581800639629364, 0.044048529118299484, 0.0607413686811924, 0.054199010133743286, 0.053755857050418854, 0.05854872241616249, 0.047914739698171616, 0.0431765578687191, 0.04414919391274452, 0.04214579984545708, 0.042067475616931915, 0.046517208218574524, 0.041676115244627, 0.045096464455127716, 0.042938992381095886, 0.04795882850885391, 0.06671324372291565, 0.04185207933187485, 0.05143168568611145, 0.045971572399139404, 0.041757527738809586, 0.04452333226799965, 0.05370928347110748, 0.04309665411710739, 0.05197668820619583, 0.052483174949884415, 0.05456934869289398, 0.05910347402095795, 0.04488774389028549, 0.04229766130447388, 0.04799444600939751, 0.0448293574154377, 0.04816121235489845, 0.045584190636873245, 0.04945738613605499, 0.06141379475593567, 0.0473235547542572, 0.04707774892449379, 0.04168498143553734, 0.05788743495941162, 0.043673526495695114, 0.04105164855718613, 0.045502401888370514, 0.07490600645542145, 0.07649868726730347, 0.04332813620567322, 0.04425283893942833, 0.04520006105303764, 0.04710511118173599, 0.04593930020928383, 0.042489178478717804, 0.049727488309144974, 0.042725346982479095, 0.04514629393815994, 0.043720196932554245, 0.04581119492650032, 0.049002595245838165, 0.050588201731443405, 0.0414009653031826, 0.04675139859318733, 0.044424716383218765, 0.046909719705581665, 0.046291522681713104, 0.04986461624503136, 0.05701364949345589, 0.0464925579726696, 0.050305962562561035, 0.04687389358878136, 0.04598129913210869, 0.043450307101011276, 0.04677790403366089, 0.0565434992313385, 0.0578281432390213, 0.07114773988723755, 0.05938474461436272, 0.05292189121246338, 0.046279482543468475, 0.044033221900463104, 0.04405597224831581, 0.05034437030553818, 0.04717069864273071, 0.05480297654867172, 0.04699356481432915, 0.04580284655094147, 0.03997625410556793, 0.049766723066568375, 0.06035679951310158, 0.04570329561829567, 0.04157609865069389, 0.0489252470433712, 0.04349547624588013, 0.04531552642583847, 0.05789589136838913, 0.04293811321258545, 0.04447135701775551, 0.05388089641928673, 0.0461006686091423, 0.041873130947351456, 0.04634515568614006, 0.051022034138441086, 0.04190269485116005, 0.04189116880297661, 0.047362469136714935, 0.045186251401901245, 0.045142870396375656, 0.05098814144730568, 0.05361805111169815, 0.059018898755311966, 0.043195690959692, 0.04387226328253746, 0.04376775398850441, 0.03990955650806427, 0.04840198531746864, 0.04295191913843155, 0.04249526187777519, 0.04241262748837471, 0.046337325125932693, 0.05203268676996231, 0.05313633382320404, 0.05080930516123772, 0.06289219856262207, 0.045770592987537384, 0.04624730721116066, 0.04480768367648125, 0.05102718994021416, 0.050612855702638626, 0.04490246623754501, 0.042368337512016296, 0.05434185639023781, 0.04755164682865143, 0.04636970907449722, 0.04178500920534134, 0.05177217721939087, 0.04855458810925484, 0.050807613879442215, 0.04619387537240982, 0.04336460307240486, 0.05187781900167465, 0.05023815110325813, 0.044230759143829346, 0.043326739221811295, 0.04347413033246994, 0.04390377551317215, 0.04794558510184288, 0.04851407930254936, 0.05556466802954674, 0.043514546006917953, 0.04293108731508255, 0.04827307537198067, 0.06258317828178406, 0.04857565090060234, 0.0593038834631443, 0.04790103808045387, 0.046634919941425323, 0.0417184941470623, 0.048897646367549896, 0.04394492879509926, 0.04931273311376572, 0.044326938688755035, 0.04342526197433472, 0.04381329193711281, 0.04544607549905777, 0.044222500175237656, 0.04914700239896774, 0.05207370966672897, 0.04668567702174187, 0.04135934263467789, 0.04694235697388649, 0.042547158896923065, 0.04590841010212898, 0.0497828871011734, 0.04871585965156555, 0.04647890850901604, 0.04729466512799263, 0.05440787598490715, 0.04658583179116249, 0.04349521920084953, 0.045717619359493256, 0.054800763726234436, 0.05849037691950798, 0.06542660295963287, 0.056414127349853516, 0.06036082282662392, 0.04767632111907005, 0.0431908518075943, 0.043484900146722794, 0.042912743985652924, 0.04825326055288315, 0.04458216205239296, 0.04514029249548912, 0.04360170662403107, 0.0459708534181118, 0.04371580854058266, 0.04534272477030754, 0.04478626698255539, 0.04625461995601654, 0.04733101651072502, 0.04189804941415787, 0.04765767604112625, 0.04256892576813698, 0.04255780577659607, 0.051927369087934494, 0.050457488745450974, 0.04425103962421417, 0.04210304096341133, 0.04930500313639641, 0.04826376959681511, 0.044555146247148514, 0.053548913449048996, 0.06285831332206726, 0.05225424841046333, 0.045200251042842865, 0.0508502721786499, 0.04472101479768753, 0.04892488569021225, 0.048940833657979965, 0.04600118100643158, 0.06502038240432739, 0.06265800446271896, 0.06045166403055191, 0.04790574312210083, 0.04644346609711647, 0.04291638359427452, 0.05090794712305069, 0.050031766295433044, 0.05019092187285423, 0.0455215722322464, 0.04980797320604324, 0.0510578528046608, 0.04398629814386368, 0.04835963994264603, 0.053287506103515625, 0.056395743042230606, 0.05930706113576889, 0.04796372726559639, 0.0451798215508461, 0.044717952609062195, 0.044606294482946396, 0.048582836985588074, 0.05981691554188728, 0.07324524223804474, 0.05137120559811592, 0.052568498998880386, 0.04740544781088829, 0.044553887099027634, 0.04366832971572876, 0.04845596104860306, 0.04301760345697403, 0.045409828424453735, 0.04513459652662277, 0.050723012536764145, 0.05435973405838013, 0.051659297198057175, 0.043892644345760345, 0.05330149456858635, 0.040331535041332245, 0.04808451607823372, 0.042092714458703995, 0.045797958970069885, 0.047720640897750854, 0.046382054686546326, 0.04272874444723129, 0.04646233469247818, 0.04470062255859375, 0.04368913173675537, 0.0432436466217041, 0.04401974380016327, 0.047360751777887344, 0.05061633512377739, 0.05491615831851959, 0.045094411820173264, 0.043550338596105576, 0.05513792857527733, 0.04973377659916878, 0.054630622267723083, 0.043557342141866684, 0.04884538799524307, 0.0479772686958313, 0.05199672281742096, 0.05155833810567856, 0.05617423728108406, 0.052701227366924286, 0.04774431884288788, 0.04461679607629776, 0.04376817122101784, 0.04482632875442505, 0.04606971889734268, 0.046654317528009415, 0.04228769242763519, 0.05431191995739937, 0.04899121820926666, 0.0509631372988224, 0.048977047204971313, 0.050814200192689896, 0.053209852427244186, 0.0526590459048748, 0.05613729730248451, 0.04541969299316406, 0.047377537935972214, 0.05860774964094162, 0.060231804847717285, 0.05238320305943489, 0.04800939932465553, 0.04523424804210663, 0.04408092051744461, 0.0529315322637558, 0.05166119709610939, 0.04444776847958565, 0.04791601374745369, 0.058731984347105026, 0.046873126178979874, 0.04337663576006889, 0.04544948413968086, 0.04645484313368797, 0.04687557741999626, 0.04349544271826744, 0.045190807431936264, 0.04864582046866417, 0.04838181659579277, 0.04699746146798134, 0.048702988773584366, 0.045272666960954666, 0.04708309471607208, 0.04678473249077797, 0.05065401643514633, 0.053007010370492935, 0.05808510631322861, 0.04795047268271446, 0.04422112926840782, 0.05007001385092735, 0.05795914679765701, 0.05102767422795296, 0.046613626182079315, 0.04702063649892807, 0.05029944330453873, 0.04740752652287483, 0.04513154178857803, 0.04458581283688545, 0.04661725461483002, 0.04625556245446205, 0.04405687004327774, 0.045453719794750214, 0.0448814332485199, 0.04524339735507965, 0.044571403414011, 0.05263523384928703, 0.04979587718844414, 0.04954187944531441, 0.05643600970506668, 0.05077828839421272, 0.047941289842128754, 0.04509624466300011, 0.04626963287591934, 0.04496593028306961, 0.04530971869826317, 0.056054066866636276, 0.05300619453191757, 0.051331669092178345, 0.04615434631705284, 0.05002925917506218, 0.05544733628630638, 0.05566754192113876, 0.04707638919353485, 0.04593957960605621, 0.05544116348028183, 0.06656957417726517, 0.05710409954190254, 0.04886176064610481, 0.04650500789284706, 0.04604262858629227, 0.04470532760024071, 0.04667927697300911, 0.04570939019322395, 0.04806989058852196, 0.04647103324532509, 0.04853683337569237, 0.04806438088417053, 0.04465917870402336, 0.044600214809179306, 0.04582773149013519, 0.04333782196044922, 0.04410582035779953, 0.050963759422302246, 0.05179966986179352, 0.05366860330104828, 0.04302269592881203, 0.05103442072868347, 0.0467798113822937, 0.05322137475013733, 0.04579692333936691, 0.04870511591434479, 0.050098858773708344, 0.05206125229597092, 0.05691857263445854, 0.06280343234539032, 0.05552215874195099, 0.04720868915319443, 0.046579934656620026, 0.04688710719347, 0.04675522819161415, 0.046084169298410416, 0.055496927350759506, 0.07375147193670273, 0.06209634989500046, 0.04925118014216423, 0.045742232352495193, 0.04340914636850357, 0.04689173772931099, 0.04410426691174507, 0.051631201058626175, 0.05439625307917595, 0.04891013726592064, 0.0443602092564106, 0.04897303879261017, 0.05156875401735306, 0.06436459720134735, 0.05898802727460861, 0.0520666129887104, 0.04631960764527321, 0.043483711779117584, 0.047224607318639755, 0.04392661526799202, 0.04685716703534126, 0.04221325367689133, 0.04378470778465271, 0.047649990767240524, 0.044489674270153046, 0.05030415207147598, 0.05235530063509941, 0.055680565536022186, 0.04481919854879379, 0.05476198345422745, 0.05019015073776245, 0.04681376740336418, 0.044660698622465134, 0.04307489097118378, 0.04765455797314644, 0.05942969396710396, 0.0497225858271122, 0.04869566857814789, 0.04719284549355507, 0.05648702383041382, 0.0554940290749073, 0.05326007679104805, 0.048185501247644424, 0.044844452291727066, 0.048307742923498154, 0.0495411679148674, 0.0460851676762104, 0.05384785681962967, 0.050367288291454315, 0.05309158191084862, 0.06185154616832733, 0.06108008697628975, 0.05253477767109871, 0.045463964343070984, 0.0474093034863472, 0.04662719741463661, 0.045793239027261734, 0.04685034230351448, 0.06327636539936066, 0.054350271821022034, 0.05656016245484352, 0.06645366549491882, 0.08505522459745407, 0.07327628135681152, 0.060949359089136124, 0.05360652878880501, 0.05464461073279381, 0.05039972439408302, 0.04893767088651657, 0.046463482081890106, 0.043263040482997894, 0.04688820242881775, 0.057803455740213394, 0.05639342591166496, 0.04619621858000755, 0.04359722137451172, 0.047502100467681885, 0.0454244390130043, 0.04176095128059387, 0.053397566080093384, 0.045089807361364365, 0.06628351658582687, 0.05240992084145546, 0.04824663698673248, 0.04518487676978111, 0.04458630084991455, 0.04936100170016289, 0.04451994225382805, 0.04944027215242386, 0.04531291872262955, 0.057135939598083496, 0.04892278090119362, 0.05255165696144104, 0.04373164102435112, 0.047633182257413864, 0.04468320310115814, 0.04687602445483208, 0.05175793170928955, 0.055298831313848495, 0.04999183118343353, 0.04745160788297653, 0.044180285185575485, 0.051468152552843094, 0.0468454472720623, 0.045589908957481384, 0.0475001260638237, 0.04789242148399353, 0.043769001960754395, 0.045335862785577774, 0.05057075247168541, 0.046876199543476105, 0.044680241495370865, 0.045677829533815384, 0.047176558524370193, 0.05596540495753288, 0.05163551867008209, 0.05176839977502823, 0.04411260783672333, 0.048532482236623764, 0.04815695807337761, 0.04755651205778122, 0.04453202337026596, 0.05400300398468971, 0.045318033546209335, 0.04648962989449501, 0.059754326939582825, 0.060524579137563705, 0.04604398459196091, 0.04618409648537636, 0.04524878039956093, 0.047609660774469376, 0.054953619837760925, 0.04707314819097519, 0.05500010773539543, 0.05547235906124115, 0.04754272848367691, 0.05363880470395088, 0.054201651364564896, 0.06244513764977455, 0.06194400414824486, 0.044603992253541946, 0.0581783652305603, 0.0681580975651741, 0.06131540611386299, 0.06280414760112762, 0.055232103914022446, 0.04447163641452789, 0.04561731219291687, 0.04650334268808365, 0.04440595954656601, 0.04575463384389877, 0.04668476805090904, 0.04918554797768593, 0.059112582355737686, 0.05332733318209648, 0.04535026103258133, 0.0485822930932045, 0.05024273321032524, 0.053366512060165405, 0.05177835375070572, 0.049067627638578415, 0.049403462558984756, 0.04760286211967468, 0.04463021084666252, 0.05211744084954262, 0.042627040296792984, 0.05714939907193184, 0.06891807168722153, 0.04618634656071663, 0.05035612732172012, 0.05505608022212982, 0.053046077489852905, 0.05098150297999382, 0.04942428693175316, 0.05210527032613754, 0.05813588574528694, 0.07455173134803772, 0.054745808243751526, 0.0446813702583313, 0.049268823117017746, 0.046470385044813156, 0.04885733127593994, 0.04646846279501915, 0.046555470675230026, 0.05064646154642105, 0.05001647770404816, 0.057418931275606155, 0.04979719966650009, 0.05156290903687477, 0.04492419585585594, 0.053194474428892136, 0.04986492544412613, 0.052386511117219925, 0.054563384503126144, 0.048338524997234344, 0.04681989923119545, 0.054171495139598846, 0.046181004494428635, 0.05139695480465889, 0.04881885647773743, 0.04635114222764969, 0.04607631266117096, 0.04476497694849968, 0.04662477597594261, 0.04877644032239914, 0.04279732704162598, 0.04766221344470978, 0.05048398673534393, 0.04727550968527794, 0.04732929542660713, 0.05042775347828865, 0.058558207005262375, 0.045583195984363556, 0.05034547671675682, 0.0485917404294014, 0.05722736194729805, 0.051354117691516876, 0.04477138817310333, 0.04516762122511864, 0.050999581813812256, 0.04694146290421486, 0.046901948750019073, 0.04882126301527023, 0.049852438271045685, 0.059630945324897766, 0.052286114543676376, 0.05132364481687546, 0.05038847774267197, 0.04467678442597389, 0.042735613882541656, 0.04701806232333183, 0.048278793692588806, 0.04577627778053284, 0.044294293969869614, 0.04900134727358818, 0.052621029317379, 0.04515157267451286, 0.061640821397304535, 0.07440579682588577, 0.05067509040236473, 0.04514297470450401, 0.04569742828607559, 0.05190981924533844, 0.04432860016822815, 0.05408041179180145, 0.04568762332201004, 0.047587573528289795, 0.04606858268380165, 0.0500125028192997, 0.06061134487390518, 0.051468003541231155, 0.04314021021127701, 0.06024681404232979, 0.047580286860466, 0.055577609688043594, 0.054520122706890106, 0.05159087851643562, 0.04877319931983948, 0.05250860005617142, 0.04726893827319145, 0.054389867931604385, 0.052288204431533813, 0.04257681220769882, 0.048331644386053085, 0.046474639326334, 0.050905294716358185, 0.04903118312358856, 0.04650067910552025, 0.04672610014677048, 0.048924025148153305, 0.06650231778621674, 0.053495123982429504, 0.046289779245853424, 0.045852456241846085, 0.05574694275856018, 0.0652502179145813, 0.056316643953323364, 0.04550812020897865, 0.051920101046562195, 0.05071093142032623, 0.048502661287784576, 0.046976059675216675, 0.046284426003694534, 0.047698576003313065, 0.04970935732126236, 0.05071784928441048, 0.05226670950651169, 0.04644959047436714, 0.0465596467256546, 0.04839594289660454, 0.05267509073019028, 0.06047985702753067, 0.05722244083881378, 0.05380361154675484, 0.04416922479867935, 0.053415700793266296, 0.05148312449455261, 0.05277705937623978, 0.047561079263687134, 0.048613935708999634, 0.0462898425757885, 0.04609159007668495, 0.06345231086015701, 0.06149949133396149, 0.04922981560230255, 0.049947090446949005, 0.045161597430706024, 0.05256102606654167, 0.05692204833030701, 0.047411613166332245, 0.043564826250076294, 0.06160590425133705, 0.0514487661421299, 0.0458773598074913, 0.04848718270659447, 0.04594259709119797, 0.04830402135848999, 0.06897467374801636, 0.05222698301076889, 0.046477675437927246, 0.06110916659235954, 0.062182217836380005, 0.054980166256427765, 0.051928918808698654, 0.04867396503686905, 0.05880845710635185, 0.04917827621102333, 0.04941916465759277, 0.047976575791835785, 0.05230475217103958, 0.04546495899558067, 0.04939563199877739, 0.058795034885406494, 0.07160171121358871, 0.05885165184736252, 0.04991890490055084, 0.04762519523501396, 0.046858157962560654, 0.05110188201069832, 0.050784725695848465, 0.06421307474374771, 0.05822758004069328, 0.06076478213071823, 0.05178482085466385, 0.04563009366393089, 0.04869099333882332, 0.05856960266828537, 0.05592023953795433, 0.06139392778277397, 0.04933832958340645, 0.0473860502243042, 0.047156624495983124, 0.05196284502744675, 0.05461828038096428, 0.0559065155684948, 0.05274346098303795, 0.05422760918736458, 0.048645321279764175, 0.04470057040452957, 0.047475848346948624, 0.04429301619529724, 0.064662866294384, 0.05258562043309212, 0.04611922428011894, 0.056253306567668915, 0.06125519424676895, 0.04915262758731842, 0.04511716216802597, 0.053103312849998474, 0.047166019678115845, 0.04700102284550667, 0.05086103826761246, 0.05853230133652687, 0.055900122970342636, 0.05096385255455971, 0.045237526297569275, 0.05118077993392944, 0.04883184656500816, 0.04651700332760811, 0.04658669978380203, 0.04855303466320038, 0.06135902553796768, 0.06592850387096405, 0.04842391610145569, 0.044883694499731064, 0.0503021776676178, 0.05131439119577408, 0.050604358315467834, 0.04609503224492073, 0.05297955870628357, 0.060379959642887115, 0.04791240766644478, 0.04758971929550171, 0.047169674187898636, 0.05313226953148842, 0.04488346725702286, 0.053080059587955475, 0.056948497891426086, 0.05564946308732033, 0.0478866845369339, 0.05020472779870033, 0.049149077385663986, 0.05627581849694252, 0.050327472388744354, 0.05127850919961929, 0.04722197726368904, 0.056533802300691605, 0.059911638498306274, 0.055099908262491226, 0.04663841053843498, 0.049286700785160065, 0.05337420478463173, 0.05920460820198059, 0.0578327439725399, 0.05852973088622093, 0.04909291863441467, 0.051017336547374725, 0.05603935569524765, 0.05471647158265114, 0.050891853868961334, 0.049557607620954514, 0.067691370844841, 0.04967992752790451, 0.0479283407330513, 0.06371165812015533, 0.06708750873804092, 0.05007784441113472, 0.04591594636440277, 0.04680243134498596, 0.0507228821516037, 0.047673847526311874, 0.05066143348813057, 0.04430752992630005, 0.05591877922415733, 0.0542919859290123, 0.04981540888547897, 0.04866292327642441, 0.05328008532524109, 0.05474792420864105, 0.05180796980857849, 0.059518203139305115, 0.060463447123765945, 0.0480252280831337, 0.0555168092250824, 0.049210261553525925, 0.04983564838767052, 0.04761118069291115, 0.05475631356239319, 0.050623975694179535, 0.0460285022854805, 0.05306634306907654, 0.05027727782726288, 0.054793376475572586, 0.062286876142024994, 0.0738871842622757, 0.04717626795172691, 0.053194593638181686, 0.049502138048410416, 0.06601131707429886, 0.06390565633773804, 0.05877194553613663, 0.048252858221530914, 0.05370441451668739, 0.05430983006954193, 0.05706138536334038, 0.05070343613624573, 0.05026692524552345, 0.047182828187942505, 0.04922110214829445, 0.05019000172615051, 0.052370112389326096, 0.05379047617316246, 0.04744173213839531, 0.0496215745806694, 0.0503317229449749, 0.056879568845033646, 0.05292479321360588, 0.046063054352998734, 0.05086164176464081, 0.05633240565657616, 0.04806600883603096, 0.08151775598526001, 0.06733514368534088, 0.05200805887579918, 0.05409978702664375, 0.06832551211118698, 0.062101323157548904, 0.05379253998398781, 0.044845856726169586, 0.06191106140613556, 0.046114109456539154, 0.048990584909915924, 0.04951585456728935, 0.04821944981813431, 0.056779082864522934, 0.05786944553256035, 0.05425253510475159, 0.04768837243318558, 0.04832334816455841, 0.04985887557268143, 0.06041225045919418, 0.0580342561006546, 0.04522966593503952, 0.046462710946798325, 0.059396907687187195, 0.05107530951499939, 0.0559481680393219, 0.053620845079422, 0.05848931893706322, 0.048994794487953186, 0.05589290335774422, 0.05890822410583496, 0.0611429288983345, 0.05254273861646652, 0.054551366716623306, 0.06487158685922623, 0.051443420350551605, 0.05567651242017746, 0.052398841828107834, 0.061236172914505005, 0.09610302746295929, 0.10815487056970596, 0.06718817353248596, 0.046803753823041916, 0.05018710345029831, 0.053324081003665924, 0.07122824341058731, 0.06235475465655327, 0.05448095500469208, 0.05088021606206894, 0.0478997565805912, 0.06970493495464325, 0.0554928332567215, 0.0519573800265789, 0.05880921334028244, 0.050529733300209045, 0.06239958480000496, 0.059282150119543076, 0.049930389970541, 0.05387764796614647, 0.048749569803476334, 0.05555703490972519, 0.06687316298484802, 0.058697398751974106, 0.049883920699357986, 0.05378419905900955, 0.05192016065120697, 0.04986894130706787, 0.04966294765472412, 0.053144671022892, 0.0516374446451664, 0.05091453343629837, 0.05037422105669975, 0.05584071949124336, 0.05189523845911026, 0.06760773807764053, 0.05276656523346901, 0.0481707789003849, 0.0592970997095108, 0.05750832334160805, 0.06079220399260521, 0.05474677309393883, 0.04838132485747337, 0.056574322283267975, 0.052918896079063416, 0.0498473197221756, 0.058438897132873535, 0.05191028490662575, 0.06224365904927254, 0.05597531050443649, 0.05917143449187279, 0.054502248764038086, 0.04704258218407631, 0.055317506194114685, 0.06522968411445618, 0.04966581240296364, 0.05266333371400833, 0.05024503171443939, 0.05101072043180466, 0.06537669152021408, 0.05116042494773865, 0.046393513679504395, 0.05283170938491821, 0.05197831615805626, 0.050650108605623245, 0.06919846683740616, 0.05431192368268967, 0.04999769851565361, 0.05634919926524162, 0.05455630645155907, 0.048750896006822586, 0.06791403889656067, 0.06580368429422379, 0.05233761668205261, 0.05161682516336441, 0.05240195244550705, 0.05953662842512131, 0.05395304784178734, 0.06295803189277649, 0.053491439670324326, 0.05239279940724373, 0.049720630049705505, 0.05356930196285248, 0.056826576590538025, 0.05799625441431999, 0.04891765117645264, 0.0570816732943058, 0.05310959368944168, 0.04886840656399727, 0.05917785316705704, 0.050992608070373535, 0.07146016508340836, 0.06345605105161667, 0.051959969103336334, 0.05067252740263939, 0.056804850697517395, 0.05638890713453293, 0.05482156202197075, 0.049657851457595825, 0.06047684699296951, 0.050341665744781494, 0.058913424611091614, 0.05004604905843735, 0.06393326073884964, 0.06755338609218597, 0.07472322136163712, 0.05561714246869087, 0.049909934401512146, 0.05741163715720177, 0.05761909484863281, 0.050685882568359375, 0.053848616778850555, 0.05160482972860336, 0.05842447653412819, 0.055683035403490067, 0.05036258324980736, 0.052245285362005234, 0.05060902237892151, 0.059979092329740524, 0.06195707246661186, 0.05375193804502487, 0.050506651401519775, 0.051056794822216034, 0.06014212220907211, 0.04763711616396904, 0.05390673130750656, 0.06907594203948975, 0.06576911360025406, 0.051684267818927765, 0.04936086758971214, 0.06975481659173965, 0.06432696431875229, 0.05624319985508919, 0.05438915267586708, 0.05399541184306145, 0.060932841151952744, 0.05532648041844368, 0.05080287158489227, 0.05077105760574341, 0.05390583723783493, 0.052900053560733795, 0.05308346822857857, 0.05326589196920395, 0.053201645612716675, 0.055067531764507294, 0.057987798005342484, 0.05505514144897461, 0.05213668942451477, 0.052596040070056915, 0.05392010137438774, 0.05021940544247627, 0.053324442356824875, 0.05142385885119438, 0.05904994532465935, 0.0571676567196846, 0.055816397070884705, 0.05054722726345062, 0.05163208395242691, 0.05257213115692139, 0.049499526619911194, 0.0581224150955677, 0.06350544095039368, 0.05669295787811279, 0.05356377363204956, 0.05179562419652939, 0.054698530584573746, 0.05700244754552841, 0.04990677908062935, 0.05981137230992317, 0.05539018660783768, 0.06379354000091553, 0.05873870477080345, 0.0538092702627182, 0.05160399526357651, 0.0540148951113224, 0.050997037440538406, 0.05961137264966965, 0.057472605258226395, 0.05122595280408859, 0.06027970090508461, 0.06319285184144974, 0.06653223931789398, 0.053464554250240326, 0.058827996253967285, 0.0508543886244297, 0.05121615529060364, 0.055113475769758224, 0.07148825377225876, 0.047909513115882874, 0.0555204376578331, 0.05508669465780258, 0.05238793045282364, 0.06431806087493896, 0.0544096939265728, 0.04715679958462715, 0.05345600098371506, 0.05633439123630524, 0.06710433959960938, 0.053887445479631424, 0.05217456445097923, 0.0632067620754242, 0.07279805094003677, 0.0490914024412632, 0.05901218578219414, 0.062446314841508865, 0.06118994951248169, 0.04980192705988884, 0.054221123456954956, 0.05455733835697174, 0.04803803563117981, 0.05895585939288139, 0.05737012252211571, 0.05640701577067375, 0.05215753987431526, 0.054228175431489944, 0.05290038138628006, 0.054297201335430145, 0.05018649622797966, 0.0493319034576416, 0.05592827498912811, 0.05099593847990036, 0.05198737606406212, 0.058469537645578384, 0.05682656541466713, 0.0533854179084301, 0.06080362945795059, 0.06159774586558342, 0.050812095403671265, 0.05898953601717949, 0.057187147438526154, 0.06383854150772095, 0.05838370695710182, 0.05552714690566063, 0.05084928497672081, 0.05829005688428879, 0.05387463793158531, 0.06624142080545425, 0.05359607934951782, 0.0490109883248806, 0.05452384799718857, 0.04910565912723541, 0.06179884448647499, 0.052407924085855484, 0.06553556025028229, 0.07513371109962463, 0.062474291771650314, 0.05772872269153595, 0.06276559084653854, 0.051815420389175415, 0.053293030709028244, 0.05426947399973869, 0.05482302978634834, 0.05719128996133804, 0.06507538259029388, 0.061463363468647, 0.05359087139368057, 0.05519408360123634, 0.0550251342356205, 0.06396779417991638, 0.07585637271404266, 0.05016305297613144, 0.05255000293254852, 0.05747056007385254, 0.05702284723520279, 0.05464443564414978, 0.05980073660612106, 0.07321543246507645, 0.05190004035830498, 0.0591682568192482, 0.0559932217001915, 0.05084586888551712, 0.06836417317390442, 0.06270192563533783, 0.05636686459183693, 0.05183368921279907, 0.0594969242811203, 0.06694251298904419, 0.07263544201850891, 0.06453340500593185, 0.05898979678750038, 0.04909606650471687, 0.060419563204050064, 0.05201152339577675, 0.05432572960853577, 0.051696691662073135, 0.05761302635073662, 0.05482679605484009, 0.06144046410918236, 0.06294100731611252, 0.05141359567642212, 0.05387119576334953, 0.05244969204068184, 0.060212478041648865, 0.06721848249435425, 0.053478993475437164, 0.05283527448773384, 0.05492895469069481, 0.0542546808719635, 0.06259764730930328, 0.057270634919404984, 0.07026001811027527, 0.0682586282491684, 0.05469590425491333, 0.05198027566075325, 0.05555875971913338, 0.056262172758579254, 0.05882110446691513, 0.06485231965780258, 0.06063257157802582, 0.05652040243148804, 0.059346720576286316, 0.06041857227683067, 0.05876535922288895, 0.05892321467399597, 0.05681655928492546, 0.07256030291318893, 0.0661531388759613, 0.06347154825925827, 0.07073219865560532, 0.05902794376015663, 0.054718099534511566, 0.051749493926763535, 0.05469640716910362, 0.05153946578502655, 0.05072147399187088, 0.05435372516512871, 0.06576386094093323, 0.0710599422454834, 0.06489386409521103, 0.056959547102451324, 0.05279135704040527, 0.05523865297436714, 0.055247679352760315, 0.05110602453351021, 0.05753440409898758, 0.05660315230488777, 0.05536163970828056, 0.05343969166278839, 0.0572948232293129, 0.06554516404867172, 0.05518711730837822, 0.05446997657418251, 0.05837293341755867, 0.056304775178432465, 0.05834997072815895, 0.06965436041355133, 0.0509214773774147, 0.054197460412979126, 0.05636228993535042, 0.05605871602892876, 0.04942288249731064, 0.051358990371227264, 0.04945340007543564, 0.0637914314866066, 0.07151833176612854, 0.06229467689990997, 0.053511470556259155, 0.06136912852525711, 0.05520371347665787, 0.056907329708337784, 0.058910273015499115, 0.06336918473243713, 0.058669328689575195, 0.049032606184482574, 0.058803021907806396, 0.062339894473552704, 0.04658142849802971, 0.05777677148580551, 0.0600133091211319, 0.06745666265487671, 0.05730002373456955, 0.05771923437714577, 0.04943966493010521, 0.051689568907022476, 0.06005197763442993, 0.06840255856513977, 0.051301371306180954, 0.053064461797475815, 0.050098858773708344, 0.04932742938399315, 0.06685905158519745, 0.04908914119005203, 0.05092544108629227, 0.05697701498866081, 0.05996967852115631, 0.0525892935693264, 0.05248843878507614, 0.0653548464179039, 0.054334308952093124, 0.0526353120803833, 0.05236005038022995, 0.05161659047007561, 0.05756330117583275, 0.05533026531338692, 0.05113371089100838, 0.06496959179639816, 0.0540800616145134, 0.050841059535741806, 0.050294820219278336, 0.05181962251663208, 0.04853459820151329, 0.048548623919487, 0.05507795885205269, 0.07938892394304276, 0.06011753901839256, 0.0519321970641613, 0.04649904742836952, 0.05816604569554329, 0.0610145702958107, 0.056193266063928604, 0.05188196897506714, 0.05172058939933777, 0.05010801926255226, 0.056250132620334625, 0.05408383905887604, 0.06967747956514359, 0.06132124736905098, 0.05787861347198486, 0.04975850135087967, 0.05596937984228134, 0.05307631194591522, 0.06497810035943985, 0.07212740927934647, 0.07830599695444107, 0.06531145423650742, 0.06272412836551666, 0.052039071917533875, 0.05551149323582649, 0.05270097404718399, 0.059570953249931335, 0.057550523430109024, 0.049807365983724594, 0.06317021697759628, 0.05798739939928055, 0.059014081954956055, 0.06196368858218193, 0.05356637015938759, 0.050252705812454224, 0.059447940438985825, 0.052662018686532974, 0.05724402517080307, 0.056983888149261475, 0.055851999670267105, 0.057269733399152756, 0.050600968301296234, 0.04791818559169769, 0.07322850078344345, 0.06754426658153534, 0.07686837017536163, 0.06423595547676086, 0.05225994065403938, 0.04760921746492386, 0.05950305983424187, 0.06191929802298546, 0.05629918724298477, 0.057227928191423416, 0.054589807987213135, 0.05213909596204758, 0.0576007254421711, 0.05183865875005722, 0.05433790013194084, 0.053372208029031754, 0.052241481840610504, 0.05095430463552475, 0.05452496558427811, 0.07050158083438873, 0.06498489528894424, 0.05640942603349686, 0.050002891570329666, 0.05253314599394798, 0.05031042546033859, 0.05483631417155266, 0.055673979222774506, 0.06099807843565941, 0.05767454952001572, 0.05111886188387871, 0.05468551442027092, 0.060996122658252716, 0.0718957781791687, 0.05209797993302345, 0.04861244559288025, 0.06471800804138184, 0.057377561926841736, 0.05834023281931877, 0.061021335422992706, 0.05362972617149353, 0.05332624539732933, 0.061486583203077316, 0.05003143474459648, 0.052500221878290176, 0.04851934686303139, 0.05387592315673828, 0.061724305152893066, 0.05394647642970085, 0.05107918754220009, 0.05165628343820572, 0.0593123622238636, 0.057785846292972565, 0.05025924742221832, 0.052127547562122345, 0.05128389224410057, 0.05286203324794769, 0.06190984323620796, 0.05904517322778702, 0.058795783668756485, 0.06277917325496674, 0.058881256729364395, 0.06000670790672302, 0.05180090293288231, 0.057198766618967056, 0.04671056941151619, 0.058138925582170486, 0.04698878154158592, 0.05529710277915001, 0.05373469740152359, 0.049146462231874466, 0.05814380198717117, 0.05392458662390709, 0.0543891079723835, 0.05491512641310692, 0.05578450486063957, 0.048996444791555405, 0.056580767035484314, 0.05033506080508232, 0.05962490662932396, 0.0502832867205143, 0.053410861641168594, 0.05920776352286339, 0.06733763217926025, 0.07315432280302048, 0.0557052381336689, 0.0605284720659256, 0.055611152201890945, 0.05221375823020935, 0.0530969612300396, 0.05529961735010147, 0.05377175286412239, 0.057346902787685394, 0.0571032389998436, 0.05335604399442673, 0.0538843609392643, 0.055161312222480774, 0.05790456011891365, 0.05249208211898804, 0.05151820182800293, 0.05515061691403389, 0.06567993015050888, 0.05981209874153137, 0.059865791350603104, 0.06345944851636887, 0.052899740636348724, 0.05029725655913353, 0.06165618449449539, 0.05145609751343727, 0.056626684963703156, 0.050318606197834015, 0.05662823095917702, 0.04918482154607773, 0.06289027631282806, 0.08533163368701935, 0.06561286747455597, 0.062080394476652145, 0.06012381985783577, 0.0644313246011734, 0.052980683743953705, 0.05170297622680664, 0.05615493655204773, 0.052233558148145676, 0.05260505899786949, 0.05814336985349655, 0.051070813089609146, 0.05899754911661148, 0.05971876159310341, 0.06404202431440353, 0.06565957516431808, 0.05461171269416809, 0.05817157402634621, 0.04952434450387955, 0.05240161344408989, 0.053749244660139084, 0.049631163477897644, 0.06785566359758377, 0.057884301990270615, 0.07242465764284134, 0.06234436854720116, 0.06012869253754616, 0.05009974539279938, 0.05821570008993149, 0.050745218992233276, 0.06062259152531624, 0.06239655986428261, 0.0597078911960125, 0.055119648575782776, 0.061326973140239716, 0.05368755757808685, 0.05407791584730148, 0.05025259777903557, 0.05542955920100212, 0.051250774413347244, 0.05559612438082695, 0.061939943581819534, 0.05401964858174324, 0.06546595692634583, 0.05555368587374687, 0.05049098655581474, 0.054950155317783356, 0.05369507521390915, 0.05180611461400986, 0.053573284298181534, 0.060451652854681015, 0.05620431900024414, 0.05773402750492096, 0.052414678037166595, 0.062335845082998276, 0.06685411185026169, 0.07049664855003357, 0.0666716918349266, 0.06271117180585861, 0.06389161944389343, 0.055318091064691544, 0.06025170162320137, 0.055592164397239685, 0.053155168890953064, 0.05139758437871933, 0.06386182457208633, 0.05640804395079613, 0.05548272654414177, 0.053565431386232376, 0.05534366890788078, 0.07498596608638763, 0.07114831358194351, 0.06326376646757126, 0.05002501606941223, 0.05968882516026497, 0.050125572830438614, 0.060458552092313766, 0.058585893362760544, 0.05317867547273636, 0.0556170679628849, 0.05083091929554939, 0.0681917667388916, 0.07092320919036865, 0.05454607680439949, 0.05319024622440338, 0.05158846825361252, 0.05592997372150421, 0.05572741851210594, 0.07588518410921097, 0.05465545877814293, 0.052588801831007004, 0.05361747369170189, 0.05360942333936691, 0.057601526379585266, 0.052727919071912766, 0.05802001804113388, 0.054056454449892044, 0.052378807216882706, 0.05170592665672302, 0.05808790773153305, 0.05631805211305618, 0.06005169451236725, 0.06473549455404282, 0.05702557414770126, 0.0572909452021122, 0.06279223412275314, 0.05887206643819809, 0.05218536779284477, 0.05482250079512596, 0.0656236782670021, 0.05538219213485718, 0.05864197015762329, 0.06663433462381363, 0.0550515353679657, 0.07554858177900314, 0.06078413128852844, 0.06096161529421806, 0.04934649169445038, 0.059808149933815, 0.048699751496315, 0.05629993602633476, 0.0509723462164402, 0.06732247024774551, 0.05678992345929146, 0.05406023934483528, 0.05525907874107361, 0.05451655015349388, 0.05782249942421913, 0.06251150369644165, 0.05469519644975662, 0.0539335235953331, 0.0591166615486145, 0.058383453637361526, 0.05457615852355957, 0.05673152580857277, 0.05436454340815544, 0.06281362473964691, 0.05244976654648781, 0.058817058801651, 0.057019080966711044, 0.05991201847791672, 0.054090823978185654, 0.05171280726790428, 0.05992083624005318, 0.07449693232774734, 0.0562523789703846, 0.05769353732466698, 0.05900496616959572, 0.05451197922229767, 0.05900220945477486, 0.0509880892932415, 0.057243771851062775, 0.053898002952337265, 0.0557972677052021, 0.05858476087450981, 0.08098240196704865, 0.05404657870531082, 0.0549861304461956, 0.057498153299093246, 0.05223410576581955, 0.06900094449520111, 0.060840606689453125, 0.060305338352918625, 0.05803463235497475, 0.055706534534692764, 0.05393224209547043, 0.05212324485182762, 0.05260785296559334, 0.056576721370220184, 0.05694655328989029, 0.06501831859350204, 0.07250145077705383, 0.07636047154664993, 0.06909541040658951, 0.0761110857129097, 0.07531226426362991, 0.07411980628967285, 0.05772558972239494, 0.06365720927715302, 0.05356946215033531, 0.052962590008974075, 0.05965335667133331, 0.05595727637410164, 0.06185657158493996, 0.054072149097919464, 0.055750466883182526, 0.07136722654104233, 0.06191995367407799, 0.06991579383611679, 0.054794903844594955, 0.05628342181444168, 0.057948824018239975, 0.05572451651096344, 0.05638645216822624, 0.057757697999477386, 0.06303983181715012, 0.06696323305368423, 0.06921689957380295, 0.06219439208507538, 0.05325127765536308, 0.06039871275424957, 0.06674396991729736, 0.06391215324401855, 0.05831503868103027, 0.05768757313489914, 0.07068085670471191, 0.05668764188885689, 0.059471406042575836, 0.07159161567687988, 0.06496131420135498, 0.06431728601455688, 0.055263470858335495, 0.06478411704301834, 0.05347634479403496, 0.05801108852028847, 0.06063995882868767, 0.053236499428749084, 0.0735255554318428, 0.059567421674728394, 0.05979059264063835, 0.058251939713954926, 0.05703526735305786, 0.057287998497486115, 0.054955292493104935, 0.06304121017456055, 0.061057720333337784, 0.056767288595438004, 0.0553097240626812, 0.057202767580747604, 0.06045856699347496, 0.06178369000554085, 0.05647958070039749, 0.05497852712869644, 0.05439923331141472, 0.05650819092988968, 0.054856233298778534, 0.06133163347840309, 0.08241421729326248, 0.061130769550800323, 0.06047305092215538, 0.055979564785957336, 0.06608829647302628, 0.05096803233027458, 0.054297640919685364, 0.05985346436500549, 0.053437333554029465, 0.06955137848854065, 0.053639013320207596, 0.054354794323444366, 0.050674643367528915, 0.052187055349349976, 0.059560567140579224, 0.06135047599673271, 0.062493227422237396, 0.05646951496601105, 0.054004933685064316, 0.05316370725631714, 0.06977201253175735, 0.061313875019550323, 0.054863087832927704, 0.05836345627903938, 0.0637572705745697, 0.06109383702278137, 0.06297093629837036, 0.058955807238817215, 0.04954059422016144, 0.053973909467458725, 0.057939786463975906, 0.05643565580248833, 0.05855163186788559, 0.051013920456171036, 0.06271417438983917, 0.061721935868263245, 0.056879326701164246, 0.05692455917596817, 0.05640121176838875, 0.05443565919995308, 0.061129406094551086, 0.053122300654649734, 0.0591491274535656, 0.05436179041862488, 0.05025500804185867, 0.0617818683385849, 0.062003325670957565, 0.05670248717069626, 0.05763153359293938, 0.05154440179467201, 0.0570676214993, 0.05307096615433693, 0.05590318515896797, 0.056723326444625854, 0.0545206256210804, 0.05288850888609886, 0.05536222085356712, 0.0651838406920433, 0.05731398984789848, 0.05305458605289459, 0.06388545036315918, 0.05069193243980408, 0.059264324605464935, 0.05359497666358948, 0.05713948607444763, 0.061915136873722076, 0.06453841179609299, 0.06241169944405556, 0.05257017910480499, 0.06435929983854294, 0.06855697929859161, 0.05726175755262375, 0.05460560321807861, 0.05532209947705269, 0.07143530994653702, 0.055392276495695114, 0.061258554458618164, 0.05187881737947464, 0.05820348113775253, 0.05251583829522133, 0.056154023855924606, 0.0570734441280365, 0.0752875804901123, 0.060071755200624466, 0.060581084340810776, 0.061137259006500244, 0.06525740027427673, 0.07583629339933395, 0.056830860674381256, 0.05305014178156853, 0.06577020138502121, 0.05799683555960655, 0.06009385734796524, 0.06002461910247803, 0.05765264108777046, 0.0586501769721508, 0.05431109294295311, 0.057455141097307205, 0.054066646844148636, 0.059125930070877075, 0.05834207683801651, 0.05437956750392914, 0.060087695717811584, 0.07142546772956848, 0.054394133388996124, 0.06253861635923386, 0.06776324659585953, 0.059071220457553864, 0.054198917001485825, 0.05557388812303543, 0.06437455862760544, 0.06338120996952057, 0.05528268590569496, 0.05436062067747116, 0.05605127662420273, 0.05825791880488396, 0.05966027081012726, 0.057377081364393234, 0.057183388620615005, 0.06273762881755829, 0.06347905099391937, 0.060175493359565735, 0.05441807210445404, 0.06399770081043243, 0.05782756581902504, 0.05513927340507507, 0.05363753065466881, 0.06923609972000122, 0.056190598756074905, 0.05651044100522995, 0.055965594947338104, 0.05829515680670738, 0.06026323139667511, 0.056312426924705505, 0.0568619966506958, 0.05683087930083275, 0.06449557095766068, 0.05578184872865677, 0.056456562131643295, 0.05839390680193901, 0.06286256015300751, 0.06692418456077576, 0.05734316259622574, 0.056241076439619064, 0.05994540825486183, 0.05751170217990875, 0.056220103055238724, 0.054088301956653595, 0.05627347156405449, 0.06530331820249557, 0.05539395660161972, 0.05551404505968094, 0.06705325096845627, 0.0711253359913826, 0.05412714183330536, 0.061558015644550323, 0.05303215608000755, 0.05605565011501312, 0.054508354514837265, 0.060241520404815674, 0.057584043592214584, 0.05434402450919151, 0.06001940369606018, 0.06198293715715408, 0.057404015213251114, 0.06677965819835663, 0.05414233356714249, 0.060751769691705704, 0.05677337199449539, 0.05439247936010361, 0.05524883791804314, 0.05685973912477493, 0.05684296041727066, 0.06655918806791306, 0.056237682700157166, 0.06213044002652168, 0.05751894786953926, 0.05549158155918121, 0.05783159285783768, 0.057203229516744614, 0.05593809857964516, 0.06449314951896667, 0.05437871813774109, 0.0569017194211483, 0.0736788958311081, 0.06141100451350212, 0.059614457190036774, 0.05508221313357353, 0.05923724174499512, 0.058843862265348434, 0.05957818031311035, 0.0606832355260849, 0.05772816762328148, 0.05786493048071861, 0.05895231291651726, 0.058616772294044495, 0.06401552259922028, 0.055019110441207886, 0.05584532022476196, 0.05682200565934181, 0.06234922632575035, 0.05735296010971069, 0.060871392488479614, 0.06552087515592575, 0.07072591036558151, 0.06006847321987152, 0.05907302722334862, 0.056455209851264954, 0.05592679977416992, 0.056310780346393585, 0.054011378437280655, 0.05053602531552315, 0.053596626967191696, 0.06488798558712006, 0.05580783635377884, 0.052359871566295624, 0.0642700269818306, 0.05987795814871788, 0.06678422540426254, 0.07771109789609909, 0.06657855212688446, 0.06161106377840042, 0.0667622983455658, 0.06308097392320633, 0.06283220648765564, 0.06531411409378052, 0.05966703221201897, 0.0627521201968193, 0.06675634533166885, 0.06239276006817818, 0.06220710277557373, 0.06963828206062317, 0.07191120833158493, 0.05994703620672226, 0.061694975942373276, 0.060470424592494965, 0.056540410965681076, 0.05883876234292984, 0.05874885618686676, 0.057513684034347534, 0.061607006937265396, 0.06181677058339119, 0.058993641287088394, 0.06205300614237785, 0.06180625408887863, 0.059755388647317886, 0.06566698849201202, 0.05700632184743881, 0.06151127442717552, 0.06096038594841957, 0.06132398545742035, 0.06506456434726715, 0.060573600232601166, 0.06810290366411209, 0.062248289585113525, 0.06259533017873764, 0.05621437728404999, 0.06084112450480461, 0.05713655427098274, 0.0635402649641037, 0.05867650732398033, 0.06255464255809784, 0.06279901415109634, 0.061012763530015945, 0.05695835500955582, 0.062490105628967285, 0.06129203736782074, 0.05838075652718544, 0.05771652236580849, 0.05933387950062752, 0.06115697696805, 0.05910729616880417, 0.0720968246459961, 0.06305123120546341, 0.057058677077293396, 0.05928082764148712, 0.06045033410191536, 0.06252868473529816, 0.06084524467587471, 0.07030241936445236, 0.058192916214466095, 0.05909651145339012, 0.06191779673099518, 0.061577074229717255, 0.05842006206512451, 0.06407480686903, 0.060171566903591156, 0.06211245432496071, 0.0613182932138443, 0.05879852548241615, 0.06245097145438194, 0.05962515249848366, 0.05876246094703674, 0.057357754558324814, 0.0645970031619072, 0.058907438069581985, 0.06643768399953842, 0.08523460477590561, 0.06311438977718353, 0.06002924218773842, 0.04772169142961502, 0.07504194229841232, 0.06161973625421524, 0.06802117079496384, 0.07368473708629608, 0.055087219923734665, 0.05405963584780693, 0.06535718590021133, 0.062107332050800323, 0.05675283446907997, 0.0554361529648304, 0.06075869873166084, 0.05879826471209526, 0.056916914880275726, 0.05644674971699715, 0.06135039031505585, 0.06442157179117203, 0.061920203268527985, 0.06449216604232788, 0.05496823042631149, 0.05526403710246086, 0.054114434868097305, 0.06178446486592293, 0.057418692857027054, 0.0578216053545475, 0.06266183406114578, 0.057939961552619934, 0.06263760477304459, 0.061181534081697464, 0.07636310905218124, 0.0858776792883873, 0.0686667189002037, 0.06507702171802521, 0.05714097619056702, 0.06159157305955887, 0.05695588141679764, 0.08318459242582321, 0.06369283050298691, 0.06130416691303253, 0.053876832127571106, 0.0758940726518631, 0.05601748079061508, 0.06293361634016037, 0.06340117752552032, 0.06132887303829193, 0.059383660554885864, 0.06647749990224838, 0.05384612828493118, 0.057205017656087875, 0.06038534641265869, 0.06193375959992409, 0.07609552890062332, 0.05873335897922516, 0.05507516488432884, 0.05805547907948494, 0.05804956704378128, 0.05987061560153961, 0.06287199258804321, 0.05744156241416931, 0.05817289650440216, 0.06548111140727997, 0.05904644355177879, 0.05797785148024559, 0.05798346549272537, 0.06646949797868729, 0.06368488073348999, 0.05795852094888687, 0.056314222514629364, 0.06144827604293823, 0.06211015209555626, 0.06454097479581833, 0.05702623724937439, 0.05961216613650322, 0.059563834220170975, 0.05739951133728027, 0.06158958747982979, 0.07096368819475174, 0.059179775416851044, 0.061454493552446365, 0.05561123788356781, 0.06588920205831528, 0.0632113441824913, 0.05504119396209717, 0.0617721863090992, 0.08055640012025833]\n",
      "val_accuracy [0.9836829900741577, 0.9850816130638123, 0.9855477809906006, 0.986480176448822, 0.9850816130638123, 0.9869464039802551, 0.9822843670845032, 0.9855477809906006, 0.9818181991577148, 0.9846153855323792, 0.9855477809906006, 0.9860140085220337, 0.986480176448822, 0.986480176448822, 0.9860140085220337, 0.9846153855323792, 0.986480176448822, 0.9874125719070435, 0.986480176448822, 0.986480176448822, 0.9850816130638123, 0.9860140085220337, 0.986480176448822, 0.9860140085220337, 0.9869464039802551, 0.9855477809906006, 0.9804195761680603, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9860140085220337, 0.9869464039802551, 0.986480176448822, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.986480176448822, 0.986480176448822, 0.986480176448822, 0.986480176448822, 0.9850816130638123, 0.9850816130638123, 0.9869464039802551, 0.9869464039802551, 0.9850816130638123, 0.9846153855323792, 0.986480176448822, 0.9850816130638123, 0.9832167625427246, 0.9836829900741577, 0.984149158000946, 0.986480176448822, 0.9869464039802551, 0.9836829900741577, 0.9855477809906006, 0.986480176448822, 0.986480176448822, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.9846153855323792, 0.9846153855323792, 0.9855477809906006, 0.9869464039802551, 0.9869464039802551, 0.9860140085220337, 0.9869464039802551, 0.986480176448822, 0.9869464039802551, 0.9836829900741577, 0.984149158000946, 0.9869464039802551, 0.9855477809906006, 0.9869464039802551, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9855477809906006, 0.9869464039802551, 0.9846153855323792, 0.986480176448822, 0.9846153855323792, 0.9850816130638123, 0.9855477809906006, 0.9869464039802551, 0.9869464039802551, 0.986480176448822, 0.9836829900741577, 0.9869464039802551, 0.9878787994384766, 0.9869464039802551, 0.9855477809906006, 0.9869464039802551, 0.9874125719070435, 0.9878787994384766, 0.9878787994384766, 0.9869464039802551, 0.986480176448822, 0.9855477809906006, 0.986480176448822, 0.9878787994384766, 0.9860140085220337, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9874125719070435, 0.9869464039802551, 0.9860140085220337, 0.9878787994384766, 0.9869464039802551, 0.9855477809906006, 0.97529137134552, 0.9855477809906006, 0.9869464039802551, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.9860140085220337, 0.9850816130638123, 0.986480176448822, 0.9869464039802551, 0.9743589758872986, 0.9827505946159363, 0.984149158000946, 0.9850816130638123, 0.9869464039802551, 0.984149158000946, 0.9855477809906006, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9846153855323792, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9869464039802551, 0.9869464039802551, 0.9850816130638123, 0.9855477809906006, 0.9846153855323792, 0.9869464039802551, 0.9846153855323792, 0.9860140085220337, 0.9869464039802551, 0.986480176448822, 0.9850816130638123, 0.9827505946159363, 0.9846153855323792, 0.9850816130638123, 0.9869464039802551, 0.9860140085220337, 0.9855477809906006, 0.986480176448822, 0.9878787994384766, 0.9869464039802551, 0.9874125719070435, 0.9846153855323792, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.9869464039802551, 0.9860140085220337, 0.9836829900741577, 0.9836829900741577, 0.9832167625427246, 0.9836829900741577, 0.9813519716262817, 0.9878787994384766, 0.9869464039802551, 0.986480176448822, 0.9874125719070435, 0.986480176448822, 0.9855477809906006, 0.986480176448822, 0.9855477809906006, 0.9869464039802551, 0.9813519716262817, 0.9878787994384766, 0.9846153855323792, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.9874125719070435, 0.9869464039802551, 0.9874125719070435, 0.9869464039802551, 0.9874125719070435, 0.9855477809906006, 0.986480176448822, 0.9860140085220337, 0.9855477809906006, 0.9869464039802551, 0.9836829900741577, 0.9878787994384766, 0.9869464039802551, 0.9878787994384766, 0.986480176448822, 0.9869464039802551, 0.984149158000946, 0.9860140085220337, 0.9855477809906006, 0.9836829900741577, 0.9846153855323792, 0.9874125719070435, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9855477809906006, 0.986480176448822, 0.9860140085220337, 0.9850816130638123, 0.9846153855323792, 0.9846153855323792, 0.9878787994384766, 0.986480176448822, 0.9836829900741577, 0.9869464039802551, 0.9869464039802551, 0.984149158000946, 0.9832167625427246, 0.9869464039802551, 0.9874125719070435, 0.9874125719070435, 0.9869464039802551, 0.9874125719070435, 0.9855477809906006, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.9874125719070435, 0.9869464039802551, 0.9869464039802551, 0.986480176448822, 0.9874125719070435, 0.9874125719070435, 0.9874125719070435, 0.9878787994384766, 0.986480176448822, 0.9846153855323792, 0.9846153855323792, 0.986480176448822, 0.9869464039802551, 0.9869464039802551, 0.9808858036994934, 0.986480176448822, 0.9874125719070435, 0.984149158000946, 0.9869464039802551, 0.9869464039802551, 0.986480176448822, 0.9878787994384766, 0.986480176448822, 0.984149158000946, 0.9846153855323792, 0.9874125719070435, 0.9855477809906006, 0.9832167625427246, 0.9836829900741577, 0.984149158000946, 0.9878787994384766, 0.9860140085220337, 0.986480176448822, 0.9869464039802551, 0.9860140085220337, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.9855477809906006, 0.9869464039802551, 0.9869464039802551, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.986480176448822, 0.9869464039802551, 0.9869464039802551, 0.9874125719070435, 0.9874125719070435, 0.9846153855323792, 0.9869464039802551, 0.9850816130638123, 0.9869464039802551, 0.9869464039802551, 0.9860140085220337, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.9860140085220337, 0.9846153855323792, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.9850816130638123, 0.9855477809906006, 0.9846153855323792, 0.9874125719070435, 0.9846153855323792, 0.9846153855323792, 0.9836829900741577, 0.984149158000946, 0.9869464039802551, 0.9850816130638123, 0.9855477809906006, 0.984149158000946, 0.9855477809906006, 0.9878787994384766, 0.9869464039802551, 0.984149158000946, 0.986480176448822, 0.9874125719070435, 0.9860140085220337, 0.9846153855323792, 0.9860140085220337, 0.9855477809906006, 0.9855477809906006, 0.986480176448822, 0.9869464039802551, 0.9850816130638123, 0.9827505946159363, 0.9832167625427246, 0.9874125719070435, 0.9832167625427246, 0.986480176448822, 0.9869464039802551, 0.9850816130638123, 0.9855477809906006, 0.9850816130638123, 0.986480176448822, 0.9869464039802551, 0.9860140085220337, 0.9855477809906006, 0.9869464039802551, 0.986480176448822, 0.9855477809906006, 0.9846153855323792, 0.984149158000946, 0.9869464039802551, 0.9855477809906006, 0.9869464039802551, 0.9874125719070435, 0.9860140085220337, 0.9860140085220337, 0.986480176448822, 0.9855477809906006, 0.9860140085220337, 0.9855477809906006, 0.9869464039802551, 0.9874125719070435, 0.9846153855323792, 0.986480176448822, 0.9836829900741577, 0.9822843670845032, 0.9813519716262817, 0.9818181991577148, 0.9808858036994934, 0.9822843670845032, 0.9850816130638123, 0.9846153855323792, 0.986480176448822, 0.9869464039802551, 0.9869464039802551, 0.9855477809906006, 0.984149158000946, 0.9869464039802551, 0.9860140085220337, 0.9869464039802551, 0.9850816130638123, 0.9860140085220337, 0.9860140085220337, 0.9855477809906006, 0.9855477809906006, 0.9846153855323792, 0.984149158000946, 0.9869464039802551, 0.9836829900741577, 0.9832167625427246, 0.984149158000946, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.986480176448822, 0.984149158000946, 0.9855477809906006, 0.9855477809906006, 0.9846153855323792, 0.9855477809906006, 0.986480176448822, 0.9874125719070435, 0.9850816130638123, 0.9869464039802551, 0.9878787994384766, 0.986480176448822, 0.9869464039802551, 0.9855477809906006, 0.9874125719070435, 0.9855477809906006, 0.9822843670845032, 0.9850816130638123, 0.9874125719070435, 0.9869464039802551, 0.9846153855323792, 0.986480176448822, 0.986480176448822, 0.9869464039802551, 0.9860140085220337, 0.9860140085220337, 0.9869464039802551, 0.9874125719070435, 0.9832167625427246, 0.9836829900741577, 0.9878787994384766, 0.9869464039802551, 0.986480176448822, 0.9874125719070435, 0.9869464039802551, 0.986480176448822, 0.986480176448822, 0.9860140085220337, 0.9860140085220337, 0.986480176448822, 0.9869464039802551, 0.9846153855323792, 0.9846153855323792, 0.9874125719070435, 0.9855477809906006, 0.9846153855323792, 0.984149158000946, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.9869464039802551, 0.9850816130638123, 0.9869464039802551, 0.9860140085220337, 0.9850816130638123, 0.9874125719070435, 0.9832167625427246, 0.9869464039802551, 0.9860140085220337, 0.9846153855323792, 0.9846153855323792, 0.9822843670845032, 0.9813519716262817, 0.9813519716262817, 0.9878787994384766, 0.9869464039802551, 0.9860140085220337, 0.986480176448822, 0.986480176448822, 0.9878787994384766, 0.9869464039802551, 0.9874125719070435, 0.9878787994384766, 0.9878787994384766, 0.986480176448822, 0.9869464039802551, 0.9855477809906006, 0.9860140085220337, 0.9869464039802551, 0.9878787994384766, 0.9850816130638123, 0.9878787994384766, 0.9850816130638123, 0.9850816130638123, 0.9813519716262817, 0.986480176448822, 0.9860140085220337, 0.9855477809906006, 0.9850816130638123, 0.9860140085220337, 0.9860140085220337, 0.986480176448822, 0.9860140085220337, 0.9878787994384766, 0.9869464039802551, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.9850816130638123, 0.9846153855323792, 0.9836829900741577, 0.9855477809906006, 0.9836829900741577, 0.9808858036994934, 0.9850816130638123, 0.9855477809906006, 0.9846153855323792, 0.9818181991577148, 0.9832167625427246, 0.9878787994384766, 0.9846153855323792, 0.9860140085220337, 0.9850816130638123, 0.986480176448822, 0.986480176448822, 0.9822843670845032, 0.9836829900741577, 0.9850816130638123, 0.9869464039802551, 0.9860140085220337, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.9855477809906006, 0.9846153855323792, 0.9878787994384766, 0.986480176448822, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.9860140085220337, 0.9874125719070435, 0.986480176448822, 0.9860140085220337, 0.9855477809906006, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9874125719070435, 0.9855477809906006, 0.9860140085220337, 0.984149158000946, 0.9850816130638123, 0.9874125719070435, 0.986480176448822, 0.9855477809906006, 0.9869464039802551, 0.9883449673652649, 0.9860140085220337, 0.9860140085220337, 0.9874125719070435, 0.9874125719070435, 0.9874125719070435, 0.9855477809906006, 0.9846153855323792, 0.9827505946159363, 0.986480176448822, 0.9855477809906006, 0.9855477809906006, 0.9855477809906006, 0.9860140085220337, 0.9874125719070435, 0.9855477809906006, 0.9869464039802551, 0.9860140085220337, 0.9855477809906006, 0.9860140085220337, 0.9860140085220337, 0.9869464039802551, 0.9869464039802551, 0.9878787994384766, 0.9874125719070435, 0.986480176448822, 0.9874125719070435, 0.9855477809906006, 0.9883449673652649, 0.9855477809906006, 0.9855477809906006, 0.9846153855323792, 0.9855477809906006, 0.9883449673652649, 0.986480176448822, 0.9855477809906006, 0.986480176448822, 0.9860140085220337, 0.9869464039802551, 0.9878787994384766, 0.9874125719070435, 0.9860140085220337, 0.9860140085220337, 0.9860140085220337, 0.9860140085220337, 0.9855477809906006, 0.9860140085220337, 0.9855477809906006, 0.9860140085220337, 0.9874125719070435, 0.9874125719070435, 0.9855477809906006, 0.9874125719070435, 0.9883449673652649, 0.9855477809906006, 0.986480176448822, 0.9860140085220337, 0.9827505946159363, 0.986480176448822, 0.9860140085220337, 0.9860140085220337, 0.9855477809906006, 0.9860140085220337, 0.9860140085220337, 0.9878787994384766, 0.9860140085220337, 0.9869464039802551, 0.986480176448822, 0.9836829900741577, 0.9860140085220337, 0.9855477809906006, 0.9869464039802551, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.9850816130638123, 0.9855477809906006, 0.9860140085220337, 0.9860140085220337, 0.9860140085220337, 0.9855477809906006, 0.986480176448822, 0.9855477809906006, 0.9855477809906006, 0.9836829900741577, 0.9818181991577148, 0.9855477809906006, 0.9869464039802551, 0.9874125719070435, 0.9869464039802551, 0.9850816130638123, 0.9869464039802551, 0.9860140085220337, 0.9855477809906006, 0.9860140085220337, 0.9860140085220337, 0.9860140085220337, 0.984149158000946, 0.9855477809906006, 0.9874125719070435, 0.9860140085220337, 0.986480176448822, 0.986480176448822, 0.9818181991577148, 0.9818181991577148, 0.9855477809906006, 0.986480176448822, 0.9878787994384766, 0.9855477809906006, 0.9860140085220337, 0.986480176448822, 0.9874125719070435, 0.9860140085220337, 0.986480176448822, 0.9855477809906006, 0.986480176448822, 0.9869464039802551, 0.9846153855323792, 0.9850816130638123, 0.9860140085220337, 0.9878787994384766, 0.9860140085220337, 0.9869464039802551, 0.986480176448822, 0.9869464039802551, 0.9855477809906006, 0.9846153855323792, 0.9874125719070435, 0.9850816130638123, 0.986480176448822, 0.9869464039802551, 0.9850816130638123, 0.9860140085220337, 0.986480176448822, 0.9860140085220337, 0.9855477809906006, 0.984149158000946, 0.9827505946159363, 0.9855477809906006, 0.986480176448822, 0.9855477809906006, 0.9855477809906006, 0.9869464039802551, 0.9827505946159363, 0.9855477809906006, 0.9850816130638123, 0.9874125719070435, 0.9860140085220337, 0.986480176448822, 0.9869464039802551, 0.9869464039802551, 0.9850816130638123, 0.9827505946159363, 0.9850816130638123, 0.9855477809906006, 0.986480176448822, 0.9869464039802551, 0.9855477809906006, 0.9855477809906006, 0.9874125719070435, 0.986480176448822, 0.9850816130638123, 0.9855477809906006, 0.9850816130638123, 0.9850816130638123, 0.9855477809906006, 0.9855477809906006, 0.9850816130638123, 0.9860140085220337, 0.9869464039802551, 0.9860140085220337, 0.9855477809906006, 0.984149158000946, 0.9827505946159363, 0.986480176448822, 0.9869464039802551, 0.9860140085220337, 0.9855477809906006, 0.9874125719070435, 0.9855477809906006, 0.9860140085220337, 0.9822843670845032, 0.9869464039802551, 0.9827505946159363, 0.9855477809906006, 0.9874125719070435, 0.9860140085220337, 0.9878787994384766, 0.9850816130638123, 0.9878787994384766, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9813519716262817, 0.9860140085220337, 0.986480176448822, 0.9855477809906006, 0.9855477809906006, 0.9855477809906006, 0.986480176448822, 0.9855477809906006, 0.9860140085220337, 0.9855477809906006, 0.986480176448822, 0.9869464039802551, 0.9869464039802551, 0.9855477809906006, 0.9855477809906006, 0.9860140085220337, 0.986480176448822, 0.9874125719070435, 0.9874125719070435, 0.9883449673652649, 0.9860140085220337, 0.9860140085220337, 0.986480176448822, 0.9846153855323792, 0.986480176448822, 0.9855477809906006, 0.9860140085220337, 0.9869464039802551, 0.986480176448822, 0.9878787994384766, 0.9855477809906006, 0.9846153855323792, 0.986480176448822, 0.9874125719070435, 0.9836829900741577, 0.986480176448822, 0.9855477809906006, 0.9855477809906006, 0.9860140085220337, 0.9874125719070435, 0.9869464039802551, 0.9855477809906006, 0.9860140085220337, 0.9855477809906006, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.9860140085220337, 0.9874125719070435, 0.9874125719070435, 0.9850816130638123, 0.9860140085220337, 0.9869464039802551, 0.9860140085220337, 0.9855477809906006, 0.9874125719070435, 0.9869464039802551, 0.9883449673652649, 0.9878787994384766, 0.9855477809906006, 0.9855477809906006, 0.986480176448822, 0.9874125719070435, 0.9869464039802551, 0.9883449673652649, 0.9855477809906006, 0.986480176448822, 0.9878787994384766, 0.9874125719070435, 0.9869464039802551, 0.9850816130638123, 0.986480176448822, 0.9874125719070435, 0.986480176448822, 0.9860140085220337, 0.9883449673652649, 0.9869464039802551, 0.9855477809906006, 0.9846153855323792, 0.9874125719070435, 0.9855477809906006, 0.9850816130638123, 0.986480176448822, 0.9874125719070435, 0.9878787994384766, 0.9855477809906006, 0.9869464039802551, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.986480176448822, 0.9878787994384766, 0.986480176448822, 0.9874125719070435, 0.9878787994384766, 0.9855477809906006, 0.9883449673652649, 0.9869464039802551, 0.9855477809906006, 0.9860140085220337, 0.9883449673652649, 0.9850816130638123, 0.9874125719070435, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9869464039802551, 0.9878787994384766, 0.9878787994384766, 0.9855477809906006, 0.9869464039802551, 0.986480176448822, 0.9878787994384766, 0.9883449673652649, 0.9874125719070435, 0.9878787994384766, 0.9878787994384766, 0.9869464039802551, 0.986480176448822, 0.9855477809906006, 0.9860140085220337, 0.986480176448822, 0.9850816130638123, 0.9874125719070435, 0.9878787994384766, 0.9883449673652649, 0.9850816130638123, 0.9874125719070435, 0.9874125719070435, 0.986480176448822, 0.9878787994384766, 0.9794871807098389, 0.9766899943351746, 0.9766899943351746, 0.9808858036994934, 0.9827505946159363, 0.9827505946159363, 0.9804195761680603, 0.9832167625427246, 0.9869464039802551, 0.9874125719070435, 0.9850816130638123, 0.986480176448822, 0.9869464039802551, 0.9869464039802551, 0.9883449673652649, 0.9850816130638123, 0.9850816130638123, 0.9874125719070435, 0.9855477809906006, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9869464039802551, 0.9813519716262817, 0.9832167625427246, 0.9869464039802551, 0.986480176448822, 0.9855477809906006, 0.9874125719070435, 0.9860140085220337, 0.9855477809906006, 0.9855477809906006, 0.9878787994384766, 0.9850816130638123, 0.9869464039802551, 0.9855477809906006, 0.9855477809906006, 0.9860140085220337, 0.9869464039802551, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.986480176448822, 0.9827505946159363, 0.984149158000946, 0.9860140085220337, 0.9883449673652649, 0.986480176448822, 0.986480176448822, 0.9855477809906006, 0.9874125719070435, 0.9869464039802551, 0.9855477809906006, 0.9878787994384766, 0.986480176448822, 0.9850816130638123, 0.9874125719070435, 0.9836829900741577, 0.9827505946159363, 0.9855477809906006, 0.986480176448822, 0.986480176448822, 0.9836829900741577, 0.9860140085220337, 0.9869464039802551, 0.9874125719070435, 0.9878787994384766, 0.9855477809906006, 0.9869464039802551, 0.9869464039802551, 0.988811194896698, 0.9860140085220337, 0.9874125719070435, 0.9869464039802551, 0.9860140085220337, 0.9850816130638123, 0.986480176448822, 0.9878787994384766, 0.9878787994384766, 0.9883449673652649, 0.9855477809906006, 0.9878787994384766, 0.986480176448822, 0.9874125719070435, 0.9869464039802551, 0.9869464039802551, 0.9878787994384766, 0.9855477809906006, 0.988811194896698, 0.9878787994384766, 0.9883449673652649, 0.9874125719070435, 0.986480176448822, 0.9860140085220337, 0.9850816130638123, 0.9860140085220337, 0.9846153855323792, 0.986480176448822, 0.9846153855323792, 0.9869464039802551, 0.986480176448822, 0.9878787994384766, 0.9869464039802551, 0.9878787994384766, 0.9883449673652649, 0.9855477809906006, 0.9878787994384766, 0.9850816130638123, 0.9874125719070435, 0.9855477809906006, 0.9860140085220337, 0.9855477809906006, 0.9855477809906006, 0.986480176448822, 0.9855477809906006, 0.9869464039802551, 0.9855477809906006, 0.986480176448822, 0.988811194896698, 0.988811194896698, 0.9855477809906006, 0.986480176448822, 0.9883449673652649, 0.9883449673652649, 0.9860140085220337, 0.9874125719070435, 0.986480176448822, 0.9850816130638123, 0.9883449673652649, 0.9869464039802551, 0.9860140085220337, 0.986480176448822, 0.9860140085220337, 0.9850816130638123, 0.9855477809906006, 0.9869464039802551, 0.986480176448822, 0.984149158000946, 0.9855477809906006, 0.9855477809906006, 0.9878787994384766, 0.9883449673652649, 0.988811194896698, 0.9832167625427246, 0.9822843670845032, 0.9846153855323792, 0.9878787994384766, 0.9869464039802551, 0.988811194896698, 0.986480176448822, 0.9878787994384766, 0.9883449673652649, 0.9874125719070435, 0.988811194896698, 0.9855477809906006, 0.9855477809906006, 0.986480176448822, 0.9874125719070435, 0.9827505946159363, 0.9818181991577148, 0.9850816130638123, 0.9878787994384766, 0.9883449673652649, 0.9883449673652649, 0.9883449673652649, 0.9846153855323792, 0.984149158000946, 0.9855477809906006, 0.9883449673652649, 0.9850816130638123, 0.9869464039802551, 0.986480176448822, 0.9874125719070435, 0.9878787994384766, 0.9874125719070435, 0.9883449673652649, 0.9878787994384766, 0.988811194896698, 0.9855477809906006, 0.9818181991577148, 0.986480176448822, 0.9850816130638123, 0.9874125719070435, 0.9874125719070435, 0.9878787994384766, 0.9878787994384766, 0.9883449673652649, 0.9878787994384766, 0.986480176448822, 0.9878787994384766, 0.9878787994384766, 0.9855477809906006, 0.9850816130638123, 0.9794871807098389, 0.9832167625427246, 0.9874125719070435, 0.9869464039802551, 0.9883449673652649, 0.984149158000946, 0.9869464039802551, 0.9850816130638123, 0.9874125719070435, 0.9874125719070435, 0.9846153855323792, 0.9874125719070435, 0.9878787994384766, 0.9855477809906006, 0.9846153855323792, 0.9874125719070435, 0.9878787994384766, 0.9850816130638123, 0.9846153855323792, 0.9855477809906006, 0.9874125719070435, 0.9869464039802551, 0.984149158000946, 0.9846153855323792, 0.9855477809906006, 0.9874125719070435, 0.9874125719070435, 0.9860140085220337, 0.9869464039802551, 0.9874125719070435, 0.9850816130638123, 0.9850816130638123, 0.984149158000946, 0.984149158000946, 0.9832167625427246, 0.9860140085220337, 0.9878787994384766, 0.9878787994384766, 0.9883449673652649, 0.9878787994384766, 0.9874125719070435, 0.9878787994384766, 0.9874125719070435, 0.984149158000946, 0.9874125719070435, 0.9878787994384766, 0.984149158000946, 0.9850816130638123, 0.9869464039802551, 0.988811194896698, 0.9878787994384766, 0.9855477809906006, 0.9874125719070435, 0.986480176448822, 0.9878787994384766, 0.9869464039802551, 0.9883449673652649, 0.9878787994384766, 0.9869464039802551, 0.9874125719070435, 0.9869464039802551, 0.9860140085220337, 0.9878787994384766, 0.9860140085220337, 0.9883449673652649, 0.9860140085220337, 0.9860140085220337, 0.9878787994384766, 0.9874125719070435, 0.9869464039802551, 0.9878787994384766, 0.9869464039802551, 0.9883449673652649, 0.9878787994384766, 0.9850816130638123, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9878787994384766, 0.9869464039802551, 0.9878787994384766, 0.9860140085220337, 0.9878787994384766, 0.9869464039802551, 0.9869464039802551, 0.988811194896698, 0.9860140085220337, 0.9855477809906006, 0.9878787994384766, 0.9883449673652649, 0.9874125719070435, 0.9860140085220337, 0.9878787994384766, 0.9855477809906006, 0.9855477809906006, 0.986480176448822, 0.9892773628234863, 0.9878787994384766, 0.986480176448822, 0.9878787994384766, 0.9832167625427246, 0.9850816130638123, 0.986480176448822, 0.9878787994384766, 0.984149158000946, 0.9874125719070435, 0.986480176448822, 0.9878787994384766, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9883449673652649, 0.9883449673652649, 0.9846153855323792, 0.9818181991577148, 0.9836829900741577, 0.9878787994384766, 0.9883449673652649, 0.9878787994384766, 0.9869464039802551, 0.9878787994384766, 0.9878787994384766, 0.9878787994384766, 0.9860140085220337, 0.984149158000946, 0.9850816130638123, 0.986480176448822, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9860140085220337, 0.9855477809906006, 0.9874125719070435, 0.9883449673652649, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9883449673652649, 0.9860140085220337, 0.986480176448822, 0.9836829900741577, 0.9846153855323792, 0.9869464039802551, 0.9874125719070435, 0.9869464039802551, 0.9883449673652649, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.9874125719070435, 0.9878787994384766, 0.9883449673652649, 0.9883449673652649, 0.9883449673652649, 0.9860140085220337, 0.9874125719070435, 0.9874125719070435, 0.986480176448822, 0.986480176448822, 0.9836829900741577, 0.9878787994384766, 0.986480176448822, 0.986480176448822, 0.986480176448822, 0.9878787994384766, 0.9869464039802551, 0.9874125719070435, 0.988811194896698, 0.9883449673652649, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9874125719070435, 0.9883449673652649, 0.9883449673652649, 0.9860140085220337, 0.9883449673652649, 0.9883449673652649, 0.9869464039802551, 0.9855477809906006, 0.9850816130638123, 0.9818181991577148, 0.9855477809906006, 0.9878787994384766, 0.9850816130638123, 0.9869464039802551, 0.9878787994384766, 0.9869464039802551, 0.9874125719070435, 0.9874125719070435, 0.9874125719070435, 0.9827505946159363, 0.9869464039802551, 0.986480176448822, 0.986480176448822, 0.9878787994384766, 0.9855477809906006, 0.9874125719070435, 0.9860140085220337, 0.9855477809906006, 0.9878787994384766, 0.9874125719070435, 0.9846153855323792, 0.9846153855323792, 0.9850816130638123, 0.9855477809906006, 0.988811194896698, 0.9855477809906006, 0.9804195761680603, 0.9846153855323792, 0.9878787994384766, 0.9860140085220337, 0.986480176448822, 0.988811194896698, 0.9846153855323792, 0.9855477809906006, 0.9883449673652649, 0.988811194896698, 0.9878787994384766, 0.9860140085220337, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9878787994384766, 0.9883449673652649, 0.9855477809906006, 0.9878787994384766, 0.9883449673652649, 0.9878787994384766, 0.9822843670845032, 0.9860140085220337, 0.986480176448822, 0.988811194896698, 0.9883449673652649, 0.986480176448822, 0.984149158000946, 0.9860140085220337, 0.9860140085220337, 0.988811194896698, 0.9883449673652649, 0.9878787994384766, 0.9808858036994934, 0.9794871807098389, 0.9869464039802551, 0.9892773628234863, 0.9874125719070435, 0.986480176448822, 0.9832167625427246, 0.9855477809906006, 0.9878787994384766, 0.988811194896698, 0.9874125719070435, 0.9878787994384766, 0.988811194896698, 0.9878787994384766, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.9878787994384766, 0.9883449673652649, 0.9878787994384766, 0.984149158000946, 0.9855477809906006, 0.9883449673652649, 0.9892773628234863, 0.984149158000946, 0.9836829900741577, 0.986480176448822, 0.9892773628234863, 0.9874125719070435, 0.9883449673652649, 0.9874125719070435, 0.9874125719070435, 0.9878787994384766, 0.9892773628234863, 0.9878787994384766, 0.986480176448822, 0.9808858036994934, 0.977622389793396, 0.9883449673652649, 0.988811194896698, 0.9874125719070435, 0.9878787994384766, 0.9883449673652649, 0.9874125719070435, 0.9804195761680603, 0.9827505946159363, 0.986480176448822, 0.986480176448822, 0.9878787994384766, 0.9878787994384766, 0.9883449673652649, 0.9878787994384766, 0.9874125719070435, 0.9883449673652649, 0.9883449673652649, 0.9850816130638123, 0.9855477809906006, 0.9883449673652649, 0.9878787994384766, 0.9846153855323792, 0.9846153855323792, 0.986480176448822, 0.986480176448822, 0.9883449673652649, 0.9874125719070435, 0.9869464039802551, 0.9883449673652649, 0.988811194896698, 0.9874125719070435, 0.9878787994384766, 0.9874125719070435, 0.9855477809906006, 0.9804195761680603, 0.9892773628234863, 0.9860140085220337, 0.9878787994384766, 0.9850816130638123, 0.9869464039802551, 0.9883449673652649, 0.9874125719070435, 0.9804195761680603, 0.9832167625427246, 0.986480176448822, 0.9878787994384766, 0.9883449673652649, 0.9883449673652649, 0.9878787994384766, 0.9869464039802551, 0.9836829900741577, 0.9846153855323792, 0.9883449673652649, 0.988811194896698, 0.9869464039802551, 0.9874125719070435, 0.9855477809906006, 0.9869464039802551, 0.9878787994384766, 0.9869464039802551, 0.9827505946159363, 0.988811194896698, 0.9850816130638123, 0.988811194896698, 0.9878787994384766, 0.9860140085220337, 0.9883449673652649, 0.9822843670845032, 0.9846153855323792, 0.9860140085220337, 0.9813519716262817, 0.9874125719070435, 0.9869464039802551, 0.9869464039802551, 0.988811194896698, 0.9883449673652649, 0.9878787994384766, 0.9883449673652649, 0.9883449673652649, 0.988811194896698, 0.9869464039802551, 0.9818181991577148, 0.9897435903549194, 0.9860140085220337, 0.9883449673652649, 0.9892773628234863, 0.988811194896698, 0.9850816130638123, 0.9892773628234863, 0.986480176448822, 0.9846153855323792, 0.9836829900741577, 0.984149158000946, 0.9878787994384766, 0.9878787994384766, 0.9855477809906006, 0.9878787994384766, 0.9860140085220337, 0.988811194896698, 0.9874125719070435, 0.9827505946159363, 0.9874125719070435, 0.9878787994384766, 0.9878787994384766, 0.9832167625427246, 0.9874125719070435, 0.988811194896698, 0.988811194896698, 0.979953408241272, 0.9785547852516174, 0.9883449673652649, 0.986480176448822, 0.9874125719070435, 0.9892773628234863, 0.9874125719070435, 0.988811194896698, 0.986480176448822, 0.9883449673652649, 0.9883449673652649, 0.9892773628234863, 0.9878787994384766, 0.9874125719070435, 0.9855477809906006, 0.9883449673652649, 0.9869464039802551, 0.9892773628234863, 0.9878787994384766, 0.9878787994384766, 0.9855477809906006, 0.9860140085220337, 0.9878787994384766, 0.9874125719070435, 0.9878787994384766, 0.9883449673652649, 0.988811194896698, 0.9878787994384766, 0.9836829900741577, 0.984149158000946, 0.9813519716262817, 0.9813519716262817, 0.9860140085220337, 0.9883449673652649, 0.9874125719070435, 0.9883449673652649, 0.986480176448822, 0.9878787994384766, 0.9846153855323792, 0.9878787994384766, 0.9892773628234863, 0.988811194896698, 0.9874125719070435, 0.984149158000946, 0.988811194896698, 0.9878787994384766, 0.9855477809906006, 0.9883449673652649, 0.9892773628234863, 0.9855477809906006, 0.988811194896698, 0.9883449673652649, 0.9850816130638123, 0.9878787994384766, 0.988811194896698, 0.9878787994384766, 0.9878787994384766, 0.9878787994384766, 0.9883449673652649, 0.988811194896698, 0.9878787994384766, 0.9883449673652649, 0.986480176448822, 0.9850816130638123, 0.9832167625427246, 0.9883449673652649, 0.988811194896698, 0.9883449673652649, 0.9897435903549194, 0.9878787994384766, 0.988811194896698, 0.9878787994384766, 0.988811194896698, 0.9883449673652649, 0.9869464039802551, 0.9855477809906006, 0.986480176448822, 0.9822843670845032, 0.9883449673652649, 0.9878787994384766, 0.9892773628234863, 0.9869464039802551, 0.9846153855323792, 0.9883449673652649, 0.9878787994384766, 0.9860140085220337, 0.9874125719070435, 0.9883449673652649, 0.9897435903549194, 0.9874125719070435, 0.9878787994384766, 0.9860140085220337, 0.9874125719070435, 0.9878787994384766, 0.9860140085220337, 0.9874125719070435, 0.9892773628234863, 0.9878787994384766, 0.9883449673652649, 0.988811194896698, 0.988811194896698, 0.986480176448822, 0.986480176448822, 0.9892773628234863, 0.988811194896698, 0.9869464039802551, 0.9822843670845032, 0.9874125719070435, 0.9836829900741577, 0.9874125719070435, 0.9878787994384766, 0.9878787994384766, 0.9874125719070435, 0.988811194896698, 0.9878787994384766, 0.9878787994384766, 0.9874125719070435, 0.9883449673652649, 0.9892773628234863, 0.9892773628234863, 0.9869464039802551, 0.9869464039802551, 0.988811194896698, 0.9892773628234863, 0.9878787994384766, 0.9874125719070435, 0.9883449673652649, 0.9869464039802551, 0.9869464039802551, 0.9883449673652649, 0.9878787994384766, 0.9850816130638123, 0.9883449673652649, 0.9874125719070435, 0.9883449673652649, 0.9860140085220337, 0.9846153855323792, 0.9813519716262817, 0.984149158000946, 0.9855477809906006, 0.9874125719070435, 0.9883449673652649, 0.9874125719070435, 0.9878787994384766, 0.9874125719070435, 0.9883449673652649, 0.9878787994384766, 0.9883449673652649, 0.9892773628234863, 0.988811194896698, 0.9869464039802551, 0.9883449673652649, 0.9878787994384766, 0.9883449673652649, 0.9874125719070435, 0.9883449673652649, 0.988811194896698, 0.9892773628234863, 0.9869464039802551, 0.9874125719070435, 0.988811194896698, 0.988811194896698, 0.9860140085220337, 0.9869464039802551, 0.986480176448822, 0.9869464039802551, 0.9836829900741577, 0.9869464039802551, 0.988811194896698, 0.9860140085220337, 0.988811194896698, 0.988811194896698, 0.9883449673652649, 0.9878787994384766, 0.9827505946159363, 0.9832167625427246, 0.9846153855323792, 0.9874125719070435, 0.9878787994384766, 0.9883449673652649, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9883449673652649, 0.9869464039802551, 0.9874125719070435, 0.988811194896698, 0.9883449673652649, 0.9855477809906006, 0.9832167625427246, 0.9860140085220337, 0.9883449673652649, 0.9869464039802551, 0.988811194896698, 0.9883449673652649, 0.9869464039802551, 0.9822843670845032, 0.9808858036994934, 0.984149158000946, 0.9874125719070435, 0.9874125719070435, 0.9897435903549194, 0.9883449673652649, 0.986480176448822, 0.9883449673652649, 0.9869464039802551, 0.988811194896698, 0.9874125719070435, 0.9836829900741577, 0.9869464039802551, 0.9892773628234863, 0.9878787994384766, 0.988811194896698, 0.9883449673652649, 0.9892773628234863, 0.9897435903549194, 0.988811194896698, 0.9874125719070435, 0.988811194896698, 0.988811194896698, 0.9883449673652649, 0.9892773628234863, 0.9878787994384766, 0.9892773628234863, 0.988811194896698, 0.986480176448822, 0.9855477809906006, 0.9892773628234863, 0.988811194896698, 0.9855477809906006, 0.9883449673652649, 0.986480176448822, 0.988811194896698, 0.9878787994384766, 0.9878787994384766, 0.9855477809906006, 0.9860140085220337, 0.984149158000946, 0.986480176448822, 0.9883449673652649, 0.9892773628234863, 0.9897435903549194, 0.9883449673652649, 0.986480176448822, 0.988811194896698, 0.9878787994384766, 0.9860140085220337, 0.988811194896698, 0.9855477809906006, 0.9878787994384766, 0.9869464039802551, 0.9855477809906006, 0.9874125719070435, 0.9846153855323792, 0.9874125719070435, 0.9878787994384766, 0.9850816130638123, 0.9827505946159363, 0.9855477809906006, 0.9883449673652649, 0.988811194896698, 0.9878787994384766, 0.9860140085220337, 0.9860140085220337, 0.9878787994384766, 0.9878787994384766, 0.9850816130638123, 0.9892773628234863, 0.9883449673652649, 0.9883449673652649, 0.9892773628234863, 0.9883449673652649, 0.9878787994384766, 0.988811194896698, 0.9869464039802551, 0.9869464039802551, 0.9874125719070435, 0.988811194896698, 0.9892773628234863, 0.9892773628234863, 0.9874125719070435, 0.9874125719070435, 0.986480176448822, 0.9846153855323792, 0.9874125719070435, 0.988811194896698, 0.9874125719070435, 0.9855477809906006, 0.9869464039802551, 0.988811194896698, 0.988811194896698, 0.9874125719070435, 0.9883449673652649, 0.9883449673652649, 0.9883449673652649, 0.9883449673652649, 0.988811194896698, 0.988811194896698, 0.9878787994384766, 0.9878787994384766, 0.9883449673652649, 0.988811194896698, 0.9869464039802551, 0.9878787994384766, 0.9883449673652649, 0.9855477809906006, 0.9878787994384766, 0.9883449673652649, 0.9883449673652649, 0.988811194896698, 0.9869464039802551, 0.9874125719070435, 0.9860140085220337, 0.9850816130638123, 0.986480176448822, 0.9878787994384766, 0.9878787994384766, 0.984149158000946, 0.9855477809906006, 0.9883449673652649, 0.9892773628234863, 0.9836829900741577, 0.9818181991577148, 0.984149158000946, 0.988811194896698, 0.9883449673652649, 0.9878787994384766, 0.9883449673652649, 0.9883449673652649, 0.9878787994384766, 0.986480176448822, 0.9878787994384766, 0.9869464039802551, 0.988811194896698, 0.9892773628234863, 0.9892773628234863, 0.9878787994384766, 0.9883449673652649, 0.9874125719070435, 0.986480176448822, 0.986480176448822, 0.9869464039802551, 0.988811194896698, 0.9874125719070435, 0.9878787994384766, 0.9860140085220337, 0.9883449673652649, 0.9869464039802551, 0.9869464039802551, 0.986480176448822, 0.9850816130638123, 0.9832167625427246, 0.986480176448822, 0.9883449673652649, 0.9869464039802551, 0.9869464039802551, 0.988811194896698, 0.9883449673652649, 0.9846153855323792, 0.9808858036994934, 0.9836829900741577, 0.9878787994384766, 0.986480176448822, 0.9883449673652649, 0.9883449673652649, 0.988811194896698, 0.9883449673652649, 0.986480176448822, 0.9883449673652649, 0.9878787994384766, 0.9869464039802551, 0.9869464039802551, 0.9827505946159363, 0.9850816130638123, 0.9869464039802551, 0.9892773628234863, 0.9878787994384766, 0.9869464039802551, 0.9878787994384766, 0.9892773628234863, 0.9892773628234863, 0.9883449673652649, 0.988811194896698, 0.9878787994384766, 0.9869464039802551, 0.9860140085220337, 0.9860140085220337, 0.988811194896698, 0.9869464039802551, 0.9883449673652649, 0.988811194896698, 0.9878787994384766, 0.988811194896698, 0.9883449673652649, 0.9860140085220337, 0.988811194896698, 0.988811194896698, 0.9883449673652649, 0.9860140085220337, 0.9878787994384766, 0.9869464039802551, 0.9878787994384766, 0.9892773628234863, 0.9874125719070435, 0.9892773628234863, 0.988811194896698, 0.9869464039802551, 0.9883449673652649, 0.9874125719070435, 0.9822843670845032, 0.9846153855323792, 0.9874125719070435, 0.9883449673652649, 0.9892773628234863, 0.9883449673652649, 0.9883449673652649, 0.9869464039802551, 0.9850816130638123, 0.9850816130638123, 0.9860140085220337, 0.9822843670845032, 0.9771561622619629, 0.979953408241272, 0.9832167625427246, 0.9850816130638123, 0.9874125719070435, 0.9883449673652649, 0.988811194896698, 0.9878787994384766, 0.9902098178863525, 0.988811194896698, 0.9850816130638123, 0.9855477809906006, 0.988811194896698, 0.9883449673652649, 0.9874125719070435, 0.9878787994384766, 0.9892773628234863, 0.9869464039802551, 0.9883449673652649, 0.9827505946159363, 0.9860140085220337, 0.986480176448822, 0.9874125719070435, 0.988811194896698, 0.986480176448822, 0.9883449673652649, 0.9892773628234863, 0.988811194896698, 0.9860140085220337, 0.9878787994384766, 0.9878787994384766, 0.9878787994384766, 0.9878787994384766, 0.9883449673652649, 0.9883449673652649, 0.9869464039802551, 0.9855477809906006, 0.9878787994384766, 0.9883449673652649, 0.9878787994384766, 0.986480176448822, 0.9878787994384766, 0.9878787994384766, 0.9892773628234863, 0.9883449673652649, 0.9883449673652649, 0.9869464039802551, 0.986480176448822, 0.9892773628234863, 0.9892773628234863, 0.988811194896698, 0.9874125719070435, 0.9855477809906006, 0.9860140085220337, 0.9869464039802551, 0.988811194896698, 0.9874125719070435, 0.9883449673652649, 0.988811194896698, 0.988811194896698, 0.986480176448822, 0.9883449673652649, 0.9883449673652649, 0.9846153855323792, 0.9846153855323792, 0.9878787994384766, 0.9869464039802551, 0.9897435903549194, 0.988811194896698, 0.986480176448822, 0.988811194896698, 0.9869464039802551, 0.9860140085220337, 0.9869464039802551, 0.986480176448822, 0.986480176448822, 0.9832167625427246, 0.9850816130638123, 0.9883449673652649, 0.9860140085220337, 0.9822843670845032, 0.984149158000946, 0.9832167625427246, 0.986480176448822, 0.9897435903549194, 0.988811194896698, 0.9869464039802551, 0.9878787994384766, 0.988811194896698, 0.9892773628234863, 0.988811194896698, 0.9846153855323792, 0.9874125719070435, 0.9883449673652649, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9878787994384766, 0.988811194896698, 0.988811194896698, 0.9878787994384766, 0.986480176448822, 0.9892773628234863, 0.9855477809906006, 0.9818181991577148, 0.988811194896698, 0.9869464039802551, 0.9869464039802551, 0.9860140085220337, 0.9869464039802551, 0.9883449673652649, 0.9869464039802551, 0.9855477809906006, 0.9818181991577148, 0.986480176448822, 0.9883449673652649, 0.9869464039802551, 0.9869464039802551, 0.9883449673652649, 0.9883449673652649, 0.9902098178863525, 0.9878787994384766, 0.9874125719070435, 0.9850816130638123, 0.9883449673652649, 0.9869464039802551, 0.9883449673652649, 0.986480176448822, 0.988811194896698, 0.9878787994384766, 0.9860140085220337, 0.9883449673652649, 0.9878787994384766, 0.9869464039802551, 0.9878787994384766, 0.988811194896698, 0.988811194896698, 0.9883449673652649, 0.9902098178863525, 0.9883449673652649, 0.9874125719070435, 0.988811194896698, 0.9883449673652649, 0.9874125719070435, 0.9892773628234863, 0.9883449673652649, 0.9883449673652649, 0.9878787994384766, 0.9855477809906006, 0.986480176448822, 0.9883449673652649, 0.988811194896698, 0.9860140085220337, 0.9878787994384766, 0.9883449673652649, 0.9883449673652649, 0.986480176448822, 0.9878787994384766, 0.9892773628234863, 0.9869464039802551, 0.9883449673652649, 0.9832167625427246, 0.9869464039802551, 0.9869464039802551, 0.9878787994384766, 0.9883449673652649, 0.988811194896698, 0.9878787994384766, 0.9869464039802551, 0.9874125719070435, 0.9874125719070435, 0.988811194896698, 0.9869464039802551, 0.9883449673652649, 0.9836829900741577, 0.9818181991577148, 0.9883449673652649, 0.9883449673652649, 0.9878787994384766, 0.9874125719070435, 0.9883449673652649, 0.9869464039802551, 0.9874125719070435, 0.988811194896698, 0.9878787994384766, 0.988811194896698, 0.9836829900741577, 0.9878787994384766, 0.988811194896698, 0.9855477809906006, 0.9878787994384766, 0.9860140085220337, 0.9860140085220337, 0.9878787994384766, 0.9874125719070435, 0.986480176448822, 0.988811194896698, 0.9860140085220337, 0.9878787994384766, 0.9897435903549194, 0.9892773628234863, 0.988811194896698, 0.9878787994384766, 0.9883449673652649, 0.9883449673652649, 0.988811194896698, 0.9883449673652649, 0.984149158000946, 0.986480176448822, 0.9897435903549194, 0.9892773628234863, 0.986480176448822, 0.9808858036994934, 0.9860140085220337, 0.9869464039802551, 0.988811194896698, 0.9883449673652649, 0.988811194896698, 0.9878787994384766, 0.988811194896698, 0.9883449673652649, 0.988811194896698, 0.9883449673652649, 0.9874125719070435, 0.9883449673652649, 0.9878787994384766, 0.9883449673652649, 0.986480176448822, 0.9846153855323792, 0.9850816130638123, 0.9860140085220337, 0.9878787994384766, 0.9869464039802551, 0.9883449673652649, 0.9874125719070435, 0.9883449673652649, 0.988811194896698, 0.988811194896698, 0.9892773628234863, 0.9836829900741577, 0.984149158000946, 0.9883449673652649, 0.9878787994384766, 0.9897435903549194, 0.9869464039802551, 0.9860140085220337, 0.9878787994384766, 0.9902098178863525, 0.9850816130638123, 0.9874125719070435, 0.9892773628234863, 0.9878787994384766, 0.9874125719070435, 0.9883449673652649, 0.9827505946159363, 0.9878787994384766, 0.9883449673652649, 0.9827505946159363, 0.984149158000946, 0.9869464039802551, 0.9883449673652649, 0.9878787994384766, 0.9855477809906006, 0.9883449673652649, 0.9874125719070435, 0.9869464039802551, 0.9874125719070435, 0.9897435903549194, 0.988811194896698, 0.9846153855323792, 0.9813519716262817, 0.984149158000946, 0.988811194896698, 0.9869464039802551, 0.9883449673652649, 0.9878787994384766, 0.9874125719070435, 0.9832167625427246, 0.9855477809906006, 0.9846153855323792, 0.988811194896698, 0.988811194896698, 0.9855477809906006, 0.9860140085220337, 0.9850816130638123, 0.9818181991577148, 0.9874125719070435, 0.9878787994384766, 0.9869464039802551, 0.988811194896698, 0.9869464039802551, 0.9855477809906006, 0.9869464039802551, 0.9860140085220337, 0.9874125719070435, 0.9892773628234863, 0.9874125719070435, 0.988811194896698, 0.9827505946159363, 0.9855477809906006, 0.988811194896698, 0.986480176448822, 0.9850816130638123, 0.988811194896698, 0.9869464039802551, 0.986480176448822, 0.988811194896698, 0.9869464039802551, 0.9869464039802551, 0.9860140085220337, 0.9850816130638123, 0.9860140085220337, 0.9869464039802551, 0.9878787994384766, 0.9883449673652649, 0.9869464039802551, 0.9869464039802551, 0.986480176448822, 0.984149158000946, 0.984149158000946, 0.9883449673652649, 0.986480176448822, 0.9883449673652649, 0.9869464039802551, 0.988811194896698, 0.9874125719070435, 0.9860140085220337, 0.9846153855323792, 0.9874125719070435, 0.9883449673652649, 0.9874125719070435, 0.9869464039802551, 0.9878787994384766, 0.988811194896698, 0.9846153855323792, 0.9855477809906006, 0.9878787994384766, 0.9860140085220337, 0.988811194896698, 0.9855477809906006, 0.9874125719070435, 0.9878787994384766, 0.9869464039802551, 0.9860140085220337, 0.9836829900741577, 0.9855477809906006, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9855477809906006, 0.984149158000946, 0.9846153855323792, 0.986480176448822, 0.9878787994384766, 0.9855477809906006, 0.9860140085220337, 0.9869464039802551, 0.986480176448822, 0.9827505946159363, 0.988811194896698, 0.9892773628234863, 0.9836829900741577, 0.984149158000946, 0.9878787994384766, 0.9878787994384766, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9878787994384766, 0.9892773628234863, 0.9860140085220337, 0.9850816130638123, 0.9878787994384766, 0.986480176448822, 0.9883449673652649, 0.9850816130638123, 0.9860140085220337, 0.9850816130638123, 0.9878787994384766, 0.9874125719070435, 0.9869464039802551, 0.9883449673652649, 0.9883449673652649, 0.9874125719070435, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.9869464039802551, 0.9869464039802551, 0.9846153855323792, 0.984149158000946, 0.9822843670845032, 0.9869464039802551, 0.9878787994384766, 0.9878787994384766, 0.9836829900741577, 0.9846153855323792, 0.9855477809906006, 0.9883449673652649, 0.9878787994384766, 0.986480176448822, 0.9850816130638123, 0.986480176448822, 0.9883449673652649, 0.986480176448822, 0.9892773628234863, 0.988811194896698, 0.986480176448822, 0.9878787994384766, 0.9869464039802551, 0.9874125719070435, 0.9869464039802551, 0.9860140085220337, 0.9883449673652649, 0.9874125719070435, 0.986480176448822, 0.986480176448822, 0.986480176448822, 0.9808858036994934, 0.9827505946159363, 0.9860140085220337, 0.9874125719070435, 0.9818181991577148, 0.9850816130638123, 0.986480176448822, 0.9883449673652649, 0.9846153855323792, 0.9878787994384766, 0.9874125719070435, 0.9869464039802551, 0.9878787994384766, 0.9860140085220337, 0.9855477809906006, 0.9878787994384766, 0.9874125719070435, 0.9874125719070435, 0.9883449673652649, 0.9855477809906006, 0.9855477809906006, 0.9874125719070435, 0.9892773628234863, 0.9850816130638123, 0.9874125719070435, 0.9860140085220337, 0.9855477809906006, 0.9850816130638123, 0.9878787994384766, 0.986480176448822, 0.9860140085220337, 0.984149158000946, 0.9874125719070435, 0.9874125719070435, 0.984149158000946, 0.9869464039802551, 0.9860140085220337, 0.9874125719070435, 0.9850816130638123, 0.977622389793396, 0.9701631665229797, 0.9846153855323792, 0.9892773628234863, 0.9855477809906006, 0.988811194896698, 0.9822843670845032, 0.9836829900741577, 0.986480176448822, 0.9874125719070435, 0.9874125719070435, 0.984149158000946, 0.9855477809906006, 0.9878787994384766, 0.9855477809906006, 0.9883449673652649, 0.984149158000946, 0.9846153855323792, 0.9878787994384766, 0.9869464039802551, 0.986480176448822, 0.9878787994384766, 0.9846153855323792, 0.9846153855323792, 0.9883449673652649, 0.986480176448822, 0.9874125719070435, 0.9869464039802551, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9878787994384766, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.984149158000946, 0.9855477809906006, 0.9860140085220337, 0.986480176448822, 0.9860140085220337, 0.9846153855323792, 0.986480176448822, 0.9883449673652649, 0.9869464039802551, 0.9874125719070435, 0.9869464039802551, 0.986480176448822, 0.986480176448822, 0.9850816130638123, 0.9878787994384766, 0.9846153855323792, 0.9878787994384766, 0.9878787994384766, 0.9860140085220337, 0.984149158000946, 0.9878787994384766, 0.9855477809906006, 0.9878787994384766, 0.9878787994384766, 0.9836829900741577, 0.9869464039802551, 0.988811194896698, 0.9883449673652649, 0.9855477809906006, 0.9878787994384766, 0.984149158000946, 0.9869464039802551, 0.9869464039802551, 0.986480176448822, 0.9874125719070435, 0.9874125719070435, 0.9832167625427246, 0.984149158000946, 0.9869464039802551, 0.9869464039802551, 0.9860140085220337, 0.9850816130638123, 0.986480176448822, 0.9846153855323792, 0.9869464039802551, 0.9860140085220337, 0.9883449673652649, 0.9874125719070435, 0.9855477809906006, 0.9874125719070435, 0.9878787994384766, 0.9869464039802551, 0.9869464039802551, 0.9878787994384766, 0.9846153855323792, 0.9869464039802551, 0.9822843670845032, 0.984149158000946, 0.9874125719070435, 0.9883449673652649, 0.9874125719070435, 0.9860140085220337, 0.986480176448822, 0.9869464039802551, 0.9850816130638123, 0.988811194896698, 0.9855477809906006, 0.9869464039802551, 0.9850816130638123, 0.984149158000946, 0.9836829900741577, 0.9855477809906006, 0.988811194896698, 0.986480176448822, 0.9869464039802551, 0.9869464039802551, 0.9860140085220337, 0.9874125719070435, 0.9860140085220337, 0.9869464039802551, 0.9878787994384766, 0.9860140085220337, 0.986480176448822, 0.9846153855323792, 0.9846153855323792, 0.986480176448822, 0.986480176448822, 0.9869464039802551, 0.9850816130638123, 0.9874125719070435, 0.9874125719070435, 0.9846153855323792, 0.9846153855323792, 0.9869464039802551, 0.9874125719070435, 0.9855477809906006, 0.9836829900741577, 0.9869464039802551, 0.9869464039802551, 0.9869464039802551, 0.9855477809906006, 0.9869464039802551, 0.9878787994384766, 0.9874125719070435, 0.9883449673652649, 0.9855477809906006, 0.9883449673652649, 0.9878787994384766, 0.9869464039802551, 0.986480176448822, 0.9846153855323792, 0.9874125719070435, 0.9874125719070435, 0.9874125719070435, 0.9860140085220337, 0.9874125719070435, 0.9869464039802551, 0.988811194896698, 0.984149158000946, 0.9860140085220337, 0.986480176448822, 0.9883449673652649, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.9860140085220337, 0.984149158000946, 0.9860140085220337, 0.9846153855323792, 0.9874125719070435, 0.9878787994384766, 0.9869464039802551, 0.988811194896698, 0.9846153855323792, 0.9860140085220337, 0.9846153855323792, 0.9846153855323792, 0.9883449673652649, 0.9874125719070435, 0.9869464039802551, 0.9878787994384766, 0.9832167625427246, 0.9855477809906006, 0.9883449673652649, 0.984149158000946, 0.9855477809906006, 0.984149158000946, 0.986480176448822, 0.9855477809906006, 0.9874125719070435, 0.988811194896698, 0.9878787994384766, 0.984149158000946, 0.9878787994384766, 0.9850816130638123, 0.9855477809906006, 0.986480176448822, 0.9850816130638123, 0.9860140085220337, 0.9878787994384766, 0.9869464039802551, 0.9860140085220337, 0.984149158000946, 0.9874125719070435, 0.9869464039802551, 0.9846153855323792, 0.984149158000946, 0.9878787994384766, 0.9869464039802551, 0.9836829900741577, 0.9850816130638123, 0.9855477809906006, 0.9869464039802551, 0.9878787994384766, 0.988811194896698, 0.9860140085220337, 0.986480176448822, 0.9860140085220337, 0.988811194896698, 0.9869464039802551, 0.9874125719070435, 0.9874125719070435, 0.9878787994384766, 0.9874125719070435, 0.9860140085220337, 0.9878787994384766, 0.9878787994384766, 0.9850816130638123, 0.9874125719070435, 0.9874125719070435, 0.984149158000946, 0.9855477809906006, 0.9874125719070435, 0.9855477809906006, 0.9860140085220337, 0.9836829900741577, 0.986480176448822, 0.9874125719070435, 0.9878787994384766, 0.9860140085220337, 0.9874125719070435, 0.9846153855323792, 0.9874125719070435, 0.988811194896698, 0.9860140085220337, 0.9874125719070435, 0.9855477809906006, 0.9869464039802551, 0.9850816130638123, 0.9808858036994934, 0.9850816130638123, 0.9860140085220337, 0.984149158000946, 0.9883449673652649, 0.9869464039802551, 0.9878787994384766, 0.9874125719070435, 0.986480176448822, 0.9846153855323792, 0.9874125719070435, 0.9874125719070435, 0.9869464039802551, 0.9874125719070435, 0.9850816130638123, 0.984149158000946, 0.9883449673652649, 0.9878787994384766, 0.9869464039802551, 0.986480176448822, 0.986480176448822, 0.9846153855323792, 0.9832167625427246, 0.9874125719070435, 0.9855477809906006, 0.9860140085220337, 0.9869464039802551, 0.9836829900741577, 0.9846153855323792, 0.986480176448822, 0.9878787994384766, 0.9874125719070435, 0.984149158000946, 0.9822843670845032, 0.9832167625427246, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.9874125719070435, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.9874125719070435, 0.9855477809906006, 0.9846153855323792, 0.9874125719070435, 0.9860140085220337, 0.9883449673652649, 0.9855477809906006, 0.9836829900741577, 0.9869464039802551, 0.9860140085220337, 0.9860140085220337, 0.9874125719070435, 0.9855477809906006, 0.9855477809906006, 0.9832167625427246, 0.984149158000946, 0.9874125719070435, 0.9878787994384766, 0.9878787994384766, 0.9869464039802551, 0.9869464039802551, 0.9850816130638123, 0.9850816130638123, 0.986480176448822, 0.986480176448822, 0.9850816130638123, 0.9878787994384766, 0.9878787994384766, 0.9869464039802551, 0.9846153855323792, 0.9850816130638123, 0.9846153855323792, 0.9827505946159363, 0.9855477809906006, 0.9874125719070435, 0.9878787994384766, 0.9860140085220337, 0.9874125719070435, 0.9874125719070435, 0.986480176448822, 0.9846153855323792, 0.9827505946159363, 0.9846153855323792, 0.9860140085220337, 0.9878787994384766, 0.9878787994384766, 0.9869464039802551, 0.9878787994384766, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.9878787994384766, 0.9878787994384766, 0.984149158000946, 0.9869464039802551, 0.9878787994384766, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.9860140085220337, 0.9883449673652649, 0.9878787994384766, 0.9874125719070435, 0.9869464039802551, 0.986480176448822, 0.9883449673652649, 0.9869464039802551, 0.9860140085220337, 0.9827505946159363, 0.9860140085220337, 0.9883449673652649, 0.9869464039802551, 0.986480176448822, 0.9874125719070435, 0.9874125719070435, 0.9855477809906006, 0.9869464039802551, 0.9878787994384766, 0.9883449673652649, 0.9860140085220337, 0.9883449673652649, 0.9878787994384766, 0.9855477809906006, 0.9850816130638123, 0.9860140085220337, 0.9874125719070435, 0.9883449673652649, 0.9869464039802551, 0.9860140085220337, 0.9855477809906006, 0.9892773628234863, 0.9878787994384766, 0.9878787994384766, 0.988811194896698, 0.9850816130638123, 0.9869464039802551, 0.986480176448822, 0.9874125719070435, 0.986480176448822, 0.9878787994384766, 0.986480176448822, 0.9850816130638123, 0.988811194896698, 0.9892773628234863, 0.9874125719070435, 0.9869464039802551, 0.9874125719070435, 0.9883449673652649, 0.988811194896698, 0.9850816130638123, 0.9869464039802551, 0.9883449673652649, 0.9878787994384766, 0.9874125719070435, 0.9874125719070435, 0.9878787994384766, 0.9883449673652649, 0.9808858036994934, 0.9860140085220337, 0.988811194896698, 0.988811194896698, 0.986480176448822, 0.9869464039802551, 0.9878787994384766, 0.9869464039802551, 0.9874125719070435, 0.9892773628234863, 0.986480176448822, 0.988811194896698, 0.984149158000946, 0.9850816130638123, 0.9869464039802551, 0.9883449673652649, 0.986480176448822, 0.9874125719070435, 0.9855477809906006, 0.9836829900741577, 0.9832167625427246, 0.9836829900741577, 0.986480176448822, 0.9892773628234863, 0.9869464039802551, 0.9874125719070435, 0.9869464039802551, 0.9869464039802551, 0.9883449673652649, 0.9860140085220337, 0.9869464039802551, 0.986480176448822, 0.9855477809906006, 0.9883449673652649, 0.988811194896698, 0.9860140085220337, 0.9883449673652649, 0.9883449673652649, 0.9855477809906006, 0.9883449673652649, 0.986480176448822, 0.986480176448822, 0.9869464039802551, 0.9850816130638123, 0.9846153855323792, 0.9836829900741577, 0.9846153855323792, 0.9883449673652649, 0.9878787994384766, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.9869464039802551, 0.9869464039802551, 0.9878787994384766, 0.986480176448822, 0.986480176448822, 0.9874125719070435, 0.9883449673652649, 0.9874125719070435, 0.9883449673652649, 0.9874125719070435, 0.984149158000946, 0.9855477809906006, 0.9874125719070435, 0.9869464039802551, 0.9883449673652649, 0.9874125719070435, 0.9878787994384766, 0.9869464039802551, 0.986480176448822, 0.986480176448822, 0.9878787994384766, 0.988811194896698, 0.9855477809906006, 0.9855477809906006, 0.986480176448822, 0.9874125719070435, 0.9855477809906006, 0.986480176448822, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.988811194896698, 0.9878787994384766, 0.9883449673652649, 0.9883449673652649, 0.9850816130638123, 0.986480176448822, 0.9897435903549194, 0.9897435903549194, 0.9860140085220337, 0.9874125719070435, 0.9892773628234863, 0.9874125719070435, 0.9883449673652649, 0.9878787994384766, 0.986480176448822, 0.9878787994384766, 0.986480176448822, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.9883449673652649, 0.9869464039802551, 0.9902098178863525, 0.9878787994384766, 0.9883449673652649, 0.9874125719070435, 0.9878787994384766, 0.9883449673652649, 0.9874125719070435, 0.9892773628234863, 0.9874125719070435, 0.988811194896698, 0.9869464039802551, 0.9897435903549194, 0.9869464039802551, 0.988811194896698, 0.9869464039802551, 0.9869464039802551, 0.9878787994384766, 0.9855477809906006, 0.9855477809906006, 0.9822843670845032, 0.9883449673652649, 0.986480176448822, 0.9874125719070435, 0.9874125719070435, 0.9869464039802551, 0.9874125719070435, 0.9878787994384766, 0.986480176448822, 0.986480176448822, 0.9878787994384766, 0.9878787994384766, 0.9878787994384766, 0.9878787994384766, 0.988811194896698, 0.986480176448822, 0.9874125719070435, 0.9850816130638123, 0.9860140085220337, 0.9869464039802551, 0.9846153855323792, 0.9878787994384766, 0.9874125719070435, 0.9869464039802551, 0.988811194896698, 0.9874125719070435, 0.9883449673652649, 0.986480176448822, 0.9892773628234863, 0.986480176448822, 0.9808858036994934, 0.9846153855323792, 0.9855477809906006, 0.9860140085220337, 0.984149158000946, 0.9874125719070435, 0.9874125719070435, 0.986480176448822, 0.9878787994384766, 0.9883449673652649, 0.9874125719070435, 0.9874125719070435, 0.9869464039802551, 0.9860140085220337, 0.9860140085220337, 0.9855477809906006, 0.9874125719070435, 0.9883449673652649, 0.9883449673652649, 0.9883449673652649, 0.9892773628234863, 0.9878787994384766, 0.9850816130638123, 0.9883449673652649, 0.9846153855323792, 0.986480176448822, 0.9855477809906006, 0.9892773628234863, 0.986480176448822, 0.988811194896698, 0.9869464039802551, 0.9878787994384766, 0.9878787994384766, 0.988811194896698, 0.9855477809906006, 0.988811194896698, 0.9878787994384766, 0.988811194896698, 0.9878787994384766, 0.988811194896698, 0.9883449673652649, 0.986480176448822, 0.9874125719070435, 0.9855477809906006, 0.9883449673652649, 0.9869464039802551, 0.9869464039802551, 0.9892773628234863, 0.986480176448822, 0.9892773628234863, 0.986480176448822, 0.9878787994384766, 0.9869464039802551, 0.988811194896698, 0.9869464039802551, 0.9836829900741577, 0.9846153855323792, 0.9850816130638123, 0.9869464039802551, 0.984149158000946, 0.9860140085220337, 0.9878787994384766, 0.9874125719070435, 0.9897435903549194, 0.988811194896698, 0.9855477809906006, 0.9869464039802551, 0.9874125719070435, 0.9878787994384766, 0.988811194896698, 0.9822843670845032, 0.984149158000946, 0.9855477809906006, 0.9897435903549194, 0.9855477809906006, 0.9883449673652649, 0.9878787994384766, 0.9883449673652649, 0.986480176448822, 0.9869464039802551, 0.988811194896698, 0.9869464039802551, 0.984149158000946, 0.9897435903549194, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9883449673652649, 0.9827505946159363, 0.9892773628234863, 0.9874125719070435, 0.988811194896698, 0.9897435903549194, 0.9869464039802551, 0.9883449673652649, 0.9878787994384766, 0.9883449673652649, 0.9897435903549194, 0.988811194896698, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9855477809906006, 0.9878787994384766, 0.9878787994384766, 0.9850816130638123, 0.9878787994384766, 0.9878787994384766, 0.9883449673652649, 0.984149158000946, 0.9878787994384766, 0.9869464039802551, 0.9860140085220337, 0.9874125719070435, 0.984149158000946, 0.9860140085220337, 0.9878787994384766, 0.9878787994384766, 0.9883449673652649, 0.9878787994384766, 0.9869464039802551, 0.988811194896698, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9878787994384766, 0.9883449673652649, 0.9878787994384766, 0.9860140085220337, 0.9874125719070435, 0.9869464039802551, 0.986480176448822, 0.9883449673652649, 0.9892773628234863, 0.986480176448822, 0.9883449673652649, 0.9874125719070435, 0.988811194896698, 0.9860140085220337, 0.9883449673652649, 0.9878787994384766, 0.9878787994384766, 0.988811194896698, 0.9869464039802551, 0.9846153855323792, 0.9869464039802551, 0.9878787994384766, 0.9869464039802551, 0.9869464039802551, 0.9883449673652649, 0.9878787994384766, 0.9869464039802551, 0.9874125719070435, 0.9883449673652649, 0.986480176448822, 0.984149158000946, 0.9860140085220337, 0.9874125719070435, 0.9874125719070435, 0.988811194896698, 0.9850816130638123, 0.986480176448822, 0.986480176448822, 0.9883449673652649, 0.9869464039802551, 0.988811194896698, 0.9869464039802551, 0.988811194896698, 0.986480176448822, 0.9878787994384766, 0.9850816130638123, 0.984149158000946, 0.984149158000946, 0.9850816130638123, 0.9832167625427246, 0.9836829900741577, 0.984149158000946, 0.9883449673652649, 0.9874125719070435, 0.988811194896698, 0.9874125719070435, 0.9846153855323792, 0.9874125719070435, 0.988811194896698, 0.9892773628234863, 0.9860140085220337, 0.9850816130638123, 0.9850816130638123, 0.9860140085220337, 0.9878787994384766, 0.9874125719070435, 0.9883449673652649, 0.988811194896698, 0.9874125719070435, 0.9883449673652649, 0.9874125719070435, 0.9855477809906006, 0.984149158000946, 0.988811194896698, 0.9883449673652649, 0.9883449673652649, 0.9878787994384766, 0.9874125719070435, 0.9878787994384766, 0.9883449673652649, 0.9874125719070435, 0.988811194896698, 0.9878787994384766, 0.9860140085220337, 0.9855477809906006, 0.9860140085220337, 0.988811194896698, 0.986480176448822, 0.9878787994384766, 0.9883449673652649, 0.988811194896698, 0.988811194896698, 0.9850816130638123, 0.9883449673652649, 0.9883449673652649, 0.9878787994384766, 0.9883449673652649, 0.9860140085220337, 0.9869464039802551, 0.9874125719070435, 0.9874125719070435, 0.988811194896698, 0.9878787994384766, 0.9883449673652649, 0.9883449673652649, 0.9883449673652649, 0.988811194896698, 0.9874125719070435, 0.9874125719070435, 0.9874125719070435, 0.986480176448822, 0.986480176448822, 0.9832167625427246, 0.986480176448822, 0.9874125719070435, 0.986480176448822, 0.9869464039802551, 0.9902098178863525, 0.9860140085220337, 0.9878787994384766, 0.9883449673652649, 0.9855477809906006, 0.9883449673652649, 0.9869464039802551, 0.9892773628234863, 0.9883449673652649, 0.9878787994384766, 0.986480176448822, 0.9850816130638123, 0.9883449673652649, 0.9869464039802551, 0.9892773628234863, 0.9846153855323792, 0.9846153855323792, 0.988811194896698, 0.988811194896698, 0.9878787994384766, 0.988811194896698, 0.9869464039802551, 0.986480176448822, 0.9892773628234863, 0.9883449673652649, 0.9869464039802551, 0.9869464039802551, 0.9874125719070435, 0.988811194896698, 0.9860140085220337, 0.986480176448822, 0.9878787994384766, 0.9869464039802551, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.9892773628234863, 0.9878787994384766, 0.9883449673652649, 0.9892773628234863, 0.9869464039802551, 0.9869464039802551, 0.986480176448822, 0.9860140085220337, 0.9874125719070435, 0.986480176448822, 0.9860140085220337, 0.9874125719070435, 0.9874125719070435, 0.986480176448822, 0.9878787994384766, 0.9860140085220337, 0.9855477809906006, 0.9860140085220337, 0.9878787994384766, 0.986480176448822, 0.9874125719070435, 0.9860140085220337, 0.9878787994384766, 0.986480176448822, 0.9860140085220337, 0.9850816130638123, 0.986480176448822, 0.9883449673652649, 0.9855477809906006, 0.9869464039802551, 0.9855477809906006, 0.9869464039802551, 0.986480176448822, 0.9846153855323792, 0.9860140085220337, 0.9883449673652649, 0.9892773628234863, 0.986480176448822, 0.9892773628234863, 0.9874125719070435, 0.9869464039802551, 0.9850816130638123, 0.9869464039802551, 0.9860140085220337, 0.9874125719070435, 0.986480176448822, 0.9827505946159363, 0.9869464039802551, 0.9869464039802551, 0.9860140085220337, 0.986480176448822, 0.9860140085220337, 0.9860140085220337, 0.9855477809906006, 0.986480176448822, 0.9878787994384766, 0.986480176448822, 0.986480176448822, 0.986480176448822, 0.9874125719070435, 0.986480176448822, 0.9869464039802551, 0.9850816130638123, 0.988811194896698, 0.9846153855323792, 0.9846153855323792, 0.9855477809906006, 0.9869464039802551, 0.9869464039802551, 0.9855477809906006, 0.9860140085220337, 0.9869464039802551, 0.9883449673652649, 0.988811194896698, 0.9855477809906006, 0.9869464039802551, 0.9869464039802551, 0.9860140085220337, 0.9860140085220337, 0.9855477809906006, 0.9869464039802551, 0.9869464039802551, 0.9855477809906006, 0.986480176448822, 0.9878787994384766, 0.9883449673652649, 0.9860140085220337, 0.9892773628234863, 0.9883449673652649, 0.9869464039802551, 0.9878787994384766, 0.9878787994384766, 0.9860140085220337, 0.9869464039802551, 0.9874125719070435, 0.9869464039802551, 0.9883449673652649, 0.986480176448822, 0.9850816130638123, 0.986480176448822, 0.986480176448822, 0.9869464039802551, 0.9878787994384766, 0.988811194896698, 0.986480176448822, 0.9874125719070435, 0.9883449673652649, 0.9878787994384766, 0.9860140085220337, 0.9860140085220337, 0.9874125719070435, 0.984149158000946, 0.9850816130638123, 0.988811194896698, 0.9860140085220337, 0.9892773628234863, 0.9878787994384766, 0.9892773628234863, 0.9860140085220337, 0.9869464039802551, 0.9874125719070435, 0.9883449673652649, 0.9860140085220337, 0.9883449673652649, 0.9860140085220337, 0.9874125719070435, 0.9860140085220337, 0.9892773628234863, 0.9878787994384766, 0.986480176448822, 0.9874125719070435, 0.988811194896698, 0.986480176448822, 0.9883449673652649, 0.9878787994384766, 0.9860140085220337, 0.9883449673652649, 0.9874125719070435, 0.9878787994384766, 0.9869464039802551, 0.986480176448822, 0.9874125719070435, 0.9869464039802551, 0.9846153855323792, 0.986480176448822, 0.9869464039802551, 0.988811194896698, 0.9883449673652649, 0.9878787994384766, 0.986480176448822, 0.9860140085220337, 0.9874125719070435, 0.988811194896698, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9878787994384766, 0.9878787994384766, 0.9869464039802551, 0.9860140085220337, 0.9883449673652649, 0.9874125719070435, 0.9860140085220337, 0.9855477809906006, 0.9883449673652649, 0.986480176448822, 0.986480176448822, 0.9878787994384766, 0.986480176448822, 0.9883449673652649, 0.9878787994384766, 0.988811194896698, 0.9869464039802551, 0.9869464039802551, 0.9897435903549194, 0.9860140085220337, 0.9878787994384766, 0.9860140085220337, 0.984149158000946, 0.9850816130638123, 0.9874125719070435, 0.9860140085220337, 0.9869464039802551, 0.9878787994384766, 0.986480176448822, 0.9855477809906006, 0.986480176448822, 0.984149158000946, 0.9883449673652649, 0.9874125719070435, 0.9836829900741577, 0.986480176448822, 0.9860140085220337, 0.986480176448822, 0.9874125719070435, 0.9883449673652649, 0.9874125719070435, 0.988811194896698, 0.9874125719070435, 0.9869464039802551, 0.986480176448822, 0.9878787994384766, 0.9860140085220337, 0.986480176448822, 0.986480176448822, 0.986480176448822, 0.9869464039802551, 0.9860140085220337, 0.9878787994384766, 0.9869464039802551, 0.9874125719070435, 0.9855477809906006, 0.9860140085220337, 0.9855477809906006, 0.986480176448822, 0.9869464039802551, 0.9874125719070435, 0.9878787994384766, 0.986480176448822, 0.9883449673652649, 0.9860140085220337, 0.9850816130638123, 0.9883449673652649, 0.9874125719070435, 0.986480176448822, 0.9883449673652649, 0.9869464039802551, 0.9883449673652649, 0.9874125719070435, 0.9883449673652649, 0.9874125719070435, 0.9855477809906006, 0.9869464039802551, 0.9883449673652649, 0.986480176448822, 0.9869464039802551, 0.986480176448822, 0.9869464039802551, 0.9850816130638123, 0.9878787994384766, 0.9874125719070435, 0.9869464039802551, 0.9869464039802551, 0.9883449673652649, 0.9850816130638123, 0.986480176448822, 0.9878787994384766, 0.9874125719070435, 0.986480176448822, 0.9874125719070435, 0.9869464039802551, 0.9878787994384766, 0.9878787994384766, 0.9860140085220337, 0.986480176448822, 0.9860140085220337, 0.9822843670845032, 0.9878787994384766, 0.9878787994384766, 0.9897435903549194, 0.9878787994384766, 0.9855477809906006, 0.9869464039802551, 0.9836829900741577, 0.988811194896698, 0.988811194896698, 0.986480176448822, 0.9860140085220337, 0.9878787994384766, 0.9883449673652649, 0.9878787994384766, 0.9869464039802551, 0.9883449673652649, 0.9874125719070435, 0.9883449673652649, 0.9855477809906006, 0.9874125719070435, 0.9869464039802551, 0.9878787994384766, 0.9874125719070435, 0.988811194896698, 0.9860140085220337, 0.988811194896698, 0.9878787994384766, 0.9869464039802551, 0.9883449673652649, 0.9878787994384766, 0.9860140085220337, 0.984149158000946, 0.9855477809906006, 0.984149158000946, 0.9892773628234863, 0.9874125719070435, 0.9855477809906006, 0.9883449673652649, 0.984149158000946, 0.9874125719070435, 0.9874125719070435, 0.9892773628234863, 0.9850816130638123, 0.9897435903549194, 0.9883449673652649, 0.9874125719070435, 0.9869464039802551, 0.9874125719070435, 0.986480176448822, 0.9883449673652649, 0.9883449673652649, 0.9874125719070435, 0.986480176448822, 0.9832167625427246, 0.9897435903549194, 0.986480176448822, 0.9883449673652649, 0.9883449673652649, 0.9878787994384766, 0.988811194896698, 0.988811194896698, 0.9883449673652649, 0.9874125719070435, 0.9878787994384766, 0.986480176448822, 0.9883449673652649, 0.9860140085220337, 0.9869464039802551, 0.9892773628234863, 0.988811194896698, 0.9878787994384766, 0.986480176448822, 0.9869464039802551, 0.9878787994384766, 0.9874125719070435, 0.988811194896698, 0.988811194896698, 0.9869464039802551, 0.9855477809906006, 0.9860140085220337, 0.9883449673652649, 0.9883449673652649, 0.9874125719070435, 0.9869464039802551, 0.9892773628234863, 0.9874125719070435, 0.9836829900741577]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "type(history.history) # dict\n",
    "\n",
    "for key, value in history.history.items():\n",
    "  print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "9PPNOr_V77Tu"
   },
   "outputs": [],
   "source": [
    "y_vloss=  history.history['val_loss']\n",
    "y_acc   =  history.history['accuracy']\n",
    "loss =  history.history['loss']\n",
    "val_accuracy =  history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "82zQALlJ8rXX",
    "outputId": "5b88a78a-e761-4559-c58f-56a9eb95ba9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f54a017add8>]"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c = \"red\", markersize = 3)\n",
    "plt.plot(x_len, y_acc, \"o\", c = \"blue\", markersize = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4BlTIJJ9xzE"
   },
   "source": [
    "## 와인의 종류 예측하기\n",
    "* 정확도가 이전 모델의 것보다 향상될때 모델 저장\n",
    "* 예측한 실험결과와 테스트셋결과 그래프로 표현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "3qS-cJ2o9TQf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "SQhTpAyp9o2W"
   },
   "outputs": [],
   "source": [
    "# seed값 설정\n",
    "seed = 156\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "qKeQawd9-R8-"
   },
   "outputs": [],
   "source": [
    "df_pre = pd.read_csv(\"/content/sample_data/wine.csv\", header = None)\n",
    "df = df_pre.sample(frac = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "CDRJ83Tf-gfn"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 분리\n",
    "datset = df.values\n",
    "X = dataset[:, 0:12]\n",
    "Y = dataset[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "IQDE2oYk-ts5"
   },
   "outputs": [],
   "source": [
    "#모델 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "id_Vsyav_EJG"
   },
   "outputs": [],
   "source": [
    "# 모델 커마일 \n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "y0wpVU3h_SKh"
   },
   "outputs": [],
   "source": [
    "# 모델정보 저장 폴더 \n",
    "MODEL_DIR = \"/content/sample_data/model/\"\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "  os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "QkTMx9aa_2aN"
   },
   "outputs": [],
   "source": [
    "# 모델 저장조건 설정\n",
    "modelpath = MODEL_DIR+\"{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 0,  save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqrAL3gWAGBQ",
    "outputId": "b93e2de3-e77a-465e-edad-bc3e5b40aad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
      "Epoch 1001/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0352 - accuracy: 0.9911 - val_loss: 0.0578 - val_accuracy: 0.9823\n",
      "Epoch 1002/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 0.9911 - val_loss: 0.0428 - val_accuracy: 0.9865\n",
      "Epoch 1003/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.0425 - val_accuracy: 0.9869\n",
      "Epoch 1004/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 0.0412 - val_accuracy: 0.9865\n",
      "Epoch 1005/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0313 - accuracy: 0.9897 - val_loss: 0.0441 - val_accuracy: 0.9869\n",
      "Epoch 1006/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 0.0480 - val_accuracy: 0.9869\n",
      "Epoch 1007/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0357 - accuracy: 0.9873 - val_loss: 0.0432 - val_accuracy: 0.9879\n",
      "Epoch 1008/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0323 - accuracy: 0.9909 - val_loss: 0.0425 - val_accuracy: 0.9879\n",
      "Epoch 1009/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0347 - accuracy: 0.9898 - val_loss: 0.0433 - val_accuracy: 0.9860\n",
      "Epoch 1010/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9927 - val_loss: 0.0437 - val_accuracy: 0.9855\n",
      "Epoch 1011/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.0481 - val_accuracy: 0.9846\n",
      "Epoch 1012/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9924 - val_loss: 0.0577 - val_accuracy: 0.9818\n",
      "Epoch 1013/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0315 - accuracy: 0.9886 - val_loss: 0.0749 - val_accuracy: 0.9758\n",
      "Epoch 1014/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0300 - accuracy: 0.9897 - val_loss: 0.0417 - val_accuracy: 0.9874\n",
      "Epoch 1015/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.0415 - val_accuracy: 0.9869\n",
      "Epoch 1016/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9910 - val_loss: 0.0430 - val_accuracy: 0.9851\n",
      "Epoch 1017/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.0508 - val_accuracy: 0.9846\n",
      "Epoch 1018/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0333 - accuracy: 0.9892 - val_loss: 0.0442 - val_accuracy: 0.9869\n",
      "Epoch 1019/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.9922 - val_loss: 0.0456 - val_accuracy: 0.9846\n",
      "Epoch 1020/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9949 - val_loss: 0.0411 - val_accuracy: 0.9865\n",
      "Epoch 1021/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0301 - accuracy: 0.9906 - val_loss: 0.0413 - val_accuracy: 0.9869\n",
      "Epoch 1022/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 0.0422 - val_accuracy: 0.9874\n",
      "Epoch 1023/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0352 - accuracy: 0.9892 - val_loss: 0.0476 - val_accuracy: 0.9841\n",
      "Epoch 1024/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.0477 - val_accuracy: 0.9855\n",
      "Epoch 1025/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0322 - accuracy: 0.9922 - val_loss: 0.0434 - val_accuracy: 0.9860\n",
      "Epoch 1026/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0317 - accuracy: 0.9898 - val_loss: 0.0424 - val_accuracy: 0.9874\n",
      "Epoch 1027/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0306 - accuracy: 0.9890 - val_loss: 0.0411 - val_accuracy: 0.9865\n",
      "Epoch 1028/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.0416 - val_accuracy: 0.9869\n",
      "Epoch 1029/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0358 - accuracy: 0.9904 - val_loss: 0.0426 - val_accuracy: 0.9883\n",
      "Epoch 1030/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.0412 - val_accuracy: 0.9865\n",
      "Epoch 1031/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9950 - val_loss: 0.0471 - val_accuracy: 0.9879\n",
      "Epoch 1032/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.0444 - val_accuracy: 0.9874\n",
      "Epoch 1033/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.0499 - val_accuracy: 0.9865\n",
      "Epoch 1034/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0388 - accuracy: 0.9884 - val_loss: 0.0510 - val_accuracy: 0.9860\n",
      "Epoch 1035/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0476 - accuracy: 0.9853 - val_loss: 0.0464 - val_accuracy: 0.9874\n",
      "Epoch 1036/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 0.0438 - val_accuracy: 0.9869\n",
      "Epoch 1037/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0331 - accuracy: 0.9917 - val_loss: 0.0417 - val_accuracy: 0.9865\n",
      "Epoch 1038/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.0420 - val_accuracy: 0.9865\n",
      "Epoch 1039/3500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0245 - accuracy: 0.9938 - val_loss: 0.0516 - val_accuracy: 0.9860\n",
      "Epoch 1040/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0569 - accuracy: 0.9807 - val_loss: 0.0620 - val_accuracy: 0.9837\n",
      "Epoch 1041/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0532 - accuracy: 0.9826 - val_loss: 0.0460 - val_accuracy: 0.9869\n",
      "Epoch 1042/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0325 - accuracy: 0.9908 - val_loss: 0.0425 - val_accuracy: 0.9865\n",
      "Epoch 1043/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0320 - accuracy: 0.9901 - val_loss: 0.0415 - val_accuracy: 0.9874\n",
      "Epoch 1044/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.0409 - val_accuracy: 0.9874\n",
      "Epoch 1045/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 0.0502 - val_accuracy: 0.9851\n",
      "Epoch 1046/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.0464 - val_accuracy: 0.9851\n",
      "Epoch 1047/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0281 - accuracy: 0.9932 - val_loss: 0.0413 - val_accuracy: 0.9865\n",
      "Epoch 1048/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9924 - val_loss: 0.0439 - val_accuracy: 0.9860\n",
      "Epoch 1049/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9946 - val_loss: 0.0416 - val_accuracy: 0.9879\n",
      "Epoch 1050/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0313 - accuracy: 0.9885 - val_loss: 0.0413 - val_accuracy: 0.9860\n",
      "Epoch 1051/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9938 - val_loss: 0.0411 - val_accuracy: 0.9874\n",
      "Epoch 1052/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0320 - accuracy: 0.9885 - val_loss: 0.0412 - val_accuracy: 0.9874\n",
      "Epoch 1053/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.0466 - val_accuracy: 0.9855\n",
      "Epoch 1054/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0319 - accuracy: 0.9913 - val_loss: 0.0435 - val_accuracy: 0.9855\n",
      "Epoch 1055/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.0412 - val_accuracy: 0.9874\n",
      "Epoch 1056/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.0443 - val_accuracy: 0.9865\n",
      "Epoch 1057/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0308 - accuracy: 0.9917 - val_loss: 0.0426 - val_accuracy: 0.9883\n",
      "Epoch 1058/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0385 - accuracy: 0.9863 - val_loss: 0.0425 - val_accuracy: 0.9883\n",
      "Epoch 1059/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0290 - accuracy: 0.9928 - val_loss: 0.0425 - val_accuracy: 0.9869\n",
      "Epoch 1060/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0324 - accuracy: 0.9899 - val_loss: 0.0411 - val_accuracy: 0.9865\n",
      "Epoch 1061/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.0453 - val_accuracy: 0.9860\n",
      "Epoch 1062/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 0.9917 - val_loss: 0.0489 - val_accuracy: 0.9860\n",
      "Epoch 1063/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.0426 - val_accuracy: 0.9865\n",
      "Epoch 1064/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0257 - accuracy: 0.9930 - val_loss: 0.0409 - val_accuracy: 0.9874\n",
      "Epoch 1065/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.0423 - val_accuracy: 0.9874\n",
      "Epoch 1066/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0286 - accuracy: 0.9918 - val_loss: 0.0517 - val_accuracy: 0.9832\n",
      "Epoch 1067/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.0586 - val_accuracy: 0.9818\n",
      "Epoch 1068/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0331 - accuracy: 0.9907 - val_loss: 0.0463 - val_accuracy: 0.9846\n",
      "Epoch 1069/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0300 - accuracy: 0.9920 - val_loss: 0.0412 - val_accuracy: 0.9874\n",
      "Epoch 1070/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0342 - accuracy: 0.9887 - val_loss: 0.0414 - val_accuracy: 0.9874\n",
      "Epoch 1071/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.0412 - val_accuracy: 0.9874\n",
      "Epoch 1072/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0337 - accuracy: 0.9910 - val_loss: 0.0429 - val_accuracy: 0.9874\n",
      "Epoch 1073/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 0.9917 - val_loss: 0.0487 - val_accuracy: 0.9851\n",
      "Epoch 1074/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.9870 - val_loss: 0.0406 - val_accuracy: 0.9869\n",
      "Epoch 1075/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.0416 - val_accuracy: 0.9874\n",
      "Epoch 1076/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 0.0411 - val_accuracy: 0.9874\n",
      "Epoch 1077/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.0425 - val_accuracy: 0.9865\n",
      "Epoch 1078/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 0.0481 - val_accuracy: 0.9855\n",
      "Epoch 1079/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.0437 - val_accuracy: 0.9865\n",
      "Epoch 1080/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 0.0468 - val_accuracy: 0.9846\n",
      "Epoch 1081/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.0470 - val_accuracy: 0.9869\n",
      "Epoch 1082/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0286 - accuracy: 0.9936 - val_loss: 0.0490 - val_accuracy: 0.9860\n",
      "Epoch 1083/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0332 - accuracy: 0.9899 - val_loss: 0.0409 - val_accuracy: 0.9860\n",
      "Epoch 1084/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0291 - accuracy: 0.9917 - val_loss: 0.0422 - val_accuracy: 0.9865\n",
      "Epoch 1085/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9930 - val_loss: 0.0413 - val_accuracy: 0.9869\n",
      "Epoch 1086/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0312 - accuracy: 0.9917 - val_loss: 0.0424 - val_accuracy: 0.9865\n",
      "Epoch 1087/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.0414 - val_accuracy: 0.9860\n",
      "Epoch 1088/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0418 - val_accuracy: 0.9865\n",
      "Epoch 1089/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0299 - accuracy: 0.9917 - val_loss: 0.0414 - val_accuracy: 0.9879\n",
      "Epoch 1090/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9914 - val_loss: 0.0412 - val_accuracy: 0.9869\n",
      "Epoch 1091/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 0.9883 - val_loss: 0.0414 - val_accuracy: 0.9874\n",
      "Epoch 1092/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9927 - val_loss: 0.0410 - val_accuracy: 0.9860\n",
      "Epoch 1093/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0406 - val_accuracy: 0.9865\n",
      "Epoch 1094/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.0428 - val_accuracy: 0.9879\n",
      "Epoch 1095/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 0.0417 - val_accuracy: 0.9879\n",
      "Epoch 1096/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0324 - accuracy: 0.9903 - val_loss: 0.0433 - val_accuracy: 0.9874\n",
      "Epoch 1097/3500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0370 - accuracy: 0.9877 - val_loss: 0.0430 - val_accuracy: 0.9874\n",
      "Epoch 1098/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0320 - accuracy: 0.9891 - val_loss: 0.0414 - val_accuracy: 0.9879\n",
      "Epoch 1099/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0390 - accuracy: 0.9875 - val_loss: 0.0542 - val_accuracy: 0.9828\n",
      "Epoch 1100/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0389 - accuracy: 0.9892 - val_loss: 0.0632 - val_accuracy: 0.9786\n",
      "Epoch 1101/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0316 - accuracy: 0.9898 - val_loss: 0.0468 - val_accuracy: 0.9860\n",
      "Epoch 1102/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0358 - accuracy: 0.9896 - val_loss: 0.0466 - val_accuracy: 0.9860\n",
      "Epoch 1103/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 0.0492 - val_accuracy: 0.9837\n",
      "Epoch 1104/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0330 - accuracy: 0.9908 - val_loss: 0.0445 - val_accuracy: 0.9860\n",
      "Epoch 1105/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0449 - val_accuracy: 0.9860\n",
      "Epoch 1106/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0316 - accuracy: 0.9923 - val_loss: 0.0519 - val_accuracy: 0.9841\n",
      "Epoch 1107/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.0530 - val_accuracy: 0.9837\n",
      "Epoch 1108/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0278 - accuracy: 0.9920 - val_loss: 0.0456 - val_accuracy: 0.9855\n",
      "Epoch 1109/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0287 - accuracy: 0.9928 - val_loss: 0.0484 - val_accuracy: 0.9860\n",
      "Epoch 1110/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0284 - accuracy: 0.9919 - val_loss: 0.0471 - val_accuracy: 0.9855\n",
      "Epoch 1111/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0286 - accuracy: 0.9907 - val_loss: 0.0424 - val_accuracy: 0.9879\n",
      "Epoch 1112/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 0.0450 - val_accuracy: 0.9879\n",
      "Epoch 1113/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 0.9890 - val_loss: 0.0421 - val_accuracy: 0.9874\n",
      "Epoch 1114/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.0467 - val_accuracy: 0.9869\n",
      "Epoch 1115/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0302 - accuracy: 0.9918 - val_loss: 0.0408 - val_accuracy: 0.9865\n",
      "Epoch 1116/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0285 - accuracy: 0.9906 - val_loss: 0.0406 - val_accuracy: 0.9874\n",
      "Epoch 1117/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0322 - accuracy: 0.9910 - val_loss: 0.0446 - val_accuracy: 0.9869\n",
      "Epoch 1118/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 0.9925 - val_loss: 0.0693 - val_accuracy: 0.9781\n",
      "Epoch 1119/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 0.0490 - val_accuracy: 0.9855\n",
      "Epoch 1120/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0300 - accuracy: 0.9909 - val_loss: 0.0454 - val_accuracy: 0.9860\n",
      "Epoch 1121/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0280 - accuracy: 0.9922 - val_loss: 0.0541 - val_accuracy: 0.9828\n",
      "Epoch 1122/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0304 - accuracy: 0.9913 - val_loss: 0.0455 - val_accuracy: 0.9865\n",
      "Epoch 1123/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0502 - val_accuracy: 0.9846\n",
      "Epoch 1124/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0265 - accuracy: 0.9925 - val_loss: 0.0458 - val_accuracy: 0.9865\n",
      "Epoch 1125/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0299 - accuracy: 0.9929 - val_loss: 0.0461 - val_accuracy: 0.9855\n",
      "Epoch 1126/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.0405 - val_accuracy: 0.9869\n",
      "Epoch 1127/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 0.0440 - val_accuracy: 0.9869\n",
      "Epoch 1128/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.0701 - val_accuracy: 0.9762\n",
      "Epoch 1129/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0403 - accuracy: 0.9874 - val_loss: 0.0565 - val_accuracy: 0.9828\n",
      "Epoch 1130/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0315 - accuracy: 0.9886 - val_loss: 0.0486 - val_accuracy: 0.9846\n",
      "Epoch 1131/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.9866 - val_loss: 0.0407 - val_accuracy: 0.9869\n",
      "Epoch 1132/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0512 - accuracy: 0.9865 - val_loss: 0.0443 - val_accuracy: 0.9879\n",
      "Epoch 1133/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0422 - accuracy: 0.9865 - val_loss: 0.0416 - val_accuracy: 0.9879\n",
      "Epoch 1134/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.0443 - val_accuracy: 0.9869\n",
      "Epoch 1135/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0359 - accuracy: 0.9875 - val_loss: 0.0430 - val_accuracy: 0.9874\n",
      "Epoch 1136/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0294 - accuracy: 0.9901 - val_loss: 0.0421 - val_accuracy: 0.9879\n",
      "Epoch 1137/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.0416 - val_accuracy: 0.9874\n",
      "Epoch 1138/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9894 - val_loss: 0.0421 - val_accuracy: 0.9869\n",
      "Epoch 1139/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0328 - accuracy: 0.9920 - val_loss: 0.0432 - val_accuracy: 0.9869\n",
      "Epoch 1140/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0273 - accuracy: 0.9932 - val_loss: 0.0499 - val_accuracy: 0.9841\n",
      "Epoch 1141/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0295 - accuracy: 0.9922 - val_loss: 0.0803 - val_accuracy: 0.9734\n",
      "Epoch 1142/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 0.9879 - val_loss: 0.0877 - val_accuracy: 0.9725\n",
      "Epoch 1143/3500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0472 - accuracy: 0.9853 - val_loss: 0.0575 - val_accuracy: 0.9800\n",
      "Epoch 1144/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0384 - accuracy: 0.9863 - val_loss: 0.0443 - val_accuracy: 0.9874\n",
      "Epoch 1145/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0314 - accuracy: 0.9883 - val_loss: 0.0427 - val_accuracy: 0.9874\n",
      "Epoch 1146/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0400 - accuracy: 0.9862 - val_loss: 0.0431 - val_accuracy: 0.9874\n",
      "Epoch 1147/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0332 - accuracy: 0.9891 - val_loss: 0.0428 - val_accuracy: 0.9879\n",
      "Epoch 1148/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0404 - accuracy: 0.9880 - val_loss: 0.0503 - val_accuracy: 0.9855\n",
      "Epoch 1149/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0296 - accuracy: 0.9913 - val_loss: 0.0494 - val_accuracy: 0.9855\n",
      "Epoch 1150/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0294 - accuracy: 0.9910 - val_loss: 0.0621 - val_accuracy: 0.9795\n",
      "Epoch 1151/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0493 - accuracy: 0.9871 - val_loss: 0.0677 - val_accuracy: 0.9776\n",
      "Epoch 1152/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0511 - accuracy: 0.9847 - val_loss: 0.0558 - val_accuracy: 0.9790\n",
      "Epoch 1153/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0389 - accuracy: 0.9882 - val_loss: 0.0513 - val_accuracy: 0.9837\n",
      "Epoch 1154/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9929 - val_loss: 0.0424 - val_accuracy: 0.9879\n",
      "Epoch 1155/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0292 - accuracy: 0.9916 - val_loss: 0.0412 - val_accuracy: 0.9869\n",
      "Epoch 1156/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.0419 - val_accuracy: 0.9874\n",
      "Epoch 1157/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 0.0420 - val_accuracy: 0.9883\n",
      "Epoch 1158/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0389 - accuracy: 0.9862 - val_loss: 0.0407 - val_accuracy: 0.9879\n",
      "Epoch 1159/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0266 - accuracy: 0.9925 - val_loss: 0.0418 - val_accuracy: 0.9860\n",
      "Epoch 1160/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0287 - accuracy: 0.9893 - val_loss: 0.0510 - val_accuracy: 0.9837\n",
      "Epoch 1161/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.0493 - val_accuracy: 0.9841\n",
      "Epoch 1162/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0260 - accuracy: 0.9910 - val_loss: 0.0666 - val_accuracy: 0.9786\n",
      "Epoch 1163/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 0.0447 - val_accuracy: 0.9869\n",
      "Epoch 1164/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0228 - accuracy: 0.9944 - val_loss: 0.0412 - val_accuracy: 0.9874\n",
      "Epoch 1165/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 0.0410 - val_accuracy: 0.9874\n",
      "Epoch 1166/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9937 - val_loss: 0.0406 - val_accuracy: 0.9874\n",
      "Epoch 1167/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 0.0427 - val_accuracy: 0.9874\n",
      "Epoch 1168/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0303 - accuracy: 0.9917 - val_loss: 0.0411 - val_accuracy: 0.9869\n",
      "Epoch 1169/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.0405 - val_accuracy: 0.9879\n",
      "Epoch 1170/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0312 - accuracy: 0.9914 - val_loss: 0.0401 - val_accuracy: 0.9874\n",
      "Epoch 1171/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0328 - accuracy: 0.9887 - val_loss: 0.0439 - val_accuracy: 0.9879\n",
      "Epoch 1172/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0346 - accuracy: 0.9878 - val_loss: 0.0417 - val_accuracy: 0.9879\n",
      "Epoch 1173/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.0411 - val_accuracy: 0.9883\n",
      "Epoch 1174/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.0408 - val_accuracy: 0.9879\n",
      "Epoch 1175/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 0.0448 - val_accuracy: 0.9860\n",
      "Epoch 1176/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.0452 - val_accuracy: 0.9855\n",
      "Epoch 1177/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0305 - accuracy: 0.9910 - val_loss: 0.0536 - val_accuracy: 0.9823\n",
      "Epoch 1178/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0297 - accuracy: 0.9914 - val_loss: 0.0513 - val_accuracy: 0.9832\n",
      "Epoch 1179/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9904 - val_loss: 0.0412 - val_accuracy: 0.9865\n",
      "Epoch 1180/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.0466 - val_accuracy: 0.9869\n",
      "Epoch 1181/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0319 - accuracy: 0.9925 - val_loss: 0.0483 - val_accuracy: 0.9855\n",
      "Epoch 1182/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 0.0820 - val_accuracy: 0.9730\n",
      "Epoch 1183/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0397 - accuracy: 0.9877 - val_loss: 0.0466 - val_accuracy: 0.9865\n",
      "Epoch 1184/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9941 - val_loss: 0.0440 - val_accuracy: 0.9874\n",
      "Epoch 1185/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 0.0467 - val_accuracy: 0.9874\n",
      "Epoch 1186/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 0.0470 - val_accuracy: 0.9860\n",
      "Epoch 1187/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.0405 - val_accuracy: 0.9874\n",
      "Epoch 1188/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.0428 - val_accuracy: 0.9869\n",
      "Epoch 1189/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9925 - val_loss: 0.0509 - val_accuracy: 0.9846\n",
      "Epoch 1190/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0341 - accuracy: 0.9904 - val_loss: 0.0427 - val_accuracy: 0.9865\n",
      "Epoch 1191/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 0.0406 - val_accuracy: 0.9879\n",
      "Epoch 1192/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 0.0416 - val_accuracy: 0.9874\n",
      "Epoch 1193/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9901 - val_loss: 0.0446 - val_accuracy: 0.9874\n",
      "Epoch 1194/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0334 - accuracy: 0.9881 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 1195/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0406 - accuracy: 0.9877 - val_loss: 0.0418 - val_accuracy: 0.9874\n",
      "Epoch 1196/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.0420 - val_accuracy: 0.9879\n",
      "Epoch 1197/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0267 - accuracy: 0.9910 - val_loss: 0.0440 - val_accuracy: 0.9874\n",
      "Epoch 1198/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 0.0423 - val_accuracy: 0.9865\n",
      "Epoch 1199/3500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0261 - accuracy: 0.9925 - val_loss: 0.0458 - val_accuracy: 0.9860\n",
      "Epoch 1200/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 0.0449 - val_accuracy: 0.9860\n",
      "Epoch 1201/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0323 - accuracy: 0.9907 - val_loss: 0.0473 - val_accuracy: 0.9851\n",
      "Epoch 1202/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0295 - accuracy: 0.9919 - val_loss: 0.0477 - val_accuracy: 0.9851\n",
      "Epoch 1203/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.0409 - val_accuracy: 0.9874\n",
      "Epoch 1204/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.0409 - val_accuracy: 0.9874\n",
      "Epoch 1205/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9932 - val_loss: 0.0436 - val_accuracy: 0.9860\n",
      "Epoch 1206/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0276 - accuracy: 0.9928 - val_loss: 0.0435 - val_accuracy: 0.9855\n",
      "Epoch 1207/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0318 - accuracy: 0.9904 - val_loss: 0.0406 - val_accuracy: 0.9874\n",
      "Epoch 1208/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0318 - accuracy: 0.9904 - val_loss: 0.0410 - val_accuracy: 0.9879\n",
      "Epoch 1209/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0414 - accuracy: 0.9868 - val_loss: 0.0416 - val_accuracy: 0.9879\n",
      "Epoch 1210/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 0.0420 - val_accuracy: 0.9879\n",
      "Epoch 1211/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 0.0412 - val_accuracy: 0.9874\n",
      "Epoch 1212/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0346 - accuracy: 0.9899 - val_loss: 0.0409 - val_accuracy: 0.9879\n",
      "Epoch 1213/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 0.0417 - val_accuracy: 0.9869\n",
      "Epoch 1214/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 0.0421 - val_accuracy: 0.9869\n",
      "Epoch 1215/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9919 - val_loss: 0.0422 - val_accuracy: 0.9869\n",
      "Epoch 1216/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 0.9902 - val_loss: 0.0419 - val_accuracy: 0.9874\n",
      "Epoch 1217/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0432 - val_accuracy: 0.9860\n",
      "Epoch 1218/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9908 - val_loss: 0.0464 - val_accuracy: 0.9846\n",
      "Epoch 1219/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 0.0576 - val_accuracy: 0.9804\n",
      "Epoch 1220/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0343 - accuracy: 0.9894 - val_loss: 0.0463 - val_accuracy: 0.9865\n",
      "Epoch 1221/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0254 - accuracy: 0.9931 - val_loss: 0.0454 - val_accuracy: 0.9869\n",
      "Epoch 1222/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.0499 - val_accuracy: 0.9851\n",
      "Epoch 1223/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 0.0496 - val_accuracy: 0.9846\n",
      "Epoch 1224/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 0.0454 - val_accuracy: 0.9860\n",
      "Epoch 1225/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9907 - val_loss: 0.0543 - val_accuracy: 0.9823\n",
      "Epoch 1226/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0270 - accuracy: 0.9924 - val_loss: 0.0464 - val_accuracy: 0.9860\n",
      "Epoch 1227/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0278 - accuracy: 0.9931 - val_loss: 0.0439 - val_accuracy: 0.9865\n",
      "Epoch 1228/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.0444 - val_accuracy: 0.9869\n",
      "Epoch 1229/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9935 - val_loss: 0.0463 - val_accuracy: 0.9879\n",
      "Epoch 1230/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9929 - val_loss: 0.0447 - val_accuracy: 0.9855\n",
      "Epoch 1231/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.0410 - val_accuracy: 0.9874\n",
      "Epoch 1232/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.0584 - val_accuracy: 0.9818\n",
      "Epoch 1233/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.0564 - val_accuracy: 0.9832\n",
      "Epoch 1234/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0394 - accuracy: 0.9884 - val_loss: 0.0690 - val_accuracy: 0.9776\n",
      "Epoch 1235/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0384 - accuracy: 0.9869 - val_loss: 0.0560 - val_accuracy: 0.9818\n",
      "Epoch 1236/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0302 - accuracy: 0.9914 - val_loss: 0.0494 - val_accuracy: 0.9851\n",
      "Epoch 1237/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0429 - accuracy: 0.9869 - val_loss: 0.0415 - val_accuracy: 0.9874\n",
      "Epoch 1238/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0336 - accuracy: 0.9885 - val_loss: 0.0433 - val_accuracy: 0.9869\n",
      "Epoch 1239/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.0438 - val_accuracy: 0.9865\n",
      "Epoch 1240/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 0.0483 - val_accuracy: 0.9846\n",
      "Epoch 1241/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0314 - accuracy: 0.9918 - val_loss: 0.0489 - val_accuracy: 0.9855\n",
      "Epoch 1242/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0294 - accuracy: 0.9919 - val_loss: 0.0594 - val_accuracy: 0.9800\n",
      "Epoch 1243/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9897 - val_loss: 0.0422 - val_accuracy: 0.9879\n",
      "Epoch 1244/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0350 - accuracy: 0.9865 - val_loss: 0.0405 - val_accuracy: 0.9879\n",
      "Epoch 1245/3500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0285 - accuracy: 0.9907 - val_loss: 0.0415 - val_accuracy: 0.9879\n",
      "Epoch 1246/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 0.0414 - val_accuracy: 0.9879\n",
      "Epoch 1247/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: 0.0406 - val_accuracy: 0.9874\n",
      "Epoch 1248/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 0.0431 - val_accuracy: 0.9869\n",
      "Epoch 1249/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 0.0425 - val_accuracy: 0.9874\n",
      "Epoch 1250/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.0403 - val_accuracy: 0.9879\n",
      "Epoch 1251/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.0415 - val_accuracy: 0.9879\n",
      "Epoch 1252/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.0440 - val_accuracy: 0.9865\n",
      "Epoch 1253/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0418 - val_accuracy: 0.9874\n",
      "Epoch 1254/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.0479 - val_accuracy: 0.9869\n",
      "Epoch 1255/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9930 - val_loss: 0.0406 - val_accuracy: 0.9874\n",
      "Epoch 1256/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.0425 - val_accuracy: 0.9865\n",
      "Epoch 1257/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
      "Epoch 1258/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 0.0421 - val_accuracy: 0.9879\n",
      "Epoch 1259/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0374 - accuracy: 0.9858 - val_loss: 0.0444 - val_accuracy: 0.9874\n",
      "Epoch 1260/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9889 - val_loss: 0.0419 - val_accuracy: 0.9874\n",
      "Epoch 1261/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0283 - accuracy: 0.9898 - val_loss: 0.0421 - val_accuracy: 0.9874\n",
      "Epoch 1262/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0303 - accuracy: 0.9904 - val_loss: 0.0407 - val_accuracy: 0.9869\n",
      "Epoch 1263/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9900 - val_loss: 0.0418 - val_accuracy: 0.9874\n",
      "Epoch 1264/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0273 - accuracy: 0.9895 - val_loss: 0.0414 - val_accuracy: 0.9874\n",
      "Epoch 1265/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0302 - accuracy: 0.9888 - val_loss: 0.0410 - val_accuracy: 0.9879\n",
      "Epoch 1266/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 0.0414 - val_accuracy: 0.9883\n",
      "Epoch 1267/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9907 - val_loss: 0.0466 - val_accuracy: 0.9869\n",
      "Epoch 1268/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0291 - accuracy: 0.9920 - val_loss: 0.0419 - val_accuracy: 0.9874\n",
      "Epoch 1269/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.0420 - val_accuracy: 0.9883\n",
      "Epoch 1270/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0300 - accuracy: 0.9898 - val_loss: 0.0538 - val_accuracy: 0.9860\n",
      "Epoch 1271/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 0.0433 - val_accuracy: 0.9869\n",
      "Epoch 1272/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0371 - accuracy: 0.9871 - val_loss: 0.0418 - val_accuracy: 0.9869\n",
      "Epoch 1273/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9932 - val_loss: 0.0428 - val_accuracy: 0.9869\n",
      "Epoch 1274/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9928 - val_loss: 0.0424 - val_accuracy: 0.9874\n",
      "Epoch 1275/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0340 - accuracy: 0.9909 - val_loss: 0.0469 - val_accuracy: 0.9865\n",
      "Epoch 1276/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0273 - accuracy: 0.9916 - val_loss: 0.0434 - val_accuracy: 0.9860\n",
      "Epoch 1277/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.0428 - val_accuracy: 0.9869\n",
      "Epoch 1278/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0413 - val_accuracy: 0.9879\n",
      "Epoch 1279/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 0.0508 - val_accuracy: 0.9841\n",
      "Epoch 1280/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 0.0410 - val_accuracy: 0.9874\n",
      "Epoch 1281/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.0509 - val_accuracy: 0.9841\n",
      "Epoch 1282/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0301 - accuracy: 0.9897 - val_loss: 0.0581 - val_accuracy: 0.9804\n",
      "Epoch 1283/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0357 - accuracy: 0.9895 - val_loss: 0.0423 - val_accuracy: 0.9874\n",
      "Epoch 1284/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0412 - accuracy: 0.9887 - val_loss: 0.0401 - val_accuracy: 0.9879\n",
      "Epoch 1285/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0469 - accuracy: 0.9871 - val_loss: 0.0433 - val_accuracy: 0.9874\n",
      "Epoch 1286/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 0.0461 - val_accuracy: 0.9879\n",
      "Epoch 1287/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0380 - accuracy: 0.9870 - val_loss: 0.0450 - val_accuracy: 0.9879\n",
      "Epoch 1288/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0349 - accuracy: 0.9876 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1289/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9897 - val_loss: 0.0426 - val_accuracy: 0.9879\n",
      "Epoch 1290/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 0.0409 - val_accuracy: 0.9879\n",
      "Epoch 1291/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.0424 - val_accuracy: 0.9869\n",
      "Epoch 1292/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9919 - val_loss: 0.0455 - val_accuracy: 0.9879\n",
      "Epoch 1293/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.0485 - val_accuracy: 0.9865\n",
      "Epoch 1294/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 0.0467 - val_accuracy: 0.9869\n",
      "Epoch 1295/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0327 - accuracy: 0.9899 - val_loss: 0.0407 - val_accuracy: 0.9869\n",
      "Epoch 1296/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.0414 - val_accuracy: 0.9865\n",
      "Epoch 1297/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0295 - accuracy: 0.9894 - val_loss: 0.0415 - val_accuracy: 0.9874\n",
      "Epoch 1298/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0308 - accuracy: 0.9912 - val_loss: 0.0415 - val_accuracy: 0.9879\n",
      "Epoch 1299/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0421 - val_accuracy: 0.9874\n",
      "Epoch 1300/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0390 - accuracy: 0.9873 - val_loss: 0.0403 - val_accuracy: 0.9879\n",
      "Epoch 1301/3500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0266 - accuracy: 0.9908 - val_loss: 0.0415 - val_accuracy: 0.9869\n",
      "Epoch 1302/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.0418 - val_accuracy: 0.9874\n",
      "Epoch 1303/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 0.0409 - val_accuracy: 0.9879\n",
      "Epoch 1304/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0249 - accuracy: 0.9924 - val_loss: 0.0412 - val_accuracy: 0.9879\n",
      "Epoch 1305/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.0467 - val_accuracy: 0.9879\n",
      "Epoch 1306/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0266 - accuracy: 0.9917 - val_loss: 0.0406 - val_accuracy: 0.9869\n",
      "Epoch 1307/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9925 - val_loss: 0.0453 - val_accuracy: 0.9879\n",
      "Epoch 1308/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9919 - val_loss: 0.0477 - val_accuracy: 0.9874\n",
      "Epoch 1309/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.0672 - val_accuracy: 0.9786\n",
      "Epoch 1310/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0367 - accuracy: 0.9879 - val_loss: 0.1008 - val_accuracy: 0.9678\n",
      "Epoch 1311/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0520 - accuracy: 0.9835 - val_loss: 0.0490 - val_accuracy: 0.9865\n",
      "Epoch 1312/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 0.0484 - val_accuracy: 0.9869\n",
      "Epoch 1313/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0310 - accuracy: 0.9886 - val_loss: 0.0476 - val_accuracy: 0.9860\n",
      "Epoch 1314/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.0439 - val_accuracy: 0.9879\n",
      "Epoch 1315/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9924 - val_loss: 0.0428 - val_accuracy: 0.9874\n",
      "Epoch 1316/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 0.0429 - val_accuracy: 0.9879\n",
      "Epoch 1317/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0263 - accuracy: 0.9926 - val_loss: 0.0526 - val_accuracy: 0.9837\n",
      "Epoch 1318/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0441 - val_accuracy: 0.9874\n",
      "Epoch 1319/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.0473 - val_accuracy: 0.9883\n",
      "Epoch 1320/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0285 - accuracy: 0.9929 - val_loss: 0.0409 - val_accuracy: 0.9879\n",
      "Epoch 1321/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0291 - accuracy: 0.9895 - val_loss: 0.0412 - val_accuracy: 0.9879\n",
      "Epoch 1322/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.0422 - val_accuracy: 0.9883\n",
      "Epoch 1323/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 0.0455 - val_accuracy: 0.9851\n",
      "Epoch 1324/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0285 - accuracy: 0.9927 - val_loss: 0.0502 - val_accuracy: 0.9860\n",
      "Epoch 1325/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 0.0444 - val_accuracy: 0.9869\n",
      "Epoch 1326/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
      "Epoch 1327/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.0537 - val_accuracy: 0.9837\n",
      "Epoch 1328/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0355 - accuracy: 0.9910 - val_loss: 0.0645 - val_accuracy: 0.9786\n",
      "Epoch 1329/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0352 - accuracy: 0.9901 - val_loss: 0.0671 - val_accuracy: 0.9781\n",
      "Epoch 1330/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 0.0656 - val_accuracy: 0.9790\n",
      "Epoch 1331/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0343 - accuracy: 0.9879 - val_loss: 0.0663 - val_accuracy: 0.9776\n",
      "Epoch 1332/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0429 - accuracy: 0.9873 - val_loss: 0.0553 - val_accuracy: 0.9804\n",
      "Epoch 1333/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9884 - val_loss: 0.0509 - val_accuracy: 0.9855\n",
      "Epoch 1334/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0517 - val_accuracy: 0.9860\n",
      "Epoch 1335/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.0408 - val_accuracy: 0.9874\n",
      "Epoch 1336/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9926 - val_loss: 0.0407 - val_accuracy: 0.9883\n",
      "Epoch 1337/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0432 - val_accuracy: 0.9874\n",
      "Epoch 1338/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.0429 - val_accuracy: 0.9879\n",
      "Epoch 1339/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0427 - val_accuracy: 0.9879\n",
      "Epoch 1340/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0265 - accuracy: 0.9907 - val_loss: 0.0441 - val_accuracy: 0.9874\n",
      "Epoch 1341/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.0507 - val_accuracy: 0.9851\n",
      "Epoch 1342/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0317 - accuracy: 0.9874 - val_loss: 0.0416 - val_accuracy: 0.9874\n",
      "Epoch 1343/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.0600 - val_accuracy: 0.9800\n",
      "Epoch 1344/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 0.0427 - val_accuracy: 0.9874\n",
      "Epoch 1345/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9941 - val_loss: 0.0485 - val_accuracy: 0.9874\n",
      "Epoch 1346/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9922 - val_loss: 0.0456 - val_accuracy: 0.9860\n",
      "Epoch 1347/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0435 - val_accuracy: 0.9879\n",
      "Epoch 1348/3500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.0432 - val_accuracy: 0.9865\n",
      "Epoch 1349/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.0431 - val_accuracy: 0.9874\n",
      "Epoch 1350/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 0.9906 - val_loss: 0.0426 - val_accuracy: 0.9869\n",
      "Epoch 1351/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0391 - accuracy: 0.9849 - val_loss: 0.0436 - val_accuracy: 0.9879\n",
      "Epoch 1352/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 0.0438 - val_accuracy: 0.9883\n",
      "Epoch 1353/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0266 - accuracy: 0.9926 - val_loss: 0.0439 - val_accuracy: 0.9879\n",
      "Epoch 1354/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0306 - accuracy: 0.9908 - val_loss: 0.0447 - val_accuracy: 0.9865\n",
      "Epoch 1355/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0287 - accuracy: 0.9930 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1356/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9932 - val_loss: 0.0409 - val_accuracy: 0.9874\n",
      "Epoch 1357/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9934 - val_loss: 0.0412 - val_accuracy: 0.9879\n",
      "Epoch 1358/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9890 - val_loss: 0.0446 - val_accuracy: 0.9879\n",
      "Epoch 1359/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0319 - accuracy: 0.9898 - val_loss: 0.0530 - val_accuracy: 0.9865\n",
      "Epoch 1360/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.0413 - val_accuracy: 0.9883\n",
      "Epoch 1361/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 0.0428 - val_accuracy: 0.9879\n",
      "Epoch 1362/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0338 - accuracy: 0.9901 - val_loss: 0.0501 - val_accuracy: 0.9865\n",
      "Epoch 1363/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0278 - accuracy: 0.9924 - val_loss: 0.0425 - val_accuracy: 0.9874\n",
      "Epoch 1364/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9913 - val_loss: 0.0411 - val_accuracy: 0.9879\n",
      "Epoch 1365/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0408 - val_accuracy: 0.9883\n",
      "Epoch 1366/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 0.0410 - val_accuracy: 0.9883\n",
      "Epoch 1367/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.0407 - val_accuracy: 0.9874\n",
      "Epoch 1368/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 0.0406 - val_accuracy: 0.9879\n",
      "Epoch 1369/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 0.0437 - val_accuracy: 0.9879\n",
      "Epoch 1370/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0354 - accuracy: 0.9896 - val_loss: 0.0421 - val_accuracy: 0.9879\n",
      "Epoch 1371/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.0424 - val_accuracy: 0.9874\n",
      "Epoch 1372/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0283 - accuracy: 0.9901 - val_loss: 0.0433 - val_accuracy: 0.9869\n",
      "Epoch 1373/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9930 - val_loss: 0.0515 - val_accuracy: 0.9860\n",
      "Epoch 1374/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9920 - val_loss: 0.0526 - val_accuracy: 0.9846\n",
      "Epoch 1375/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9925 - val_loss: 0.0434 - val_accuracy: 0.9883\n",
      "Epoch 1376/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9927 - val_loss: 0.0434 - val_accuracy: 0.9874\n",
      "Epoch 1377/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.0421 - val_accuracy: 0.9874\n",
      "Epoch 1378/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0428 - val_accuracy: 0.9874\n",
      "Epoch 1379/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9934 - val_loss: 0.0425 - val_accuracy: 0.9869\n",
      "Epoch 1380/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.9932 - val_loss: 0.0409 - val_accuracy: 0.9874\n",
      "Epoch 1381/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9928 - val_loss: 0.0426 - val_accuracy: 0.9874\n",
      "Epoch 1382/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9918 - val_loss: 0.0444 - val_accuracy: 0.9865\n",
      "Epoch 1383/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 0.0413 - val_accuracy: 0.9879\n",
      "Epoch 1384/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0302 - accuracy: 0.9909 - val_loss: 0.0416 - val_accuracy: 0.9883\n",
      "Epoch 1385/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.0407 - val_accuracy: 0.9883\n",
      "Epoch 1386/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9929 - val_loss: 0.0421 - val_accuracy: 0.9883\n",
      "Epoch 1387/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.0444 - val_accuracy: 0.9869\n",
      "Epoch 1388/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0313 - accuracy: 0.9915 - val_loss: 0.0439 - val_accuracy: 0.9869\n",
      "Epoch 1389/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9934 - val_loss: 0.0441 - val_accuracy: 0.9865\n",
      "Epoch 1390/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 0.0504 - val_accuracy: 0.9865\n",
      "Epoch 1391/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.0542 - val_accuracy: 0.9841\n",
      "Epoch 1392/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0339 - accuracy: 0.9909 - val_loss: 0.0582 - val_accuracy: 0.9823\n",
      "Epoch 1393/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0340 - accuracy: 0.9884 - val_loss: 0.0434 - val_accuracy: 0.9879\n",
      "Epoch 1394/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0411 - val_accuracy: 0.9883\n",
      "Epoch 1395/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0411 - val_accuracy: 0.9874\n",
      "Epoch 1396/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1397/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.0425 - val_accuracy: 0.9879\n",
      "Epoch 1398/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.0410 - val_accuracy: 0.9879\n",
      "Epoch 1399/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 0.0431 - val_accuracy: 0.9879\n",
      "Epoch 1400/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0256 - accuracy: 0.9938 - val_loss: 0.0416 - val_accuracy: 0.9874\n",
      "Epoch 1401/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.0444 - val_accuracy: 0.9879\n",
      "Epoch 1402/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0363 - accuracy: 0.9879 - val_loss: 0.0495 - val_accuracy: 0.9879\n",
      "Epoch 1403/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0528 - val_accuracy: 0.9879\n",
      "Epoch 1404/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0427 - accuracy: 0.9868 - val_loss: 0.0416 - val_accuracy: 0.9874\n",
      "Epoch 1405/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 0.0417 - val_accuracy: 0.9869\n",
      "Epoch 1406/3500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.0484 - val_accuracy: 0.9879\n",
      "Epoch 1407/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0323 - accuracy: 0.9911 - val_loss: 0.0469 - val_accuracy: 0.9879\n",
      "Epoch 1408/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0378 - accuracy: 0.9891 - val_loss: 0.0601 - val_accuracy: 0.9804\n",
      "Epoch 1409/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0311 - accuracy: 0.9925 - val_loss: 0.0421 - val_accuracy: 0.9874\n",
      "Epoch 1410/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.0455 - val_accuracy: 0.9879\n",
      "Epoch 1411/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0288 - accuracy: 0.9917 - val_loss: 0.0434 - val_accuracy: 0.9888\n",
      "Epoch 1412/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.0420 - val_accuracy: 0.9883\n",
      "Epoch 1413/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 0.0414 - val_accuracy: 0.9874\n",
      "Epoch 1414/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.0443 - val_accuracy: 0.9869\n",
      "Epoch 1415/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0283 - accuracy: 0.9917 - val_loss: 0.0424 - val_accuracy: 0.9874\n",
      "Epoch 1416/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 0.0426 - val_accuracy: 0.9879\n",
      "Epoch 1417/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9890 - val_loss: 0.0411 - val_accuracy: 0.9874\n",
      "Epoch 1418/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.0432 - val_accuracy: 0.9883\n",
      "Epoch 1419/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.0417 - val_accuracy: 0.9883\n",
      "Epoch 1420/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.0431 - val_accuracy: 0.9879\n",
      "Epoch 1421/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.0445 - val_accuracy: 0.9883\n",
      "Epoch 1422/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9940 - val_loss: 0.0408 - val_accuracy: 0.9874\n",
      "Epoch 1423/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.0422 - val_accuracy: 0.9879\n",
      "Epoch 1424/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 0.0587 - val_accuracy: 0.9818\n",
      "Epoch 1425/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0323 - accuracy: 0.9904 - val_loss: 0.0512 - val_accuracy: 0.9851\n",
      "Epoch 1426/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.0410 - val_accuracy: 0.9879\n",
      "Epoch 1427/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 0.0423 - val_accuracy: 0.9883\n",
      "Epoch 1428/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0337 - accuracy: 0.9897 - val_loss: 0.0417 - val_accuracy: 0.9883\n",
      "Epoch 1429/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0335 - accuracy: 0.9908 - val_loss: 0.0423 - val_accuracy: 0.9879\n",
      "Epoch 1430/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 0.0619 - val_accuracy: 0.9790\n",
      "Epoch 1431/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.0888 - val_accuracy: 0.9725\n",
      "Epoch 1432/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.0580 - val_accuracy: 0.9800\n",
      "Epoch 1433/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0346 - accuracy: 0.9897 - val_loss: 0.0429 - val_accuracy: 0.9874\n",
      "Epoch 1434/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0261 - accuracy: 0.9908 - val_loss: 0.0455 - val_accuracy: 0.9883\n",
      "Epoch 1435/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 0.0416 - val_accuracy: 0.9883\n",
      "Epoch 1436/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9899 - val_loss: 0.0424 - val_accuracy: 0.9874\n",
      "Epoch 1437/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.0441 - val_accuracy: 0.9869\n",
      "Epoch 1438/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.0435 - val_accuracy: 0.9879\n",
      "Epoch 1439/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0357 - accuracy: 0.9899 - val_loss: 0.0473 - val_accuracy: 0.9879\n",
      "Epoch 1440/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0436 - accuracy: 0.9877 - val_loss: 0.0460 - val_accuracy: 0.9869\n",
      "Epoch 1441/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9922 - val_loss: 0.0460 - val_accuracy: 0.9869\n",
      "Epoch 1442/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9908 - val_loss: 0.0420 - val_accuracy: 0.9879\n",
      "Epoch 1443/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.0416 - val_accuracy: 0.9874\n",
      "Epoch 1444/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 0.0432 - val_accuracy: 0.9883\n",
      "Epoch 1445/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0307 - accuracy: 0.9898 - val_loss: 0.0420 - val_accuracy: 0.9874\n",
      "Epoch 1446/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 0.0419 - val_accuracy: 0.9869\n",
      "Epoch 1447/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0233 - accuracy: 0.9948 - val_loss: 0.0410 - val_accuracy: 0.9879\n",
      "Epoch 1448/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9940 - val_loss: 0.0413 - val_accuracy: 0.9883\n",
      "Epoch 1449/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0354 - accuracy: 0.9898 - val_loss: 0.0535 - val_accuracy: 0.9846\n",
      "Epoch 1450/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 0.0475 - val_accuracy: 0.9879\n",
      "Epoch 1451/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0276 - accuracy: 0.9925 - val_loss: 0.0493 - val_accuracy: 0.9865\n",
      "Epoch 1452/3500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 0.0481 - val_accuracy: 0.9879\n",
      "Epoch 1453/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0248 - accuracy: 0.9940 - val_loss: 0.0635 - val_accuracy: 0.9790\n",
      "Epoch 1454/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0350 - accuracy: 0.9898 - val_loss: 0.0635 - val_accuracy: 0.9790\n",
      "Epoch 1455/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0285 - accuracy: 0.9897 - val_loss: 0.0525 - val_accuracy: 0.9841\n",
      "Epoch 1456/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9903 - val_loss: 0.0566 - val_accuracy: 0.9814\n",
      "Epoch 1457/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.9922 - val_loss: 0.0700 - val_accuracy: 0.9772\n",
      "Epoch 1458/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0317 - accuracy: 0.9870 - val_loss: 0.0549 - val_accuracy: 0.9841\n",
      "Epoch 1459/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 0.0417 - val_accuracy: 0.9879\n",
      "Epoch 1460/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.0428 - val_accuracy: 0.9869\n",
      "Epoch 1461/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0270 - accuracy: 0.9919 - val_loss: 0.0454 - val_accuracy: 0.9883\n",
      "Epoch 1462/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9930 - val_loss: 0.0530 - val_accuracy: 0.9851\n",
      "Epoch 1463/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.0488 - val_accuracy: 0.9869\n",
      "Epoch 1464/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.0440 - val_accuracy: 0.9879\n",
      "Epoch 1465/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 0.0420 - val_accuracy: 0.9879\n",
      "Epoch 1466/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 0.0433 - val_accuracy: 0.9865\n",
      "Epoch 1467/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0233 - accuracy: 0.9935 - val_loss: 0.0453 - val_accuracy: 0.9869\n",
      "Epoch 1468/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0280 - accuracy: 0.9934 - val_loss: 0.0460 - val_accuracy: 0.9865\n",
      "Epoch 1469/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 0.0452 - val_accuracy: 0.9888\n",
      "Epoch 1470/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0305 - accuracy: 0.9920 - val_loss: 0.0417 - val_accuracy: 0.9874\n",
      "Epoch 1471/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0250 - accuracy: 0.9914 - val_loss: 0.0440 - val_accuracy: 0.9869\n",
      "Epoch 1472/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0736 - val_accuracy: 0.9762\n",
      "Epoch 1473/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.0440 - val_accuracy: 0.9883\n",
      "Epoch 1474/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0344 - accuracy: 0.9894 - val_loss: 0.0499 - val_accuracy: 0.9874\n",
      "Epoch 1475/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0518 - accuracy: 0.9852 - val_loss: 0.0429 - val_accuracy: 0.9874\n",
      "Epoch 1476/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0501 - val_accuracy: 0.9879\n",
      "Epoch 1477/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0400 - accuracy: 0.9883 - val_loss: 0.0423 - val_accuracy: 0.9879\n",
      "Epoch 1478/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9940 - val_loss: 0.0453 - val_accuracy: 0.9874\n",
      "Epoch 1479/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0288 - accuracy: 0.9929 - val_loss: 0.0467 - val_accuracy: 0.9879\n",
      "Epoch 1480/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.0638 - val_accuracy: 0.9814\n",
      "Epoch 1481/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0370 - accuracy: 0.9875 - val_loss: 0.0740 - val_accuracy: 0.9772\n",
      "Epoch 1482/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.0517 - val_accuracy: 0.9869\n",
      "Epoch 1483/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9930 - val_loss: 0.0431 - val_accuracy: 0.9869\n",
      "Epoch 1484/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9934 - val_loss: 0.0423 - val_accuracy: 0.9874\n",
      "Epoch 1485/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.0420 - val_accuracy: 0.9874\n",
      "Epoch 1486/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.0420 - val_accuracy: 0.9874\n",
      "Epoch 1487/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 0.0417 - val_accuracy: 0.9883\n",
      "Epoch 1488/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0297 - accuracy: 0.9890 - val_loss: 0.0413 - val_accuracy: 0.9883\n",
      "Epoch 1489/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0297 - accuracy: 0.9919 - val_loss: 0.0432 - val_accuracy: 0.9865\n",
      "Epoch 1490/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1491/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9929 - val_loss: 0.0431 - val_accuracy: 0.9869\n",
      "Epoch 1492/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0326 - accuracy: 0.9884 - val_loss: 0.0412 - val_accuracy: 0.9874\n",
      "Epoch 1493/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.0414 - val_accuracy: 0.9879\n",
      "Epoch 1494/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0283 - accuracy: 0.9904 - val_loss: 0.0468 - val_accuracy: 0.9879\n",
      "Epoch 1495/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9939 - val_loss: 0.0488 - val_accuracy: 0.9869\n",
      "Epoch 1496/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9926 - val_loss: 0.0469 - val_accuracy: 0.9860\n",
      "Epoch 1497/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.0430 - val_accuracy: 0.9879\n",
      "Epoch 1498/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 0.0410 - val_accuracy: 0.9874\n",
      "Epoch 1499/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0283 - accuracy: 0.9926 - val_loss: 0.0423 - val_accuracy: 0.9879\n",
      "Epoch 1500/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0276 - accuracy: 0.9923 - val_loss: 0.0408 - val_accuracy: 0.9874\n",
      "Epoch 1501/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 0.0455 - val_accuracy: 0.9874\n",
      "Epoch 1502/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 0.0586 - val_accuracy: 0.9832\n",
      "Epoch 1503/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0360 - accuracy: 0.9902 - val_loss: 0.0481 - val_accuracy: 0.9869\n",
      "Epoch 1504/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.9935 - val_loss: 0.0458 - val_accuracy: 0.9869\n",
      "Epoch 1505/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0294 - accuracy: 0.9917 - val_loss: 0.0441 - val_accuracy: 0.9888\n",
      "Epoch 1506/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.0416 - val_accuracy: 0.9883\n",
      "Epoch 1507/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0276 - accuracy: 0.9918 - val_loss: 0.0449 - val_accuracy: 0.9879\n",
      "Epoch 1508/3500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.0439 - val_accuracy: 0.9874\n",
      "Epoch 1509/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.0565 - val_accuracy: 0.9823\n",
      "Epoch 1510/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9925 - val_loss: 0.0508 - val_accuracy: 0.9855\n",
      "Epoch 1511/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0272 - accuracy: 0.9917 - val_loss: 0.0688 - val_accuracy: 0.9790\n",
      "Epoch 1512/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0346 - accuracy: 0.9885 - val_loss: 0.0728 - val_accuracy: 0.9758\n",
      "Epoch 1513/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0369 - accuracy: 0.9878 - val_loss: 0.0499 - val_accuracy: 0.9879\n",
      "Epoch 1514/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.0808 - val_accuracy: 0.9744\n",
      "Epoch 1515/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0451 - accuracy: 0.9871 - val_loss: 0.0607 - val_accuracy: 0.9814\n",
      "Epoch 1516/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0420 - accuracy: 0.9875 - val_loss: 0.0546 - val_accuracy: 0.9846\n",
      "Epoch 1517/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.0543 - val_accuracy: 0.9837\n",
      "Epoch 1518/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.0434 - val_accuracy: 0.9879\n",
      "Epoch 1519/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9940 - val_loss: 0.0553 - val_accuracy: 0.9846\n",
      "Epoch 1520/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9923 - val_loss: 0.0476 - val_accuracy: 0.9869\n",
      "Epoch 1521/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9950 - val_loss: 0.0417 - val_accuracy: 0.9874\n",
      "Epoch 1522/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 0.0444 - val_accuracy: 0.9874\n",
      "Epoch 1523/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.0418 - val_accuracy: 0.9883\n",
      "Epoch 1524/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0287 - accuracy: 0.9913 - val_loss: 0.0417 - val_accuracy: 0.9879\n",
      "Epoch 1525/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.0419 - val_accuracy: 0.9874\n",
      "Epoch 1526/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.0454 - val_accuracy: 0.9869\n",
      "Epoch 1527/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0310 - accuracy: 0.9918 - val_loss: 0.0459 - val_accuracy: 0.9879\n",
      "Epoch 1528/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1529/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9902 - val_loss: 0.0435 - val_accuracy: 0.9874\n",
      "Epoch 1530/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0299 - accuracy: 0.9890 - val_loss: 0.0429 - val_accuracy: 0.9879\n",
      "Epoch 1531/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 0.0428 - val_accuracy: 0.9879\n",
      "Epoch 1532/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9949 - val_loss: 0.0540 - val_accuracy: 0.9860\n",
      "Epoch 1533/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 0.0443 - val_accuracy: 0.9879\n",
      "Epoch 1534/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.0432 - val_accuracy: 0.9883\n",
      "Epoch 1535/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.0413 - val_accuracy: 0.9874\n",
      "Epoch 1536/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.0422 - val_accuracy: 0.9879\n",
      "Epoch 1537/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 0.0426 - val_accuracy: 0.9879\n",
      "Epoch 1538/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 0.0419 - val_accuracy: 0.9888\n",
      "Epoch 1539/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0275 - accuracy: 0.9913 - val_loss: 0.0421 - val_accuracy: 0.9874\n",
      "Epoch 1540/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.0452 - val_accuracy: 0.9879\n",
      "Epoch 1541/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9934 - val_loss: 0.0448 - val_accuracy: 0.9869\n",
      "Epoch 1542/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.0413 - val_accuracy: 0.9879\n",
      "Epoch 1543/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.0469 - val_accuracy: 0.9879\n",
      "Epoch 1544/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9929 - val_loss: 0.0434 - val_accuracy: 0.9874\n",
      "Epoch 1545/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.0420 - val_accuracy: 0.9879\n",
      "Epoch 1546/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9892 - val_loss: 0.0411 - val_accuracy: 0.9883\n",
      "Epoch 1547/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0493 - val_accuracy: 0.9869\n",
      "Epoch 1548/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0510 - val_accuracy: 0.9846\n",
      "Epoch 1549/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.0601 - val_accuracy: 0.9804\n",
      "Epoch 1550/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 0.0466 - val_accuracy: 0.9874\n",
      "Epoch 1551/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.0426 - val_accuracy: 0.9874\n",
      "Epoch 1552/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.0433 - val_accuracy: 0.9869\n",
      "Epoch 1553/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.0427 - val_accuracy: 0.9883\n",
      "Epoch 1554/3500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0422 - val_accuracy: 0.9869\n",
      "Epoch 1555/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.0427 - val_accuracy: 0.9879\n",
      "Epoch 1556/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9927 - val_loss: 0.0567 - val_accuracy: 0.9828\n",
      "Epoch 1557/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.0423 - val_accuracy: 0.9874\n",
      "Epoch 1558/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1559/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
      "Epoch 1560/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9930 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
      "Epoch 1561/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9915 - val_loss: 0.0425 - val_accuracy: 0.9879\n",
      "Epoch 1562/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0303 - accuracy: 0.9908 - val_loss: 0.0418 - val_accuracy: 0.9883\n",
      "Epoch 1563/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.0433 - val_accuracy: 0.9874\n",
      "Epoch 1564/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9951 - val_loss: 0.0422 - val_accuracy: 0.9879\n",
      "Epoch 1565/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 0.0460 - val_accuracy: 0.9874\n",
      "Epoch 1566/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9941 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1567/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.0413 - val_accuracy: 0.9869\n",
      "Epoch 1568/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.0432 - val_accuracy: 0.9869\n",
      "Epoch 1569/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.0437 - val_accuracy: 0.9888\n",
      "Epoch 1570/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0470 - val_accuracy: 0.9865\n",
      "Epoch 1571/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.0573 - val_accuracy: 0.9841\n",
      "Epoch 1572/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.0472 - val_accuracy: 0.9869\n",
      "Epoch 1573/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9938 - val_loss: 0.0444 - val_accuracy: 0.9869\n",
      "Epoch 1574/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0433 - val_accuracy: 0.9879\n",
      "Epoch 1575/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.0459 - val_accuracy: 0.9869\n",
      "Epoch 1576/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9938 - val_loss: 0.0466 - val_accuracy: 0.9874\n",
      "Epoch 1577/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9932 - val_loss: 0.0416 - val_accuracy: 0.9879\n",
      "Epoch 1578/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.0454 - val_accuracy: 0.9888\n",
      "Epoch 1579/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.0520 - val_accuracy: 0.9846\n",
      "Epoch 1580/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.0419 - val_accuracy: 0.9883\n",
      "Epoch 1581/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 0.0423 - val_accuracy: 0.9874\n",
      "Epoch 1582/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9934 - val_loss: 0.0409 - val_accuracy: 0.9883\n",
      "Epoch 1583/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.0487 - val_accuracy: 0.9860\n",
      "Epoch 1584/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0322 - accuracy: 0.9907 - val_loss: 0.0508 - val_accuracy: 0.9855\n",
      "Epoch 1585/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0344 - accuracy: 0.9899 - val_loss: 0.0500 - val_accuracy: 0.9869\n",
      "Epoch 1586/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0265 - accuracy: 0.9939 - val_loss: 0.0607 - val_accuracy: 0.9818\n",
      "Epoch 1587/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9901 - val_loss: 0.0460 - val_accuracy: 0.9874\n",
      "Epoch 1588/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.0494 - val_accuracy: 0.9865\n",
      "Epoch 1589/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.0445 - val_accuracy: 0.9879\n",
      "Epoch 1590/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.0423 - val_accuracy: 0.9869\n",
      "Epoch 1591/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0299 - accuracy: 0.9894 - val_loss: 0.0426 - val_accuracy: 0.9879\n",
      "Epoch 1592/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.0427 - val_accuracy: 0.9874\n",
      "Epoch 1593/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.0442 - val_accuracy: 0.9879\n",
      "Epoch 1594/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0334 - accuracy: 0.9866 - val_loss: 0.0514 - val_accuracy: 0.9874\n",
      "Epoch 1595/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0384 - accuracy: 0.9880 - val_loss: 0.0449 - val_accuracy: 0.9879\n",
      "Epoch 1596/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9917 - val_loss: 0.0415 - val_accuracy: 0.9874\n",
      "Epoch 1597/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0496 - val_accuracy: 0.9874\n",
      "Epoch 1598/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 0.0448 - val_accuracy: 0.9883\n",
      "Epoch 1599/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.0513 - val_accuracy: 0.9865\n",
      "Epoch 1600/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.0488 - val_accuracy: 0.9869\n",
      "Epoch 1601/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9935 - val_loss: 0.0559 - val_accuracy: 0.9841\n",
      "Epoch 1602/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9908 - val_loss: 0.0758 - val_accuracy: 0.9767\n",
      "Epoch 1603/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.0576 - val_accuracy: 0.9823\n",
      "Epoch 1604/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 0.0475 - val_accuracy: 0.9869\n",
      "Epoch 1605/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.0421 - val_accuracy: 0.9874\n",
      "Epoch 1606/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 0.0424 - val_accuracy: 0.9874\n",
      "Epoch 1607/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.0446 - val_accuracy: 0.9879\n",
      "Epoch 1608/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 0.0464 - val_accuracy: 0.9874\n",
      "Epoch 1609/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9935 - val_loss: 0.0421 - val_accuracy: 0.9874\n",
      "Epoch 1610/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0246 - accuracy: 0.9934 - val_loss: 0.0431 - val_accuracy: 0.9879\n",
      "Epoch 1611/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.0411 - val_accuracy: 0.9888\n",
      "Epoch 1612/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 0.0481 - val_accuracy: 0.9879\n",
      "Epoch 1613/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 0.0603 - val_accuracy: 0.9818\n",
      "Epoch 1614/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0370 - accuracy: 0.9858 - val_loss: 0.0478 - val_accuracy: 0.9874\n",
      "Epoch 1615/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0312 - accuracy: 0.9890 - val_loss: 0.0423 - val_accuracy: 0.9869\n",
      "Epoch 1616/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9913 - val_loss: 0.0480 - val_accuracy: 0.9879\n",
      "Epoch 1617/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0290 - accuracy: 0.9914 - val_loss: 0.0466 - val_accuracy: 0.9869\n",
      "Epoch 1618/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9945 - val_loss: 0.0661 - val_accuracy: 0.9790\n",
      "Epoch 1619/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0263 - accuracy: 0.9896 - val_loss: 0.0488 - val_accuracy: 0.9869\n",
      "Epoch 1620/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9932 - val_loss: 0.0418 - val_accuracy: 0.9874\n",
      "Epoch 1621/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0450 - val_accuracy: 0.9879\n",
      "Epoch 1622/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 0.9881 - val_loss: 0.0478 - val_accuracy: 0.9874\n",
      "Epoch 1623/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0428 - accuracy: 0.9854 - val_loss: 0.0467 - val_accuracy: 0.9874\n",
      "Epoch 1624/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.0488 - val_accuracy: 0.9874\n",
      "Epoch 1625/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9909 - val_loss: 0.0446 - val_accuracy: 0.9874\n",
      "Epoch 1626/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 0.0432 - val_accuracy: 0.9879\n",
      "Epoch 1627/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 1628/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0580 - val_accuracy: 0.9832\n",
      "Epoch 1629/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 0.0426 - val_accuracy: 0.9883\n",
      "Epoch 1630/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0271 - accuracy: 0.9906 - val_loss: 0.0460 - val_accuracy: 0.9879\n",
      "Epoch 1631/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0282 - accuracy: 0.9916 - val_loss: 0.0616 - val_accuracy: 0.9800\n",
      "Epoch 1632/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.0439 - val_accuracy: 0.9879\n",
      "Epoch 1633/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0450 - val_accuracy: 0.9883\n",
      "Epoch 1634/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9934 - val_loss: 0.0426 - val_accuracy: 0.9879\n",
      "Epoch 1635/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 0.0417 - val_accuracy: 0.9879\n",
      "Epoch 1636/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9936 - val_loss: 0.0428 - val_accuracy: 0.9874\n",
      "Epoch 1637/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.0439 - val_accuracy: 0.9865\n",
      "Epoch 1638/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.0465 - val_accuracy: 0.9869\n",
      "Epoch 1639/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.0426 - val_accuracy: 0.9879\n",
      "Epoch 1640/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 0.0447 - val_accuracy: 0.9874\n",
      "Epoch 1641/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9912 - val_loss: 0.0447 - val_accuracy: 0.9874\n",
      "Epoch 1642/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0312 - accuracy: 0.9889 - val_loss: 0.0422 - val_accuracy: 0.9874\n",
      "Epoch 1643/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.0421 - val_accuracy: 0.9879\n",
      "Epoch 1644/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0302 - accuracy: 0.9902 - val_loss: 0.0443 - val_accuracy: 0.9879\n",
      "Epoch 1645/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9948 - val_loss: 0.0496 - val_accuracy: 0.9865\n",
      "Epoch 1646/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 0.0575 - val_accuracy: 0.9846\n",
      "Epoch 1647/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 0.0534 - val_accuracy: 0.9865\n",
      "Epoch 1648/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.0450 - val_accuracy: 0.9879\n",
      "Epoch 1649/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9935 - val_loss: 0.0436 - val_accuracy: 0.9879\n",
      "Epoch 1650/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.0460 - val_accuracy: 0.9883\n",
      "Epoch 1651/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9936 - val_loss: 0.0523 - val_accuracy: 0.9860\n",
      "Epoch 1652/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9932 - val_loss: 0.0493 - val_accuracy: 0.9879\n",
      "Epoch 1653/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 0.9929 - val_loss: 0.0436 - val_accuracy: 0.9874\n",
      "Epoch 1654/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.0425 - val_accuracy: 0.9869\n",
      "Epoch 1655/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 1656/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9939 - val_loss: 0.0487 - val_accuracy: 0.9869\n",
      "Epoch 1657/3500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 0.0435 - val_accuracy: 0.9879\n",
      "Epoch 1658/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 0.0434 - val_accuracy: 0.9879\n",
      "Epoch 1659/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.0427 - val_accuracy: 0.9883\n",
      "Epoch 1660/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0427 - val_accuracy: 0.9874\n",
      "Epoch 1661/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.0559 - val_accuracy: 0.9841\n",
      "Epoch 1662/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0493 - val_accuracy: 0.9869\n",
      "Epoch 1663/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.0418 - val_accuracy: 0.9879\n",
      "Epoch 1664/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 0.0423 - val_accuracy: 0.9879\n",
      "Epoch 1665/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.0641 - val_accuracy: 0.9800\n",
      "Epoch 1666/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0274 - accuracy: 0.9925 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 1667/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9917 - val_loss: 0.0427 - val_accuracy: 0.9879\n",
      "Epoch 1668/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.0443 - val_accuracy: 0.9879\n",
      "Epoch 1669/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.0543 - val_accuracy: 0.9846\n",
      "Epoch 1670/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0398 - accuracy: 0.9885 - val_loss: 0.0847 - val_accuracy: 0.9758\n",
      "Epoch 1671/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0624 - accuracy: 0.9789 - val_loss: 0.0898 - val_accuracy: 0.9744\n",
      "Epoch 1672/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0592 - accuracy: 0.9822 - val_loss: 0.0588 - val_accuracy: 0.9823\n",
      "Epoch 1673/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0431 - accuracy: 0.9861 - val_loss: 0.0458 - val_accuracy: 0.9869\n",
      "Epoch 1674/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0310 - accuracy: 0.9916 - val_loss: 0.0468 - val_accuracy: 0.9874\n",
      "Epoch 1675/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.0431 - val_accuracy: 0.9874\n",
      "Epoch 1676/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.0447 - val_accuracy: 0.9879\n",
      "Epoch 1677/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 0.9911 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
      "Epoch 1678/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.0423 - val_accuracy: 0.9874\n",
      "Epoch 1679/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 0.0442 - val_accuracy: 0.9879\n",
      "Epoch 1680/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0243 - accuracy: 0.9934 - val_loss: 0.0425 - val_accuracy: 0.9874\n",
      "Epoch 1681/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.0436 - val_accuracy: 0.9874\n",
      "Epoch 1682/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0489 - val_accuracy: 0.9874\n",
      "Epoch 1683/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 0.0467 - val_accuracy: 0.9879\n",
      "Epoch 1684/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 0.0533 - val_accuracy: 0.9860\n",
      "Epoch 1685/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
      "Epoch 1686/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0281 - accuracy: 0.9918 - val_loss: 0.0629 - val_accuracy: 0.9814\n",
      "Epoch 1687/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0263 - accuracy: 0.9924 - val_loss: 0.0461 - val_accuracy: 0.9883\n",
      "Epoch 1688/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.0461 - val_accuracy: 0.9869\n",
      "Epoch 1689/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9943 - val_loss: 0.0468 - val_accuracy: 0.9879\n",
      "Epoch 1690/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0420 - val_accuracy: 0.9874\n",
      "Epoch 1691/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.0499 - val_accuracy: 0.9874\n",
      "Epoch 1692/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0590 - val_accuracy: 0.9832\n",
      "Epoch 1693/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 0.9935 - val_loss: 0.0412 - val_accuracy: 0.9869\n",
      "Epoch 1694/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
      "Epoch 1695/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0440 - val_accuracy: 0.9874\n",
      "Epoch 1696/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.0444 - val_accuracy: 0.9874\n",
      "Epoch 1697/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.0432 - val_accuracy: 0.9869\n",
      "Epoch 1698/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0282 - accuracy: 0.9896 - val_loss: 0.0468 - val_accuracy: 0.9874\n",
      "Epoch 1699/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.0419 - val_accuracy: 0.9874\n",
      "Epoch 1700/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.9919 - val_loss: 0.0422 - val_accuracy: 0.9869\n",
      "Epoch 1701/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.0425 - val_accuracy: 0.9874\n",
      "Epoch 1702/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 1703/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 0.0432 - val_accuracy: 0.9879\n",
      "Epoch 1704/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9930 - val_loss: 0.0416 - val_accuracy: 0.9874\n",
      "Epoch 1705/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0474 - val_accuracy: 0.9869\n",
      "Epoch 1706/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0260 - accuracy: 0.9919 - val_loss: 0.0465 - val_accuracy: 0.9874\n",
      "Epoch 1707/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0492 - val_accuracy: 0.9869\n",
      "Epoch 1708/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
      "Epoch 1709/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 0.0434 - val_accuracy: 0.9874\n",
      "Epoch 1710/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9940 - val_loss: 0.0440 - val_accuracy: 0.9874\n",
      "Epoch 1711/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.0433 - val_accuracy: 0.9874\n",
      "Epoch 1712/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.0425 - val_accuracy: 0.9869\n",
      "Epoch 1713/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 0.0439 - val_accuracy: 0.9874\n",
      "Epoch 1714/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9935 - val_loss: 0.0476 - val_accuracy: 0.9874\n",
      "Epoch 1715/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 0.0544 - val_accuracy: 0.9841\n",
      "Epoch 1716/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0346 - accuracy: 0.9910 - val_loss: 0.0984 - val_accuracy: 0.9706\n",
      "Epoch 1717/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0439 - accuracy: 0.9870 - val_loss: 0.0612 - val_accuracy: 0.9809\n",
      "Epoch 1718/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0311 - accuracy: 0.9927 - val_loss: 0.0542 - val_accuracy: 0.9855\n",
      "Epoch 1719/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0364 - accuracy: 0.9877 - val_loss: 0.0433 - val_accuracy: 0.9879\n",
      "Epoch 1720/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0435 - val_accuracy: 0.9869\n",
      "Epoch 1721/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.0422 - val_accuracy: 0.9869\n",
      "Epoch 1722/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.0426 - val_accuracy: 0.9879\n",
      "Epoch 1723/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0304 - accuracy: 0.9910 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 1724/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0338 - accuracy: 0.9901 - val_loss: 0.0456 - val_accuracy: 0.9869\n",
      "Epoch 1725/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.0507 - val_accuracy: 0.9869\n",
      "Epoch 1726/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9940 - val_loss: 0.0478 - val_accuracy: 0.9883\n",
      "Epoch 1727/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.0483 - val_accuracy: 0.9869\n",
      "Epoch 1728/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.0416 - val_accuracy: 0.9888\n",
      "Epoch 1729/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0328 - accuracy: 0.9909 - val_loss: 0.0424 - val_accuracy: 0.9874\n",
      "Epoch 1730/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0272 - accuracy: 0.9904 - val_loss: 0.0435 - val_accuracy: 0.9874\n",
      "Epoch 1731/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0428 - val_accuracy: 0.9869\n",
      "Epoch 1732/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 0.0429 - val_accuracy: 0.9879\n",
      "Epoch 1733/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.0425 - val_accuracy: 0.9874\n",
      "Epoch 1734/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0314 - accuracy: 0.9895 - val_loss: 0.0467 - val_accuracy: 0.9874\n",
      "Epoch 1735/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0435 - val_accuracy: 0.9874\n",
      "Epoch 1736/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0415 - val_accuracy: 0.9879\n",
      "Epoch 1737/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 0.0429 - val_accuracy: 0.9874\n",
      "Epoch 1738/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.0470 - val_accuracy: 0.9879\n",
      "Epoch 1739/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 1740/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0436 - val_accuracy: 0.9874\n",
      "Epoch 1741/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 0.0431 - val_accuracy: 0.9869\n",
      "Epoch 1742/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.0502 - val_accuracy: 0.9869\n",
      "Epoch 1743/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.0441 - val_accuracy: 0.9865\n",
      "Epoch 1744/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.0439 - val_accuracy: 0.9869\n",
      "Epoch 1745/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 0.0432 - val_accuracy: 0.9874\n",
      "Epoch 1746/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.0470 - val_accuracy: 0.9869\n",
      "Epoch 1747/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9925 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 1748/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0438 - val_accuracy: 0.9869\n",
      "Epoch 1749/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.0426 - val_accuracy: 0.9869\n",
      "Epoch 1750/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9905 - val_loss: 0.0484 - val_accuracy: 0.9874\n",
      "Epoch 1751/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9931 - val_loss: 0.0527 - val_accuracy: 0.9874\n",
      "Epoch 1752/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.0545 - val_accuracy: 0.9865\n",
      "Epoch 1753/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.0504 - val_accuracy: 0.9879\n",
      "Epoch 1754/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9934 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
      "Epoch 1755/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9953 - val_loss: 0.0487 - val_accuracy: 0.9869\n",
      "Epoch 1756/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9940 - val_loss: 0.0510 - val_accuracy: 0.9874\n",
      "Epoch 1757/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 1758/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0254 - accuracy: 0.9906 - val_loss: 0.0429 - val_accuracy: 0.9874\n",
      "Epoch 1759/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 0.0446 - val_accuracy: 0.9874\n",
      "Epoch 1760/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 0.0439 - val_accuracy: 0.9874\n",
      "Epoch 1761/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0307 - accuracy: 0.9893 - val_loss: 0.0452 - val_accuracy: 0.9869\n",
      "Epoch 1762/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 0.0442 - val_accuracy: 0.9869\n",
      "Epoch 1763/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.0486 - val_accuracy: 0.9874\n",
      "Epoch 1764/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0408 - accuracy: 0.9881 - val_loss: 0.0475 - val_accuracy: 0.9869\n",
      "Epoch 1765/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0308 - accuracy: 0.9910 - val_loss: 0.0448 - val_accuracy: 0.9869\n",
      "Epoch 1766/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.0437 - val_accuracy: 0.9869\n",
      "Epoch 1767/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0312 - accuracy: 0.9899 - val_loss: 0.0431 - val_accuracy: 0.9869\n",
      "Epoch 1768/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.0442 - val_accuracy: 0.9874\n",
      "Epoch 1769/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9939 - val_loss: 0.0455 - val_accuracy: 0.9874\n",
      "Epoch 1770/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9903 - val_loss: 0.0436 - val_accuracy: 0.9869\n",
      "Epoch 1771/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0291 - accuracy: 0.9892 - val_loss: 0.0434 - val_accuracy: 0.9869\n",
      "Epoch 1772/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.0433 - val_accuracy: 0.9869\n",
      "Epoch 1773/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0288 - accuracy: 0.9901 - val_loss: 0.0425 - val_accuracy: 0.9869\n",
      "Epoch 1774/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9949 - val_loss: 0.0427 - val_accuracy: 0.9874\n",
      "Epoch 1775/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 1776/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9930 - val_loss: 0.0456 - val_accuracy: 0.9879\n",
      "Epoch 1777/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.0435 - val_accuracy: 0.9879\n",
      "Epoch 1778/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0304 - accuracy: 0.9924 - val_loss: 0.0505 - val_accuracy: 0.9874\n",
      "Epoch 1779/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.0552 - val_accuracy: 0.9851\n",
      "Epoch 1780/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9930 - val_loss: 0.0581 - val_accuracy: 0.9841\n",
      "Epoch 1781/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0277 - accuracy: 0.9908 - val_loss: 0.0816 - val_accuracy: 0.9767\n",
      "Epoch 1782/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0387 - accuracy: 0.9868 - val_loss: 0.0502 - val_accuracy: 0.9869\n",
      "Epoch 1783/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.0556 - val_accuracy: 0.9860\n",
      "Epoch 1784/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0287 - accuracy: 0.9915 - val_loss: 0.0455 - val_accuracy: 0.9874\n",
      "Epoch 1785/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0443 - val_accuracy: 0.9869\n",
      "Epoch 1786/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0436 - val_accuracy: 0.9874\n",
      "Epoch 1787/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.0471 - val_accuracy: 0.9883\n",
      "Epoch 1788/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 0.0474 - val_accuracy: 0.9874\n",
      "Epoch 1789/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0280 - accuracy: 0.9923 - val_loss: 0.0599 - val_accuracy: 0.9818\n",
      "Epoch 1790/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0326 - accuracy: 0.9892 - val_loss: 0.0552 - val_accuracy: 0.9855\n",
      "Epoch 1791/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0266 - accuracy: 0.9928 - val_loss: 0.0426 - val_accuracy: 0.9879\n",
      "Epoch 1792/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0310 - accuracy: 0.9903 - val_loss: 0.0434 - val_accuracy: 0.9869\n",
      "Epoch 1793/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 0.0530 - val_accuracy: 0.9874\n",
      "Epoch 1794/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0193 - accuracy: 0.9960 - val_loss: 0.0468 - val_accuracy: 0.9883\n",
      "Epoch 1795/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.0454 - val_accuracy: 0.9883\n",
      "Epoch 1796/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.0532 - val_accuracy: 0.9865\n",
      "Epoch 1797/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0576 - val_accuracy: 0.9832\n",
      "Epoch 1798/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9919 - val_loss: 0.0444 - val_accuracy: 0.9874\n",
      "Epoch 1799/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.0435 - val_accuracy: 0.9865\n",
      "Epoch 1800/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.0437 - val_accuracy: 0.9874\n",
      "Epoch 1801/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9940 - val_loss: 0.0432 - val_accuracy: 0.9874\n",
      "Epoch 1802/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0224 - accuracy: 0.9937 - val_loss: 0.0463 - val_accuracy: 0.9883\n",
      "Epoch 1803/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0455 - val_accuracy: 0.9893\n",
      "Epoch 1804/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0282 - accuracy: 0.9907 - val_loss: 0.0448 - val_accuracy: 0.9874\n",
      "Epoch 1805/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 0.0519 - val_accuracy: 0.9874\n",
      "Epoch 1806/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0338 - accuracy: 0.9909 - val_loss: 0.0435 - val_accuracy: 0.9879\n",
      "Epoch 1807/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 0.0463 - val_accuracy: 0.9879\n",
      "Epoch 1808/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 0.9892 - val_loss: 0.0480 - val_accuracy: 0.9865\n",
      "Epoch 1809/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0309 - accuracy: 0.9914 - val_loss: 0.0427 - val_accuracy: 0.9874\n",
      "Epoch 1810/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.0432 - val_accuracy: 0.9869\n",
      "Epoch 1811/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0293 - accuracy: 0.9897 - val_loss: 0.0446 - val_accuracy: 0.9865\n",
      "Epoch 1812/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.0432 - val_accuracy: 0.9874\n",
      "Epoch 1813/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 0.0431 - val_accuracy: 0.9874\n",
      "Epoch 1814/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9943 - val_loss: 0.0422 - val_accuracy: 0.9883\n",
      "Epoch 1815/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9954 - val_loss: 0.0433 - val_accuracy: 0.9874\n",
      "Epoch 1816/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0424 - val_accuracy: 0.9879\n",
      "Epoch 1817/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.0430 - val_accuracy: 0.9874\n",
      "Epoch 1818/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9950 - val_loss: 0.0530 - val_accuracy: 0.9860\n",
      "Epoch 1819/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.0589 - val_accuracy: 0.9832\n",
      "Epoch 1820/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.0420 - val_accuracy: 0.9879\n",
      "Epoch 1821/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0256 - accuracy: 0.9929 - val_loss: 0.0434 - val_accuracy: 0.9874\n",
      "Epoch 1822/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.0432 - val_accuracy: 0.9874\n",
      "Epoch 1823/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 0.0423 - val_accuracy: 0.9888\n",
      "Epoch 1824/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.0459 - val_accuracy: 0.9883\n",
      "Epoch 1825/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.0582 - val_accuracy: 0.9832\n",
      "Epoch 1826/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.0533 - val_accuracy: 0.9874\n",
      "Epoch 1827/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.0552 - val_accuracy: 0.9841\n",
      "Epoch 1828/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 0.9894 - val_loss: 0.0431 - val_accuracy: 0.9869\n",
      "Epoch 1829/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 0.0463 - val_accuracy: 0.9874\n",
      "Epoch 1830/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0351 - accuracy: 0.9870 - val_loss: 0.0529 - val_accuracy: 0.9874\n",
      "Epoch 1831/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0314 - accuracy: 0.9904 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 1832/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0286 - accuracy: 0.9904 - val_loss: 0.0449 - val_accuracy: 0.9874\n",
      "Epoch 1833/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.0475 - val_accuracy: 0.9888\n",
      "Epoch 1834/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0446 - val_accuracy: 0.9874\n",
      "Epoch 1835/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.0425 - val_accuracy: 0.9874\n",
      "Epoch 1836/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 0.0469 - val_accuracy: 0.9888\n",
      "Epoch 1837/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 0.0541 - val_accuracy: 0.9874\n",
      "Epoch 1838/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 1839/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.0527 - val_accuracy: 0.9869\n",
      "Epoch 1840/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 0.0430 - val_accuracy: 0.9879\n",
      "Epoch 1841/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0279 - accuracy: 0.9913 - val_loss: 0.0438 - val_accuracy: 0.9879\n",
      "Epoch 1842/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.0472 - val_accuracy: 0.9869\n",
      "Epoch 1843/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.0512 - val_accuracy: 0.9874\n",
      "Epoch 1844/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 0.0500 - val_accuracy: 0.9865\n",
      "Epoch 1845/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.0544 - val_accuracy: 0.9865\n",
      "Epoch 1846/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.0508 - val_accuracy: 0.9874\n",
      "Epoch 1847/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
      "Epoch 1848/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0226 - accuracy: 0.9943 - val_loss: 0.0495 - val_accuracy: 0.9879\n",
      "Epoch 1849/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0551 - val_accuracy: 0.9846\n",
      "Epoch 1850/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0548 - val_accuracy: 0.9869\n",
      "Epoch 1851/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 0.0615 - val_accuracy: 0.9823\n",
      "Epoch 1852/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0313 - accuracy: 0.9914 - val_loss: 0.0546 - val_accuracy: 0.9855\n",
      "Epoch 1853/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.0461 - val_accuracy: 0.9883\n",
      "Epoch 1854/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0284 - accuracy: 0.9905 - val_loss: 0.0446 - val_accuracy: 0.9874\n",
      "Epoch 1855/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0294 - accuracy: 0.9888 - val_loss: 0.0444 - val_accuracy: 0.9879\n",
      "Epoch 1856/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.0442 - val_accuracy: 0.9869\n",
      "Epoch 1857/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.0447 - val_accuracy: 0.9869\n",
      "Epoch 1858/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0224 - accuracy: 0.9920 - val_loss: 0.0451 - val_accuracy: 0.9869\n",
      "Epoch 1859/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 0.0438 - val_accuracy: 0.9869\n",
      "Epoch 1860/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0457 - val_accuracy: 0.9874\n",
      "Epoch 1861/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0214 - accuracy: 0.9944 - val_loss: 0.0463 - val_accuracy: 0.9874\n",
      "Epoch 1862/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.0448 - val_accuracy: 0.9874\n",
      "Epoch 1863/3500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0435 - val_accuracy: 0.9874\n",
      "Epoch 1864/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.0426 - val_accuracy: 0.9874\n",
      "Epoch 1865/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.0535 - val_accuracy: 0.9860\n",
      "Epoch 1866/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 0.9929 - val_loss: 0.0962 - val_accuracy: 0.9730\n",
      "Epoch 1867/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0320 - accuracy: 0.9898 - val_loss: 0.0615 - val_accuracy: 0.9804\n",
      "Epoch 1868/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0271 - accuracy: 0.9899 - val_loss: 0.0502 - val_accuracy: 0.9883\n",
      "Epoch 1869/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0282 - accuracy: 0.9925 - val_loss: 0.0472 - val_accuracy: 0.9888\n",
      "Epoch 1870/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0261 - accuracy: 0.9907 - val_loss: 0.0439 - val_accuracy: 0.9874\n",
      "Epoch 1871/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.0440 - val_accuracy: 0.9874\n",
      "Epoch 1872/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.0429 - val_accuracy: 0.9874\n",
      "Epoch 1873/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.0434 - val_accuracy: 0.9879\n",
      "Epoch 1874/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0436 - val_accuracy: 0.9874\n",
      "Epoch 1875/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9935 - val_loss: 0.0430 - val_accuracy: 0.9874\n",
      "Epoch 1876/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.0431 - val_accuracy: 0.9874\n",
      "Epoch 1877/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9939 - val_loss: 0.0439 - val_accuracy: 0.9883\n",
      "Epoch 1878/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 0.0506 - val_accuracy: 0.9874\n",
      "Epoch 1879/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.0468 - val_accuracy: 0.9874\n",
      "Epoch 1880/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.0436 - val_accuracy: 0.9874\n",
      "Epoch 1881/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0452 - val_accuracy: 0.9879\n",
      "Epoch 1882/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0306 - accuracy: 0.9891 - val_loss: 0.0441 - val_accuracy: 0.9874\n",
      "Epoch 1883/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0436 - val_accuracy: 0.9874\n",
      "Epoch 1884/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0470 - val_accuracy: 0.9883\n",
      "Epoch 1885/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 1886/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9943 - val_loss: 0.0446 - val_accuracy: 0.9879\n",
      "Epoch 1887/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.0683 - val_accuracy: 0.9795\n",
      "Epoch 1888/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0324 - accuracy: 0.9899 - val_loss: 0.0584 - val_accuracy: 0.9851\n",
      "Epoch 1889/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0254 - accuracy: 0.9938 - val_loss: 0.0491 - val_accuracy: 0.9874\n",
      "Epoch 1890/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0490 - val_accuracy: 0.9879\n",
      "Epoch 1891/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0457 - val_accuracy: 0.9883\n",
      "Epoch 1892/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9935 - val_loss: 0.0462 - val_accuracy: 0.9879\n",
      "Epoch 1893/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0463 - val_accuracy: 0.9888\n",
      "Epoch 1894/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.0459 - val_accuracy: 0.9879\n",
      "Epoch 1895/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.0498 - val_accuracy: 0.9869\n",
      "Epoch 1896/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 0.0512 - val_accuracy: 0.9874\n",
      "Epoch 1897/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0214 - accuracy: 0.9947 - val_loss: 0.0439 - val_accuracy: 0.9874\n",
      "Epoch 1898/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 1899/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0431 - val_accuracy: 0.9883\n",
      "Epoch 1900/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0276 - accuracy: 0.9919 - val_loss: 0.0479 - val_accuracy: 0.9874\n",
      "Epoch 1901/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0509 - val_accuracy: 0.9874\n",
      "Epoch 1902/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.0634 - val_accuracy: 0.9818\n",
      "Epoch 1903/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 0.0617 - val_accuracy: 0.9823\n",
      "Epoch 1904/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0645 - val_accuracy: 0.9814\n",
      "Epoch 1905/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.0762 - val_accuracy: 0.9767\n",
      "Epoch 1906/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.0581 - val_accuracy: 0.9851\n",
      "Epoch 1907/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.0504 - val_accuracy: 0.9865\n",
      "Epoch 1908/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.0438 - val_accuracy: 0.9874\n",
      "Epoch 1909/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9880 - val_loss: 0.0439 - val_accuracy: 0.9865\n",
      "Epoch 1910/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 0.0468 - val_accuracy: 0.9883\n",
      "Epoch 1911/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.0510 - val_accuracy: 0.9874\n",
      "Epoch 1912/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0452 - val_accuracy: 0.9874\n",
      "Epoch 1913/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.0463 - val_accuracy: 0.9888\n",
      "Epoch 1914/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.0441 - val_accuracy: 0.9883\n",
      "Epoch 1915/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0443 - val_accuracy: 0.9869\n",
      "Epoch 1916/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0462 - val_accuracy: 0.9883\n",
      "Epoch 1917/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.0447 - val_accuracy: 0.9874\n",
      "Epoch 1918/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0286 - accuracy: 0.9910 - val_loss: 0.0778 - val_accuracy: 0.9781\n",
      "Epoch 1919/3500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0298 - accuracy: 0.9901 - val_loss: 0.0844 - val_accuracy: 0.9753\n",
      "Epoch 1920/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0357 - accuracy: 0.9900 - val_loss: 0.0622 - val_accuracy: 0.9823\n",
      "Epoch 1921/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.0597 - val_accuracy: 0.9828\n",
      "Epoch 1922/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.0499 - val_accuracy: 0.9874\n",
      "Epoch 1923/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.0635 - val_accuracy: 0.9809\n",
      "Epoch 1924/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9915 - val_loss: 0.0471 - val_accuracy: 0.9888\n",
      "Epoch 1925/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.0519 - val_accuracy: 0.9865\n",
      "Epoch 1926/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0251 - accuracy: 0.9934 - val_loss: 0.0444 - val_accuracy: 0.9883\n",
      "Epoch 1927/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.0448 - val_accuracy: 0.9874\n",
      "Epoch 1928/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0227 - accuracy: 0.9909 - val_loss: 0.0432 - val_accuracy: 0.9883\n",
      "Epoch 1929/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0251 - accuracy: 0.9911 - val_loss: 0.0437 - val_accuracy: 0.9874\n",
      "Epoch 1930/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 0.0475 - val_accuracy: 0.9879\n",
      "Epoch 1931/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.0436 - val_accuracy: 0.9874\n",
      "Epoch 1932/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0480 - val_accuracy: 0.9879\n",
      "Epoch 1933/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.9926 - val_loss: 0.0461 - val_accuracy: 0.9879\n",
      "Epoch 1934/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.0477 - val_accuracy: 0.9879\n",
      "Epoch 1935/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.0454 - val_accuracy: 0.9883\n",
      "Epoch 1936/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.0442 - val_accuracy: 0.9874\n",
      "Epoch 1937/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.0491 - val_accuracy: 0.9869\n",
      "Epoch 1938/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9948 - val_loss: 0.0435 - val_accuracy: 0.9883\n",
      "Epoch 1939/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 0.0434 - val_accuracy: 0.9879\n",
      "Epoch 1940/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.0457 - val_accuracy: 0.9888\n",
      "Epoch 1941/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9934 - val_loss: 0.0427 - val_accuracy: 0.9879\n",
      "Epoch 1942/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0258 - accuracy: 0.9907 - val_loss: 0.0500 - val_accuracy: 0.9879\n",
      "Epoch 1943/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0266 - accuracy: 0.9924 - val_loss: 0.0482 - val_accuracy: 0.9879\n",
      "Epoch 1944/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.0525 - val_accuracy: 0.9865\n",
      "Epoch 1945/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.0783 - val_accuracy: 0.9772\n",
      "Epoch 1946/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9908 - val_loss: 0.0594 - val_accuracy: 0.9841\n",
      "Epoch 1947/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.0532 - val_accuracy: 0.9860\n",
      "Epoch 1948/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0248 - accuracy: 0.9935 - val_loss: 0.0437 - val_accuracy: 0.9874\n",
      "Epoch 1949/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.0460 - val_accuracy: 0.9883\n",
      "Epoch 1950/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9931 - val_loss: 0.0489 - val_accuracy: 0.9883\n",
      "Epoch 1951/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.0467 - val_accuracy: 0.9879\n",
      "Epoch 1952/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 0.0439 - val_accuracy: 0.9888\n",
      "Epoch 1953/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.0447 - val_accuracy: 0.9883\n",
      "Epoch 1954/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0351 - accuracy: 0.9867 - val_loss: 0.0496 - val_accuracy: 0.9869\n",
      "Epoch 1955/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0390 - accuracy: 0.9871 - val_loss: 0.0446 - val_accuracy: 0.9879\n",
      "Epoch 1956/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0232 - accuracy: 0.9946 - val_loss: 0.0463 - val_accuracy: 0.9874\n",
      "Epoch 1957/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0330 - accuracy: 0.9899 - val_loss: 0.0508 - val_accuracy: 0.9865\n",
      "Epoch 1958/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0378 - accuracy: 0.9881 - val_loss: 0.0434 - val_accuracy: 0.9874\n",
      "Epoch 1959/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0242 - accuracy: 0.9934 - val_loss: 0.0436 - val_accuracy: 0.9869\n",
      "Epoch 1960/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 0.0481 - val_accuracy: 0.9883\n",
      "Epoch 1961/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0235 - accuracy: 0.9940 - val_loss: 0.0438 - val_accuracy: 0.9879\n",
      "Epoch 1962/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9941 - val_loss: 0.0471 - val_accuracy: 0.9883\n",
      "Epoch 1963/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9935 - val_loss: 0.0505 - val_accuracy: 0.9869\n",
      "Epoch 1964/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 1965/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.0454 - val_accuracy: 0.9883\n",
      "Epoch 1966/3500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.0543 - val_accuracy: 0.9860\n",
      "Epoch 1967/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.0453 - val_accuracy: 0.9869\n",
      "Epoch 1968/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9946 - val_loss: 0.0500 - val_accuracy: 0.9869\n",
      "Epoch 1969/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 0.9913 - val_loss: 0.0467 - val_accuracy: 0.9869\n",
      "Epoch 1970/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9926 - val_loss: 0.0513 - val_accuracy: 0.9879\n",
      "Epoch 1971/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 0.0557 - val_accuracy: 0.9860\n",
      "Epoch 1972/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 0.0499 - val_accuracy: 0.9874\n",
      "Epoch 1973/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.0518 - val_accuracy: 0.9879\n",
      "Epoch 1974/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.0536 - val_accuracy: 0.9865\n",
      "Epoch 1975/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 0.0491 - val_accuracy: 0.9874\n",
      "Epoch 1976/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.0526 - val_accuracy: 0.9865\n",
      "Epoch 1977/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.0457 - val_accuracy: 0.9888\n",
      "Epoch 1978/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0445 - val_accuracy: 0.9874\n",
      "Epoch 1979/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9907 - val_loss: 0.0462 - val_accuracy: 0.9879\n",
      "Epoch 1980/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.0455 - val_accuracy: 0.9888\n",
      "Epoch 1981/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.0485 - val_accuracy: 0.9883\n",
      "Epoch 1982/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0569 - val_accuracy: 0.9855\n",
      "Epoch 1983/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0504 - val_accuracy: 0.9879\n",
      "Epoch 1984/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9927 - val_loss: 0.0671 - val_accuracy: 0.9828\n",
      "Epoch 1985/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 0.0783 - val_accuracy: 0.9776\n",
      "Epoch 1986/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0363 - accuracy: 0.9894 - val_loss: 0.0468 - val_accuracy: 0.9879\n",
      "Epoch 1987/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0280 - accuracy: 0.9904 - val_loss: 0.0446 - val_accuracy: 0.9869\n",
      "Epoch 1988/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.0446 - val_accuracy: 0.9874\n",
      "Epoch 1989/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0313 - accuracy: 0.9885 - val_loss: 0.0518 - val_accuracy: 0.9869\n",
      "Epoch 1990/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.0466 - val_accuracy: 0.9879\n",
      "Epoch 1991/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.0461 - val_accuracy: 0.9874\n",
      "Epoch 1992/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0515 - val_accuracy: 0.9865\n",
      "Epoch 1993/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.0496 - val_accuracy: 0.9879\n",
      "Epoch 1994/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.0487 - val_accuracy: 0.9888\n",
      "Epoch 1995/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0544 - val_accuracy: 0.9860\n",
      "Epoch 1996/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9914 - val_loss: 0.0510 - val_accuracy: 0.9874\n",
      "Epoch 1997/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.0440 - val_accuracy: 0.9879\n",
      "Epoch 1998/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 0.9910 - val_loss: 0.0455 - val_accuracy: 0.9874\n",
      "Epoch 1999/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0579 - val_accuracy: 0.9846\n",
      "Epoch 2000/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9929 - val_loss: 0.0446 - val_accuracy: 0.9879\n",
      "Epoch 2001/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.0453 - val_accuracy: 0.9883\n",
      "Epoch 2002/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.0543 - val_accuracy: 0.9860\n",
      "Epoch 2003/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0441 - val_accuracy: 0.9874\n",
      "Epoch 2004/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.0459 - val_accuracy: 0.9874\n",
      "Epoch 2005/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0199 - accuracy: 0.9946 - val_loss: 0.0441 - val_accuracy: 0.9879\n",
      "Epoch 2006/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0443 - val_accuracy: 0.9874\n",
      "Epoch 2007/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0497 - val_accuracy: 0.9874\n",
      "Epoch 2008/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9944 - val_loss: 0.0576 - val_accuracy: 0.9855\n",
      "Epoch 2009/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 0.0892 - val_accuracy: 0.9744\n",
      "Epoch 2010/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0443 - accuracy: 0.9875 - val_loss: 0.0722 - val_accuracy: 0.9795\n",
      "Epoch 2011/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0297 - accuracy: 0.9899 - val_loss: 0.0509 - val_accuracy: 0.9874\n",
      "Epoch 2012/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0463 - val_accuracy: 0.9874\n",
      "Epoch 2013/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9920 - val_loss: 0.0470 - val_accuracy: 0.9883\n",
      "Epoch 2014/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.0442 - val_accuracy: 0.9874\n",
      "Epoch 2015/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.0471 - val_accuracy: 0.9879\n",
      "Epoch 2016/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.0446 - val_accuracy: 0.9874\n",
      "Epoch 2017/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.0441 - val_accuracy: 0.9874\n",
      "Epoch 2018/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.0450 - val_accuracy: 0.9883\n",
      "Epoch 2019/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.0621 - val_accuracy: 0.9837\n",
      "Epoch 2020/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9910 - val_loss: 0.0480 - val_accuracy: 0.9883\n",
      "Epoch 2021/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9935 - val_loss: 0.0691 - val_accuracy: 0.9800\n",
      "Epoch 2022/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.0626 - val_accuracy: 0.9828\n",
      "Epoch 2023/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9940 - val_loss: 0.0555 - val_accuracy: 0.9874\n",
      "Epoch 2024/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.0507 - val_accuracy: 0.9879\n",
      "Epoch 2025/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.0623 - val_accuracy: 0.9823\n",
      "Epoch 2026/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 0.0628 - val_accuracy: 0.9841\n",
      "Epoch 2027/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9942 - val_loss: 0.0489 - val_accuracy: 0.9883\n",
      "Epoch 2028/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.0455 - val_accuracy: 0.9874\n",
      "Epoch 2029/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.0482 - val_accuracy: 0.9874\n",
      "Epoch 2030/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.0488 - val_accuracy: 0.9879\n",
      "Epoch 2031/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.0437 - val_accuracy: 0.9879\n",
      "Epoch 2032/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0215 - accuracy: 0.9924 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 2033/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.0454 - val_accuracy: 0.9879\n",
      "Epoch 2034/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0480 - val_accuracy: 0.9883\n",
      "Epoch 2035/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9941 - val_loss: 0.0491 - val_accuracy: 0.9874\n",
      "Epoch 2036/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.0674 - val_accuracy: 0.9809\n",
      "Epoch 2037/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9913 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 2038/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.0470 - val_accuracy: 0.9874\n",
      "Epoch 2039/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9891 - val_loss: 0.0446 - val_accuracy: 0.9874\n",
      "Epoch 2040/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.0458 - val_accuracy: 0.9879\n",
      "Epoch 2041/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0224 - accuracy: 0.9915 - val_loss: 0.0444 - val_accuracy: 0.9883\n",
      "Epoch 2042/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9897 - val_loss: 0.0576 - val_accuracy: 0.9851\n",
      "Epoch 2043/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0284 - accuracy: 0.9921 - val_loss: 0.0697 - val_accuracy: 0.9795\n",
      "Epoch 2044/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.0645 - val_accuracy: 0.9823\n",
      "Epoch 2045/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 0.9937 - val_loss: 0.0466 - val_accuracy: 0.9883\n",
      "Epoch 2046/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.0493 - val_accuracy: 0.9879\n",
      "Epoch 2047/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.0547 - val_accuracy: 0.9869\n",
      "Epoch 2048/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.0632 - val_accuracy: 0.9828\n",
      "Epoch 2049/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.0598 - val_accuracy: 0.9832\n",
      "Epoch 2050/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0344 - accuracy: 0.9895 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 2051/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0281 - accuracy: 0.9900 - val_loss: 0.0483 - val_accuracy: 0.9888\n",
      "Epoch 2052/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0432 - val_accuracy: 0.9874\n",
      "Epoch 2053/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.0438 - val_accuracy: 0.9883\n",
      "Epoch 2054/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.0451 - val_accuracy: 0.9874\n",
      "Epoch 2055/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0327 - accuracy: 0.9866 - val_loss: 0.0462 - val_accuracy: 0.9874\n",
      "Epoch 2056/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0467 - val_accuracy: 0.9874\n",
      "Epoch 2057/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.0436 - val_accuracy: 0.9874\n",
      "Epoch 2058/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.0493 - val_accuracy: 0.9888\n",
      "Epoch 2059/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
      "Epoch 2060/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.0464 - val_accuracy: 0.9888\n",
      "Epoch 2061/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.0494 - val_accuracy: 0.9874\n",
      "Epoch 2062/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0436 - val_accuracy: 0.9874\n",
      "Epoch 2063/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.0449 - val_accuracy: 0.9874\n",
      "Epoch 2064/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 0.0542 - val_accuracy: 0.9865\n",
      "Epoch 2065/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.0574 - val_accuracy: 0.9841\n",
      "Epoch 2066/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 0.0482 - val_accuracy: 0.9888\n",
      "Epoch 2067/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0473 - val_accuracy: 0.9883\n",
      "Epoch 2068/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0332 - accuracy: 0.9889 - val_loss: 0.0460 - val_accuracy: 0.9874\n",
      "Epoch 2069/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9914 - val_loss: 0.0443 - val_accuracy: 0.9874\n",
      "Epoch 2070/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 0.0521 - val_accuracy: 0.9869\n",
      "Epoch 2071/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0348 - accuracy: 0.9888 - val_loss: 0.0606 - val_accuracy: 0.9860\n",
      "Epoch 2072/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0417 - accuracy: 0.9862 - val_loss: 0.0476 - val_accuracy: 0.9869\n",
      "Epoch 2073/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0286 - accuracy: 0.9895 - val_loss: 0.0459 - val_accuracy: 0.9865\n",
      "Epoch 2074/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.0487 - val_accuracy: 0.9888\n",
      "Epoch 2075/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0466 - val_accuracy: 0.9883\n",
      "Epoch 2076/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0248 - accuracy: 0.9909 - val_loss: 0.0462 - val_accuracy: 0.9883\n",
      "Epoch 2077/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 0.0500 - val_accuracy: 0.9883\n",
      "Epoch 2078/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.0491 - val_accuracy: 0.9879\n",
      "Epoch 2079/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.0502 - val_accuracy: 0.9879\n",
      "Epoch 2080/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9934 - val_loss: 0.0468 - val_accuracy: 0.9883\n",
      "Epoch 2081/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.0465 - val_accuracy: 0.9874\n",
      "Epoch 2082/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0291 - accuracy: 0.9904 - val_loss: 0.0446 - val_accuracy: 0.9869\n",
      "Epoch 2083/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0273 - accuracy: 0.9907 - val_loss: 0.0475 - val_accuracy: 0.9879\n",
      "Epoch 2084/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 0.0464 - val_accuracy: 0.9869\n",
      "Epoch 2085/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0277 - accuracy: 0.9899 - val_loss: 0.0449 - val_accuracy: 0.9874\n",
      "Epoch 2086/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 0.9934 - val_loss: 0.0441 - val_accuracy: 0.9879\n",
      "Epoch 2087/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.0446 - val_accuracy: 0.9865\n",
      "Epoch 2088/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.0440 - val_accuracy: 0.9879\n",
      "Epoch 2089/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.0459 - val_accuracy: 0.9874\n",
      "Epoch 2090/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0492 - val_accuracy: 0.9883\n",
      "Epoch 2091/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 0.0476 - val_accuracy: 0.9879\n",
      "Epoch 2092/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9951 - val_loss: 0.0492 - val_accuracy: 0.9883\n",
      "Epoch 2093/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0224 - accuracy: 0.9940 - val_loss: 0.0450 - val_accuracy: 0.9883\n",
      "Epoch 2094/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0442 - val_accuracy: 0.9874\n",
      "Epoch 2095/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0436 - val_accuracy: 0.9879\n",
      "Epoch 2096/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 2097/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0439 - val_accuracy: 0.9879\n",
      "Epoch 2098/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0462 - val_accuracy: 0.9883\n",
      "Epoch 2099/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0197 - accuracy: 0.9927 - val_loss: 0.0454 - val_accuracy: 0.9883\n",
      "Epoch 2100/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0496 - val_accuracy: 0.9869\n",
      "Epoch 2101/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.0744 - val_accuracy: 0.9786\n",
      "Epoch 2102/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0396 - accuracy: 0.9880 - val_loss: 0.0901 - val_accuracy: 0.9753\n",
      "Epoch 2103/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0330 - accuracy: 0.9898 - val_loss: 0.0640 - val_accuracy: 0.9832\n",
      "Epoch 2104/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.0471 - val_accuracy: 0.9874\n",
      "Epoch 2105/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 2106/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 0.0457 - val_accuracy: 0.9874\n",
      "Epoch 2107/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.0447 - val_accuracy: 0.9874\n",
      "Epoch 2108/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9942 - val_loss: 0.0502 - val_accuracy: 0.9883\n",
      "Epoch 2109/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 2110/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.0518 - val_accuracy: 0.9879\n",
      "Epoch 2111/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0185 - accuracy: 0.9954 - val_loss: 0.0575 - val_accuracy: 0.9855\n",
      "Epoch 2112/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 0.0644 - val_accuracy: 0.9823\n",
      "Epoch 2113/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0529 - val_accuracy: 0.9883\n",
      "Epoch 2114/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.0566 - val_accuracy: 0.9855\n",
      "Epoch 2115/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.0448 - val_accuracy: 0.9874\n",
      "Epoch 2116/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0497 - val_accuracy: 0.9879\n",
      "Epoch 2117/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.0522 - val_accuracy: 0.9888\n",
      "Epoch 2118/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0563 - val_accuracy: 0.9855\n",
      "Epoch 2119/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0215 - accuracy: 0.9943 - val_loss: 0.0451 - val_accuracy: 0.9874\n",
      "Epoch 2120/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 2121/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0315 - accuracy: 0.9894 - val_loss: 0.0445 - val_accuracy: 0.9869\n",
      "Epoch 2122/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0308 - accuracy: 0.9895 - val_loss: 0.0439 - val_accuracy: 0.9879\n",
      "Epoch 2123/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.0654 - val_accuracy: 0.9809\n",
      "Epoch 2124/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 0.0684 - val_accuracy: 0.9809\n",
      "Epoch 2125/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.0667 - val_accuracy: 0.9809\n",
      "Epoch 2126/3500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.0624 - val_accuracy: 0.9851\n",
      "Epoch 2127/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.0541 - val_accuracy: 0.9860\n",
      "Epoch 2128/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 0.0451 - val_accuracy: 0.9869\n",
      "Epoch 2129/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.0513 - val_accuracy: 0.9879\n",
      "Epoch 2130/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.0519 - val_accuracy: 0.9883\n",
      "Epoch 2131/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 0.0585 - val_accuracy: 0.9855\n",
      "Epoch 2132/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9930 - val_loss: 0.0486 - val_accuracy: 0.9874\n",
      "Epoch 2133/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 0.9910 - val_loss: 0.0459 - val_accuracy: 0.9879\n",
      "Epoch 2134/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 2135/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.0442 - val_accuracy: 0.9874\n",
      "Epoch 2136/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9935 - val_loss: 0.0450 - val_accuracy: 0.9869\n",
      "Epoch 2137/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.0462 - val_accuracy: 0.9869\n",
      "Epoch 2138/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9918 - val_loss: 0.0447 - val_accuracy: 0.9874\n",
      "Epoch 2139/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.0467 - val_accuracy: 0.9874\n",
      "Epoch 2140/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
      "Epoch 2141/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.0528 - val_accuracy: 0.9879\n",
      "Epoch 2142/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0287 - accuracy: 0.9913 - val_loss: 0.0563 - val_accuracy: 0.9846\n",
      "Epoch 2143/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.0459 - val_accuracy: 0.9879\n",
      "Epoch 2144/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0440 - val_accuracy: 0.9869\n",
      "Epoch 2145/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9928 - val_loss: 0.0446 - val_accuracy: 0.9874\n",
      "Epoch 2146/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.0466 - val_accuracy: 0.9874\n",
      "Epoch 2147/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0442 - val_accuracy: 0.9869\n",
      "Epoch 2148/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.0514 - val_accuracy: 0.9879\n",
      "Epoch 2149/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.0813 - val_accuracy: 0.9772\n",
      "Epoch 2150/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0289 - accuracy: 0.9892 - val_loss: 0.0477 - val_accuracy: 0.9883\n",
      "Epoch 2151/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.0471 - val_accuracy: 0.9883\n",
      "Epoch 2152/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9948 - val_loss: 0.0477 - val_accuracy: 0.9888\n",
      "Epoch 2153/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.0488 - val_accuracy: 0.9883\n",
      "Epoch 2154/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.0460 - val_accuracy: 0.9879\n",
      "Epoch 2155/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0448 - val_accuracy: 0.9874\n",
      "Epoch 2156/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0461 - val_accuracy: 0.9879\n",
      "Epoch 2157/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 2158/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9949 - val_loss: 0.0511 - val_accuracy: 0.9865\n",
      "Epoch 2159/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9932 - val_loss: 0.0501 - val_accuracy: 0.9879\n",
      "Epoch 2160/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.0483 - val_accuracy: 0.9888\n",
      "Epoch 2161/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.0519 - val_accuracy: 0.9874\n",
      "Epoch 2162/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.0778 - val_accuracy: 0.9800\n",
      "Epoch 2163/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0404 - accuracy: 0.9880 - val_loss: 0.0489 - val_accuracy: 0.9874\n",
      "Epoch 2164/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9916 - val_loss: 0.0480 - val_accuracy: 0.9883\n",
      "Epoch 2165/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 2166/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.0448 - val_accuracy: 0.9879\n",
      "Epoch 2167/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 0.0445 - val_accuracy: 0.9865\n",
      "Epoch 2168/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9911 - val_loss: 0.0460 - val_accuracy: 0.9874\n",
      "Epoch 2169/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0269 - accuracy: 0.9905 - val_loss: 0.0440 - val_accuracy: 0.9874\n",
      "Epoch 2170/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.0470 - val_accuracy: 0.9883\n",
      "Epoch 2171/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9959 - val_loss: 0.0462 - val_accuracy: 0.9869\n",
      "Epoch 2172/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.0455 - val_accuracy: 0.9888\n",
      "Epoch 2173/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.0486 - val_accuracy: 0.9879\n",
      "Epoch 2174/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 0.9914 - val_loss: 0.0695 - val_accuracy: 0.9800\n",
      "Epoch 2175/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.0546 - val_accuracy: 0.9865\n",
      "Epoch 2176/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
      "Epoch 2177/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.0560 - val_accuracy: 0.9855\n",
      "Epoch 2178/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.0613 - val_accuracy: 0.9841\n",
      "Epoch 2179/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9922 - val_loss: 0.0573 - val_accuracy: 0.9851\n",
      "Epoch 2180/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0253 - accuracy: 0.9911 - val_loss: 0.0476 - val_accuracy: 0.9883\n",
      "Epoch 2181/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.0498 - val_accuracy: 0.9883\n",
      "Epoch 2182/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.0491 - val_accuracy: 0.9879\n",
      "Epoch 2183/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.0554 - val_accuracy: 0.9869\n",
      "Epoch 2184/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0279 - accuracy: 0.9913 - val_loss: 0.0549 - val_accuracy: 0.9865\n",
      "Epoch 2185/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9910 - val_loss: 0.0469 - val_accuracy: 0.9879\n",
      "Epoch 2186/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 0.9892 - val_loss: 0.0446 - val_accuracy: 0.9874\n",
      "Epoch 2187/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 0.0442 - val_accuracy: 0.9883\n",
      "Epoch 2188/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.0441 - val_accuracy: 0.9869\n",
      "Epoch 2189/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.0493 - val_accuracy: 0.9879\n",
      "Epoch 2190/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0535 - val_accuracy: 0.9869\n",
      "Epoch 2191/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.0474 - val_accuracy: 0.9883\n",
      "Epoch 2192/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0473 - val_accuracy: 0.9879\n",
      "Epoch 2193/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0609 - val_accuracy: 0.9855\n",
      "Epoch 2194/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.0548 - val_accuracy: 0.9879\n",
      "Epoch 2195/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0247 - accuracy: 0.9943 - val_loss: 0.0520 - val_accuracy: 0.9879\n",
      "Epoch 2196/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.0464 - val_accuracy: 0.9883\n",
      "Epoch 2197/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.0434 - val_accuracy: 0.9879\n",
      "Epoch 2198/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0443 - val_accuracy: 0.9874\n",
      "Epoch 2199/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0490 - val_accuracy: 0.9869\n",
      "Epoch 2200/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 0.0458 - val_accuracy: 0.9869\n",
      "Epoch 2201/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9929 - val_loss: 0.0462 - val_accuracy: 0.9874\n",
      "Epoch 2202/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.0439 - val_accuracy: 0.9874\n",
      "Epoch 2203/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9923 - val_loss: 0.0462 - val_accuracy: 0.9869\n",
      "Epoch 2204/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.0593 - val_accuracy: 0.9846\n",
      "Epoch 2205/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.0496 - val_accuracy: 0.9883\n",
      "Epoch 2206/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 0.0489 - val_accuracy: 0.9888\n",
      "Epoch 2207/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9949 - val_loss: 0.0462 - val_accuracy: 0.9879\n",
      "Epoch 2208/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0515 - val_accuracy: 0.9883\n",
      "Epoch 2209/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.0521 - val_accuracy: 0.9879\n",
      "Epoch 2210/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0450 - val_accuracy: 0.9879\n",
      "Epoch 2211/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9934 - val_loss: 0.0460 - val_accuracy: 0.9883\n",
      "Epoch 2212/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.0468 - val_accuracy: 0.9883\n",
      "Epoch 2213/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.0478 - val_accuracy: 0.9879\n",
      "Epoch 2214/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.0472 - val_accuracy: 0.9883\n",
      "Epoch 2215/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.0474 - val_accuracy: 0.9888\n",
      "Epoch 2216/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0571 - val_accuracy: 0.9860\n",
      "Epoch 2217/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0249 - accuracy: 0.9907 - val_loss: 0.0574 - val_accuracy: 0.9860\n",
      "Epoch 2218/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.0463 - val_accuracy: 0.9879\n",
      "Epoch 2219/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.0466 - val_accuracy: 0.9879\n",
      "Epoch 2220/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9953 - val_loss: 0.0494 - val_accuracy: 0.9879\n",
      "Epoch 2221/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0459 - val_accuracy: 0.9874\n",
      "Epoch 2222/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.0512 - val_accuracy: 0.9883\n",
      "Epoch 2223/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9935 - val_loss: 0.0550 - val_accuracy: 0.9874\n",
      "Epoch 2224/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9931 - val_loss: 0.0483 - val_accuracy: 0.9888\n",
      "Epoch 2225/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0197 - accuracy: 0.9927 - val_loss: 0.0487 - val_accuracy: 0.9879\n",
      "Epoch 2226/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.0472 - val_accuracy: 0.9883\n",
      "Epoch 2227/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 0.9931 - val_loss: 0.0457 - val_accuracy: 0.9879\n",
      "Epoch 2228/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0451 - val_accuracy: 0.9874\n",
      "Epoch 2229/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.0457 - val_accuracy: 0.9874\n",
      "Epoch 2230/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0240 - accuracy: 0.9913 - val_loss: 0.0452 - val_accuracy: 0.9869\n",
      "Epoch 2231/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
      "Epoch 2232/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.0666 - val_accuracy: 0.9828\n",
      "Epoch 2233/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9929 - val_loss: 0.0553 - val_accuracy: 0.9865\n",
      "Epoch 2234/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 0.0457 - val_accuracy: 0.9874\n",
      "Epoch 2235/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 0.9905 - val_loss: 0.0443 - val_accuracy: 0.9874\n",
      "Epoch 2236/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.0464 - val_accuracy: 0.9874\n",
      "Epoch 2237/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.0511 - val_accuracy: 0.9879\n",
      "Epoch 2238/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.0648 - val_accuracy: 0.9837\n",
      "Epoch 2239/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0699 - val_accuracy: 0.9804\n",
      "Epoch 2240/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0502 - val_accuracy: 0.9883\n",
      "Epoch 2241/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.0460 - val_accuracy: 0.9860\n",
      "Epoch 2242/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 2243/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.0456 - val_accuracy: 0.9865\n",
      "Epoch 2244/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.0461 - val_accuracy: 0.9869\n",
      "Epoch 2245/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0206 - accuracy: 0.9948 - val_loss: 0.0462 - val_accuracy: 0.9888\n",
      "Epoch 2246/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.0481 - val_accuracy: 0.9883\n",
      "Epoch 2247/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9934 - val_loss: 0.0521 - val_accuracy: 0.9883\n",
      "Epoch 2248/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.0450 - val_accuracy: 0.9865\n",
      "Epoch 2249/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.0475 - val_accuracy: 0.9883\n",
      "Epoch 2250/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9934 - val_loss: 0.0471 - val_accuracy: 0.9883\n",
      "Epoch 2251/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.0456 - val_accuracy: 0.9879\n",
      "Epoch 2252/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0510 - val_accuracy: 0.9879\n",
      "Epoch 2253/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0473 - val_accuracy: 0.9888\n",
      "Epoch 2254/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.0437 - val_accuracy: 0.9874\n",
      "Epoch 2255/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 0.9919 - val_loss: 0.0522 - val_accuracy: 0.9879\n",
      "Epoch 2256/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.0453 - val_accuracy: 0.9865\n",
      "Epoch 2257/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.0472 - val_accuracy: 0.9879\n",
      "Epoch 2258/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.0449 - val_accuracy: 0.9883\n",
      "Epoch 2259/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9944 - val_loss: 0.0475 - val_accuracy: 0.9893\n",
      "Epoch 2260/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0470 - val_accuracy: 0.9879\n",
      "Epoch 2261/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 2262/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.0458 - val_accuracy: 0.9879\n",
      "Epoch 2263/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.0442 - val_accuracy: 0.9883\n",
      "Epoch 2264/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 0.0479 - val_accuracy: 0.9874\n",
      "Epoch 2265/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0353 - accuracy: 0.9873 - val_loss: 0.0469 - val_accuracy: 0.9888\n",
      "Epoch 2266/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9935 - val_loss: 0.0581 - val_accuracy: 0.9855\n",
      "Epoch 2267/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0280 - accuracy: 0.9916 - val_loss: 0.0737 - val_accuracy: 0.9804\n",
      "Epoch 2268/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0305 - accuracy: 0.9920 - val_loss: 0.0527 - val_accuracy: 0.9869\n",
      "Epoch 2269/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0206 - accuracy: 0.9944 - val_loss: 0.0729 - val_accuracy: 0.9800\n",
      "Epoch 2270/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0271 - accuracy: 0.9913 - val_loss: 0.0921 - val_accuracy: 0.9767\n",
      "Epoch 2271/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0314 - accuracy: 0.9919 - val_loss: 0.0479 - val_accuracy: 0.9883\n",
      "Epoch 2272/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0473 - val_accuracy: 0.9883\n",
      "Epoch 2273/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9925 - val_loss: 0.0560 - val_accuracy: 0.9865\n",
      "Epoch 2274/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 0.0525 - val_accuracy: 0.9883\n",
      "Epoch 2275/3500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.0457 - val_accuracy: 0.9879\n",
      "Epoch 2276/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0539 - val_accuracy: 0.9879\n",
      "Epoch 2277/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0518 - val_accuracy: 0.9879\n",
      "Epoch 2278/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.0446 - val_accuracy: 0.9883\n",
      "Epoch 2279/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.0525 - val_accuracy: 0.9883\n",
      "Epoch 2280/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9946 - val_loss: 0.0483 - val_accuracy: 0.9888\n",
      "Epoch 2281/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.0444 - val_accuracy: 0.9879\n",
      "Epoch 2282/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0267 - accuracy: 0.9903 - val_loss: 0.0458 - val_accuracy: 0.9874\n",
      "Epoch 2283/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0435 - val_accuracy: 0.9883\n",
      "Epoch 2284/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.0585 - val_accuracy: 0.9851\n",
      "Epoch 2285/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0220 - accuracy: 0.9942 - val_loss: 0.0539 - val_accuracy: 0.9883\n",
      "Epoch 2286/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.0600 - val_accuracy: 0.9855\n",
      "Epoch 2287/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.0699 - val_accuracy: 0.9804\n",
      "Epoch 2288/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.0818 - val_accuracy: 0.9781\n",
      "Epoch 2289/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.0550 - val_accuracy: 0.9865\n",
      "Epoch 2290/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 0.0782 - val_accuracy: 0.9781\n",
      "Epoch 2291/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0336 - accuracy: 0.9894 - val_loss: 0.0499 - val_accuracy: 0.9883\n",
      "Epoch 2292/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0282 - accuracy: 0.9919 - val_loss: 0.0541 - val_accuracy: 0.9869\n",
      "Epoch 2293/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.0468 - val_accuracy: 0.9869\n",
      "Epoch 2294/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0253 - accuracy: 0.9918 - val_loss: 0.0480 - val_accuracy: 0.9869\n",
      "Epoch 2295/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.0483 - val_accuracy: 0.9865\n",
      "Epoch 2296/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0334 - accuracy: 0.9886 - val_loss: 0.0461 - val_accuracy: 0.9869\n",
      "Epoch 2297/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0285 - accuracy: 0.9906 - val_loss: 0.0467 - val_accuracy: 0.9869\n",
      "Epoch 2298/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.0479 - val_accuracy: 0.9879\n",
      "Epoch 2299/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 2300/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.0526 - val_accuracy: 0.9874\n",
      "Epoch 2301/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0439 - val_accuracy: 0.9869\n",
      "Epoch 2302/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.0454 - val_accuracy: 0.9869\n",
      "Epoch 2303/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0250 - accuracy: 0.9929 - val_loss: 0.0635 - val_accuracy: 0.9828\n",
      "Epoch 2304/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 0.0450 - val_accuracy: 0.9883\n",
      "Epoch 2305/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.0488 - val_accuracy: 0.9888\n",
      "Epoch 2306/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.0495 - val_accuracy: 0.9879\n",
      "Epoch 2307/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.0476 - val_accuracy: 0.9883\n",
      "Epoch 2308/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9954 - val_loss: 0.0458 - val_accuracy: 0.9874\n",
      "Epoch 2309/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.0514 - val_accuracy: 0.9874\n",
      "Epoch 2310/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 0.0474 - val_accuracy: 0.9888\n",
      "Epoch 2311/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.0723 - val_accuracy: 0.9790\n",
      "Epoch 2312/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0281 - accuracy: 0.9907 - val_loss: 0.0499 - val_accuracy: 0.9879\n",
      "Epoch 2313/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.0545 - val_accuracy: 0.9869\n",
      "Epoch 2314/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0581 - val_accuracy: 0.9860\n",
      "Epoch 2315/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0266 - accuracy: 0.9929 - val_loss: 0.0762 - val_accuracy: 0.9781\n",
      "Epoch 2316/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.0500 - val_accuracy: 0.9879\n",
      "Epoch 2317/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0486 - val_accuracy: 0.9874\n",
      "Epoch 2318/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.0495 - val_accuracy: 0.9874\n",
      "Epoch 2319/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9914 - val_loss: 0.0591 - val_accuracy: 0.9869\n",
      "Epoch 2320/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0373 - accuracy: 0.9882 - val_loss: 0.0445 - val_accuracy: 0.9879\n",
      "Epoch 2321/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0464 - val_accuracy: 0.9888\n",
      "Epoch 2322/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 2323/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.0490 - val_accuracy: 0.9883\n",
      "Epoch 2324/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9898 - val_loss: 0.0462 - val_accuracy: 0.9865\n",
      "Epoch 2325/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0463 - val_accuracy: 0.9869\n",
      "Epoch 2326/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.0458 - val_accuracy: 0.9865\n",
      "Epoch 2327/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.0536 - val_accuracy: 0.9879\n",
      "Epoch 2328/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.0530 - val_accuracy: 0.9874\n",
      "Epoch 2329/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.0487 - val_accuracy: 0.9879\n",
      "Epoch 2330/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0476 - val_accuracy: 0.9879\n",
      "Epoch 2331/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 2332/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.0488 - val_accuracy: 0.9874\n",
      "Epoch 2333/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0306 - accuracy: 0.9897 - val_loss: 0.0446 - val_accuracy: 0.9874\n",
      "Epoch 2334/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0270 - accuracy: 0.9895 - val_loss: 0.0494 - val_accuracy: 0.9883\n",
      "Epoch 2335/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.0495 - val_accuracy: 0.9874\n",
      "Epoch 2336/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.0481 - val_accuracy: 0.9883\n",
      "Epoch 2337/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.0456 - val_accuracy: 0.9869\n",
      "Epoch 2338/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.0454 - val_accuracy: 0.9874\n",
      "Epoch 2339/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9923 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
      "Epoch 2340/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.0602 - val_accuracy: 0.9851\n",
      "Epoch 2341/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.0612 - val_accuracy: 0.9851\n",
      "Epoch 2342/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.0695 - val_accuracy: 0.9809\n",
      "Epoch 2343/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.0585 - val_accuracy: 0.9869\n",
      "Epoch 2344/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.0458 - val_accuracy: 0.9869\n",
      "Epoch 2345/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0335 - accuracy: 0.9901 - val_loss: 0.0459 - val_accuracy: 0.9874\n",
      "Epoch 2346/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.0469 - val_accuracy: 0.9869\n",
      "Epoch 2347/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.0516 - val_accuracy: 0.9879\n",
      "Epoch 2348/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 0.0563 - val_accuracy: 0.9874\n",
      "Epoch 2349/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 0.9931 - val_loss: 0.0472 - val_accuracy: 0.9883\n",
      "Epoch 2350/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9928 - val_loss: 0.0485 - val_accuracy: 0.9883\n",
      "Epoch 2351/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.0475 - val_accuracy: 0.9883\n",
      "Epoch 2352/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0565 - val_accuracy: 0.9865\n",
      "Epoch 2353/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0555 - val_accuracy: 0.9874\n",
      "Epoch 2354/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 2355/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.0481 - val_accuracy: 0.9883\n",
      "Epoch 2356/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0477 - val_accuracy: 0.9869\n",
      "Epoch 2357/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9883 - val_loss: 0.0514 - val_accuracy: 0.9883\n",
      "Epoch 2358/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.0607 - val_accuracy: 0.9860\n",
      "Epoch 2359/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0318 - accuracy: 0.9907 - val_loss: 0.0516 - val_accuracy: 0.9879\n",
      "Epoch 2360/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0569 - val_accuracy: 0.9865\n",
      "Epoch 2361/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0538 - val_accuracy: 0.9879\n",
      "Epoch 2362/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0514 - val_accuracy: 0.9874\n",
      "Epoch 2363/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.0494 - val_accuracy: 0.9883\n",
      "Epoch 2364/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9937 - val_loss: 0.0462 - val_accuracy: 0.9874\n",
      "Epoch 2365/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0585 - val_accuracy: 0.9869\n",
      "Epoch 2366/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9964 - val_loss: 0.0898 - val_accuracy: 0.9767\n",
      "Epoch 2367/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9893 - val_loss: 0.0500 - val_accuracy: 0.9888\n",
      "Epoch 2368/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0472 - val_accuracy: 0.9865\n",
      "Epoch 2369/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.0463 - val_accuracy: 0.9879\n",
      "Epoch 2370/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 0.0478 - val_accuracy: 0.9893\n",
      "Epoch 2371/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.0455 - val_accuracy: 0.9865\n",
      "Epoch 2372/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.0511 - val_accuracy: 0.9879\n",
      "Epoch 2373/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0250 - accuracy: 0.9903 - val_loss: 0.0455 - val_accuracy: 0.9869\n",
      "Epoch 2374/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.0481 - val_accuracy: 0.9883\n",
      "Epoch 2375/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.0467 - val_accuracy: 0.9879\n",
      "Epoch 2376/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.0468 - val_accuracy: 0.9874\n",
      "Epoch 2377/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9907 - val_loss: 0.0559 - val_accuracy: 0.9869\n",
      "Epoch 2378/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9936 - val_loss: 0.0515 - val_accuracy: 0.9879\n",
      "Epoch 2379/3500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.0736 - val_accuracy: 0.9795\n",
      "Epoch 2380/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0281 - accuracy: 0.9906 - val_loss: 0.0525 - val_accuracy: 0.9874\n",
      "Epoch 2381/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0475 - val_accuracy: 0.9874\n",
      "Epoch 2382/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.0464 - val_accuracy: 0.9874\n",
      "Epoch 2383/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.0466 - val_accuracy: 0.9869\n",
      "Epoch 2384/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0261 - accuracy: 0.9914 - val_loss: 0.0487 - val_accuracy: 0.9879\n",
      "Epoch 2385/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9955 - val_loss: 0.0470 - val_accuracy: 0.9888\n",
      "Epoch 2386/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9915 - val_loss: 0.0461 - val_accuracy: 0.9865\n",
      "Epoch 2387/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 0.0479 - val_accuracy: 0.9888\n",
      "Epoch 2388/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 0.0588 - val_accuracy: 0.9869\n",
      "Epoch 2389/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.0532 - val_accuracy: 0.9869\n",
      "Epoch 2390/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9917 - val_loss: 0.0449 - val_accuracy: 0.9874\n",
      "Epoch 2391/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 0.9893 - val_loss: 0.0474 - val_accuracy: 0.9869\n",
      "Epoch 2392/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9912 - val_loss: 0.0491 - val_accuracy: 0.9879\n",
      "Epoch 2393/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0512 - val_accuracy: 0.9874\n",
      "Epoch 2394/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9938 - val_loss: 0.0634 - val_accuracy: 0.9841\n",
      "Epoch 2395/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0302 - accuracy: 0.9918 - val_loss: 0.0699 - val_accuracy: 0.9814\n",
      "Epoch 2396/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0729 - val_accuracy: 0.9809\n",
      "Epoch 2397/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9901 - val_loss: 0.0647 - val_accuracy: 0.9837\n",
      "Epoch 2398/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0487 - val_accuracy: 0.9879\n",
      "Epoch 2399/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 0.0452 - val_accuracy: 0.9879\n",
      "Epoch 2400/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0482 - val_accuracy: 0.9883\n",
      "Epoch 2401/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.0452 - val_accuracy: 0.9874\n",
      "Epoch 2402/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0279 - accuracy: 0.9904 - val_loss: 0.0459 - val_accuracy: 0.9874\n",
      "Epoch 2403/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0459 - val_accuracy: 0.9879\n",
      "Epoch 2404/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0316 - accuracy: 0.9877 - val_loss: 0.0845 - val_accuracy: 0.9767\n",
      "Epoch 2405/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 0.0647 - val_accuracy: 0.9823\n",
      "Epoch 2406/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0533 - val_accuracy: 0.9883\n",
      "Epoch 2407/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.0499 - val_accuracy: 0.9883\n",
      "Epoch 2408/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9924 - val_loss: 0.0543 - val_accuracy: 0.9879\n",
      "Epoch 2409/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9932 - val_loss: 0.0485 - val_accuracy: 0.9883\n",
      "Epoch 2410/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9913 - val_loss: 0.0471 - val_accuracy: 0.9874\n",
      "Epoch 2411/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0299 - accuracy: 0.9884 - val_loss: 0.0548 - val_accuracy: 0.9874\n",
      "Epoch 2412/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9879 - val_loss: 0.0484 - val_accuracy: 0.9874\n",
      "Epoch 2413/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 0.0496 - val_accuracy: 0.9879\n",
      "Epoch 2414/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.0538 - val_accuracy: 0.9879\n",
      "Epoch 2415/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 2416/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0452 - val_accuracy: 0.9869\n",
      "Epoch 2417/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
      "Epoch 2418/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9925 - val_loss: 0.0468 - val_accuracy: 0.9879\n",
      "Epoch 2419/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.9934 - val_loss: 0.0557 - val_accuracy: 0.9879\n",
      "Epoch 2420/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0521 - val_accuracy: 0.9874\n",
      "Epoch 2421/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.0568 - val_accuracy: 0.9869\n",
      "Epoch 2422/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
      "Epoch 2423/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.0614 - val_accuracy: 0.9855\n",
      "Epoch 2424/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.0485 - val_accuracy: 0.9883\n",
      "Epoch 2425/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.0468 - val_accuracy: 0.9874\n",
      "Epoch 2426/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9925 - val_loss: 0.0472 - val_accuracy: 0.9879\n",
      "Epoch 2427/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.0455 - val_accuracy: 0.9874\n",
      "Epoch 2428/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.0462 - val_accuracy: 0.9879\n",
      "Epoch 2429/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 0.0483 - val_accuracy: 0.9874\n",
      "Epoch 2430/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0294 - accuracy: 0.9891 - val_loss: 0.0468 - val_accuracy: 0.9888\n",
      "Epoch 2431/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0455 - val_accuracy: 0.9888\n",
      "Epoch 2432/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.0470 - val_accuracy: 0.9874\n",
      "Epoch 2433/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0459 - val_accuracy: 0.9879\n",
      "Epoch 2434/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0237 - accuracy: 0.9938 - val_loss: 0.0446 - val_accuracy: 0.9874\n",
      "Epoch 2435/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0468 - val_accuracy: 0.9874\n",
      "Epoch 2436/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9926 - val_loss: 0.0478 - val_accuracy: 0.9879\n",
      "Epoch 2437/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9916 - val_loss: 0.0488 - val_accuracy: 0.9883\n",
      "Epoch 2438/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0485 - val_accuracy: 0.9883\n",
      "Epoch 2439/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.0568 - val_accuracy: 0.9874\n",
      "Epoch 2440/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0271 - accuracy: 0.9919 - val_loss: 0.0589 - val_accuracy: 0.9869\n",
      "Epoch 2441/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 0.9939 - val_loss: 0.0636 - val_accuracy: 0.9828\n",
      "Epoch 2442/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0505 - val_accuracy: 0.9883\n",
      "Epoch 2443/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0540 - val_accuracy: 0.9879\n",
      "Epoch 2444/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0476 - val_accuracy: 0.9874\n",
      "Epoch 2445/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 0.0446 - val_accuracy: 0.9879\n",
      "Epoch 2446/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0260 - accuracy: 0.9897 - val_loss: 0.0534 - val_accuracy: 0.9883\n",
      "Epoch 2447/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.0530 - val_accuracy: 0.9879\n",
      "Epoch 2448/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0474 - val_accuracy: 0.9888\n",
      "Epoch 2449/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 0.0562 - val_accuracy: 0.9874\n",
      "Epoch 2450/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 0.0563 - val_accuracy: 0.9874\n",
      "Epoch 2451/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9944 - val_loss: 0.0580 - val_accuracy: 0.9865\n",
      "Epoch 2452/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 0.0602 - val_accuracy: 0.9851\n",
      "Epoch 2453/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.0449 - val_accuracy: 0.9874\n",
      "Epoch 2454/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9928 - val_loss: 0.0442 - val_accuracy: 0.9879\n",
      "Epoch 2455/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9892 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 2456/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9918 - val_loss: 0.0445 - val_accuracy: 0.9883\n",
      "Epoch 2457/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9920 - val_loss: 0.0458 - val_accuracy: 0.9879\n",
      "Epoch 2458/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.0477 - val_accuracy: 0.9874\n",
      "Epoch 2459/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9920 - val_loss: 0.0478 - val_accuracy: 0.9874\n",
      "Epoch 2460/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9935 - val_loss: 0.0452 - val_accuracy: 0.9874\n",
      "Epoch 2461/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 0.9930 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 2462/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0460 - val_accuracy: 0.9874\n",
      "Epoch 2463/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 0.9910 - val_loss: 0.0486 - val_accuracy: 0.9869\n",
      "Epoch 2464/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0372 - accuracy: 0.9887 - val_loss: 0.0496 - val_accuracy: 0.9874\n",
      "Epoch 2465/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0480 - val_accuracy: 0.9865\n",
      "Epoch 2466/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.0612 - val_accuracy: 0.9851\n",
      "Epoch 2467/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.0604 - val_accuracy: 0.9851\n",
      "Epoch 2468/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9939 - val_loss: 0.0683 - val_accuracy: 0.9823\n",
      "Epoch 2469/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 0.0513 - val_accuracy: 0.9879\n",
      "Epoch 2470/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0663 - val_accuracy: 0.9823\n",
      "Epoch 2471/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0273 - accuracy: 0.9924 - val_loss: 0.0487 - val_accuracy: 0.9883\n",
      "Epoch 2472/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
      "Epoch 2473/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0537 - val_accuracy: 0.9879\n",
      "Epoch 2474/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.0563 - val_accuracy: 0.9869\n",
      "Epoch 2475/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.0631 - val_accuracy: 0.9855\n",
      "Epoch 2476/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.0707 - val_accuracy: 0.9809\n",
      "Epoch 2477/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 0.0475 - val_accuracy: 0.9883\n",
      "Epoch 2478/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.0469 - val_accuracy: 0.9879\n",
      "Epoch 2479/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.0489 - val_accuracy: 0.9883\n",
      "Epoch 2480/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0448 - val_accuracy: 0.9879\n",
      "Epoch 2481/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.0519 - val_accuracy: 0.9874\n",
      "Epoch 2482/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.0542 - val_accuracy: 0.9874\n",
      "Epoch 2483/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0313 - accuracy: 0.9877 - val_loss: 0.0499 - val_accuracy: 0.9879\n",
      "Epoch 2484/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0293 - accuracy: 0.9889 - val_loss: 0.0483 - val_accuracy: 0.9874\n",
      "Epoch 2485/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0298 - accuracy: 0.9882 - val_loss: 0.0490 - val_accuracy: 0.9883\n",
      "Epoch 2486/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 0.9924 - val_loss: 0.0486 - val_accuracy: 0.9879\n",
      "Epoch 2487/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.0491 - val_accuracy: 0.9883\n",
      "Epoch 2488/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 2489/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.0462 - val_accuracy: 0.9869\n",
      "Epoch 2490/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.0456 - val_accuracy: 0.9879\n",
      "Epoch 2491/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.0452 - val_accuracy: 0.9883\n",
      "Epoch 2492/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0483 - val_accuracy: 0.9874\n",
      "Epoch 2493/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.0520 - val_accuracy: 0.9874\n",
      "Epoch 2494/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.0439 - val_accuracy: 0.9874\n",
      "Epoch 2495/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.0470 - val_accuracy: 0.9874\n",
      "Epoch 2496/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.0461 - val_accuracy: 0.9883\n",
      "Epoch 2497/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 2498/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0453 - val_accuracy: 0.9883\n",
      "Epoch 2499/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.0456 - val_accuracy: 0.9869\n",
      "Epoch 2500/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.0453 - val_accuracy: 0.9883\n",
      "Epoch 2501/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.0627 - val_accuracy: 0.9855\n",
      "Epoch 2502/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9940 - val_loss: 0.0574 - val_accuracy: 0.9869\n",
      "Epoch 2503/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 0.0491 - val_accuracy: 0.9883\n",
      "Epoch 2504/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.0459 - val_accuracy: 0.9874\n",
      "Epoch 2505/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0521 - val_accuracy: 0.9883\n",
      "Epoch 2506/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0558 - val_accuracy: 0.9879\n",
      "Epoch 2507/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0203 - accuracy: 0.9943 - val_loss: 0.0493 - val_accuracy: 0.9893\n",
      "Epoch 2508/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0487 - val_accuracy: 0.9888\n",
      "Epoch 2509/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.0471 - val_accuracy: 0.9874\n",
      "Epoch 2510/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0427 - accuracy: 0.9873 - val_loss: 0.0656 - val_accuracy: 0.9841\n",
      "Epoch 2511/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0360 - accuracy: 0.9882 - val_loss: 0.0524 - val_accuracy: 0.9874\n",
      "Epoch 2512/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0289 - accuracy: 0.9918 - val_loss: 0.0629 - val_accuracy: 0.9846\n",
      "Epoch 2513/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9948 - val_loss: 0.0596 - val_accuracy: 0.9865\n",
      "Epoch 2514/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.0544 - val_accuracy: 0.9874\n",
      "Epoch 2515/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.0459 - val_accuracy: 0.9883\n",
      "Epoch 2516/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.0564 - val_accuracy: 0.9874\n",
      "Epoch 2517/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.0581 - val_accuracy: 0.9874\n",
      "Epoch 2518/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 0.0534 - val_accuracy: 0.9879\n",
      "Epoch 2519/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0464 - val_accuracy: 0.9879\n",
      "Epoch 2520/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 0.0497 - val_accuracy: 0.9888\n",
      "Epoch 2521/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9955 - val_loss: 0.0457 - val_accuracy: 0.9883\n",
      "Epoch 2522/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.0474 - val_accuracy: 0.9879\n",
      "Epoch 2523/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9948 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 2524/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 0.0506 - val_accuracy: 0.9879\n",
      "Epoch 2525/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 0.0626 - val_accuracy: 0.9846\n",
      "Epoch 2526/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9917 - val_loss: 0.0687 - val_accuracy: 0.9809\n",
      "Epoch 2527/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 0.0674 - val_accuracy: 0.9818\n",
      "Epoch 2528/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.0577 - val_accuracy: 0.9865\n",
      "Epoch 2529/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0509 - val_accuracy: 0.9879\n",
      "Epoch 2530/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0606 - val_accuracy: 0.9865\n",
      "Epoch 2531/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.0471 - val_accuracy: 0.9874\n",
      "Epoch 2532/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 0.0452 - val_accuracy: 0.9874\n",
      "Epoch 2533/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.0449 - val_accuracy: 0.9874\n",
      "Epoch 2534/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9926 - val_loss: 0.0490 - val_accuracy: 0.9879\n",
      "Epoch 2535/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 0.0499 - val_accuracy: 0.9888\n",
      "Epoch 2536/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0308 - accuracy: 0.9878 - val_loss: 0.0487 - val_accuracy: 0.9869\n",
      "Epoch 2537/3500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.0217 - accuracy: 0.9913 - val_loss: 0.0464 - val_accuracy: 0.9874\n",
      "Epoch 2538/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.0450 - val_accuracy: 0.9888\n",
      "Epoch 2539/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 2540/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.0461 - val_accuracy: 0.9879\n",
      "Epoch 2541/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.0490 - val_accuracy: 0.9888\n",
      "Epoch 2542/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0483 - val_accuracy: 0.9893\n",
      "Epoch 2543/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0464 - val_accuracy: 0.9879\n",
      "Epoch 2544/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0243 - accuracy: 0.9909 - val_loss: 0.0454 - val_accuracy: 0.9883\n",
      "Epoch 2545/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9929 - val_loss: 0.0464 - val_accuracy: 0.9879\n",
      "Epoch 2546/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9929 - val_loss: 0.0491 - val_accuracy: 0.9874\n",
      "Epoch 2547/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9887 - val_loss: 0.0457 - val_accuracy: 0.9879\n",
      "Epoch 2548/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9922 - val_loss: 0.0499 - val_accuracy: 0.9874\n",
      "Epoch 2549/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0322 - accuracy: 0.9893 - val_loss: 0.0470 - val_accuracy: 0.9874\n",
      "Epoch 2550/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0528 - val_accuracy: 0.9879\n",
      "Epoch 2551/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0604 - val_accuracy: 0.9865\n",
      "Epoch 2552/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.0524 - val_accuracy: 0.9879\n",
      "Epoch 2553/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9941 - val_loss: 0.0515 - val_accuracy: 0.9874\n",
      "Epoch 2554/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.0580 - val_accuracy: 0.9879\n",
      "Epoch 2555/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.0861 - val_accuracy: 0.9758\n",
      "Epoch 2556/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0267 - accuracy: 0.9926 - val_loss: 0.0508 - val_accuracy: 0.9879\n",
      "Epoch 2557/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.0469 - val_accuracy: 0.9893\n",
      "Epoch 2558/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.0467 - val_accuracy: 0.9874\n",
      "Epoch 2559/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.0463 - val_accuracy: 0.9869\n",
      "Epoch 2560/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9956 - val_loss: 0.0454 - val_accuracy: 0.9879\n",
      "Epoch 2561/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.0501 - val_accuracy: 0.9883\n",
      "Epoch 2562/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.0518 - val_accuracy: 0.9879\n",
      "Epoch 2563/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0241 - accuracy: 0.9930 - val_loss: 0.0613 - val_accuracy: 0.9860\n",
      "Epoch 2564/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.0473 - val_accuracy: 0.9879\n",
      "Epoch 2565/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0263 - accuracy: 0.9902 - val_loss: 0.0530 - val_accuracy: 0.9879\n",
      "Epoch 2566/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 0.9948 - val_loss: 0.0506 - val_accuracy: 0.9883\n",
      "Epoch 2567/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9937 - val_loss: 0.0464 - val_accuracy: 0.9883\n",
      "Epoch 2568/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0477 - val_accuracy: 0.9888\n",
      "Epoch 2569/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0170 - accuracy: 0.9932 - val_loss: 0.0483 - val_accuracy: 0.9893\n",
      "Epoch 2570/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.0462 - val_accuracy: 0.9874\n",
      "Epoch 2571/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 2572/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.0475 - val_accuracy: 0.9893\n",
      "Epoch 2573/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 0.9955 - val_loss: 0.0498 - val_accuracy: 0.9883\n",
      "Epoch 2574/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.0464 - val_accuracy: 0.9879\n",
      "Epoch 2575/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 0.0455 - val_accuracy: 0.9869\n",
      "Epoch 2576/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9922 - val_loss: 0.0498 - val_accuracy: 0.9888\n",
      "Epoch 2577/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.0462 - val_accuracy: 0.9865\n",
      "Epoch 2578/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9955 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 2579/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0535 - val_accuracy: 0.9883\n",
      "Epoch 2580/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0198 - accuracy: 0.9950 - val_loss: 0.0483 - val_accuracy: 0.9893\n",
      "Epoch 2581/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0468 - val_accuracy: 0.9888\n",
      "Epoch 2582/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.0475 - val_accuracy: 0.9888\n",
      "Epoch 2583/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9926 - val_loss: 0.0476 - val_accuracy: 0.9879\n",
      "Epoch 2584/3500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.0458 - val_accuracy: 0.9869\n",
      "Epoch 2585/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9924 - val_loss: 0.0499 - val_accuracy: 0.9883\n",
      "Epoch 2586/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 0.0542 - val_accuracy: 0.9874\n",
      "Epoch 2587/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0496 - val_accuracy: 0.9888\n",
      "Epoch 2588/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.0459 - val_accuracy: 0.9874\n",
      "Epoch 2589/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.0472 - val_accuracy: 0.9888\n",
      "Epoch 2590/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0222 - accuracy: 0.9918 - val_loss: 0.0471 - val_accuracy: 0.9874\n",
      "Epoch 2591/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0228 - accuracy: 0.9920 - val_loss: 0.0514 - val_accuracy: 0.9874\n",
      "Epoch 2592/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9906 - val_loss: 0.0497 - val_accuracy: 0.9879\n",
      "Epoch 2593/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0285 - accuracy: 0.9906 - val_loss: 0.0466 - val_accuracy: 0.9874\n",
      "Epoch 2594/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0508 - val_accuracy: 0.9874\n",
      "Epoch 2595/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.0499 - val_accuracy: 0.9883\n",
      "Epoch 2596/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.0511 - val_accuracy: 0.9874\n",
      "Epoch 2597/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.0497 - val_accuracy: 0.9888\n",
      "Epoch 2598/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.0483 - val_accuracy: 0.9893\n",
      "Epoch 2599/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.0526 - val_accuracy: 0.9879\n",
      "Epoch 2600/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.0516 - val_accuracy: 0.9879\n",
      "Epoch 2601/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.0482 - val_accuracy: 0.9874\n",
      "Epoch 2602/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.0449 - val_accuracy: 0.9879\n",
      "Epoch 2603/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.0496 - val_accuracy: 0.9888\n",
      "Epoch 2604/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9935 - val_loss: 0.0538 - val_accuracy: 0.9869\n",
      "Epoch 2605/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0459 - val_accuracy: 0.9883\n",
      "Epoch 2606/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0451 - val_accuracy: 0.9874\n",
      "Epoch 2607/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 0.0497 - val_accuracy: 0.9883\n",
      "Epoch 2608/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 0.0569 - val_accuracy: 0.9869\n",
      "Epoch 2609/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.0494 - val_accuracy: 0.9879\n",
      "Epoch 2610/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 0.0542 - val_accuracy: 0.9874\n",
      "Epoch 2611/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0671 - val_accuracy: 0.9837\n",
      "Epoch 2612/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.0609 - val_accuracy: 0.9865\n",
      "Epoch 2613/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0472 - val_accuracy: 0.9888\n",
      "Epoch 2614/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9935 - val_loss: 0.0484 - val_accuracy: 0.9888\n",
      "Epoch 2615/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.0457 - val_accuracy: 0.9888\n",
      "Epoch 2616/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0454 - val_accuracy: 0.9883\n",
      "Epoch 2617/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9935 - val_loss: 0.0464 - val_accuracy: 0.9883\n",
      "Epoch 2618/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0486 - val_accuracy: 0.9893\n",
      "Epoch 2619/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.0471 - val_accuracy: 0.9883\n",
      "Epoch 2620/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0224 - accuracy: 0.9919 - val_loss: 0.0716 - val_accuracy: 0.9823\n",
      "Epoch 2621/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0331 - accuracy: 0.9898 - val_loss: 0.0900 - val_accuracy: 0.9776\n",
      "Epoch 2622/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0358 - accuracy: 0.9899 - val_loss: 0.0548 - val_accuracy: 0.9869\n",
      "Epoch 2623/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.0480 - val_accuracy: 0.9874\n",
      "Epoch 2624/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.0468 - val_accuracy: 0.9883\n",
      "Epoch 2625/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0509 - val_accuracy: 0.9883\n",
      "Epoch 2626/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.0467 - val_accuracy: 0.9874\n",
      "Epoch 2627/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0466 - val_accuracy: 0.9869\n",
      "Epoch 2628/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.0459 - val_accuracy: 0.9874\n",
      "Epoch 2629/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9936 - val_loss: 0.0457 - val_accuracy: 0.9869\n",
      "Epoch 2630/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9948 - val_loss: 0.0471 - val_accuracy: 0.9883\n",
      "Epoch 2631/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.0462 - val_accuracy: 0.9883\n",
      "Epoch 2632/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0557 - val_accuracy: 0.9879\n",
      "Epoch 2633/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0510 - val_accuracy: 0.9888\n",
      "Epoch 2634/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 0.0506 - val_accuracy: 0.9874\n",
      "Epoch 2635/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 0.9910 - val_loss: 0.0457 - val_accuracy: 0.9883\n",
      "Epoch 2636/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.0561 - val_accuracy: 0.9874\n",
      "Epoch 2637/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0741 - val_accuracy: 0.9809\n",
      "Epoch 2638/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0275 - accuracy: 0.9915 - val_loss: 0.0534 - val_accuracy: 0.9879\n",
      "Epoch 2639/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.0580 - val_accuracy: 0.9869\n",
      "Epoch 2640/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 0.0493 - val_accuracy: 0.9888\n",
      "Epoch 2641/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0482 - val_accuracy: 0.9893\n",
      "Epoch 2642/3500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.0500 - val_accuracy: 0.9888\n",
      "Epoch 2643/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0520 - val_accuracy: 0.9879\n",
      "Epoch 2644/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.0455 - val_accuracy: 0.9883\n",
      "Epoch 2645/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0468 - val_accuracy: 0.9883\n",
      "Epoch 2646/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9934 - val_loss: 0.0529 - val_accuracy: 0.9888\n",
      "Epoch 2647/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0654 - val_accuracy: 0.9828\n",
      "Epoch 2648/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0358 - accuracy: 0.9894 - val_loss: 0.0456 - val_accuracy: 0.9883\n",
      "Epoch 2649/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.0482 - val_accuracy: 0.9888\n",
      "Epoch 2650/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0286 - accuracy: 0.9898 - val_loss: 0.0462 - val_accuracy: 0.9869\n",
      "Epoch 2651/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.0468 - val_accuracy: 0.9883\n",
      "Epoch 2652/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.0482 - val_accuracy: 0.9893\n",
      "Epoch 2653/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.0485 - val_accuracy: 0.9888\n",
      "Epoch 2654/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9960 - val_loss: 0.0521 - val_accuracy: 0.9883\n",
      "Epoch 2655/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.0472 - val_accuracy: 0.9883\n",
      "Epoch 2656/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.0559 - val_accuracy: 0.9883\n",
      "Epoch 2657/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0594 - val_accuracy: 0.9874\n",
      "Epoch 2658/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.0545 - val_accuracy: 0.9879\n",
      "Epoch 2659/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.0574 - val_accuracy: 0.9879\n",
      "Epoch 2660/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.0665 - val_accuracy: 0.9841\n",
      "Epoch 2661/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9934 - val_loss: 0.0862 - val_accuracy: 0.9772\n",
      "Epoch 2662/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0319 - accuracy: 0.9892 - val_loss: 0.0884 - val_accuracy: 0.9772\n",
      "Epoch 2663/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9887 - val_loss: 0.0614 - val_accuracy: 0.9855\n",
      "Epoch 2664/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9958 - val_loss: 0.0531 - val_accuracy: 0.9865\n",
      "Epoch 2665/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9943 - val_loss: 0.0640 - val_accuracy: 0.9851\n",
      "Epoch 2666/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 0.0497 - val_accuracy: 0.9883\n",
      "Epoch 2667/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0520 - val_accuracy: 0.9879\n",
      "Epoch 2668/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.0513 - val_accuracy: 0.9888\n",
      "Epoch 2669/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0323 - accuracy: 0.9915 - val_loss: 0.0735 - val_accuracy: 0.9804\n",
      "Epoch 2670/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0243 - accuracy: 0.9929 - val_loss: 0.0732 - val_accuracy: 0.9800\n",
      "Epoch 2671/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 0.0693 - val_accuracy: 0.9818\n",
      "Epoch 2672/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0284 - accuracy: 0.9904 - val_loss: 0.0548 - val_accuracy: 0.9874\n",
      "Epoch 2673/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0463 - val_accuracy: 0.9883\n",
      "Epoch 2674/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.0473 - val_accuracy: 0.9879\n",
      "Epoch 2675/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.0486 - val_accuracy: 0.9888\n",
      "Epoch 2676/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.0482 - val_accuracy: 0.9893\n",
      "Epoch 2677/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0485 - val_accuracy: 0.9883\n",
      "Epoch 2678/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.0475 - val_accuracy: 0.9874\n",
      "Epoch 2679/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.0491 - val_accuracy: 0.9893\n",
      "Epoch 2680/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 2681/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.0541 - val_accuracy: 0.9883\n",
      "Epoch 2682/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0558 - val_accuracy: 0.9879\n",
      "Epoch 2683/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.0486 - val_accuracy: 0.9893\n",
      "Epoch 2684/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.0474 - val_accuracy: 0.9874\n",
      "Epoch 2685/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.0481 - val_accuracy: 0.9874\n",
      "Epoch 2686/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9891 - val_loss: 0.0498 - val_accuracy: 0.9879\n",
      "Epoch 2687/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 0.0582 - val_accuracy: 0.9883\n",
      "Epoch 2688/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0308 - accuracy: 0.9897 - val_loss: 0.0806 - val_accuracy: 0.9786\n",
      "Epoch 2689/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 0.9884 - val_loss: 0.0707 - val_accuracy: 0.9814\n",
      "Epoch 2690/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0352 - accuracy: 0.9894 - val_loss: 0.0707 - val_accuracy: 0.9809\n",
      "Epoch 2691/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.0527 - val_accuracy: 0.9879\n",
      "Epoch 2692/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.0490 - val_accuracy: 0.9883\n",
      "Epoch 2693/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.0535 - val_accuracy: 0.9879\n",
      "Epoch 2694/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.0507 - val_accuracy: 0.9897\n",
      "Epoch 2695/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.0513 - val_accuracy: 0.9879\n",
      "Epoch 2696/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.0532 - val_accuracy: 0.9879\n",
      "Epoch 2697/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.0487 - val_accuracy: 0.9883\n",
      "Epoch 2698/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.0524 - val_accuracy: 0.9888\n",
      "Epoch 2699/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0465 - val_accuracy: 0.9879\n",
      "Epoch 2700/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0451 - val_accuracy: 0.9879\n",
      "Epoch 2701/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 2702/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.0503 - val_accuracy: 0.9893\n",
      "Epoch 2703/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.0488 - val_accuracy: 0.9888\n",
      "Epoch 2704/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.0561 - val_accuracy: 0.9879\n",
      "Epoch 2705/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.0544 - val_accuracy: 0.9879\n",
      "Epoch 2706/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0541 - val_accuracy: 0.9883\n",
      "Epoch 2707/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0478 - val_accuracy: 0.9883\n",
      "Epoch 2708/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9945 - val_loss: 0.0464 - val_accuracy: 0.9883\n",
      "Epoch 2709/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9916 - val_loss: 0.0482 - val_accuracy: 0.9874\n",
      "Epoch 2710/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.0498 - val_accuracy: 0.9879\n",
      "Epoch 2711/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0393 - accuracy: 0.9886 - val_loss: 0.0468 - val_accuracy: 0.9879\n",
      "Epoch 2712/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 2713/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9907 - val_loss: 0.0577 - val_accuracy: 0.9879\n",
      "Epoch 2714/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0322 - accuracy: 0.9907 - val_loss: 0.0700 - val_accuracy: 0.9809\n",
      "Epoch 2715/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 0.0580 - val_accuracy: 0.9874\n",
      "Epoch 2716/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9943 - val_loss: 0.0493 - val_accuracy: 0.9883\n",
      "Epoch 2717/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.0547 - val_accuracy: 0.9879\n",
      "Epoch 2718/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.0491 - val_accuracy: 0.9879\n",
      "Epoch 2719/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0458 - val_accuracy: 0.9879\n",
      "Epoch 2720/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0488 - val_accuracy: 0.9883\n",
      "Epoch 2721/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0469 - val_accuracy: 0.9888\n",
      "Epoch 2722/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0245 - accuracy: 0.9900 - val_loss: 0.0459 - val_accuracy: 0.9879\n",
      "Epoch 2723/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.0585 - val_accuracy: 0.9869\n",
      "Epoch 2724/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.0661 - val_accuracy: 0.9837\n",
      "Epoch 2725/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
      "Epoch 2726/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0461 - val_accuracy: 0.9883\n",
      "Epoch 2727/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.0475 - val_accuracy: 0.9874\n",
      "Epoch 2728/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0255 - accuracy: 0.9892 - val_loss: 0.0500 - val_accuracy: 0.9879\n",
      "Epoch 2729/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 0.0484 - val_accuracy: 0.9879\n",
      "Epoch 2730/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0393 - accuracy: 0.9880 - val_loss: 0.0492 - val_accuracy: 0.9865\n",
      "Epoch 2731/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9901 - val_loss: 0.0478 - val_accuracy: 0.9879\n",
      "Epoch 2732/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9912 - val_loss: 0.0456 - val_accuracy: 0.9879\n",
      "Epoch 2733/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.0454 - val_accuracy: 0.9879\n",
      "Epoch 2734/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.0460 - val_accuracy: 0.9879\n",
      "Epoch 2735/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0512 - val_accuracy: 0.9888\n",
      "Epoch 2736/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.0461 - val_accuracy: 0.9879\n",
      "Epoch 2737/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.0476 - val_accuracy: 0.9888\n",
      "Epoch 2738/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.0492 - val_accuracy: 0.9888\n",
      "Epoch 2739/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.0476 - val_accuracy: 0.9888\n",
      "Epoch 2740/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.0492 - val_accuracy: 0.9893\n",
      "Epoch 2741/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.0519 - val_accuracy: 0.9883\n",
      "Epoch 2742/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.9907 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 2743/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9929 - val_loss: 0.0581 - val_accuracy: 0.9879\n",
      "Epoch 2744/3500\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 0.0490 - val_accuracy: 0.9883\n",
      "Epoch 2745/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.0647 - val_accuracy: 0.9851\n",
      "Epoch 2746/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.0501 - val_accuracy: 0.9879\n",
      "Epoch 2747/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 0.9909 - val_loss: 0.0463 - val_accuracy: 0.9874\n",
      "Epoch 2748/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 0.0477 - val_accuracy: 0.9879\n",
      "Epoch 2749/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9923 - val_loss: 0.0502 - val_accuracy: 0.9869\n",
      "Epoch 2750/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9936 - val_loss: 0.0535 - val_accuracy: 0.9893\n",
      "Epoch 2751/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.0546 - val_accuracy: 0.9879\n",
      "Epoch 2752/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0572 - val_accuracy: 0.9874\n",
      "Epoch 2753/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.0588 - val_accuracy: 0.9874\n",
      "Epoch 2754/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0263 - accuracy: 0.9924 - val_loss: 0.0586 - val_accuracy: 0.9879\n",
      "Epoch 2755/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.0471 - val_accuracy: 0.9888\n",
      "Epoch 2756/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.0545 - val_accuracy: 0.9883\n",
      "Epoch 2757/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0215 - accuracy: 0.9946 - val_loss: 0.0502 - val_accuracy: 0.9888\n",
      "Epoch 2758/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0462 - val_accuracy: 0.9883\n",
      "Epoch 2759/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9956 - val_loss: 0.0603 - val_accuracy: 0.9869\n",
      "Epoch 2760/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.0468 - val_accuracy: 0.9883\n",
      "Epoch 2761/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 0.9905 - val_loss: 0.0476 - val_accuracy: 0.9888\n",
      "Epoch 2762/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.0459 - val_accuracy: 0.9874\n",
      "Epoch 2763/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0479 - val_accuracy: 0.9883\n",
      "Epoch 2764/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.0486 - val_accuracy: 0.9869\n",
      "Epoch 2765/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.0488 - val_accuracy: 0.9883\n",
      "Epoch 2766/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9935 - val_loss: 0.0471 - val_accuracy: 0.9888\n",
      "Epoch 2767/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 2768/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9906 - val_loss: 0.0451 - val_accuracy: 0.9874\n",
      "Epoch 2769/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 0.0464 - val_accuracy: 0.9893\n",
      "Epoch 2770/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.0519 - val_accuracy: 0.9879\n",
      "Epoch 2771/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9919 - val_loss: 0.0519 - val_accuracy: 0.9874\n",
      "Epoch 2772/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9916 - val_loss: 0.0486 - val_accuracy: 0.9874\n",
      "Epoch 2773/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9904 - val_loss: 0.0505 - val_accuracy: 0.9879\n",
      "Epoch 2774/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.0490 - val_accuracy: 0.9888\n",
      "Epoch 2775/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0494 - val_accuracy: 0.9879\n",
      "Epoch 2776/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.0476 - val_accuracy: 0.9888\n",
      "Epoch 2777/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.0488 - val_accuracy: 0.9888\n",
      "Epoch 2778/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0504 - val_accuracy: 0.9879\n",
      "Epoch 2779/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.0558 - val_accuracy: 0.9888\n",
      "Epoch 2780/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 0.0476 - val_accuracy: 0.9879\n",
      "Epoch 2781/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.9911 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 2782/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.0477 - val_accuracy: 0.9874\n",
      "Epoch 2783/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0251 - accuracy: 0.9894 - val_loss: 0.0455 - val_accuracy: 0.9883\n",
      "Epoch 2784/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.0486 - val_accuracy: 0.9869\n",
      "Epoch 2785/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9919 - val_loss: 0.0481 - val_accuracy: 0.9883\n",
      "Epoch 2786/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.0482 - val_accuracy: 0.9883\n",
      "Epoch 2787/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0498 - val_accuracy: 0.9888\n",
      "Epoch 2788/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.0473 - val_accuracy: 0.9879\n",
      "Epoch 2789/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.0502 - val_accuracy: 0.9874\n",
      "Epoch 2790/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.0468 - val_accuracy: 0.9874\n",
      "Epoch 2791/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.0536 - val_accuracy: 0.9883\n",
      "Epoch 2792/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0479 - val_accuracy: 0.9888\n",
      "Epoch 2793/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.0849 - val_accuracy: 0.9772\n",
      "Epoch 2794/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 0.0916 - val_accuracy: 0.9767\n",
      "Epoch 2795/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.0614 - val_accuracy: 0.9865\n",
      "Epoch 2796/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0603 - val_accuracy: 0.9869\n",
      "Epoch 2797/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0481 - val_accuracy: 0.9879\n",
      "Epoch 2798/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.0524 - val_accuracy: 0.9883\n",
      "Epoch 2799/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0572 - val_accuracy: 0.9879\n",
      "Epoch 2800/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.0500 - val_accuracy: 0.9883\n",
      "Epoch 2801/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0189 - accuracy: 0.9930 - val_loss: 0.0518 - val_accuracy: 0.9879\n",
      "Epoch 2802/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0189 - accuracy: 0.9917 - val_loss: 0.0485 - val_accuracy: 0.9888\n",
      "Epoch 2803/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9913 - val_loss: 0.0453 - val_accuracy: 0.9888\n",
      "Epoch 2804/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9909 - val_loss: 0.0477 - val_accuracy: 0.9869\n",
      "Epoch 2805/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0488 - val_accuracy: 0.9883\n",
      "Epoch 2806/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.0550 - val_accuracy: 0.9879\n",
      "Epoch 2807/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.0494 - val_accuracy: 0.9888\n",
      "Epoch 2808/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.0467 - val_accuracy: 0.9879\n",
      "Epoch 2809/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0457 - val_accuracy: 0.9879\n",
      "Epoch 2810/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0479 - val_accuracy: 0.9865\n",
      "Epoch 2811/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0350 - accuracy: 0.9866 - val_loss: 0.0458 - val_accuracy: 0.9879\n",
      "Epoch 2812/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.0467 - val_accuracy: 0.9893\n",
      "Epoch 2813/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.0510 - val_accuracy: 0.9883\n",
      "Epoch 2814/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.0509 - val_accuracy: 0.9879\n",
      "Epoch 2815/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9937 - val_loss: 0.0529 - val_accuracy: 0.9883\n",
      "Epoch 2816/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.0514 - val_accuracy: 0.9883\n",
      "Epoch 2817/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.0506 - val_accuracy: 0.9897\n",
      "Epoch 2818/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0484 - val_accuracy: 0.9888\n",
      "Epoch 2819/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.0612 - val_accuracy: 0.9869\n",
      "Epoch 2820/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 0.0478 - val_accuracy: 0.9888\n",
      "Epoch 2821/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 0.9912 - val_loss: 0.0468 - val_accuracy: 0.9893\n",
      "Epoch 2822/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.0542 - val_accuracy: 0.9879\n",
      "Epoch 2823/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0553 - val_accuracy: 0.9879\n",
      "Epoch 2824/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0218 - accuracy: 0.9935 - val_loss: 0.0490 - val_accuracy: 0.9893\n",
      "Epoch 2825/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0482 - val_accuracy: 0.9893\n",
      "Epoch 2826/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.0479 - val_accuracy: 0.9888\n",
      "Epoch 2827/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 2828/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0523 - val_accuracy: 0.9879\n",
      "Epoch 2829/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9955 - val_loss: 0.0571 - val_accuracy: 0.9879\n",
      "Epoch 2830/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9904 - val_loss: 0.0678 - val_accuracy: 0.9823\n",
      "Epoch 2831/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9932 - val_loss: 0.0664 - val_accuracy: 0.9832\n",
      "Epoch 2832/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9942 - val_loss: 0.0595 - val_accuracy: 0.9869\n",
      "Epoch 2833/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 0.0572 - val_accuracy: 0.9874\n",
      "Epoch 2834/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.0546 - val_accuracy: 0.9874\n",
      "Epoch 2835/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.0918 - val_accuracy: 0.9748\n",
      "Epoch 2836/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 0.9901 - val_loss: 0.0861 - val_accuracy: 0.9776\n",
      "Epoch 2837/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0337 - accuracy: 0.9897 - val_loss: 0.0586 - val_accuracy: 0.9879\n",
      "Epoch 2838/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.0609 - val_accuracy: 0.9865\n",
      "Epoch 2839/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.0613 - val_accuracy: 0.9851\n",
      "Epoch 2840/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.0736 - val_accuracy: 0.9814\n",
      "Epoch 2841/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0322 - accuracy: 0.9915 - val_loss: 0.0767 - val_accuracy: 0.9804\n",
      "Epoch 2842/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0305 - accuracy: 0.9898 - val_loss: 0.0580 - val_accuracy: 0.9874\n",
      "Epoch 2843/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.0614 - val_accuracy: 0.9855\n",
      "Epoch 2844/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 0.0583 - val_accuracy: 0.9879\n",
      "Epoch 2845/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.0480 - val_accuracy: 0.9883\n",
      "Epoch 2846/3500\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.0465 - val_accuracy: 0.9874\n",
      "Epoch 2847/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0466 - val_accuracy: 0.9874\n",
      "Epoch 2848/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9888\n",
      "Epoch 2849/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.0466 - val_accuracy: 0.9888\n",
      "Epoch 2850/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.0503 - val_accuracy: 0.9883\n",
      "Epoch 2851/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0482 - val_accuracy: 0.9893\n",
      "Epoch 2852/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0509 - val_accuracy: 0.9888\n",
      "Epoch 2853/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.0571 - val_accuracy: 0.9879\n",
      "Epoch 2854/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9938 - val_loss: 0.0542 - val_accuracy: 0.9879\n",
      "Epoch 2855/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.0477 - val_accuracy: 0.9893\n",
      "Epoch 2856/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.0465 - val_accuracy: 0.9879\n",
      "Epoch 2857/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.0463 - val_accuracy: 0.9888\n",
      "Epoch 2858/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0233 - accuracy: 0.9908 - val_loss: 0.0466 - val_accuracy: 0.9888\n",
      "Epoch 2859/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.0483 - val_accuracy: 0.9888\n",
      "Epoch 2860/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.0459 - val_accuracy: 0.9883\n",
      "Epoch 2861/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.0460 - val_accuracy: 0.9879\n",
      "Epoch 2862/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.0478 - val_accuracy: 0.9888\n",
      "Epoch 2863/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 0.0470 - val_accuracy: 0.9883\n",
      "Epoch 2864/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.0487 - val_accuracy: 0.9893\n",
      "Epoch 2865/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.0533 - val_accuracy: 0.9888\n",
      "Epoch 2866/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0576 - val_accuracy: 0.9888\n",
      "Epoch 2867/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0457 - val_accuracy: 0.9879\n",
      "Epoch 2868/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9935 - val_loss: 0.0507 - val_accuracy: 0.9888\n",
      "Epoch 2869/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.0554 - val_accuracy: 0.9874\n",
      "Epoch 2870/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9960 - val_loss: 0.0502 - val_accuracy: 0.9888\n",
      "Epoch 2871/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9922 - val_loss: 0.0472 - val_accuracy: 0.9874\n",
      "Epoch 2872/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0491 - val_accuracy: 0.9893\n",
      "Epoch 2873/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 0.0491 - val_accuracy: 0.9893\n",
      "Epoch 2874/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0516 - val_accuracy: 0.9879\n",
      "Epoch 2875/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.0556 - val_accuracy: 0.9879\n",
      "Epoch 2876/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 0.0498 - val_accuracy: 0.9893\n",
      "Epoch 2877/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.0497 - val_accuracy: 0.9893\n",
      "Epoch 2878/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.0488 - val_accuracy: 0.9874\n",
      "Epoch 2879/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0245 - accuracy: 0.9913 - val_loss: 0.0476 - val_accuracy: 0.9883\n",
      "Epoch 2880/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.0508 - val_accuracy: 0.9893\n",
      "Epoch 2881/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0478 - val_accuracy: 0.9883\n",
      "Epoch 2882/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.0483 - val_accuracy: 0.9893\n",
      "Epoch 2883/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.0486 - val_accuracy: 0.9888\n",
      "Epoch 2884/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9926 - val_loss: 0.0523 - val_accuracy: 0.9879\n",
      "Epoch 2885/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9943 - val_loss: 0.0525 - val_accuracy: 0.9879\n",
      "Epoch 2886/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.0476 - val_accuracy: 0.9888\n",
      "Epoch 2887/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.0499 - val_accuracy: 0.9897\n",
      "Epoch 2888/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 2889/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.0662 - val_accuracy: 0.9837\n",
      "Epoch 2890/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.0522 - val_accuracy: 0.9883\n",
      "Epoch 2891/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 0.0476 - val_accuracy: 0.9893\n",
      "Epoch 2892/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.0462 - val_accuracy: 0.9883\n",
      "Epoch 2893/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0195 - accuracy: 0.9931 - val_loss: 0.0472 - val_accuracy: 0.9879\n",
      "Epoch 2894/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.0501 - val_accuracy: 0.9893\n",
      "Epoch 2895/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0568 - val_accuracy: 0.9874\n",
      "Epoch 2896/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.0472 - val_accuracy: 0.9874\n",
      "Epoch 2897/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.0462 - val_accuracy: 0.9874\n",
      "Epoch 2898/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9904 - val_loss: 0.0563 - val_accuracy: 0.9888\n",
      "Epoch 2899/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 0.0570 - val_accuracy: 0.9883\n",
      "Epoch 2900/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 0.0487 - val_accuracy: 0.9883\n",
      "Epoch 2901/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 2902/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9934 - val_loss: 0.0460 - val_accuracy: 0.9879\n",
      "Epoch 2903/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0212 - accuracy: 0.9945 - val_loss: 0.0512 - val_accuracy: 0.9888\n",
      "Epoch 2904/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0491 - val_accuracy: 0.9888\n",
      "Epoch 2905/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.0577 - val_accuracy: 0.9883\n",
      "Epoch 2906/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0558 - val_accuracy: 0.9879\n",
      "Epoch 2907/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.0806 - val_accuracy: 0.9790\n",
      "Epoch 2908/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0284 - accuracy: 0.9917 - val_loss: 0.0721 - val_accuracy: 0.9814\n",
      "Epoch 2909/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.0666 - val_accuracy: 0.9837\n",
      "Epoch 2910/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.0574 - val_accuracy: 0.9879\n",
      "Epoch 2911/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.0484 - val_accuracy: 0.9888\n",
      "Epoch 2912/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0284 - accuracy: 0.9893 - val_loss: 0.0460 - val_accuracy: 0.9879\n",
      "Epoch 2913/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.0469 - val_accuracy: 0.9879\n",
      "Epoch 2914/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.0493 - val_accuracy: 0.9865\n",
      "Epoch 2915/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.0475 - val_accuracy: 0.9888\n",
      "Epoch 2916/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.0470 - val_accuracy: 0.9879\n",
      "Epoch 2917/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 0.0469 - val_accuracy: 0.9879\n",
      "Epoch 2918/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.0471 - val_accuracy: 0.9879\n",
      "Epoch 2919/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 0.0502 - val_accuracy: 0.9883\n",
      "Epoch 2920/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0513 - val_accuracy: 0.9883\n",
      "Epoch 2921/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9926 - val_loss: 0.0567 - val_accuracy: 0.9874\n",
      "Epoch 2922/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0508 - val_accuracy: 0.9883\n",
      "Epoch 2923/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9915 - val_loss: 0.0477 - val_accuracy: 0.9888\n",
      "Epoch 2924/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.0499 - val_accuracy: 0.9888\n",
      "Epoch 2925/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.0578 - val_accuracy: 0.9879\n",
      "Epoch 2926/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9940 - val_loss: 0.0542 - val_accuracy: 0.9883\n",
      "Epoch 2927/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0488 - val_accuracy: 0.9893\n",
      "Epoch 2928/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9961 - val_loss: 0.0526 - val_accuracy: 0.9874\n",
      "Epoch 2929/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0359 - accuracy: 0.9891 - val_loss: 0.0471 - val_accuracy: 0.9879\n",
      "Epoch 2930/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0481 - val_accuracy: 0.9883\n",
      "Epoch 2931/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 0.0473 - val_accuracy: 0.9883\n",
      "Epoch 2932/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9930 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 2933/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.0618 - val_accuracy: 0.9869\n",
      "Epoch 2934/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.0532 - val_accuracy: 0.9879\n",
      "Epoch 2935/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.0535 - val_accuracy: 0.9883\n",
      "Epoch 2936/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.0712 - val_accuracy: 0.9818\n",
      "Epoch 2937/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.0760 - val_accuracy: 0.9800\n",
      "Epoch 2938/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.0698 - val_accuracy: 0.9823\n",
      "Epoch 2939/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.0654 - val_accuracy: 0.9837\n",
      "Epoch 2940/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0521 - val_accuracy: 0.9888\n",
      "Epoch 2941/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.0561 - val_accuracy: 0.9874\n",
      "Epoch 2942/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9918 - val_loss: 0.0578 - val_accuracy: 0.9879\n",
      "Epoch 2943/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0660 - val_accuracy: 0.9855\n",
      "Epoch 2944/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.0520 - val_accuracy: 0.9888\n",
      "Epoch 2945/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.0572 - val_accuracy: 0.9874\n",
      "Epoch 2946/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0526 - val_accuracy: 0.9879\n",
      "Epoch 2947/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.0546 - val_accuracy: 0.9874\n",
      "Epoch 2948/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 0.0562 - val_accuracy: 0.9883\n",
      "Epoch 2949/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0697 - val_accuracy: 0.9828\n",
      "Epoch 2950/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9933 - val_loss: 0.0492 - val_accuracy: 0.9888\n",
      "Epoch 2951/3500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.0473 - val_accuracy: 0.9879\n",
      "Epoch 2952/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 0.9930 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 2953/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.0495 - val_accuracy: 0.9888\n",
      "Epoch 2954/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 0.9955 - val_loss: 0.0506 - val_accuracy: 0.9888\n",
      "Epoch 2955/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.0445 - val_accuracy: 0.9883\n",
      "Epoch 2956/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0237 - accuracy: 0.9918 - val_loss: 0.0469 - val_accuracy: 0.9874\n",
      "Epoch 2957/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 0.0456 - val_accuracy: 0.9879\n",
      "Epoch 2958/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
      "Epoch 2959/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0461 - val_accuracy: 0.9879\n",
      "Epoch 2960/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9924 - val_loss: 0.0460 - val_accuracy: 0.9879\n",
      "Epoch 2961/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.0464 - val_accuracy: 0.9888\n",
      "Epoch 2962/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.0468 - val_accuracy: 0.9888\n",
      "Epoch 2963/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9941 - val_loss: 0.0497 - val_accuracy: 0.9883\n",
      "Epoch 2964/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.0549 - val_accuracy: 0.9883\n",
      "Epoch 2965/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 2966/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0485 - val_accuracy: 0.9883\n",
      "Epoch 2967/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.0538 - val_accuracy: 0.9883\n",
      "Epoch 2968/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0549 - val_accuracy: 0.9879\n",
      "Epoch 2969/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0679 - val_accuracy: 0.9828\n",
      "Epoch 2970/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.0706 - val_accuracy: 0.9818\n",
      "Epoch 2971/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 0.0545 - val_accuracy: 0.9883\n",
      "Epoch 2972/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.0553 - val_accuracy: 0.9879\n",
      "Epoch 2973/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 2974/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 0.0526 - val_accuracy: 0.9879\n",
      "Epoch 2975/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.0773 - val_accuracy: 0.9795\n",
      "Epoch 2976/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.0680 - val_accuracy: 0.9828\n",
      "Epoch 2977/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0509 - val_accuracy: 0.9879\n",
      "Epoch 2978/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.0500 - val_accuracy: 0.9883\n",
      "Epoch 2979/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9925 - val_loss: 0.0494 - val_accuracy: 0.9893\n",
      "Epoch 2980/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9952 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 2981/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.0472 - val_accuracy: 0.9874\n",
      "Epoch 2982/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.0504 - val_accuracy: 0.9883\n",
      "Epoch 2983/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.0453 - val_accuracy: 0.9893\n",
      "Epoch 2984/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.0486 - val_accuracy: 0.9888\n",
      "Epoch 2985/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0514 - val_accuracy: 0.9888\n",
      "Epoch 2986/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.0526 - val_accuracy: 0.9879\n",
      "Epoch 2987/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0479 - val_accuracy: 0.9879\n",
      "Epoch 2988/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.0487 - val_accuracy: 0.9883\n",
      "Epoch 2989/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0545 - val_accuracy: 0.9883\n",
      "Epoch 2990/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.0565 - val_accuracy: 0.9874\n",
      "Epoch 2991/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0946 - val_accuracy: 0.9758\n",
      "Epoch 2992/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0404 - accuracy: 0.9878 - val_loss: 0.0683 - val_accuracy: 0.9818\n",
      "Epoch 2993/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0760 - val_accuracy: 0.9818\n",
      "Epoch 2994/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0330 - accuracy: 0.9906 - val_loss: 0.0819 - val_accuracy: 0.9781\n",
      "Epoch 2995/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0625 - val_accuracy: 0.9851\n",
      "Epoch 2996/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.0710 - val_accuracy: 0.9823\n",
      "Epoch 2997/3500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0688 - val_accuracy: 0.9846\n",
      "Epoch 2998/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9937 - val_loss: 0.0522 - val_accuracy: 0.9883\n",
      "Epoch 2999/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.0476 - val_accuracy: 0.9883\n",
      "Epoch 3000/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.0515 - val_accuracy: 0.9883\n",
      "Epoch 3001/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.0488 - val_accuracy: 0.9888\n",
      "Epoch 3002/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0469 - val_accuracy: 0.9879\n",
      "Epoch 3003/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.0478 - val_accuracy: 0.9893\n",
      "Epoch 3004/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.0468 - val_accuracy: 0.9874\n",
      "Epoch 3005/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.0475 - val_accuracy: 0.9879\n",
      "Epoch 3006/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0233 - accuracy: 0.9904 - val_loss: 0.0472 - val_accuracy: 0.9874\n",
      "Epoch 3007/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 0.0466 - val_accuracy: 0.9883\n",
      "Epoch 3008/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0488 - val_accuracy: 0.9874\n",
      "Epoch 3009/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 3010/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.0473 - val_accuracy: 0.9874\n",
      "Epoch 3011/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.0547 - val_accuracy: 0.9879\n",
      "Epoch 3012/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0417 - accuracy: 0.9877 - val_loss: 0.0539 - val_accuracy: 0.9869\n",
      "Epoch 3013/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0397 - accuracy: 0.9890 - val_loss: 0.0451 - val_accuracy: 0.9888\n",
      "Epoch 3014/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9922 - val_loss: 0.0493 - val_accuracy: 0.9883\n",
      "Epoch 3015/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9918 - val_loss: 0.0543 - val_accuracy: 0.9888\n",
      "Epoch 3016/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0529 - val_accuracy: 0.9879\n",
      "Epoch 3017/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0617 - val_accuracy: 0.9874\n",
      "Epoch 3018/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.0570 - val_accuracy: 0.9879\n",
      "Epoch 3019/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0635 - val_accuracy: 0.9855\n",
      "Epoch 3020/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0237 - accuracy: 0.9910 - val_loss: 0.0565 - val_accuracy: 0.9874\n",
      "Epoch 3021/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0476 - val_accuracy: 0.9874\n",
      "Epoch 3022/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.0491 - val_accuracy: 0.9879\n",
      "Epoch 3023/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.0480 - val_accuracy: 0.9879\n",
      "Epoch 3024/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 0.0624 - val_accuracy: 0.9846\n",
      "Epoch 3025/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.0555 - val_accuracy: 0.9874\n",
      "Epoch 3026/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.0725 - val_accuracy: 0.9823\n",
      "Epoch 3027/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.0612 - val_accuracy: 0.9860\n",
      "Epoch 3028/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0536 - val_accuracy: 0.9883\n",
      "Epoch 3029/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 0.0493 - val_accuracy: 0.9893\n",
      "Epoch 3030/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 3031/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.0475 - val_accuracy: 0.9879\n",
      "Epoch 3032/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 0.9918 - val_loss: 0.0471 - val_accuracy: 0.9869\n",
      "Epoch 3033/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.0491 - val_accuracy: 0.9883\n",
      "Epoch 3034/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9931 - val_loss: 0.0495 - val_accuracy: 0.9883\n",
      "Epoch 3035/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.0494 - val_accuracy: 0.9879\n",
      "Epoch 3036/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0495 - val_accuracy: 0.9883\n",
      "Epoch 3037/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0477 - val_accuracy: 0.9893\n",
      "Epoch 3038/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0471 - val_accuracy: 0.9883\n",
      "Epoch 3039/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.0475 - val_accuracy: 0.9893\n",
      "Epoch 3040/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.0475 - val_accuracy: 0.9893\n",
      "Epoch 3041/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0497 - val_accuracy: 0.9883\n",
      "Epoch 3042/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.0514 - val_accuracy: 0.9888\n",
      "Epoch 3043/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9955 - val_loss: 0.0588 - val_accuracy: 0.9874\n",
      "Epoch 3044/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.0554 - val_accuracy: 0.9888\n",
      "Epoch 3045/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.0493 - val_accuracy: 0.9893\n",
      "Epoch 3046/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.0511 - val_accuracy: 0.9888\n",
      "Epoch 3047/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 0.0603 - val_accuracy: 0.9879\n",
      "Epoch 3048/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.0573 - val_accuracy: 0.9883\n",
      "Epoch 3049/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0484 - val_accuracy: 0.9888\n",
      "Epoch 3050/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0540 - val_accuracy: 0.9879\n",
      "Epoch 3051/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.0487 - val_accuracy: 0.9893\n",
      "Epoch 3052/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.0478 - val_accuracy: 0.9893\n",
      "Epoch 3053/3500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0476 - val_accuracy: 0.9883\n",
      "Epoch 3054/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0488 - val_accuracy: 0.9879\n",
      "Epoch 3055/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.0514 - val_accuracy: 0.9883\n",
      "Epoch 3056/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.0607 - val_accuracy: 0.9865\n",
      "Epoch 3057/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.0474 - val_accuracy: 0.9879\n",
      "Epoch 3058/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9925 - val_loss: 0.0479 - val_accuracy: 0.9874\n",
      "Epoch 3059/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9926 - val_loss: 0.0470 - val_accuracy: 0.9883\n",
      "Epoch 3060/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.0472 - val_accuracy: 0.9879\n",
      "Epoch 3061/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.0488 - val_accuracy: 0.9874\n",
      "Epoch 3062/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0570 - val_accuracy: 0.9883\n",
      "Epoch 3063/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9925 - val_loss: 0.0574 - val_accuracy: 0.9869\n",
      "Epoch 3064/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
      "Epoch 3065/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9960 - val_loss: 0.0561 - val_accuracy: 0.9879\n",
      "Epoch 3066/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.0543 - val_accuracy: 0.9883\n",
      "Epoch 3067/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.0500 - val_accuracy: 0.9879\n",
      "Epoch 3068/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 0.0631 - val_accuracy: 0.9874\n",
      "Epoch 3069/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.0568 - val_accuracy: 0.9879\n",
      "Epoch 3070/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.0585 - val_accuracy: 0.9879\n",
      "Epoch 3071/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0532 - val_accuracy: 0.9883\n",
      "Epoch 3072/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0540 - val_accuracy: 0.9874\n",
      "Epoch 3073/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9916 - val_loss: 0.0483 - val_accuracy: 0.9879\n",
      "Epoch 3074/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.0590 - val_accuracy: 0.9874\n",
      "Epoch 3075/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0492 - val_accuracy: 0.9888\n",
      "Epoch 3076/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0480 - val_accuracy: 0.9874\n",
      "Epoch 3077/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.0462 - val_accuracy: 0.9883\n",
      "Epoch 3078/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0294 - accuracy: 0.9914 - val_loss: 0.0471 - val_accuracy: 0.9883\n",
      "Epoch 3079/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.0613 - val_accuracy: 0.9879\n",
      "Epoch 3080/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.0525 - val_accuracy: 0.9879\n",
      "Epoch 3081/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.0483 - val_accuracy: 0.9888\n",
      "Epoch 3082/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0552 - val_accuracy: 0.9883\n",
      "Epoch 3083/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.0579 - val_accuracy: 0.9879\n",
      "Epoch 3084/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0170 - accuracy: 0.9935 - val_loss: 0.0540 - val_accuracy: 0.9883\n",
      "Epoch 3085/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.0498 - val_accuracy: 0.9888\n",
      "Epoch 3086/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0608 - val_accuracy: 0.9874\n",
      "Epoch 3087/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.0589 - val_accuracy: 0.9874\n",
      "Epoch 3088/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.0491 - val_accuracy: 0.9888\n",
      "Epoch 3089/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.0522 - val_accuracy: 0.9883\n",
      "Epoch 3090/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0181 - accuracy: 0.9957 - val_loss: 0.0507 - val_accuracy: 0.9883\n",
      "Epoch 3091/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0540 - val_accuracy: 0.9874\n",
      "Epoch 3092/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9954 - val_loss: 0.0509 - val_accuracy: 0.9883\n",
      "Epoch 3093/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.0486 - val_accuracy: 0.9888\n",
      "Epoch 3094/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9934 - val_loss: 0.0472 - val_accuracy: 0.9879\n",
      "Epoch 3095/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.0480 - val_accuracy: 0.9879\n",
      "Epoch 3096/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.0480 - val_accuracy: 0.9874\n",
      "Epoch 3097/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.0479 - val_accuracy: 0.9888\n",
      "Epoch 3098/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.0474 - val_accuracy: 0.9879\n",
      "Epoch 3099/3500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.0469 - val_accuracy: 0.9874\n",
      "Epoch 3100/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.0549 - val_accuracy: 0.9883\n",
      "Epoch 3101/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 0.0565 - val_accuracy: 0.9874\n",
      "Epoch 3102/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 0.9948 - val_loss: 0.0560 - val_accuracy: 0.9879\n",
      "Epoch 3103/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.0490 - val_accuracy: 0.9893\n",
      "Epoch 3104/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0194 - accuracy: 0.9944 - val_loss: 0.0575 - val_accuracy: 0.9879\n",
      "Epoch 3105/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.0568 - val_accuracy: 0.9879\n",
      "Epoch 3106/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.0527 - val_accuracy: 0.9883\n",
      "Epoch 3107/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.0490 - val_accuracy: 0.9893\n",
      "Epoch 3108/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9929 - val_loss: 0.0465 - val_accuracy: 0.9893\n",
      "Epoch 3109/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.0500 - val_accuracy: 0.9888\n",
      "Epoch 3110/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0169 - accuracy: 0.9941 - val_loss: 0.0524 - val_accuracy: 0.9883\n",
      "Epoch 3111/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9961 - val_loss: 0.0508 - val_accuracy: 0.9893\n",
      "Epoch 3112/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.0484 - val_accuracy: 0.9893\n",
      "Epoch 3113/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.0508 - val_accuracy: 0.9883\n",
      "Epoch 3114/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0203 - accuracy: 0.9954 - val_loss: 0.0527 - val_accuracy: 0.9883\n",
      "Epoch 3115/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.0532 - val_accuracy: 0.9888\n",
      "Epoch 3116/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0791 - val_accuracy: 0.9795\n",
      "Epoch 3117/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 0.1184 - val_accuracy: 0.9688\n",
      "Epoch 3118/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0395 - accuracy: 0.9861 - val_loss: 0.0998 - val_accuracy: 0.9725\n",
      "Epoch 3119/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 0.0530 - val_accuracy: 0.9888\n",
      "Epoch 3120/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0538 - val_accuracy: 0.9879\n",
      "Epoch 3121/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0573 - val_accuracy: 0.9879\n",
      "Epoch 3122/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0562 - val_accuracy: 0.9879\n",
      "Epoch 3123/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0520 - val_accuracy: 0.9883\n",
      "Epoch 3124/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0477 - val_accuracy: 0.9883\n",
      "Epoch 3125/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9948 - val_loss: 0.0547 - val_accuracy: 0.9883\n",
      "Epoch 3126/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 0.0631 - val_accuracy: 0.9855\n",
      "Epoch 3127/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.0596 - val_accuracy: 0.9869\n",
      "Epoch 3128/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0522 - val_accuracy: 0.9883\n",
      "Epoch 3129/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9940 - val_loss: 0.0622 - val_accuracy: 0.9860\n",
      "Epoch 3130/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.0789 - val_accuracy: 0.9790\n",
      "Epoch 3131/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.0697 - val_accuracy: 0.9841\n",
      "Epoch 3132/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0284 - accuracy: 0.9897 - val_loss: 0.1621 - val_accuracy: 0.9590\n",
      "Epoch 3133/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0547 - accuracy: 0.9836 - val_loss: 0.0816 - val_accuracy: 0.9804\n",
      "Epoch 3134/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0376 - accuracy: 0.9879 - val_loss: 0.0657 - val_accuracy: 0.9846\n",
      "Epoch 3135/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 0.0481 - val_accuracy: 0.9883\n",
      "Epoch 3136/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.0480 - val_accuracy: 0.9883\n",
      "Epoch 3137/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0206 - accuracy: 0.9943 - val_loss: 0.0536 - val_accuracy: 0.9879\n",
      "Epoch 3138/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0467 - val_accuracy: 0.9893\n",
      "Epoch 3139/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.0574 - val_accuracy: 0.9879\n",
      "Epoch 3140/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.0478 - val_accuracy: 0.9888\n",
      "Epoch 3141/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0461 - val_accuracy: 0.9883\n",
      "Epoch 3142/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0474 - val_accuracy: 0.9879\n",
      "Epoch 3143/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0470 - val_accuracy: 0.9883\n",
      "Epoch 3144/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0501 - val_accuracy: 0.9897\n",
      "Epoch 3145/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.0467 - val_accuracy: 0.9888\n",
      "Epoch 3146/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0465 - val_accuracy: 0.9888\n",
      "Epoch 3147/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9918 - val_loss: 0.0461 - val_accuracy: 0.9902\n",
      "Epoch 3148/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.0456 - val_accuracy: 0.9902\n",
      "Epoch 3149/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9923 - val_loss: 0.0539 - val_accuracy: 0.9888\n",
      "Epoch 3150/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9951 - val_loss: 0.0586 - val_accuracy: 0.9883\n",
      "Epoch 3151/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9935 - val_loss: 0.0556 - val_accuracy: 0.9879\n",
      "Epoch 3152/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0570 - val_accuracy: 0.9893\n",
      "Epoch 3153/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0519 - val_accuracy: 0.9888\n",
      "Epoch 3154/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.0507 - val_accuracy: 0.9893\n",
      "Epoch 3155/3500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.0472 - val_accuracy: 0.9897\n",
      "Epoch 3156/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0462 - val_accuracy: 0.9893\n",
      "Epoch 3157/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.0506 - val_accuracy: 0.9888\n",
      "Epoch 3158/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9917 - val_loss: 0.0516 - val_accuracy: 0.9888\n",
      "Epoch 3159/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.0479 - val_accuracy: 0.9879\n",
      "Epoch 3160/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.0512 - val_accuracy: 0.9902\n",
      "Epoch 3161/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0462 - val_accuracy: 0.9888\n",
      "Epoch 3162/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.0486 - val_accuracy: 0.9888\n",
      "Epoch 3163/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0473 - val_accuracy: 0.9883\n",
      "Epoch 3164/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.0531 - val_accuracy: 0.9883\n",
      "Epoch 3165/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.0661 - val_accuracy: 0.9841\n",
      "Epoch 3166/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.0472 - val_accuracy: 0.9888\n",
      "Epoch 3167/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.0528 - val_accuracy: 0.9897\n",
      "Epoch 3168/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 0.9960 - val_loss: 0.0494 - val_accuracy: 0.9888\n",
      "Epoch 3169/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.0480 - val_accuracy: 0.9888\n",
      "Epoch 3170/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.0466 - val_accuracy: 0.9879\n",
      "Epoch 3171/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.0465 - val_accuracy: 0.9897\n",
      "Epoch 3172/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.0465 - val_accuracy: 0.9897\n",
      "Epoch 3173/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9937 - val_loss: 0.0455 - val_accuracy: 0.9902\n",
      "Epoch 3174/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.0458 - val_accuracy: 0.9883\n",
      "Epoch 3175/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9923 - val_loss: 0.0483 - val_accuracy: 0.9902\n",
      "Epoch 3176/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.0458 - val_accuracy: 0.9883\n",
      "Epoch 3177/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.0496 - val_accuracy: 0.9893\n",
      "Epoch 3178/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.0554 - val_accuracy: 0.9883\n",
      "Epoch 3179/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 0.0509 - val_accuracy: 0.9897\n",
      "Epoch 3180/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0511 - val_accuracy: 0.9893\n",
      "Epoch 3181/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 3182/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.0478 - val_accuracy: 0.9902\n",
      "Epoch 3183/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.0457 - val_accuracy: 0.9883\n",
      "Epoch 3184/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.0482 - val_accuracy: 0.9893\n",
      "Epoch 3185/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0509 - val_accuracy: 0.9888\n",
      "Epoch 3186/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.0585 - val_accuracy: 0.9883\n",
      "Epoch 3187/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0569 - val_accuracy: 0.9874\n",
      "Epoch 3188/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9961 - val_loss: 0.0499 - val_accuracy: 0.9902\n",
      "Epoch 3189/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.0599 - val_accuracy: 0.9874\n",
      "Epoch 3190/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0473 - val_accuracy: 0.9888\n",
      "Epoch 3191/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.0474 - val_accuracy: 0.9883\n",
      "Epoch 3192/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0466 - val_accuracy: 0.9879\n",
      "Epoch 3193/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0165 - accuracy: 0.9937 - val_loss: 0.0477 - val_accuracy: 0.9888\n",
      "Epoch 3194/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.0487 - val_accuracy: 0.9879\n",
      "Epoch 3195/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9907 - val_loss: 0.0490 - val_accuracy: 0.9888\n",
      "Epoch 3196/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0498 - val_accuracy: 0.9888\n",
      "Epoch 3197/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.0769 - val_accuracy: 0.9809\n",
      "Epoch 3198/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 0.0496 - val_accuracy: 0.9897\n",
      "Epoch 3199/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0510 - val_accuracy: 0.9893\n",
      "Epoch 3200/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.0517 - val_accuracy: 0.9897\n",
      "Epoch 3201/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0528 - val_accuracy: 0.9897\n",
      "Epoch 3202/3500\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.0514 - val_accuracy: 0.9893\n",
      "Epoch 3203/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.0553 - val_accuracy: 0.9893\n",
      "Epoch 3204/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0538 - val_accuracy: 0.9893\n",
      "Epoch 3205/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0535 - val_accuracy: 0.9888\n",
      "Epoch 3206/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.9960 - val_loss: 0.0503 - val_accuracy: 0.9897\n",
      "Epoch 3207/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0492 - val_accuracy: 0.9883\n",
      "Epoch 3208/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0502 - val_accuracy: 0.9902\n",
      "Epoch 3209/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0474 - val_accuracy: 0.9893\n",
      "Epoch 3210/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0476 - val_accuracy: 0.9888\n",
      "Epoch 3211/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.0459 - val_accuracy: 0.9897\n",
      "Epoch 3212/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.0602 - val_accuracy: 0.9874\n",
      "Epoch 3213/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0525 - val_accuracy: 0.9902\n",
      "Epoch 3214/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0550 - val_accuracy: 0.9883\n",
      "Epoch 3215/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.0635 - val_accuracy: 0.9865\n",
      "Epoch 3216/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.0793 - val_accuracy: 0.9804\n",
      "Epoch 3217/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.0619 - val_accuracy: 0.9874\n",
      "Epoch 3218/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.0513 - val_accuracy: 0.9897\n",
      "Epoch 3219/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0538 - val_accuracy: 0.9874\n",
      "Epoch 3220/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.0480 - val_accuracy: 0.9888\n",
      "Epoch 3221/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9916 - val_loss: 0.0508 - val_accuracy: 0.9888\n",
      "Epoch 3222/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 0.0474 - val_accuracy: 0.9883\n",
      "Epoch 3223/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.0469 - val_accuracy: 0.9893\n",
      "Epoch 3224/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 0.0530 - val_accuracy: 0.9888\n",
      "Epoch 3225/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.0651 - val_accuracy: 0.9865\n",
      "Epoch 3226/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.0863 - val_accuracy: 0.9776\n",
      "Epoch 3227/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.0595 - val_accuracy: 0.9874\n",
      "Epoch 3228/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0632 - val_accuracy: 0.9874\n",
      "Epoch 3229/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.0560 - val_accuracy: 0.9879\n",
      "Epoch 3230/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.0526 - val_accuracy: 0.9883\n",
      "Epoch 3231/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.0526 - val_accuracy: 0.9888\n",
      "Epoch 3232/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0177 - accuracy: 0.9952 - val_loss: 0.0493 - val_accuracy: 0.9888\n",
      "Epoch 3233/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.0512 - val_accuracy: 0.9893\n",
      "Epoch 3234/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0475 - val_accuracy: 0.9883\n",
      "Epoch 3235/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0307 - accuracy: 0.9885 - val_loss: 0.0580 - val_accuracy: 0.9869\n",
      "Epoch 3236/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9968 - val_loss: 0.0573 - val_accuracy: 0.9879\n",
      "Epoch 3237/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9941 - val_loss: 0.0540 - val_accuracy: 0.9893\n",
      "Epoch 3238/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0512 - val_accuracy: 0.9883\n",
      "Epoch 3239/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.0485 - val_accuracy: 0.9897\n",
      "Epoch 3240/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.0475 - val_accuracy: 0.9883\n",
      "Epoch 3241/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9931 - val_loss: 0.0484 - val_accuracy: 0.9888\n",
      "Epoch 3242/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0508 - val_accuracy: 0.9888\n",
      "Epoch 3243/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0507 - val_accuracy: 0.9888\n",
      "Epoch 3244/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0504 - val_accuracy: 0.9883\n",
      "Epoch 3245/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.0479 - val_accuracy: 0.9888\n",
      "Epoch 3246/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 0.0482 - val_accuracy: 0.9883\n",
      "Epoch 3247/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0476 - val_accuracy: 0.9883\n",
      "Epoch 3248/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.0488 - val_accuracy: 0.9897\n",
      "Epoch 3249/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.0474 - val_accuracy: 0.9888\n",
      "Epoch 3250/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.0492 - val_accuracy: 0.9897\n",
      "Epoch 3251/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.0525 - val_accuracy: 0.9893\n",
      "Epoch 3252/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.0579 - val_accuracy: 0.9874\n",
      "Epoch 3253/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9930 - val_loss: 0.0584 - val_accuracy: 0.9879\n",
      "Epoch 3254/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9918 - val_loss: 0.0744 - val_accuracy: 0.9832\n",
      "Epoch 3255/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0318 - accuracy: 0.9893 - val_loss: 0.0536 - val_accuracy: 0.9883\n",
      "Epoch 3256/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.0540 - val_accuracy: 0.9883\n",
      "Epoch 3257/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9949 - val_loss: 0.0607 - val_accuracy: 0.9869\n",
      "Epoch 3258/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0638 - val_accuracy: 0.9865\n",
      "Epoch 3259/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0641 - val_accuracy: 0.9860\n",
      "Epoch 3260/3500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 0.0558 - val_accuracy: 0.9893\n",
      "Epoch 3261/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0577 - val_accuracy: 0.9883\n",
      "Epoch 3262/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0183 - accuracy: 0.9957 - val_loss: 0.0674 - val_accuracy: 0.9860\n",
      "Epoch 3263/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 0.0564 - val_accuracy: 0.9879\n",
      "Epoch 3264/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.0478 - val_accuracy: 0.9879\n",
      "Epoch 3265/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 0.0499 - val_accuracy: 0.9888\n",
      "Epoch 3266/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0523 - val_accuracy: 0.9893\n",
      "Epoch 3267/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.0563 - val_accuracy: 0.9883\n",
      "Epoch 3268/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0490 - val_accuracy: 0.9897\n",
      "Epoch 3269/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9941 - val_loss: 0.0476 - val_accuracy: 0.9897\n",
      "Epoch 3270/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
      "Epoch 3271/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9955 - val_loss: 0.0496 - val_accuracy: 0.9893\n",
      "Epoch 3272/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0487 - val_accuracy: 0.9888\n",
      "Epoch 3273/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0506 - val_accuracy: 0.9879\n",
      "Epoch 3274/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0587 - val_accuracy: 0.9879\n",
      "Epoch 3275/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 0.0635 - val_accuracy: 0.9879\n",
      "Epoch 3276/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0577 - val_accuracy: 0.9883\n",
      "Epoch 3277/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.0638 - val_accuracy: 0.9860\n",
      "Epoch 3278/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.0561 - val_accuracy: 0.9893\n",
      "Epoch 3279/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.0485 - val_accuracy: 0.9883\n",
      "Epoch 3280/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0542 - val_accuracy: 0.9893\n",
      "Epoch 3281/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.0677 - val_accuracy: 0.9855\n",
      "Epoch 3282/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.0614 - val_accuracy: 0.9879\n",
      "Epoch 3283/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.0520 - val_accuracy: 0.9888\n",
      "Epoch 3284/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0541 - val_accuracy: 0.9897\n",
      "Epoch 3285/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9956 - val_loss: 0.0528 - val_accuracy: 0.9893\n",
      "Epoch 3286/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0528 - val_accuracy: 0.9888\n",
      "Epoch 3287/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.0558 - val_accuracy: 0.9888\n",
      "Epoch 3288/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9957 - val_loss: 0.0552 - val_accuracy: 0.9888\n",
      "Epoch 3289/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.0650 - val_accuracy: 0.9855\n",
      "Epoch 3290/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 0.0539 - val_accuracy: 0.9893\n",
      "Epoch 3291/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0697 - val_accuracy: 0.9855\n",
      "Epoch 3292/3500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.0562 - val_accuracy: 0.9893\n",
      "Epoch 3293/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.0488 - val_accuracy: 0.9879\n",
      "Epoch 3294/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0504 - val_accuracy: 0.9893\n",
      "Epoch 3295/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0523 - val_accuracy: 0.9902\n",
      "Epoch 3296/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.0487 - val_accuracy: 0.9888\n",
      "Epoch 3297/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.0518 - val_accuracy: 0.9902\n",
      "Epoch 3298/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0487 - val_accuracy: 0.9883\n",
      "Epoch 3299/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.0491 - val_accuracy: 0.9879\n",
      "Epoch 3300/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 3301/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9923 - val_loss: 0.0505 - val_accuracy: 0.9893\n",
      "Epoch 3302/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0247 - accuracy: 0.9940 - val_loss: 0.0590 - val_accuracy: 0.9883\n",
      "Epoch 3303/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9935 - val_loss: 0.0595 - val_accuracy: 0.9869\n",
      "Epoch 3304/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0763 - val_accuracy: 0.9832\n",
      "Epoch 3305/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0563 - val_accuracy: 0.9893\n",
      "Epoch 3306/3500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.0594 - val_accuracy: 0.9893\n",
      "Epoch 3307/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0549 - val_accuracy: 0.9893\n",
      "Epoch 3308/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.0538 - val_accuracy: 0.9883\n",
      "Epoch 3309/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.0479 - val_accuracy: 0.9879\n",
      "Epoch 3310/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 0.0497 - val_accuracy: 0.9874\n",
      "Epoch 3311/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0482 - val_accuracy: 0.9883\n",
      "Epoch 3312/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0487 - val_accuracy: 0.9888\n",
      "Epoch 3313/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0504 - val_accuracy: 0.9893\n",
      "Epoch 3314/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.0542 - val_accuracy: 0.9893\n",
      "Epoch 3315/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.0609 - val_accuracy: 0.9879\n",
      "Epoch 3316/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0617 - val_accuracy: 0.9865\n",
      "Epoch 3317/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.0496 - val_accuracy: 0.9897\n",
      "Epoch 3318/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.0548 - val_accuracy: 0.9888\n",
      "Epoch 3319/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.0510 - val_accuracy: 0.9883\n",
      "Epoch 3320/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0495 - val_accuracy: 0.9883\n",
      "Epoch 3321/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 0.0506 - val_accuracy: 0.9888\n",
      "Epoch 3322/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0549 - val_accuracy: 0.9897\n",
      "Epoch 3323/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0555 - val_accuracy: 0.9888\n",
      "Epoch 3324/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.0581 - val_accuracy: 0.9883\n",
      "Epoch 3325/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9961 - val_loss: 0.0576 - val_accuracy: 0.9879\n",
      "Epoch 3326/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.0628 - val_accuracy: 0.9879\n",
      "Epoch 3327/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.0633 - val_accuracy: 0.9869\n",
      "Epoch 3328/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0548 - val_accuracy: 0.9883\n",
      "Epoch 3329/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.0501 - val_accuracy: 0.9893\n",
      "Epoch 3330/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.0552 - val_accuracy: 0.9893\n",
      "Epoch 3331/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9948 - val_loss: 0.0536 - val_accuracy: 0.9897\n",
      "Epoch 3332/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0507 - val_accuracy: 0.9883\n",
      "Epoch 3333/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9918 - val_loss: 0.0491 - val_accuracy: 0.9902\n",
      "Epoch 3334/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0591 - val_accuracy: 0.9879\n",
      "Epoch 3335/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0848 - val_accuracy: 0.9795\n",
      "Epoch 3336/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 0.0931 - val_accuracy: 0.9772\n",
      "Epoch 3337/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.0602 - val_accuracy: 0.9865\n",
      "Epoch 3338/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.9926 - val_loss: 0.0605 - val_accuracy: 0.9874\n",
      "Epoch 3339/3500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 0.0597 - val_accuracy: 0.9869\n",
      "Epoch 3340/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0197 - accuracy: 0.9925 - val_loss: 0.0608 - val_accuracy: 0.9869\n",
      "Epoch 3341/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.0571 - val_accuracy: 0.9893\n",
      "Epoch 3342/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 0.0505 - val_accuracy: 0.9893\n",
      "Epoch 3343/3500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.0495 - val_accuracy: 0.9879\n",
      "Epoch 3344/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0270 - accuracy: 0.9924 - val_loss: 0.0545 - val_accuracy: 0.9883\n",
      "Epoch 3345/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9893 - val_loss: 0.0518 - val_accuracy: 0.9888\n",
      "Epoch 3346/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0282 - accuracy: 0.9886 - val_loss: 0.0489 - val_accuracy: 0.9879\n",
      "Epoch 3347/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 0.0524 - val_accuracy: 0.9888\n",
      "Epoch 3348/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.0541 - val_accuracy: 0.9883\n",
      "Epoch 3349/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0498 - val_accuracy: 0.9897\n",
      "Epoch 3350/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.0560 - val_accuracy: 0.9883\n",
      "Epoch 3351/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.0605 - val_accuracy: 0.9879\n",
      "Epoch 3352/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9948 - val_loss: 0.0573 - val_accuracy: 0.9893\n",
      "Epoch 3353/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0488 - val_accuracy: 0.9888\n",
      "Epoch 3354/3500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0564 - val_accuracy: 0.9902\n",
      "Epoch 3355/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0214 - accuracy: 0.9938 - val_loss: 0.0547 - val_accuracy: 0.9883\n",
      "Epoch 3356/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.0615 - val_accuracy: 0.9874\n",
      "Epoch 3357/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.0620 - val_accuracy: 0.9879\n",
      "Epoch 3358/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.0623 - val_accuracy: 0.9879\n",
      "Epoch 3359/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.0565 - val_accuracy: 0.9902\n",
      "Epoch 3360/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.0527 - val_accuracy: 0.9883\n",
      "Epoch 3361/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0578 - val_accuracy: 0.9893\n",
      "Epoch 3362/3500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0639 - val_accuracy: 0.9874\n",
      "Epoch 3363/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.0601 - val_accuracy: 0.9883\n",
      "Epoch 3364/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0145 - accuracy: 0.9944 - val_loss: 0.0535 - val_accuracy: 0.9893\n",
      "Epoch 3365/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0554 - val_accuracy: 0.9893\n",
      "Epoch 3366/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.0624 - val_accuracy: 0.9879\n",
      "Epoch 3367/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.0663 - val_accuracy: 0.9851\n",
      "Epoch 3368/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0829 - val_accuracy: 0.9809\n",
      "Epoch 3369/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0249 - accuracy: 0.9909 - val_loss: 0.0689 - val_accuracy: 0.9841\n",
      "Epoch 3370/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.0495 - val_accuracy: 0.9888\n",
      "Epoch 3371/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.0551 - val_accuracy: 0.9883\n",
      "Epoch 3372/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0608 - val_accuracy: 0.9879\n",
      "Epoch 3373/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0590 - val_accuracy: 0.9883\n",
      "Epoch 3374/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0712 - val_accuracy: 0.9851\n",
      "Epoch 3375/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0600 - val_accuracy: 0.9888\n",
      "Epoch 3376/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.0501 - val_accuracy: 0.9897\n",
      "Epoch 3377/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.0512 - val_accuracy: 0.9883\n",
      "Epoch 3378/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0490 - val_accuracy: 0.9888\n",
      "Epoch 3379/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 0.0495 - val_accuracy: 0.9883\n",
      "Epoch 3380/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 0.0517 - val_accuracy: 0.9897\n",
      "Epoch 3381/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.0537 - val_accuracy: 0.9888\n",
      "Epoch 3382/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9959 - val_loss: 0.0487 - val_accuracy: 0.9879\n",
      "Epoch 3383/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 0.0493 - val_accuracy: 0.9893\n",
      "Epoch 3384/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9960 - val_loss: 0.0569 - val_accuracy: 0.9888\n",
      "Epoch 3385/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 0.0616 - val_accuracy: 0.9879\n",
      "Epoch 3386/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0565 - val_accuracy: 0.9897\n",
      "Epoch 3387/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.0511 - val_accuracy: 0.9883\n",
      "Epoch 3388/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 0.0651 - val_accuracy: 0.9874\n",
      "Epoch 3389/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.0608 - val_accuracy: 0.9883\n",
      "Epoch 3390/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0583 - val_accuracy: 0.9879\n",
      "Epoch 3391/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.0649 - val_accuracy: 0.9860\n",
      "Epoch 3392/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0753 - val_accuracy: 0.9832\n",
      "Epoch 3393/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0305 - accuracy: 0.9917 - val_loss: 0.0619 - val_accuracy: 0.9865\n",
      "Epoch 3394/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.0510 - val_accuracy: 0.9897\n",
      "Epoch 3395/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.0496 - val_accuracy: 0.9874\n",
      "Epoch 3396/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0203 - accuracy: 0.9924 - val_loss: 0.0506 - val_accuracy: 0.9893\n",
      "Epoch 3397/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.0524 - val_accuracy: 0.9893\n",
      "Epoch 3398/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.0550 - val_accuracy: 0.9893\n",
      "Epoch 3399/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0514 - val_accuracy: 0.9893\n",
      "Epoch 3400/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 0.0483 - val_accuracy: 0.9888\n",
      "Epoch 3401/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.0626 - val_accuracy: 0.9869\n",
      "Epoch 3402/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.0626 - val_accuracy: 0.9874\n",
      "Epoch 3403/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.0511 - val_accuracy: 0.9888\n",
      "Epoch 3404/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9922 - val_loss: 0.0497 - val_accuracy: 0.9879\n",
      "Epoch 3405/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0544 - val_accuracy: 0.9883\n",
      "Epoch 3406/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.0624 - val_accuracy: 0.9869\n",
      "Epoch 3407/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.0615 - val_accuracy: 0.9869\n",
      "Epoch 3408/3500\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.0193 - accuracy: 0.9951 - val_loss: 0.0533 - val_accuracy: 0.9893\n",
      "Epoch 3409/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.0527 - val_accuracy: 0.9893\n",
      "Epoch 3410/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.0537 - val_accuracy: 0.9888\n",
      "Epoch 3411/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 0.0522 - val_accuracy: 0.9902\n",
      "Epoch 3412/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0546 - val_accuracy: 0.9893\n",
      "Epoch 3413/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.0497 - val_accuracy: 0.9893\n",
      "Epoch 3414/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.0537 - val_accuracy: 0.9893\n",
      "Epoch 3415/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0564 - val_accuracy: 0.9893\n",
      "Epoch 3416/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.0568 - val_accuracy: 0.9888\n",
      "Epoch 3417/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 0.0569 - val_accuracy: 0.9888\n",
      "Epoch 3418/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0139 - accuracy: 0.9965 - val_loss: 0.0494 - val_accuracy: 0.9893\n",
      "Epoch 3419/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9927 - val_loss: 0.0486 - val_accuracy: 0.9879\n",
      "Epoch 3420/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.0522 - val_accuracy: 0.9888\n",
      "Epoch 3421/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0617 - val_accuracy: 0.9879\n",
      "Epoch 3422/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.0577 - val_accuracy: 0.9883\n",
      "Epoch 3423/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.0548 - val_accuracy: 0.9897\n",
      "Epoch 3424/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0179 - accuracy: 0.9933 - val_loss: 0.0491 - val_accuracy: 0.9869\n",
      "Epoch 3425/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0253 - accuracy: 0.9923 - val_loss: 0.0488 - val_accuracy: 0.9888\n",
      "Epoch 3426/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0603 - val_accuracy: 0.9883\n",
      "Epoch 3427/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 0.0501 - val_accuracy: 0.9888\n",
      "Epoch 3428/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9918 - val_loss: 0.0525 - val_accuracy: 0.9893\n",
      "Epoch 3429/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9895 - val_loss: 0.0491 - val_accuracy: 0.9869\n",
      "Epoch 3430/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0547 - val_accuracy: 0.9893\n",
      "Epoch 3431/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.0493 - val_accuracy: 0.9883\n",
      "Epoch 3432/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0170 - accuracy: 0.9933 - val_loss: 0.0538 - val_accuracy: 0.9893\n",
      "Epoch 3433/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9914 - val_loss: 0.0503 - val_accuracy: 0.9869\n",
      "Epoch 3434/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0172 - accuracy: 0.9934 - val_loss: 0.0487 - val_accuracy: 0.9879\n",
      "Epoch 3435/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 0.9924 - val_loss: 0.0520 - val_accuracy: 0.9888\n",
      "Epoch 3436/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.0502 - val_accuracy: 0.9879\n",
      "Epoch 3437/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9933 - val_loss: 0.0492 - val_accuracy: 0.9893\n",
      "Epoch 3438/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.0504 - val_accuracy: 0.9883\n",
      "Epoch 3439/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0536 - val_accuracy: 0.9893\n",
      "Epoch 3440/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.0504 - val_accuracy: 0.9888\n",
      "Epoch 3441/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.0509 - val_accuracy: 0.9888\n",
      "Epoch 3442/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0499 - val_accuracy: 0.9888\n",
      "Epoch 3443/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0294 - accuracy: 0.9898 - val_loss: 0.0498 - val_accuracy: 0.9897\n",
      "Epoch 3444/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.0513 - val_accuracy: 0.9897\n",
      "Epoch 3445/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0161 - accuracy: 0.9940 - val_loss: 0.0532 - val_accuracy: 0.9883\n",
      "Epoch 3446/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0198 - accuracy: 0.9946 - val_loss: 0.0561 - val_accuracy: 0.9888\n",
      "Epoch 3447/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0560 - val_accuracy: 0.9897\n",
      "Epoch 3448/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0601 - val_accuracy: 0.9883\n",
      "Epoch 3449/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.0546 - val_accuracy: 0.9897\n",
      "Epoch 3450/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.0497 - val_accuracy: 0.9879\n",
      "Epoch 3451/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0278 - accuracy: 0.9919 - val_loss: 0.0500 - val_accuracy: 0.9888\n",
      "Epoch 3452/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9914 - val_loss: 0.0506 - val_accuracy: 0.9874\n",
      "Epoch 3453/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.0507 - val_accuracy: 0.9888\n",
      "Epoch 3454/3500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 0.0499 - val_accuracy: 0.9879\n",
      "Epoch 3455/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.0541 - val_accuracy: 0.9883\n",
      "Epoch 3456/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0227 - accuracy: 0.9916 - val_loss: 0.0925 - val_accuracy: 0.9786\n",
      "Epoch 3457/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0331 - accuracy: 0.9893 - val_loss: 0.0578 - val_accuracy: 0.9869\n",
      "Epoch 3458/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0305 - accuracy: 0.9899 - val_loss: 0.0544 - val_accuracy: 0.9888\n",
      "Epoch 3459/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0615 - val_accuracy: 0.9874\n",
      "Epoch 3460/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.0641 - val_accuracy: 0.9869\n",
      "Epoch 3461/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0742 - val_accuracy: 0.9851\n",
      "Epoch 3462/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 0.0580 - val_accuracy: 0.9888\n",
      "Epoch 3463/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.0779 - val_accuracy: 0.9832\n",
      "Epoch 3464/3500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.0206 - accuracy: 0.9943 - val_loss: 0.0618 - val_accuracy: 0.9879\n",
      "Epoch 3465/3500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.0527 - val_accuracy: 0.9888\n",
      "Epoch 3466/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.0517 - val_accuracy: 0.9893\n",
      "Epoch 3467/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.0556 - val_accuracy: 0.9888\n",
      "Epoch 3468/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0526 - val_accuracy: 0.9893\n",
      "Epoch 3469/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0528 - val_accuracy: 0.9883\n",
      "Epoch 3470/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.0549 - val_accuracy: 0.9893\n",
      "Epoch 3471/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0582 - val_accuracy: 0.9879\n",
      "Epoch 3472/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0517 - val_accuracy: 0.9888\n",
      "Epoch 3473/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.0486 - val_accuracy: 0.9879\n",
      "Epoch 3474/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9927 - val_loss: 0.0517 - val_accuracy: 0.9893\n",
      "Epoch 3475/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.0500 - val_accuracy: 0.9888\n",
      "Epoch 3476/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0337 - accuracy: 0.9857 - val_loss: 0.0569 - val_accuracy: 0.9869\n",
      "Epoch 3477/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0360 - accuracy: 0.9914 - val_loss: 0.0521 - val_accuracy: 0.9888\n",
      "Epoch 3478/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.0577 - val_accuracy: 0.9879\n",
      "Epoch 3479/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 0.0516 - val_accuracy: 0.9883\n",
      "Epoch 3480/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 0.0514 - val_accuracy: 0.9888\n",
      "Epoch 3481/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.0497 - val_accuracy: 0.9888\n",
      "Epoch 3482/3500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.0505 - val_accuracy: 0.9883\n",
      "Epoch 3483/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0545 - val_accuracy: 0.9897\n",
      "Epoch 3484/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.0525 - val_accuracy: 0.9888\n",
      "Epoch 3485/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.0493 - val_accuracy: 0.9888\n",
      "Epoch 3486/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0514 - val_accuracy: 0.9893\n",
      "Epoch 3487/3500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.0537 - val_accuracy: 0.9888\n",
      "Epoch 3488/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0593 - val_accuracy: 0.9879\n",
      "Epoch 3489/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9959 - val_loss: 0.0593 - val_accuracy: 0.9888\n",
      "Epoch 3490/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.0572 - val_accuracy: 0.9883\n",
      "Epoch 3491/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 0.0581 - val_accuracy: 0.9888\n",
      "Epoch 3492/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.0602 - val_accuracy: 0.9869\n",
      "Epoch 3493/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9944 - val_loss: 0.0557 - val_accuracy: 0.9888\n",
      "Epoch 3494/3500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9940 - val_loss: 0.0535 - val_accuracy: 0.9897\n",
      "Epoch 3495/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.0524 - val_accuracy: 0.9897\n",
      "Epoch 3496/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0179 - accuracy: 0.9929 - val_loss: 0.0489 - val_accuracy: 0.9893\n",
      "Epoch 3497/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.0517 - val_accuracy: 0.9897\n",
      "Epoch 3498/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.0544 - val_accuracy: 0.9893\n",
      "Epoch 3499/3500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.0507 - val_accuracy: 0.9897\n",
      "Epoch 3500/3500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.0494 - val_accuracy: 0.9879\n"
     ]
    }
   ],
   "source": [
    "# 모델 실행 및 저장\n",
    "history = model.fit(X, Y, batch_size=500, epochs=3500, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "vj6TQvZiAUXV",
    "outputId": "6078766f-f837-4cbf-99fb-e2e3400bf322"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 실험결과의 오차값 저장\n",
    "val_loss = history.history['val_loss']  #테스트오차\n",
    "\n",
    "accuracy = history.history['accuracy']  # 학습셋 정확도 \n",
    "x_len = np.arange(len(accuracy))\n",
    "\n",
    "plt.plot(x_len, val_loss, \"o\", c = 'red', markersize = 3)\n",
    "plt.plot(x_len, accuracy, \"*\", c = 'blue', markersize = 3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTWRl-hS_BiW"
   },
   "source": [
    "* 학습셋의 정확도는 시간이 흐를수록 좋아지지만, 테스트 결과는 어느정도 이상 시간이 흐르면 더 나아지지 않는것을 그래프로 확인 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IF87tjFCCkCV"
   },
   "source": [
    "### 학습 자동 중단 \n",
    "* 학습이 진행될 수록 학습셋의 정확도는 올라가지만 과적합때문에 테스트셋의 결과는 점점 더 나빠지게 됩니다.케라스에는 이렇게 학습이 진행되어도 테스트셋 오차가 줄지않으면 학습을 멈추게 하는 함수가 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "2Ax9Oq1VCtNG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor = 'val_loss', patience= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhNwPbINDds6",
    "outputId": "a36fcdb5-f88f-4406-b127-89c5b75aca00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.0493 - val_accuracy: 0.9879\n",
      "Epoch 2/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.0513 - val_accuracy: 0.9897\n",
      "Epoch 3/2000\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0561 - val_accuracy: 0.9893\n",
      "Epoch 4/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: 0.0497 - val_accuracy: 0.9893\n",
      "Epoch 5/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0498 - val_accuracy: 0.9893\n",
      "Epoch 6/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0520 - val_accuracy: 0.9888\n",
      "Epoch 7/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.0534 - val_accuracy: 0.9902\n",
      "Epoch 8/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.0545 - val_accuracy: 0.9888\n",
      "Epoch 9/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0148 - accuracy: 0.9961 - val_loss: 0.0514 - val_accuracy: 0.9888\n",
      "Epoch 10/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0161 - accuracy: 0.9938 - val_loss: 0.0580 - val_accuracy: 0.9888\n",
      "Epoch 11/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.0570 - val_accuracy: 0.9888\n",
      "Epoch 12/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0551 - val_accuracy: 0.9888\n",
      "Epoch 13/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0722 - val_accuracy: 0.9860\n",
      "Epoch 14/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0590 - val_accuracy: 0.9888\n",
      "Epoch 15/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0582 - val_accuracy: 0.9888\n",
      "Epoch 16/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0541 - val_accuracy: 0.9897\n",
      "Epoch 17/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 0.9959 - val_loss: 0.0509 - val_accuracy: 0.9879\n",
      "Epoch 18/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0494 - val_accuracy: 0.9893\n",
      "Epoch 19/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.0510 - val_accuracy: 0.9893\n",
      "Epoch 20/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0558 - val_accuracy: 0.9888\n",
      "Epoch 21/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0538 - val_accuracy: 0.9897\n",
      "Epoch 22/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.0534 - val_accuracy: 0.9902\n",
      "Epoch 23/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0567 - val_accuracy: 0.9897\n",
      "Epoch 24/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0555 - val_accuracy: 0.9888\n",
      "Epoch 25/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0522 - val_accuracy: 0.9897\n",
      "Epoch 26/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.0504 - val_accuracy: 0.9874\n",
      "Epoch 27/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.0530 - val_accuracy: 0.9897\n",
      "Epoch 28/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.0553 - val_accuracy: 0.9893\n",
      "Epoch 29/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.0524 - val_accuracy: 0.9897\n",
      "Epoch 30/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0511 - val_accuracy: 0.9888\n",
      "Epoch 31/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0507 - val_accuracy: 0.9883\n",
      "Epoch 32/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0564 - val_accuracy: 0.9888\n",
      "Epoch 33/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.0560 - val_accuracy: 0.9893\n",
      "Epoch 34/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0148 - accuracy: 0.9961 - val_loss: 0.0523 - val_accuracy: 0.9893\n",
      "Epoch 35/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 0.0512 - val_accuracy: 0.9893\n",
      "Epoch 36/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.0506 - val_accuracy: 0.9888\n",
      "Epoch 37/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0600 - val_accuracy: 0.9879\n",
      "Epoch 38/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0547 - val_accuracy: 0.9893\n",
      "Epoch 39/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.0568 - val_accuracy: 0.9888\n",
      "Epoch 40/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0579 - val_accuracy: 0.9893\n",
      "Epoch 41/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0609 - val_accuracy: 0.9874\n",
      "Epoch 42/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.0565 - val_accuracy: 0.9893\n",
      "Epoch 43/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0679 - val_accuracy: 0.9869\n",
      "Epoch 44/2000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0292 - accuracy: 0.9899 - val_loss: 0.0668 - val_accuracy: 0.9860\n",
      "Epoch 45/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.0621 - val_accuracy: 0.9883\n",
      "Epoch 46/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0546 - val_accuracy: 0.9888\n",
      "Epoch 47/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0552 - val_accuracy: 0.9897\n",
      "Epoch 48/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.0683 - val_accuracy: 0.9869\n",
      "Epoch 49/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0685 - val_accuracy: 0.9860\n",
      "Epoch 50/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.0528 - val_accuracy: 0.9893\n",
      "Epoch 51/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.0598 - val_accuracy: 0.9888\n",
      "Epoch 52/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 0.0517 - val_accuracy: 0.9888\n",
      "Epoch 53/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 0.0564 - val_accuracy: 0.9893\n",
      "Epoch 54/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0519 - val_accuracy: 0.9902\n",
      "Epoch 55/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0600 - val_accuracy: 0.9883\n",
      "Epoch 56/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0499 - val_accuracy: 0.9883\n",
      "Epoch 57/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0574 - val_accuracy: 0.9893\n",
      "Epoch 58/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0706 - val_accuracy: 0.9865\n",
      "Epoch 59/2000\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.0500 - val_accuracy: 0.9879\n",
      "Epoch 60/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0500 - val_accuracy: 0.9883\n",
      "Epoch 61/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0584 - val_accuracy: 0.9893\n",
      "Epoch 62/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0559 - val_accuracy: 0.9893\n",
      "Epoch 63/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.0506 - val_accuracy: 0.9893\n",
      "Epoch 64/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.0525 - val_accuracy: 0.9897\n",
      "Epoch 65/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0495 - val_accuracy: 0.9888\n",
      "Epoch 66/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.0503 - val_accuracy: 0.9897\n",
      "Epoch 67/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0556 - val_accuracy: 0.9879\n",
      "Epoch 68/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0344 - accuracy: 0.9890 - val_loss: 0.1027 - val_accuracy: 0.9767\n",
      "Epoch 69/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.0741 - val_accuracy: 0.9837\n",
      "Epoch 70/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.0705 - val_accuracy: 0.9865\n",
      "Epoch 71/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.0784 - val_accuracy: 0.9841\n",
      "Epoch 72/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.0540 - val_accuracy: 0.9902\n",
      "Epoch 73/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9959 - val_loss: 0.0515 - val_accuracy: 0.9888\n",
      "Epoch 74/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0527 - val_accuracy: 0.9902\n",
      "Epoch 75/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0602 - val_accuracy: 0.9883\n",
      "Epoch 76/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0533 - val_accuracy: 0.9897\n",
      "Epoch 77/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.0521 - val_accuracy: 0.9897\n",
      "Epoch 78/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.0533 - val_accuracy: 0.9893\n",
      "Epoch 79/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0519 - val_accuracy: 0.9897\n",
      "Epoch 80/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0536 - val_accuracy: 0.9893\n",
      "Epoch 81/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0561 - val_accuracy: 0.9893\n",
      "Epoch 82/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.0590 - val_accuracy: 0.9883\n",
      "Epoch 83/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.0593 - val_accuracy: 0.9893\n",
      "Epoch 84/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0543 - val_accuracy: 0.9907\n",
      "Epoch 85/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.0636 - val_accuracy: 0.9879\n",
      "Epoch 86/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0552 - val_accuracy: 0.9893\n",
      "Epoch 87/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0540 - val_accuracy: 0.9902\n",
      "Epoch 88/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 0.0772 - val_accuracy: 0.9841\n",
      "Epoch 89/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.0842 - val_accuracy: 0.9823\n",
      "Epoch 90/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0194 - accuracy: 0.9947 - val_loss: 0.0613 - val_accuracy: 0.9888\n",
      "Epoch 91/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0614 - val_accuracy: 0.9888\n",
      "Epoch 92/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0581 - val_accuracy: 0.9888\n",
      "Epoch 93/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0640 - val_accuracy: 0.9879\n",
      "Epoch 94/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.0555 - val_accuracy: 0.9888\n",
      "Epoch 95/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.0579 - val_accuracy: 0.9893\n",
      "Epoch 96/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0595 - val_accuracy: 0.9888\n",
      "Epoch 97/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0513 - val_accuracy: 0.9874\n",
      "Epoch 98/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0503 - val_accuracy: 0.9879\n",
      "Epoch 99/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0696 - val_accuracy: 0.9860\n",
      "Epoch 100/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0560 - val_accuracy: 0.9883\n",
      "Epoch 101/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.0614 - val_accuracy: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f54427601d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, validation_split= 0.33, epochs=2000, batch_size=500, callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7tL8KiVD4nh"
   },
   "source": [
    "## 와인의 종류 예측 - 학습중단 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "DFDKleEcD8dj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "#seed값 설정\n",
    "np.random.seed(11)\n",
    "tf.random.set_seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "iePos--uEigt"
   },
   "outputs": [],
   "source": [
    "df_pre = pd.read_csv(\"/content/sample_data/wine.csv\", header = None)\n",
    "df = df_pre.sample(frac= 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "cdF_GTSeEwHQ"
   },
   "outputs": [],
   "source": [
    "dataset = df.values\n",
    "X = dataset[:, 0:12]\n",
    "Y = dataset[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "_0L8ggv-E59N"
   },
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "hHbyKTebFc-Y"
   },
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "Z3D0v5XtFqK5"
   },
   "outputs": [],
   "source": [
    "# 학습 자동 중단 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQbOa2BKF1lB",
    "outputId": "5671355f-76a1-468f-eda2-d44678b141f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "2/2 [==============================] - 1s 172ms/step - loss: 0.5136 - accuracy: 0.7875 - val_loss: 0.3818 - val_accuracy: 0.8410\n",
      "Epoch 2/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3911 - accuracy: 0.8115 - val_loss: 0.3695 - val_accuracy: 0.8974\n",
      "Epoch 3/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3663 - accuracy: 0.8957 - val_loss: 0.4128 - val_accuracy: 0.8513\n",
      "Epoch 4/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3804 - accuracy: 0.8922 - val_loss: 0.3504 - val_accuracy: 0.9026\n",
      "Epoch 5/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3283 - accuracy: 0.9117 - val_loss: 0.3170 - val_accuracy: 0.9026\n",
      "Epoch 6/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3090 - accuracy: 0.8949 - val_loss: 0.3114 - val_accuracy: 0.8974\n",
      "Epoch 7/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3032 - accuracy: 0.8860 - val_loss: 0.3080 - val_accuracy: 0.9026\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3072 - accuracy: 0.8844 - val_loss: 0.2985 - val_accuracy: 0.9077\n",
      "Epoch 9/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2997 - accuracy: 0.8971 - val_loss: 0.2879 - val_accuracy: 0.9077\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2811 - accuracy: 0.9139 - val_loss: 0.2820 - val_accuracy: 0.9231\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2595 - accuracy: 0.9242 - val_loss: 0.2835 - val_accuracy: 0.9179\n",
      "Epoch 12/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2607 - accuracy: 0.9180 - val_loss: 0.2876 - val_accuracy: 0.9128\n",
      "Epoch 13/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2628 - accuracy: 0.9166 - val_loss: 0.2853 - val_accuracy: 0.9128\n",
      "Epoch 14/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2641 - accuracy: 0.9166 - val_loss: 0.2772 - val_accuracy: 0.9179\n",
      "Epoch 15/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2572 - accuracy: 0.9190 - val_loss: 0.2699 - val_accuracy: 0.9179\n",
      "Epoch 16/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2512 - accuracy: 0.9200 - val_loss: 0.2657 - val_accuracy: 0.9179\n",
      "Epoch 17/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2418 - accuracy: 0.9210 - val_loss: 0.2636 - val_accuracy: 0.9179\n",
      "Epoch 18/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2523 - accuracy: 0.9170 - val_loss: 0.2619 - val_accuracy: 0.9179\n",
      "Epoch 19/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2487 - accuracy: 0.9162 - val_loss: 0.2604 - val_accuracy: 0.9179\n",
      "Epoch 20/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2429 - accuracy: 0.9197 - val_loss: 0.2593 - val_accuracy: 0.9179\n",
      "Epoch 21/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2339 - accuracy: 0.9188 - val_loss: 0.2591 - val_accuracy: 0.9179\n",
      "Epoch 22/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2315 - accuracy: 0.9217 - val_loss: 0.2600 - val_accuracy: 0.9179\n",
      "Epoch 23/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2460 - accuracy: 0.9162 - val_loss: 0.2604 - val_accuracy: 0.9179\n",
      "Epoch 24/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2335 - accuracy: 0.9210 - val_loss: 0.2586 - val_accuracy: 0.9179\n",
      "Epoch 25/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2368 - accuracy: 0.9210 - val_loss: 0.2558 - val_accuracy: 0.9179\n",
      "Epoch 26/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2321 - accuracy: 0.9182 - val_loss: 0.2531 - val_accuracy: 0.9179\n",
      "Epoch 27/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2307 - accuracy: 0.9186 - val_loss: 0.2514 - val_accuracy: 0.9179\n",
      "Epoch 28/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2356 - accuracy: 0.9131 - val_loss: 0.2501 - val_accuracy: 0.9179\n",
      "Epoch 29/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2320 - accuracy: 0.9202 - val_loss: 0.2491 - val_accuracy: 0.9179\n",
      "Epoch 30/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.2293 - accuracy: 0.9195 - val_loss: 0.2486 - val_accuracy: 0.9179\n",
      "Epoch 31/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2278 - accuracy: 0.9230 - val_loss: 0.2474 - val_accuracy: 0.9179\n",
      "Epoch 32/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2326 - accuracy: 0.9177 - val_loss: 0.2464 - val_accuracy: 0.9179\n",
      "Epoch 33/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2242 - accuracy: 0.9259 - val_loss: 0.2452 - val_accuracy: 0.9179\n",
      "Epoch 34/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2297 - accuracy: 0.9199 - val_loss: 0.2441 - val_accuracy: 0.9179\n",
      "Epoch 35/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2247 - accuracy: 0.9232 - val_loss: 0.2433 - val_accuracy: 0.9179\n",
      "Epoch 36/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2289 - accuracy: 0.9205 - val_loss: 0.2421 - val_accuracy: 0.9179\n",
      "Epoch 37/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2206 - accuracy: 0.9232 - val_loss: 0.2409 - val_accuracy: 0.9179\n",
      "Epoch 38/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2211 - accuracy: 0.9217 - val_loss: 0.2398 - val_accuracy: 0.9179\n",
      "Epoch 39/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2111 - accuracy: 0.9270 - val_loss: 0.2390 - val_accuracy: 0.9179\n",
      "Epoch 40/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2294 - accuracy: 0.9190 - val_loss: 0.2389 - val_accuracy: 0.9179\n",
      "Epoch 41/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2252 - accuracy: 0.9203 - val_loss: 0.2380 - val_accuracy: 0.9179\n",
      "Epoch 42/2000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.2149 - accuracy: 0.9232 - val_loss: 0.2368 - val_accuracy: 0.9179\n",
      "Epoch 43/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2275 - accuracy: 0.9179 - val_loss: 0.2362 - val_accuracy: 0.9179\n",
      "Epoch 44/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2195 - accuracy: 0.9219 - val_loss: 0.2352 - val_accuracy: 0.9179\n",
      "Epoch 45/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2203 - accuracy: 0.9245 - val_loss: 0.2356 - val_accuracy: 0.9179\n",
      "Epoch 46/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2155 - accuracy: 0.9229 - val_loss: 0.2381 - val_accuracy: 0.9179\n",
      "Epoch 47/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2193 - accuracy: 0.9214 - val_loss: 0.2420 - val_accuracy: 0.9231\n",
      "Epoch 48/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2196 - accuracy: 0.9262 - val_loss: 0.2446 - val_accuracy: 0.9282\n",
      "Epoch 49/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2164 - accuracy: 0.9227 - val_loss: 0.2455 - val_accuracy: 0.9385\n",
      "Epoch 50/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2154 - accuracy: 0.9234 - val_loss: 0.2438 - val_accuracy: 0.9333\n",
      "Epoch 51/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2095 - accuracy: 0.9296 - val_loss: 0.2401 - val_accuracy: 0.9333\n",
      "Epoch 52/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.2226 - accuracy: 0.9226 - val_loss: 0.2365 - val_accuracy: 0.9282\n",
      "Epoch 53/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2137 - accuracy: 0.9266 - val_loss: 0.2324 - val_accuracy: 0.9231\n",
      "Epoch 54/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2129 - accuracy: 0.9279 - val_loss: 0.2285 - val_accuracy: 0.9231\n",
      "Epoch 55/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2155 - accuracy: 0.9251 - val_loss: 0.2273 - val_accuracy: 0.9231\n",
      "Epoch 56/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2053 - accuracy: 0.9258 - val_loss: 0.2262 - val_accuracy: 0.9231\n",
      "Epoch 57/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2039 - accuracy: 0.9281 - val_loss: 0.2261 - val_accuracy: 0.9282\n",
      "Epoch 58/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2105 - accuracy: 0.9275 - val_loss: 0.2273 - val_accuracy: 0.9385\n",
      "Epoch 59/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2027 - accuracy: 0.9317 - val_loss: 0.2285 - val_accuracy: 0.9436\n",
      "Epoch 60/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2073 - accuracy: 0.9268 - val_loss: 0.2300 - val_accuracy: 0.9436\n",
      "Epoch 61/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2097 - accuracy: 0.9268 - val_loss: 0.2300 - val_accuracy: 0.9333\n",
      "Epoch 62/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2092 - accuracy: 0.9288 - val_loss: 0.2290 - val_accuracy: 0.9333\n",
      "Epoch 63/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2069 - accuracy: 0.9275 - val_loss: 0.2273 - val_accuracy: 0.9333\n",
      "Epoch 64/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2041 - accuracy: 0.9297 - val_loss: 0.2241 - val_accuracy: 0.9333\n",
      "Epoch 65/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1992 - accuracy: 0.9332 - val_loss: 0.2212 - val_accuracy: 0.9385\n",
      "Epoch 66/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2048 - accuracy: 0.9325 - val_loss: 0.2223 - val_accuracy: 0.9333\n",
      "Epoch 67/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2115 - accuracy: 0.9290 - val_loss: 0.2216 - val_accuracy: 0.9333\n",
      "Epoch 68/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2054 - accuracy: 0.9277 - val_loss: 0.2177 - val_accuracy: 0.9385\n",
      "Epoch 69/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1972 - accuracy: 0.9362 - val_loss: 0.2164 - val_accuracy: 0.9231\n",
      "Epoch 70/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2064 - accuracy: 0.9320 - val_loss: 0.2163 - val_accuracy: 0.9179\n",
      "Epoch 71/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2038 - accuracy: 0.9298 - val_loss: 0.2171 - val_accuracy: 0.9385\n",
      "Epoch 72/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2056 - accuracy: 0.9294 - val_loss: 0.2201 - val_accuracy: 0.9385\n",
      "Epoch 73/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1972 - accuracy: 0.9332 - val_loss: 0.2199 - val_accuracy: 0.9385\n",
      "Epoch 74/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2001 - accuracy: 0.9272 - val_loss: 0.2171 - val_accuracy: 0.9333\n",
      "Epoch 75/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1984 - accuracy: 0.9332 - val_loss: 0.2168 - val_accuracy: 0.9333\n",
      "Epoch 76/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1933 - accuracy: 0.9340 - val_loss: 0.2186 - val_accuracy: 0.9333\n",
      "Epoch 77/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1890 - accuracy: 0.9345 - val_loss: 0.2196 - val_accuracy: 0.9333\n",
      "Epoch 78/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1951 - accuracy: 0.9325 - val_loss: 0.2201 - val_accuracy: 0.9385\n",
      "Epoch 79/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2022 - accuracy: 0.9278 - val_loss: 0.2175 - val_accuracy: 0.9436\n",
      "Epoch 80/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1948 - accuracy: 0.9290 - val_loss: 0.2138 - val_accuracy: 0.9333\n",
      "Epoch 81/2000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2030 - accuracy: 0.9283 - val_loss: 0.2123 - val_accuracy: 0.9333\n",
      "Epoch 82/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2019 - accuracy: 0.9278 - val_loss: 0.2123 - val_accuracy: 0.9333\n",
      "Epoch 83/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2033 - accuracy: 0.9265 - val_loss: 0.2134 - val_accuracy: 0.9333\n",
      "Epoch 84/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1963 - accuracy: 0.9322 - val_loss: 0.2126 - val_accuracy: 0.9333\n",
      "Epoch 85/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1971 - accuracy: 0.9327 - val_loss: 0.2106 - val_accuracy: 0.9333\n",
      "Epoch 86/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1860 - accuracy: 0.9352 - val_loss: 0.2105 - val_accuracy: 0.9385\n",
      "Epoch 87/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1951 - accuracy: 0.9312 - val_loss: 0.2120 - val_accuracy: 0.9385\n",
      "Epoch 88/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1961 - accuracy: 0.9322 - val_loss: 0.2099 - val_accuracy: 0.9385\n",
      "Epoch 89/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1881 - accuracy: 0.9318 - val_loss: 0.2093 - val_accuracy: 0.9282\n",
      "Epoch 90/2000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.1881 - accuracy: 0.9320 - val_loss: 0.2085 - val_accuracy: 0.9282\n",
      "Epoch 91/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1893 - accuracy: 0.9336 - val_loss: 0.2061 - val_accuracy: 0.9333\n",
      "Epoch 92/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1914 - accuracy: 0.9292 - val_loss: 0.2072 - val_accuracy: 0.9436\n",
      "Epoch 93/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1876 - accuracy: 0.9371 - val_loss: 0.2083 - val_accuracy: 0.9385\n",
      "Epoch 94/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1913 - accuracy: 0.9359 - val_loss: 0.2077 - val_accuracy: 0.9385\n",
      "Epoch 95/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1944 - accuracy: 0.9296 - val_loss: 0.2073 - val_accuracy: 0.9333\n",
      "Epoch 96/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1887 - accuracy: 0.9336 - val_loss: 0.2076 - val_accuracy: 0.9231\n",
      "Epoch 97/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1955 - accuracy: 0.9322 - val_loss: 0.2063 - val_accuracy: 0.9231\n",
      "Epoch 98/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1846 - accuracy: 0.9325 - val_loss: 0.2045 - val_accuracy: 0.9385\n",
      "Epoch 99/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1842 - accuracy: 0.9342 - val_loss: 0.2046 - val_accuracy: 0.9385\n",
      "Epoch 100/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1953 - accuracy: 0.9302 - val_loss: 0.2022 - val_accuracy: 0.9436\n",
      "Epoch 101/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1903 - accuracy: 0.9329 - val_loss: 0.2010 - val_accuracy: 0.9282\n",
      "Epoch 102/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1843 - accuracy: 0.9364 - val_loss: 0.2019 - val_accuracy: 0.9231\n",
      "Epoch 103/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1885 - accuracy: 0.9351 - val_loss: 0.2013 - val_accuracy: 0.9385\n",
      "Epoch 104/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1841 - accuracy: 0.9309 - val_loss: 0.2013 - val_accuracy: 0.9436\n",
      "Epoch 105/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1852 - accuracy: 0.9373 - val_loss: 0.1992 - val_accuracy: 0.9436\n",
      "Epoch 106/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1905 - accuracy: 0.9339 - val_loss: 0.1967 - val_accuracy: 0.9333\n",
      "Epoch 107/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1827 - accuracy: 0.9373 - val_loss: 0.1960 - val_accuracy: 0.9282\n",
      "Epoch 108/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1929 - accuracy: 0.9326 - val_loss: 0.1958 - val_accuracy: 0.9282\n",
      "Epoch 109/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1832 - accuracy: 0.9346 - val_loss: 0.1960 - val_accuracy: 0.9333\n",
      "Epoch 110/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1792 - accuracy: 0.9375 - val_loss: 0.1982 - val_accuracy: 0.9436\n",
      "Epoch 111/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1801 - accuracy: 0.9375 - val_loss: 0.2020 - val_accuracy: 0.9385\n",
      "Epoch 112/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1824 - accuracy: 0.9333 - val_loss: 0.2004 - val_accuracy: 0.9436\n",
      "Epoch 113/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1809 - accuracy: 0.9383 - val_loss: 0.1970 - val_accuracy: 0.9436\n",
      "Epoch 114/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1824 - accuracy: 0.9361 - val_loss: 0.1936 - val_accuracy: 0.9436\n",
      "Epoch 115/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1779 - accuracy: 0.9388 - val_loss: 0.1927 - val_accuracy: 0.9436\n",
      "Epoch 116/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1842 - accuracy: 0.9370 - val_loss: 0.1920 - val_accuracy: 0.9436\n",
      "Epoch 117/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1805 - accuracy: 0.9390 - val_loss: 0.1915 - val_accuracy: 0.9436\n",
      "Epoch 118/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1748 - accuracy: 0.9416 - val_loss: 0.1921 - val_accuracy: 0.9436\n",
      "Epoch 119/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1836 - accuracy: 0.9335 - val_loss: 0.1936 - val_accuracy: 0.9436\n",
      "Epoch 120/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1678 - accuracy: 0.9403 - val_loss: 0.1944 - val_accuracy: 0.9436\n",
      "Epoch 121/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1748 - accuracy: 0.9363 - val_loss: 0.1941 - val_accuracy: 0.9436\n",
      "Epoch 122/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1719 - accuracy: 0.9366 - val_loss: 0.1904 - val_accuracy: 0.9436\n",
      "Epoch 123/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1721 - accuracy: 0.9414 - val_loss: 0.1876 - val_accuracy: 0.9436\n",
      "Epoch 124/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1744 - accuracy: 0.9363 - val_loss: 0.1886 - val_accuracy: 0.9385\n",
      "Epoch 125/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1722 - accuracy: 0.9359 - val_loss: 0.1886 - val_accuracy: 0.9333\n",
      "Epoch 126/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1760 - accuracy: 0.9346 - val_loss: 0.1869 - val_accuracy: 0.9333\n",
      "Epoch 127/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1714 - accuracy: 0.9346 - val_loss: 0.1863 - val_accuracy: 0.9333\n",
      "Epoch 128/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1648 - accuracy: 0.9401 - val_loss: 0.1885 - val_accuracy: 0.9333\n",
      "Epoch 129/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1733 - accuracy: 0.9326 - val_loss: 0.1922 - val_accuracy: 0.9333\n",
      "Epoch 130/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1666 - accuracy: 0.9383 - val_loss: 0.1905 - val_accuracy: 0.9333\n",
      "Epoch 131/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1595 - accuracy: 0.9392 - val_loss: 0.1880 - val_accuracy: 0.9385\n",
      "Epoch 132/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1631 - accuracy: 0.9396 - val_loss: 0.1877 - val_accuracy: 0.9333\n",
      "Epoch 133/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1582 - accuracy: 0.9434 - val_loss: 0.1869 - val_accuracy: 0.9385\n",
      "Epoch 134/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1596 - accuracy: 0.9449 - val_loss: 0.1806 - val_accuracy: 0.9385\n",
      "Epoch 135/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1531 - accuracy: 0.9449 - val_loss: 0.1819 - val_accuracy: 0.9385\n",
      "Epoch 136/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1543 - accuracy: 0.9431 - val_loss: 0.1872 - val_accuracy: 0.9436\n",
      "Epoch 137/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1550 - accuracy: 0.9422 - val_loss: 0.1791 - val_accuracy: 0.9487\n",
      "Epoch 138/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1554 - accuracy: 0.9459 - val_loss: 0.1769 - val_accuracy: 0.9487\n",
      "Epoch 139/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1687 - accuracy: 0.9389 - val_loss: 0.1778 - val_accuracy: 0.9487\n",
      "Epoch 140/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1560 - accuracy: 0.9429 - val_loss: 0.1738 - val_accuracy: 0.9487\n",
      "Epoch 141/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1536 - accuracy: 0.9452 - val_loss: 0.1744 - val_accuracy: 0.9487\n",
      "Epoch 142/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1520 - accuracy: 0.9490 - val_loss: 0.1764 - val_accuracy: 0.9538\n",
      "Epoch 143/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1568 - accuracy: 0.9406 - val_loss: 0.1712 - val_accuracy: 0.9487\n",
      "Epoch 144/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1542 - accuracy: 0.9459 - val_loss: 0.1692 - val_accuracy: 0.9538\n",
      "Epoch 145/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1555 - accuracy: 0.9465 - val_loss: 0.1698 - val_accuracy: 0.9487\n",
      "Epoch 146/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1587 - accuracy: 0.9421 - val_loss: 0.1700 - val_accuracy: 0.9487\n",
      "Epoch 147/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1523 - accuracy: 0.9470 - val_loss: 0.1690 - val_accuracy: 0.9487\n",
      "Epoch 148/2000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1576 - accuracy: 0.9451 - val_loss: 0.1700 - val_accuracy: 0.9487\n",
      "Epoch 149/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1470 - accuracy: 0.9491 - val_loss: 0.1704 - val_accuracy: 0.9538\n",
      "Epoch 150/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1477 - accuracy: 0.9478 - val_loss: 0.1686 - val_accuracy: 0.9538\n",
      "Epoch 151/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1442 - accuracy: 0.9507 - val_loss: 0.1666 - val_accuracy: 0.9487\n",
      "Epoch 152/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1514 - accuracy: 0.9458 - val_loss: 0.1673 - val_accuracy: 0.9538\n",
      "Epoch 153/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1455 - accuracy: 0.9493 - val_loss: 0.1659 - val_accuracy: 0.9487\n",
      "Epoch 154/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1478 - accuracy: 0.9491 - val_loss: 0.1639 - val_accuracy: 0.9487\n",
      "Epoch 155/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1459 - accuracy: 0.9485 - val_loss: 0.1638 - val_accuracy: 0.9538\n",
      "Epoch 156/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1502 - accuracy: 0.9456 - val_loss: 0.1650 - val_accuracy: 0.9538\n",
      "Epoch 157/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1441 - accuracy: 0.9485 - val_loss: 0.1611 - val_accuracy: 0.9487\n",
      "Epoch 158/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1426 - accuracy: 0.9498 - val_loss: 0.1615 - val_accuracy: 0.9538\n",
      "Epoch 159/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1438 - accuracy: 0.9470 - val_loss: 0.1617 - val_accuracy: 0.9538\n",
      "Epoch 160/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1422 - accuracy: 0.9500 - val_loss: 0.1669 - val_accuracy: 0.9538\n",
      "Epoch 161/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1454 - accuracy: 0.9500 - val_loss: 0.1626 - val_accuracy: 0.9487\n",
      "Epoch 162/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1453 - accuracy: 0.9502 - val_loss: 0.1626 - val_accuracy: 0.9487\n",
      "Epoch 163/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1426 - accuracy: 0.9498 - val_loss: 0.1641 - val_accuracy: 0.9590\n",
      "Epoch 164/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1396 - accuracy: 0.9544 - val_loss: 0.1626 - val_accuracy: 0.9590\n",
      "Epoch 165/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1477 - accuracy: 0.9482 - val_loss: 0.1610 - val_accuracy: 0.9538\n",
      "Epoch 166/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1421 - accuracy: 0.9478 - val_loss: 0.1584 - val_accuracy: 0.9487\n",
      "Epoch 167/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1396 - accuracy: 0.9456 - val_loss: 0.1662 - val_accuracy: 0.9590\n",
      "Epoch 168/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1519 - accuracy: 0.9440 - val_loss: 0.1575 - val_accuracy: 0.9487\n",
      "Epoch 169/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1394 - accuracy: 0.9478 - val_loss: 0.1591 - val_accuracy: 0.9538\n",
      "Epoch 170/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1388 - accuracy: 0.9510 - val_loss: 0.1581 - val_accuracy: 0.9538\n",
      "Epoch 171/2000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1373 - accuracy: 0.9537 - val_loss: 0.1621 - val_accuracy: 0.9590\n",
      "Epoch 172/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1391 - accuracy: 0.9487 - val_loss: 0.1548 - val_accuracy: 0.9538\n",
      "Epoch 173/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1459 - accuracy: 0.9487 - val_loss: 0.1539 - val_accuracy: 0.9487\n",
      "Epoch 174/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1321 - accuracy: 0.9503 - val_loss: 0.1597 - val_accuracy: 0.9590\n",
      "Epoch 175/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1357 - accuracy: 0.9515 - val_loss: 0.1606 - val_accuracy: 0.9590\n",
      "Epoch 176/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1336 - accuracy: 0.9524 - val_loss: 0.1555 - val_accuracy: 0.9487\n",
      "Epoch 177/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1389 - accuracy: 0.9456 - val_loss: 0.1534 - val_accuracy: 0.9487\n",
      "Epoch 178/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1301 - accuracy: 0.9503 - val_loss: 0.1540 - val_accuracy: 0.9590\n",
      "Epoch 179/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1364 - accuracy: 0.9539 - val_loss: 0.1547 - val_accuracy: 0.9590\n",
      "Epoch 180/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1350 - accuracy: 0.9504 - val_loss: 0.1529 - val_accuracy: 0.9487\n",
      "Epoch 181/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1375 - accuracy: 0.9493 - val_loss: 0.1528 - val_accuracy: 0.9487\n",
      "Epoch 182/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1362 - accuracy: 0.9495 - val_loss: 0.1555 - val_accuracy: 0.9641\n",
      "Epoch 183/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1383 - accuracy: 0.9510 - val_loss: 0.1533 - val_accuracy: 0.9590\n",
      "Epoch 184/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1294 - accuracy: 0.9517 - val_loss: 0.1523 - val_accuracy: 0.9538\n",
      "Epoch 185/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1299 - accuracy: 0.9490 - val_loss: 0.1505 - val_accuracy: 0.9487\n",
      "Epoch 186/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1272 - accuracy: 0.9522 - val_loss: 0.1542 - val_accuracy: 0.9590\n",
      "Epoch 187/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1313 - accuracy: 0.9559 - val_loss: 0.1514 - val_accuracy: 0.9641\n",
      "Epoch 188/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1308 - accuracy: 0.9530 - val_loss: 0.1506 - val_accuracy: 0.9538\n",
      "Epoch 189/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1392 - accuracy: 0.9497 - val_loss: 0.1515 - val_accuracy: 0.9538\n",
      "Epoch 190/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1276 - accuracy: 0.9550 - val_loss: 0.1545 - val_accuracy: 0.9641\n",
      "Epoch 191/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1307 - accuracy: 0.9522 - val_loss: 0.1570 - val_accuracy: 0.9590\n",
      "Epoch 192/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1347 - accuracy: 0.9526 - val_loss: 0.1512 - val_accuracy: 0.9487\n",
      "Epoch 193/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1318 - accuracy: 0.9515 - val_loss: 0.1508 - val_accuracy: 0.9538\n",
      "Epoch 194/2000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1319 - accuracy: 0.9443 - val_loss: 0.1519 - val_accuracy: 0.9641\n",
      "Epoch 195/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1222 - accuracy: 0.9572 - val_loss: 0.1506 - val_accuracy: 0.9641\n",
      "Epoch 196/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1283 - accuracy: 0.9554 - val_loss: 0.1486 - val_accuracy: 0.9590\n",
      "Epoch 197/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1312 - accuracy: 0.9524 - val_loss: 0.1477 - val_accuracy: 0.9487\n",
      "Epoch 198/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1265 - accuracy: 0.9530 - val_loss: 0.1477 - val_accuracy: 0.9641\n",
      "Epoch 199/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1272 - accuracy: 0.9552 - val_loss: 0.1483 - val_accuracy: 0.9641\n",
      "Epoch 200/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1306 - accuracy: 0.9504 - val_loss: 0.1454 - val_accuracy: 0.9590\n",
      "Epoch 201/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1306 - accuracy: 0.9502 - val_loss: 0.1460 - val_accuracy: 0.9487\n",
      "Epoch 202/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1295 - accuracy: 0.9502 - val_loss: 0.1469 - val_accuracy: 0.9641\n",
      "Epoch 203/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1283 - accuracy: 0.9517 - val_loss: 0.1475 - val_accuracy: 0.9641\n",
      "Epoch 204/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1316 - accuracy: 0.9504 - val_loss: 0.1471 - val_accuracy: 0.9641\n",
      "Epoch 205/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1227 - accuracy: 0.9529 - val_loss: 0.1459 - val_accuracy: 0.9590\n",
      "Epoch 206/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1280 - accuracy: 0.9529 - val_loss: 0.1460 - val_accuracy: 0.9641\n",
      "Epoch 207/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1239 - accuracy: 0.9552 - val_loss: 0.1448 - val_accuracy: 0.9641\n",
      "Epoch 208/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1274 - accuracy: 0.9532 - val_loss: 0.1427 - val_accuracy: 0.9487\n",
      "Epoch 209/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1334 - accuracy: 0.9484 - val_loss: 0.1431 - val_accuracy: 0.9538\n",
      "Epoch 210/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1254 - accuracy: 0.9561 - val_loss: 0.1443 - val_accuracy: 0.9641\n",
      "Epoch 211/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1307 - accuracy: 0.9510 - val_loss: 0.1453 - val_accuracy: 0.9641\n",
      "Epoch 212/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1176 - accuracy: 0.9581 - val_loss: 0.1445 - val_accuracy: 0.9641\n",
      "Epoch 213/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1269 - accuracy: 0.9495 - val_loss: 0.1435 - val_accuracy: 0.9641\n",
      "Epoch 214/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1269 - accuracy: 0.9554 - val_loss: 0.1440 - val_accuracy: 0.9641\n",
      "Epoch 215/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1175 - accuracy: 0.9559 - val_loss: 0.1422 - val_accuracy: 0.9641\n",
      "Epoch 216/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1184 - accuracy: 0.9546 - val_loss: 0.1419 - val_accuracy: 0.9641\n",
      "Epoch 217/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1282 - accuracy: 0.9512 - val_loss: 0.1427 - val_accuracy: 0.9641\n",
      "Epoch 218/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1196 - accuracy: 0.9546 - val_loss: 0.1443 - val_accuracy: 0.9641\n",
      "Epoch 219/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1208 - accuracy: 0.9546 - val_loss: 0.1443 - val_accuracy: 0.9641\n",
      "Epoch 220/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1175 - accuracy: 0.9566 - val_loss: 0.1431 - val_accuracy: 0.9641\n",
      "Epoch 221/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.1226 - accuracy: 0.9559 - val_loss: 0.1434 - val_accuracy: 0.9641\n",
      "Epoch 222/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1215 - accuracy: 0.9517 - val_loss: 0.1420 - val_accuracy: 0.9641\n",
      "Epoch 223/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1186 - accuracy: 0.9581 - val_loss: 0.1412 - val_accuracy: 0.9692\n",
      "Epoch 224/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1254 - accuracy: 0.9524 - val_loss: 0.1423 - val_accuracy: 0.9641\n",
      "Epoch 225/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1205 - accuracy: 0.9512 - val_loss: 0.1421 - val_accuracy: 0.9641\n",
      "Epoch 226/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1173 - accuracy: 0.9537 - val_loss: 0.1408 - val_accuracy: 0.9692\n",
      "Epoch 227/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1162 - accuracy: 0.9568 - val_loss: 0.1419 - val_accuracy: 0.9641\n",
      "Epoch 228/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1122 - accuracy: 0.9631 - val_loss: 0.1395 - val_accuracy: 0.9641\n",
      "Epoch 229/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1242 - accuracy: 0.9526 - val_loss: 0.1398 - val_accuracy: 0.9641\n",
      "Epoch 230/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1148 - accuracy: 0.9561 - val_loss: 0.1434 - val_accuracy: 0.9641\n",
      "Epoch 231/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1255 - accuracy: 0.9566 - val_loss: 0.1423 - val_accuracy: 0.9641\n",
      "Epoch 232/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1209 - accuracy: 0.9521 - val_loss: 0.1435 - val_accuracy: 0.9538\n",
      "Epoch 233/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1212 - accuracy: 0.9520 - val_loss: 0.1402 - val_accuracy: 0.9692\n",
      "Epoch 234/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1136 - accuracy: 0.9571 - val_loss: 0.1524 - val_accuracy: 0.9641\n",
      "Epoch 235/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1256 - accuracy: 0.9571 - val_loss: 0.1383 - val_accuracy: 0.9641\n",
      "Epoch 236/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1138 - accuracy: 0.9568 - val_loss: 0.1392 - val_accuracy: 0.9590\n",
      "Epoch 237/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1204 - accuracy: 0.9552 - val_loss: 0.1376 - val_accuracy: 0.9641\n",
      "Epoch 238/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1167 - accuracy: 0.9573 - val_loss: 0.1416 - val_accuracy: 0.9641\n",
      "Epoch 239/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1210 - accuracy: 0.9597 - val_loss: 0.1362 - val_accuracy: 0.9692\n",
      "Epoch 240/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1202 - accuracy: 0.9519 - val_loss: 0.1366 - val_accuracy: 0.9590\n",
      "Epoch 241/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1140 - accuracy: 0.9539 - val_loss: 0.1390 - val_accuracy: 0.9692\n",
      "Epoch 242/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1236 - accuracy: 0.9588 - val_loss: 0.1386 - val_accuracy: 0.9641\n",
      "Epoch 243/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1150 - accuracy: 0.9585 - val_loss: 0.1397 - val_accuracy: 0.9590\n",
      "Epoch 244/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1144 - accuracy: 0.9557 - val_loss: 0.1372 - val_accuracy: 0.9641\n",
      "Epoch 245/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1200 - accuracy: 0.9576 - val_loss: 0.1445 - val_accuracy: 0.9641\n",
      "Epoch 246/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1150 - accuracy: 0.9611 - val_loss: 0.1395 - val_accuracy: 0.9590\n",
      "Epoch 247/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1128 - accuracy: 0.9537 - val_loss: 0.1412 - val_accuracy: 0.9538\n",
      "Epoch 248/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1233 - accuracy: 0.9506 - val_loss: 0.1433 - val_accuracy: 0.9641\n",
      "Epoch 249/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1187 - accuracy: 0.9582 - val_loss: 0.1363 - val_accuracy: 0.9641\n",
      "Epoch 250/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1114 - accuracy: 0.9615 - val_loss: 0.1378 - val_accuracy: 0.9538\n",
      "Epoch 251/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1150 - accuracy: 0.9530 - val_loss: 0.1351 - val_accuracy: 0.9692\n",
      "Epoch 252/2000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.1074 - accuracy: 0.9630 - val_loss: 0.1414 - val_accuracy: 0.9692\n",
      "Epoch 253/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.1138 - accuracy: 0.9597 - val_loss: 0.1365 - val_accuracy: 0.9692\n",
      "Epoch 254/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1117 - accuracy: 0.9615 - val_loss: 0.1362 - val_accuracy: 0.9641\n",
      "Epoch 255/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1044 - accuracy: 0.9611 - val_loss: 0.1356 - val_accuracy: 0.9692\n",
      "Epoch 256/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1194 - accuracy: 0.9602 - val_loss: 0.1381 - val_accuracy: 0.9692\n",
      "Epoch 257/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1161 - accuracy: 0.9604 - val_loss: 0.1367 - val_accuracy: 0.9590\n",
      "Epoch 258/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1136 - accuracy: 0.9535 - val_loss: 0.1336 - val_accuracy: 0.9641\n",
      "Epoch 259/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1179 - accuracy: 0.9558 - val_loss: 0.1381 - val_accuracy: 0.9692\n",
      "Epoch 260/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1123 - accuracy: 0.9573 - val_loss: 0.1326 - val_accuracy: 0.9641\n",
      "Epoch 261/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1118 - accuracy: 0.9602 - val_loss: 0.1321 - val_accuracy: 0.9692\n",
      "Epoch 262/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1101 - accuracy: 0.9595 - val_loss: 0.1328 - val_accuracy: 0.9641\n",
      "Epoch 263/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1034 - accuracy: 0.9613 - val_loss: 0.1350 - val_accuracy: 0.9692\n",
      "Epoch 264/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1145 - accuracy: 0.9590 - val_loss: 0.1346 - val_accuracy: 0.9692\n",
      "Epoch 265/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1089 - accuracy: 0.9628 - val_loss: 0.1342 - val_accuracy: 0.9692\n",
      "Epoch 266/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1119 - accuracy: 0.9602 - val_loss: 0.1347 - val_accuracy: 0.9744\n",
      "Epoch 267/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1111 - accuracy: 0.9595 - val_loss: 0.1318 - val_accuracy: 0.9744\n",
      "Epoch 268/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1047 - accuracy: 0.9608 - val_loss: 0.1306 - val_accuracy: 0.9692\n",
      "Epoch 269/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1061 - accuracy: 0.9615 - val_loss: 0.1302 - val_accuracy: 0.9692\n",
      "Epoch 270/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1033 - accuracy: 0.9608 - val_loss: 0.1343 - val_accuracy: 0.9692\n",
      "Epoch 271/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1112 - accuracy: 0.9580 - val_loss: 0.1328 - val_accuracy: 0.9692\n",
      "Epoch 272/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1090 - accuracy: 0.9593 - val_loss: 0.1320 - val_accuracy: 0.9692\n",
      "Epoch 273/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1169 - accuracy: 0.9568 - val_loss: 0.1320 - val_accuracy: 0.9692\n",
      "Epoch 274/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1132 - accuracy: 0.9588 - val_loss: 0.1328 - val_accuracy: 0.9744\n",
      "Epoch 275/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1075 - accuracy: 0.9602 - val_loss: 0.1312 - val_accuracy: 0.9744\n",
      "Epoch 276/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1125 - accuracy: 0.9610 - val_loss: 0.1295 - val_accuracy: 0.9692\n",
      "Epoch 277/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1123 - accuracy: 0.9610 - val_loss: 0.1299 - val_accuracy: 0.9744\n",
      "Epoch 278/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1025 - accuracy: 0.9608 - val_loss: 0.1302 - val_accuracy: 0.9744\n",
      "Epoch 279/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1028 - accuracy: 0.9608 - val_loss: 0.1301 - val_accuracy: 0.9744\n",
      "Epoch 280/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0975 - accuracy: 0.9622 - val_loss: 0.1309 - val_accuracy: 0.9744\n",
      "Epoch 281/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1106 - accuracy: 0.9643 - val_loss: 0.1299 - val_accuracy: 0.9692\n",
      "Epoch 282/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1074 - accuracy: 0.9600 - val_loss: 0.1276 - val_accuracy: 0.9744\n",
      "Epoch 283/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1140 - accuracy: 0.9584 - val_loss: 0.1273 - val_accuracy: 0.9744\n",
      "Epoch 284/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1087 - accuracy: 0.9595 - val_loss: 0.1285 - val_accuracy: 0.9744\n",
      "Epoch 285/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1004 - accuracy: 0.9630 - val_loss: 0.1292 - val_accuracy: 0.9744\n",
      "Epoch 286/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1107 - accuracy: 0.9612 - val_loss: 0.1283 - val_accuracy: 0.9744\n",
      "Epoch 287/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1057 - accuracy: 0.9619 - val_loss: 0.1272 - val_accuracy: 0.9744\n",
      "Epoch 288/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1039 - accuracy: 0.9622 - val_loss: 0.1266 - val_accuracy: 0.9744\n",
      "Epoch 289/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1008 - accuracy: 0.9639 - val_loss: 0.1310 - val_accuracy: 0.9692\n",
      "Epoch 290/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1098 - accuracy: 0.9627 - val_loss: 0.1274 - val_accuracy: 0.9744\n",
      "Epoch 291/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1086 - accuracy: 0.9575 - val_loss: 0.1290 - val_accuracy: 0.9692\n",
      "Epoch 292/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1091 - accuracy: 0.9595 - val_loss: 0.1294 - val_accuracy: 0.9744\n",
      "Epoch 293/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1009 - accuracy: 0.9615 - val_loss: 0.1311 - val_accuracy: 0.9692\n",
      "Epoch 294/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1089 - accuracy: 0.9612 - val_loss: 0.1282 - val_accuracy: 0.9744\n",
      "Epoch 295/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1030 - accuracy: 0.9615 - val_loss: 0.1279 - val_accuracy: 0.9744\n",
      "Epoch 296/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1070 - accuracy: 0.9575 - val_loss: 0.1283 - val_accuracy: 0.9744\n",
      "Epoch 297/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1021 - accuracy: 0.9590 - val_loss: 0.1271 - val_accuracy: 0.9744\n",
      "Epoch 298/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1012 - accuracy: 0.9602 - val_loss: 0.1266 - val_accuracy: 0.9744\n",
      "Epoch 299/2000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1069 - accuracy: 0.9588 - val_loss: 0.1266 - val_accuracy: 0.9744\n",
      "Epoch 300/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1066 - accuracy: 0.9621 - val_loss: 0.1256 - val_accuracy: 0.9744\n",
      "Epoch 301/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0945 - accuracy: 0.9635 - val_loss: 0.1252 - val_accuracy: 0.9744\n",
      "Epoch 302/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.1009 - accuracy: 0.9602 - val_loss: 0.1270 - val_accuracy: 0.9744\n",
      "Epoch 303/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0961 - accuracy: 0.9654 - val_loss: 0.1275 - val_accuracy: 0.9744\n",
      "Epoch 304/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1006 - accuracy: 0.9645 - val_loss: 0.1270 - val_accuracy: 0.9744\n",
      "Epoch 305/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1012 - accuracy: 0.9588 - val_loss: 0.1267 - val_accuracy: 0.9744\n",
      "Epoch 306/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1016 - accuracy: 0.9634 - val_loss: 0.1267 - val_accuracy: 0.9692\n",
      "Epoch 307/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1097 - accuracy: 0.9592 - val_loss: 0.1237 - val_accuracy: 0.9744\n",
      "Epoch 308/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1067 - accuracy: 0.9575 - val_loss: 0.1267 - val_accuracy: 0.9641\n",
      "Epoch 309/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1088 - accuracy: 0.9573 - val_loss: 0.1247 - val_accuracy: 0.9744\n",
      "Epoch 310/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.1094 - accuracy: 0.9538 - val_loss: 0.1279 - val_accuracy: 0.9692\n",
      "Epoch 311/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1011 - accuracy: 0.9608 - val_loss: 0.1270 - val_accuracy: 0.9744\n",
      "Epoch 312/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1016 - accuracy: 0.9595 - val_loss: 0.1276 - val_accuracy: 0.9744\n",
      "Epoch 313/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0993 - accuracy: 0.9588 - val_loss: 0.1286 - val_accuracy: 0.9692\n",
      "Epoch 314/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1064 - accuracy: 0.9616 - val_loss: 0.1255 - val_accuracy: 0.9692\n",
      "Epoch 315/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0948 - accuracy: 0.9647 - val_loss: 0.1241 - val_accuracy: 0.9744\n",
      "Epoch 316/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1049 - accuracy: 0.9602 - val_loss: 0.1239 - val_accuracy: 0.9692\n",
      "Epoch 317/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0995 - accuracy: 0.9610 - val_loss: 0.1276 - val_accuracy: 0.9692\n",
      "Epoch 318/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1044 - accuracy: 0.9629 - val_loss: 0.1243 - val_accuracy: 0.9744\n",
      "Epoch 319/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0986 - accuracy: 0.9595 - val_loss: 0.1266 - val_accuracy: 0.9692\n",
      "Epoch 320/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0980 - accuracy: 0.9617 - val_loss: 0.1254 - val_accuracy: 0.9744\n",
      "Epoch 321/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.1045 - accuracy: 0.9599 - val_loss: 0.1293 - val_accuracy: 0.9692\n",
      "Epoch 322/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1054 - accuracy: 0.9621 - val_loss: 0.1254 - val_accuracy: 0.9744\n",
      "Epoch 323/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0999 - accuracy: 0.9588 - val_loss: 0.1264 - val_accuracy: 0.9744\n",
      "Epoch 324/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1037 - accuracy: 0.9604 - val_loss: 0.1267 - val_accuracy: 0.9692\n",
      "Epoch 325/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0992 - accuracy: 0.9654 - val_loss: 0.1268 - val_accuracy: 0.9692\n",
      "Epoch 326/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0937 - accuracy: 0.9663 - val_loss: 0.1270 - val_accuracy: 0.9692\n",
      "Epoch 327/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1008 - accuracy: 0.9627 - val_loss: 0.1268 - val_accuracy: 0.9744\n",
      "Epoch 328/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0973 - accuracy: 0.9602 - val_loss: 0.1263 - val_accuracy: 0.9744\n",
      "Epoch 329/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0861 - accuracy: 0.9689 - val_loss: 0.1268 - val_accuracy: 0.9744\n",
      "Epoch 330/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0920 - accuracy: 0.9678 - val_loss: 0.1253 - val_accuracy: 0.9744\n",
      "Epoch 331/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1003 - accuracy: 0.9582 - val_loss: 0.1253 - val_accuracy: 0.9692\n",
      "Epoch 332/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1005 - accuracy: 0.9588 - val_loss: 0.1248 - val_accuracy: 0.9692\n",
      "Epoch 333/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0908 - accuracy: 0.9669 - val_loss: 0.1237 - val_accuracy: 0.9692\n",
      "Epoch 334/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0904 - accuracy: 0.9645 - val_loss: 0.1241 - val_accuracy: 0.9744\n",
      "Epoch 335/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0943 - accuracy: 0.9615 - val_loss: 0.1239 - val_accuracy: 0.9744\n",
      "Epoch 336/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0979 - accuracy: 0.9649 - val_loss: 0.1251 - val_accuracy: 0.9692\n",
      "Epoch 337/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0980 - accuracy: 0.9649 - val_loss: 0.1246 - val_accuracy: 0.9744\n",
      "Epoch 338/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0967 - accuracy: 0.9641 - val_loss: 0.1243 - val_accuracy: 0.9744\n",
      "Epoch 339/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0920 - accuracy: 0.9641 - val_loss: 0.1241 - val_accuracy: 0.9744\n",
      "Epoch 340/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0961 - accuracy: 0.9608 - val_loss: 0.1232 - val_accuracy: 0.9692\n",
      "Epoch 341/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0928 - accuracy: 0.9649 - val_loss: 0.1222 - val_accuracy: 0.9692\n",
      "Epoch 342/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0907 - accuracy: 0.9624 - val_loss: 0.1216 - val_accuracy: 0.9744\n",
      "Epoch 343/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1032 - accuracy: 0.9607 - val_loss: 0.1225 - val_accuracy: 0.9692\n",
      "Epoch 344/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0896 - accuracy: 0.9669 - val_loss: 0.1227 - val_accuracy: 0.9692\n",
      "Epoch 345/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0903 - accuracy: 0.9669 - val_loss: 0.1224 - val_accuracy: 0.9744\n",
      "Epoch 346/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0959 - accuracy: 0.9634 - val_loss: 0.1234 - val_accuracy: 0.9744\n",
      "Epoch 347/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0936 - accuracy: 0.9615 - val_loss: 0.1224 - val_accuracy: 0.9744\n",
      "Epoch 348/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0894 - accuracy: 0.9663 - val_loss: 0.1257 - val_accuracy: 0.9641\n",
      "Epoch 349/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0997 - accuracy: 0.9703 - val_loss: 0.1208 - val_accuracy: 0.9744\n",
      "Epoch 350/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0923 - accuracy: 0.9652 - val_loss: 0.1212 - val_accuracy: 0.9744\n",
      "Epoch 351/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0920 - accuracy: 0.9636 - val_loss: 0.1233 - val_accuracy: 0.9692\n",
      "Epoch 352/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0939 - accuracy: 0.9702 - val_loss: 0.1230 - val_accuracy: 0.9744\n",
      "Epoch 353/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0911 - accuracy: 0.9644 - val_loss: 0.1235 - val_accuracy: 0.9744\n",
      "Epoch 354/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0924 - accuracy: 0.9630 - val_loss: 0.1252 - val_accuracy: 0.9692\n",
      "Epoch 355/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0899 - accuracy: 0.9702 - val_loss: 0.1214 - val_accuracy: 0.9692\n",
      "Epoch 356/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0918 - accuracy: 0.9702 - val_loss: 0.1210 - val_accuracy: 0.9692\n",
      "Epoch 357/2000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.0927 - accuracy: 0.9628 - val_loss: 0.1192 - val_accuracy: 0.9744\n",
      "Epoch 358/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0940 - accuracy: 0.9621 - val_loss: 0.1246 - val_accuracy: 0.9641\n",
      "Epoch 359/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0971 - accuracy: 0.9666 - val_loss: 0.1206 - val_accuracy: 0.9744\n",
      "Epoch 360/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0944 - accuracy: 0.9612 - val_loss: 0.1220 - val_accuracy: 0.9744\n",
      "Epoch 361/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0951 - accuracy: 0.9619 - val_loss: 0.1251 - val_accuracy: 0.9641\n",
      "Epoch 362/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0912 - accuracy: 0.9688 - val_loss: 0.1240 - val_accuracy: 0.9692\n",
      "Epoch 363/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0906 - accuracy: 0.9664 - val_loss: 0.1231 - val_accuracy: 0.9744\n",
      "Epoch 364/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0920 - accuracy: 0.9645 - val_loss: 0.1225 - val_accuracy: 0.9744\n",
      "Epoch 365/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0942 - accuracy: 0.9636 - val_loss: 0.1236 - val_accuracy: 0.9692\n",
      "Epoch 366/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0865 - accuracy: 0.9708 - val_loss: 0.1234 - val_accuracy: 0.9692\n",
      "Epoch 367/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0862 - accuracy: 0.9698 - val_loss: 0.1226 - val_accuracy: 0.9744\n",
      "Epoch 368/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0968 - accuracy: 0.9627 - val_loss: 0.1217 - val_accuracy: 0.9744\n",
      "Epoch 369/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0903 - accuracy: 0.9671 - val_loss: 0.1237 - val_accuracy: 0.9641\n",
      "Epoch 370/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0924 - accuracy: 0.9695 - val_loss: 0.1225 - val_accuracy: 0.9692\n",
      "Epoch 371/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0922 - accuracy: 0.9688 - val_loss: 0.1238 - val_accuracy: 0.9744\n",
      "Epoch 372/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0926 - accuracy: 0.9654 - val_loss: 0.1227 - val_accuracy: 0.9692\n",
      "Epoch 373/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0869 - accuracy: 0.9671 - val_loss: 0.1267 - val_accuracy: 0.9641\n",
      "Epoch 374/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0920 - accuracy: 0.9695 - val_loss: 0.1238 - val_accuracy: 0.9692\n",
      "Epoch 375/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0910 - accuracy: 0.9654 - val_loss: 0.1268 - val_accuracy: 0.9692\n",
      "Epoch 376/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0928 - accuracy: 0.9610 - val_loss: 0.1244 - val_accuracy: 0.9692\n",
      "Epoch 377/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0922 - accuracy: 0.9695 - val_loss: 0.1239 - val_accuracy: 0.9641\n",
      "Epoch 378/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0874 - accuracy: 0.9702 - val_loss: 0.1219 - val_accuracy: 0.9692\n",
      "Epoch 379/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0907 - accuracy: 0.9678 - val_loss: 0.1226 - val_accuracy: 0.9692\n",
      "Epoch 380/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0964 - accuracy: 0.9685 - val_loss: 0.1231 - val_accuracy: 0.9692\n",
      "Epoch 381/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0902 - accuracy: 0.9671 - val_loss: 0.1240 - val_accuracy: 0.9744\n",
      "Epoch 382/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0878 - accuracy: 0.9678 - val_loss: 0.1236 - val_accuracy: 0.9692\n",
      "Epoch 383/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0927 - accuracy: 0.9719 - val_loss: 0.1220 - val_accuracy: 0.9692\n",
      "Epoch 384/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0903 - accuracy: 0.9695 - val_loss: 0.1224 - val_accuracy: 0.9692\n",
      "Epoch 385/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0853 - accuracy: 0.9667 - val_loss: 0.1197 - val_accuracy: 0.9692\n",
      "Epoch 386/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0933 - accuracy: 0.9680 - val_loss: 0.1262 - val_accuracy: 0.9641\n",
      "Epoch 387/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0934 - accuracy: 0.9682 - val_loss: 0.1222 - val_accuracy: 0.9692\n",
      "Epoch 388/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0965 - accuracy: 0.9612 - val_loss: 0.1231 - val_accuracy: 0.9692\n",
      "Epoch 389/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0913 - accuracy: 0.9651 - val_loss: 0.1261 - val_accuracy: 0.9641\n",
      "Epoch 390/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0941 - accuracy: 0.9710 - val_loss: 0.1237 - val_accuracy: 0.9641\n",
      "Epoch 391/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0870 - accuracy: 0.9712 - val_loss: 0.1244 - val_accuracy: 0.9692\n",
      "Epoch 392/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0945 - accuracy: 0.9639 - val_loss: 0.1214 - val_accuracy: 0.9744\n",
      "Epoch 393/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0876 - accuracy: 0.9680 - val_loss: 0.1266 - val_accuracy: 0.9641\n",
      "Epoch 394/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0918 - accuracy: 0.9703 - val_loss: 0.1211 - val_accuracy: 0.9744\n",
      "Epoch 395/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0852 - accuracy: 0.9654 - val_loss: 0.1217 - val_accuracy: 0.9744\n",
      "Epoch 396/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0935 - accuracy: 0.9621 - val_loss: 0.1224 - val_accuracy: 0.9641\n",
      "Epoch 397/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0956 - accuracy: 0.9675 - val_loss: 0.1194 - val_accuracy: 0.9692\n",
      "Epoch 398/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0827 - accuracy: 0.9706 - val_loss: 0.1207 - val_accuracy: 0.9692\n",
      "Epoch 399/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0903 - accuracy: 0.9632 - val_loss: 0.1191 - val_accuracy: 0.9692\n",
      "Epoch 400/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0939 - accuracy: 0.9677 - val_loss: 0.1229 - val_accuracy: 0.9641\n",
      "Epoch 401/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0902 - accuracy: 0.9703 - val_loss: 0.1196 - val_accuracy: 0.9744\n",
      "Epoch 402/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0837 - accuracy: 0.9673 - val_loss: 0.1197 - val_accuracy: 0.9744\n",
      "Epoch 403/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0840 - accuracy: 0.9686 - val_loss: 0.1201 - val_accuracy: 0.9692\n",
      "Epoch 404/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0872 - accuracy: 0.9717 - val_loss: 0.1200 - val_accuracy: 0.9641\n",
      "Epoch 405/2000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.0871 - accuracy: 0.9697 - val_loss: 0.1191 - val_accuracy: 0.9744\n",
      "Epoch 406/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0837 - accuracy: 0.9693 - val_loss: 0.1187 - val_accuracy: 0.9692\n",
      "Epoch 407/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0894 - accuracy: 0.9675 - val_loss: 0.1197 - val_accuracy: 0.9692\n",
      "Epoch 408/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0906 - accuracy: 0.9690 - val_loss: 0.1197 - val_accuracy: 0.9744\n",
      "Epoch 409/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0815 - accuracy: 0.9676 - val_loss: 0.1198 - val_accuracy: 0.9744\n",
      "Epoch 410/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0787 - accuracy: 0.9717 - val_loss: 0.1218 - val_accuracy: 0.9641\n",
      "Epoch 411/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0843 - accuracy: 0.9717 - val_loss: 0.1193 - val_accuracy: 0.9641\n",
      "Epoch 412/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0865 - accuracy: 0.9715 - val_loss: 0.1185 - val_accuracy: 0.9744\n",
      "Epoch 413/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0844 - accuracy: 0.9693 - val_loss: 0.1184 - val_accuracy: 0.9744\n",
      "Epoch 414/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0896 - accuracy: 0.9644 - val_loss: 0.1183 - val_accuracy: 0.9692\n",
      "Epoch 415/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0866 - accuracy: 0.9686 - val_loss: 0.1179 - val_accuracy: 0.9744\n",
      "Epoch 416/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0788 - accuracy: 0.9706 - val_loss: 0.1182 - val_accuracy: 0.9744\n",
      "Epoch 417/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0872 - accuracy: 0.9700 - val_loss: 0.1183 - val_accuracy: 0.9692\n",
      "Epoch 418/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0778 - accuracy: 0.9739 - val_loss: 0.1191 - val_accuracy: 0.9641\n",
      "Epoch 419/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0896 - accuracy: 0.9673 - val_loss: 0.1183 - val_accuracy: 0.9744\n",
      "Epoch 420/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0790 - accuracy: 0.9700 - val_loss: 0.1181 - val_accuracy: 0.9744\n",
      "Epoch 421/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0784 - accuracy: 0.9722 - val_loss: 0.1174 - val_accuracy: 0.9641\n",
      "Epoch 422/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0873 - accuracy: 0.9697 - val_loss: 0.1179 - val_accuracy: 0.9641\n",
      "Epoch 423/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0872 - accuracy: 0.9710 - val_loss: 0.1151 - val_accuracy: 0.9744\n",
      "Epoch 424/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0826 - accuracy: 0.9658 - val_loss: 0.1154 - val_accuracy: 0.9744\n",
      "Epoch 425/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0823 - accuracy: 0.9728 - val_loss: 0.1159 - val_accuracy: 0.9692\n",
      "Epoch 426/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0863 - accuracy: 0.9682 - val_loss: 0.1162 - val_accuracy: 0.9744\n",
      "Epoch 427/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0871 - accuracy: 0.9666 - val_loss: 0.1176 - val_accuracy: 0.9744\n",
      "Epoch 428/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0833 - accuracy: 0.9684 - val_loss: 0.1191 - val_accuracy: 0.9744\n",
      "Epoch 429/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0828 - accuracy: 0.9730 - val_loss: 0.1201 - val_accuracy: 0.9641\n",
      "Epoch 430/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0889 - accuracy: 0.9699 - val_loss: 0.1195 - val_accuracy: 0.9744\n",
      "Epoch 431/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0788 - accuracy: 0.9728 - val_loss: 0.1193 - val_accuracy: 0.9744\n",
      "Epoch 432/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0826 - accuracy: 0.9660 - val_loss: 0.1201 - val_accuracy: 0.9641\n",
      "Epoch 433/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0910 - accuracy: 0.9699 - val_loss: 0.1185 - val_accuracy: 0.9641\n",
      "Epoch 434/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0868 - accuracy: 0.9688 - val_loss: 0.1184 - val_accuracy: 0.9744\n",
      "Epoch 435/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0829 - accuracy: 0.9684 - val_loss: 0.1176 - val_accuracy: 0.9744\n",
      "Epoch 436/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0874 - accuracy: 0.9697 - val_loss: 0.1200 - val_accuracy: 0.9641\n",
      "Epoch 437/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0835 - accuracy: 0.9702 - val_loss: 0.1196 - val_accuracy: 0.9744\n",
      "Epoch 438/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0816 - accuracy: 0.9691 - val_loss: 0.1196 - val_accuracy: 0.9744\n",
      "Epoch 439/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0817 - accuracy: 0.9693 - val_loss: 0.1219 - val_accuracy: 0.9641\n",
      "Epoch 440/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0777 - accuracy: 0.9717 - val_loss: 0.1192 - val_accuracy: 0.9692\n",
      "Epoch 441/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0850 - accuracy: 0.9660 - val_loss: 0.1178 - val_accuracy: 0.9744\n",
      "Epoch 442/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0814 - accuracy: 0.9666 - val_loss: 0.1170 - val_accuracy: 0.9744\n",
      "Epoch 443/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0784 - accuracy: 0.9688 - val_loss: 0.1169 - val_accuracy: 0.9641\n",
      "Epoch 444/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0785 - accuracy: 0.9730 - val_loss: 0.1162 - val_accuracy: 0.9744\n",
      "Epoch 445/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0851 - accuracy: 0.9683 - val_loss: 0.1174 - val_accuracy: 0.9641\n",
      "Epoch 446/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0778 - accuracy: 0.9693 - val_loss: 0.1171 - val_accuracy: 0.9744\n",
      "Epoch 447/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0849 - accuracy: 0.9673 - val_loss: 0.1165 - val_accuracy: 0.9744\n",
      "Epoch 448/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0840 - accuracy: 0.9658 - val_loss: 0.1163 - val_accuracy: 0.9744\n",
      "Epoch 449/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0761 - accuracy: 0.9722 - val_loss: 0.1194 - val_accuracy: 0.9641\n",
      "Epoch 450/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0864 - accuracy: 0.9677 - val_loss: 0.1176 - val_accuracy: 0.9692\n",
      "Epoch 451/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0870 - accuracy: 0.9662 - val_loss: 0.1183 - val_accuracy: 0.9744\n",
      "Epoch 452/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0864 - accuracy: 0.9666 - val_loss: 0.1186 - val_accuracy: 0.9744\n",
      "Epoch 453/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0810 - accuracy: 0.9686 - val_loss: 0.1213 - val_accuracy: 0.9641\n",
      "Epoch 454/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0837 - accuracy: 0.9734 - val_loss: 0.1188 - val_accuracy: 0.9641\n",
      "Epoch 455/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0881 - accuracy: 0.9683 - val_loss: 0.1193 - val_accuracy: 0.9795\n",
      "Epoch 456/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0774 - accuracy: 0.9691 - val_loss: 0.1175 - val_accuracy: 0.9744\n",
      "Epoch 457/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0868 - accuracy: 0.9677 - val_loss: 0.1199 - val_accuracy: 0.9641\n",
      "Epoch 458/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0860 - accuracy: 0.9683 - val_loss: 0.1173 - val_accuracy: 0.9744\n",
      "Epoch 459/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0865 - accuracy: 0.9639 - val_loss: 0.1187 - val_accuracy: 0.9744\n",
      "Epoch 460/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0870 - accuracy: 0.9666 - val_loss: 0.1247 - val_accuracy: 0.9641\n",
      "Epoch 461/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0826 - accuracy: 0.9758 - val_loss: 0.1179 - val_accuracy: 0.9641\n",
      "Epoch 462/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0837 - accuracy: 0.9673 - val_loss: 0.1200 - val_accuracy: 0.9744\n",
      "Epoch 463/2000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0858 - accuracy: 0.9660 - val_loss: 0.1174 - val_accuracy: 0.9744\n",
      "Epoch 464/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0798 - accuracy: 0.9695 - val_loss: 0.1195 - val_accuracy: 0.9641\n",
      "Epoch 465/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0780 - accuracy: 0.9719 - val_loss: 0.1154 - val_accuracy: 0.9744\n",
      "Epoch 466/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0712 - accuracy: 0.9706 - val_loss: 0.1151 - val_accuracy: 0.9744\n",
      "Epoch 467/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0813 - accuracy: 0.9660 - val_loss: 0.1159 - val_accuracy: 0.9641\n",
      "Epoch 468/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0809 - accuracy: 0.9688 - val_loss: 0.1161 - val_accuracy: 0.9692\n",
      "Epoch 469/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0759 - accuracy: 0.9686 - val_loss: 0.1162 - val_accuracy: 0.9641\n",
      "Epoch 470/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0826 - accuracy: 0.9682 - val_loss: 0.1160 - val_accuracy: 0.9641\n",
      "Epoch 471/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0756 - accuracy: 0.9737 - val_loss: 0.1146 - val_accuracy: 0.9692\n",
      "Epoch 472/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0819 - accuracy: 0.9682 - val_loss: 0.1145 - val_accuracy: 0.9692\n",
      "Epoch 473/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0770 - accuracy: 0.9686 - val_loss: 0.1150 - val_accuracy: 0.9744\n",
      "Epoch 474/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0788 - accuracy: 0.9708 - val_loss: 0.1171 - val_accuracy: 0.9641\n",
      "Epoch 475/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0850 - accuracy: 0.9685 - val_loss: 0.1174 - val_accuracy: 0.9641\n",
      "Epoch 476/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0778 - accuracy: 0.9688 - val_loss: 0.1178 - val_accuracy: 0.9692\n",
      "Epoch 477/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0767 - accuracy: 0.9712 - val_loss: 0.1178 - val_accuracy: 0.9744\n",
      "Epoch 478/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0818 - accuracy: 0.9651 - val_loss: 0.1168 - val_accuracy: 0.9692\n",
      "Epoch 479/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0811 - accuracy: 0.9677 - val_loss: 0.1156 - val_accuracy: 0.9692\n",
      "Epoch 480/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0822 - accuracy: 0.9690 - val_loss: 0.1149 - val_accuracy: 0.9692\n",
      "Epoch 481/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0811 - accuracy: 0.9675 - val_loss: 0.1149 - val_accuracy: 0.9795\n",
      "Epoch 482/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0747 - accuracy: 0.9706 - val_loss: 0.1158 - val_accuracy: 0.9692\n",
      "Epoch 483/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0735 - accuracy: 0.9732 - val_loss: 0.1166 - val_accuracy: 0.9692\n",
      "Epoch 484/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0775 - accuracy: 0.9703 - val_loss: 0.1163 - val_accuracy: 0.9744\n",
      "Epoch 485/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0719 - accuracy: 0.9723 - val_loss: 0.1161 - val_accuracy: 0.9744\n",
      "Epoch 486/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0789 - accuracy: 0.9699 - val_loss: 0.1173 - val_accuracy: 0.9641\n",
      "Epoch 487/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0705 - accuracy: 0.9759 - val_loss: 0.1161 - val_accuracy: 0.9692\n",
      "Epoch 488/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0801 - accuracy: 0.9703 - val_loss: 0.1162 - val_accuracy: 0.9692\n",
      "Epoch 489/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0803 - accuracy: 0.9686 - val_loss: 0.1167 - val_accuracy: 0.9744\n",
      "Epoch 490/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0739 - accuracy: 0.9713 - val_loss: 0.1182 - val_accuracy: 0.9641\n",
      "Epoch 491/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0701 - accuracy: 0.9745 - val_loss: 0.1184 - val_accuracy: 0.9641\n",
      "Epoch 492/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0760 - accuracy: 0.9702 - val_loss: 0.1160 - val_accuracy: 0.9692\n",
      "Epoch 493/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0750 - accuracy: 0.9702 - val_loss: 0.1158 - val_accuracy: 0.9692\n",
      "Epoch 494/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0754 - accuracy: 0.9730 - val_loss: 0.1163 - val_accuracy: 0.9692\n",
      "Epoch 495/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0808 - accuracy: 0.9703 - val_loss: 0.1170 - val_accuracy: 0.9692\n",
      "Epoch 496/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0745 - accuracy: 0.9697 - val_loss: 0.1176 - val_accuracy: 0.9692\n",
      "Epoch 497/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0717 - accuracy: 0.9745 - val_loss: 0.1158 - val_accuracy: 0.9692\n",
      "Epoch 498/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0741 - accuracy: 0.9710 - val_loss: 0.1139 - val_accuracy: 0.9744\n",
      "Epoch 499/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0706 - accuracy: 0.9747 - val_loss: 0.1127 - val_accuracy: 0.9744\n",
      "Epoch 500/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0775 - accuracy: 0.9690 - val_loss: 0.1123 - val_accuracy: 0.9744\n",
      "Epoch 501/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0765 - accuracy: 0.9705 - val_loss: 0.1130 - val_accuracy: 0.9692\n",
      "Epoch 502/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0790 - accuracy: 0.9690 - val_loss: 0.1127 - val_accuracy: 0.9692\n",
      "Epoch 503/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0816 - accuracy: 0.9685 - val_loss: 0.1131 - val_accuracy: 0.9744\n",
      "Epoch 504/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0754 - accuracy: 0.9712 - val_loss: 0.1147 - val_accuracy: 0.9692\n",
      "Epoch 505/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0748 - accuracy: 0.9705 - val_loss: 0.1156 - val_accuracy: 0.9692\n",
      "Epoch 506/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0726 - accuracy: 0.9734 - val_loss: 0.1144 - val_accuracy: 0.9692\n",
      "Epoch 507/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0700 - accuracy: 0.9723 - val_loss: 0.1139 - val_accuracy: 0.9692\n",
      "Epoch 508/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0733 - accuracy: 0.9723 - val_loss: 0.1122 - val_accuracy: 0.9744\n",
      "Epoch 509/2000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0755 - accuracy: 0.9719 - val_loss: 0.1119 - val_accuracy: 0.9744\n",
      "Epoch 510/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0799 - accuracy: 0.9699 - val_loss: 0.1130 - val_accuracy: 0.9692\n",
      "Epoch 511/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 0.1119 - val_accuracy: 0.9744\n",
      "Epoch 512/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0728 - accuracy: 0.9719 - val_loss: 0.1126 - val_accuracy: 0.9692\n",
      "Epoch 513/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0769 - accuracy: 0.9688 - val_loss: 0.1144 - val_accuracy: 0.9641\n",
      "Epoch 514/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0773 - accuracy: 0.9727 - val_loss: 0.1129 - val_accuracy: 0.9744\n",
      "Epoch 515/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0740 - accuracy: 0.9703 - val_loss: 0.1141 - val_accuracy: 0.9795\n",
      "Epoch 516/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0782 - accuracy: 0.9688 - val_loss: 0.1160 - val_accuracy: 0.9692\n",
      "Epoch 517/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0743 - accuracy: 0.9717 - val_loss: 0.1156 - val_accuracy: 0.9692\n",
      "Epoch 518/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0760 - accuracy: 0.9693 - val_loss: 0.1132 - val_accuracy: 0.9744\n",
      "Epoch 519/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0791 - accuracy: 0.9707 - val_loss: 0.1132 - val_accuracy: 0.9692\n",
      "Epoch 520/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0793 - accuracy: 0.9697 - val_loss: 0.1129 - val_accuracy: 0.9692\n",
      "Epoch 521/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0678 - accuracy: 0.9730 - val_loss: 0.1125 - val_accuracy: 0.9744\n",
      "Epoch 522/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0729 - accuracy: 0.9697 - val_loss: 0.1146 - val_accuracy: 0.9641\n",
      "Epoch 523/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0783 - accuracy: 0.9699 - val_loss: 0.1136 - val_accuracy: 0.9744\n",
      "Epoch 524/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0793 - accuracy: 0.9701 - val_loss: 0.1144 - val_accuracy: 0.9795\n",
      "Epoch 525/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0805 - accuracy: 0.9677 - val_loss: 0.1148 - val_accuracy: 0.9744\n",
      "Epoch 526/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0739 - accuracy: 0.9754 - val_loss: 0.1168 - val_accuracy: 0.9641\n",
      "Epoch 527/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0772 - accuracy: 0.9741 - val_loss: 0.1140 - val_accuracy: 0.9744\n",
      "Epoch 528/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0726 - accuracy: 0.9705 - val_loss: 0.1148 - val_accuracy: 0.9795\n",
      "Epoch 529/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0807 - accuracy: 0.9677 - val_loss: 0.1142 - val_accuracy: 0.9641\n",
      "Epoch 530/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0750 - accuracy: 0.9742 - val_loss: 0.1167 - val_accuracy: 0.9641\n",
      "Epoch 531/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0712 - accuracy: 0.9741 - val_loss: 0.1124 - val_accuracy: 0.9795\n",
      "Epoch 532/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0807 - accuracy: 0.9690 - val_loss: 0.1142 - val_accuracy: 0.9795\n",
      "Epoch 533/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0714 - accuracy: 0.9723 - val_loss: 0.1164 - val_accuracy: 0.9641\n",
      "Epoch 534/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0791 - accuracy: 0.9729 - val_loss: 0.1164 - val_accuracy: 0.9641\n",
      "Epoch 535/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0757 - accuracy: 0.9762 - val_loss: 0.1155 - val_accuracy: 0.9795\n",
      "Epoch 536/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0720 - accuracy: 0.9703 - val_loss: 0.1173 - val_accuracy: 0.9692\n",
      "Epoch 537/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0692 - accuracy: 0.9793 - val_loss: 0.1171 - val_accuracy: 0.9641\n",
      "Epoch 538/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0666 - accuracy: 0.9762 - val_loss: 0.1126 - val_accuracy: 0.9744\n",
      "Epoch 539/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0713 - accuracy: 0.9715 - val_loss: 0.1110 - val_accuracy: 0.9744\n",
      "Epoch 540/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0685 - accuracy: 0.9719 - val_loss: 0.1198 - val_accuracy: 0.9641\n",
      "Epoch 541/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0786 - accuracy: 0.9751 - val_loss: 0.1100 - val_accuracy: 0.9744\n",
      "Epoch 542/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0767 - accuracy: 0.9690 - val_loss: 0.1101 - val_accuracy: 0.9744\n",
      "Epoch 543/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0661 - accuracy: 0.9743 - val_loss: 0.1109 - val_accuracy: 0.9744\n",
      "Epoch 544/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0729 - accuracy: 0.9725 - val_loss: 0.1157 - val_accuracy: 0.9641\n",
      "Epoch 545/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0736 - accuracy: 0.9752 - val_loss: 0.1117 - val_accuracy: 0.9744\n",
      "Epoch 546/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0739 - accuracy: 0.9705 - val_loss: 0.1129 - val_accuracy: 0.9744\n",
      "Epoch 547/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0727 - accuracy: 0.9727 - val_loss: 0.1136 - val_accuracy: 0.9744\n",
      "Epoch 548/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0734 - accuracy: 0.9736 - val_loss: 0.1145 - val_accuracy: 0.9744\n",
      "Epoch 549/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0702 - accuracy: 0.9762 - val_loss: 0.1153 - val_accuracy: 0.9744\n",
      "Epoch 550/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0780 - accuracy: 0.9746 - val_loss: 0.1156 - val_accuracy: 0.9744\n",
      "Epoch 551/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0734 - accuracy: 0.9779 - val_loss: 0.1156 - val_accuracy: 0.9744\n",
      "Epoch 552/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0733 - accuracy: 0.9749 - val_loss: 0.1157 - val_accuracy: 0.9744\n",
      "Epoch 553/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0703 - accuracy: 0.9725 - val_loss: 0.1153 - val_accuracy: 0.9744\n",
      "Epoch 554/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0676 - accuracy: 0.9797 - val_loss: 0.1182 - val_accuracy: 0.9641\n",
      "Epoch 555/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0726 - accuracy: 0.9741 - val_loss: 0.1131 - val_accuracy: 0.9744\n",
      "Epoch 556/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0684 - accuracy: 0.9712 - val_loss: 0.1139 - val_accuracy: 0.9744\n",
      "Epoch 557/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0698 - accuracy: 0.9723 - val_loss: 0.1139 - val_accuracy: 0.9744\n",
      "Epoch 558/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0789 - accuracy: 0.9759 - val_loss: 0.1154 - val_accuracy: 0.9641\n",
      "Epoch 559/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0762 - accuracy: 0.9725 - val_loss: 0.1147 - val_accuracy: 0.9744\n",
      "Epoch 560/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0788 - accuracy: 0.9683 - val_loss: 0.1142 - val_accuracy: 0.9744\n",
      "Epoch 561/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0733 - accuracy: 0.9766 - val_loss: 0.1142 - val_accuracy: 0.9692\n",
      "Epoch 562/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0703 - accuracy: 0.9725 - val_loss: 0.1111 - val_accuracy: 0.9744\n",
      "Epoch 563/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0706 - accuracy: 0.9710 - val_loss: 0.1104 - val_accuracy: 0.9744\n",
      "Epoch 564/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0711 - accuracy: 0.9725 - val_loss: 0.1150 - val_accuracy: 0.9641\n",
      "Epoch 565/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0678 - accuracy: 0.9771 - val_loss: 0.1112 - val_accuracy: 0.9744\n",
      "Epoch 566/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0646 - accuracy: 0.9754 - val_loss: 0.1116 - val_accuracy: 0.9744\n",
      "Epoch 567/2000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0674 - accuracy: 0.9747 - val_loss: 0.1130 - val_accuracy: 0.9744\n",
      "Epoch 568/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0707 - accuracy: 0.9797 - val_loss: 0.1139 - val_accuracy: 0.9744\n",
      "Epoch 569/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0721 - accuracy: 0.9781 - val_loss: 0.1123 - val_accuracy: 0.9744\n",
      "Epoch 570/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0745 - accuracy: 0.9775 - val_loss: 0.1112 - val_accuracy: 0.9744\n",
      "Epoch 571/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0693 - accuracy: 0.9756 - val_loss: 0.1104 - val_accuracy: 0.9744\n",
      "Epoch 572/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0713 - accuracy: 0.9719 - val_loss: 0.1101 - val_accuracy: 0.9744\n",
      "Epoch 573/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0706 - accuracy: 0.9719 - val_loss: 0.1120 - val_accuracy: 0.9744\n",
      "Epoch 574/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0670 - accuracy: 0.9788 - val_loss: 0.1159 - val_accuracy: 0.9641\n",
      "Epoch 575/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0698 - accuracy: 0.9803 - val_loss: 0.1137 - val_accuracy: 0.9744\n",
      "Epoch 576/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0756 - accuracy: 0.9701 - val_loss: 0.1138 - val_accuracy: 0.9744\n",
      "Epoch 577/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0733 - accuracy: 0.9712 - val_loss: 0.1158 - val_accuracy: 0.9692\n",
      "Epoch 578/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0739 - accuracy: 0.9768 - val_loss: 0.1163 - val_accuracy: 0.9692\n",
      "Epoch 579/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0733 - accuracy: 0.9768 - val_loss: 0.1143 - val_accuracy: 0.9744\n",
      "Epoch 580/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0707 - accuracy: 0.9710 - val_loss: 0.1140 - val_accuracy: 0.9744\n",
      "Epoch 581/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0728 - accuracy: 0.9703 - val_loss: 0.1151 - val_accuracy: 0.9692\n",
      "Epoch 582/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0689 - accuracy: 0.9753 - val_loss: 0.1158 - val_accuracy: 0.9692\n",
      "Epoch 583/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0709 - accuracy: 0.9764 - val_loss: 0.1119 - val_accuracy: 0.9744\n",
      "Epoch 584/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0708 - accuracy: 0.9717 - val_loss: 0.1119 - val_accuracy: 0.9744\n",
      "Epoch 585/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0731 - accuracy: 0.9714 - val_loss: 0.1127 - val_accuracy: 0.9744\n",
      "Epoch 586/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0672 - accuracy: 0.9751 - val_loss: 0.1142 - val_accuracy: 0.9744\n",
      "Epoch 587/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0618 - accuracy: 0.9778 - val_loss: 0.1141 - val_accuracy: 0.9744\n",
      "Epoch 588/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0699 - accuracy: 0.9759 - val_loss: 0.1136 - val_accuracy: 0.9744\n",
      "Epoch 589/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0645 - accuracy: 0.9749 - val_loss: 0.1127 - val_accuracy: 0.9744\n",
      "Epoch 590/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0656 - accuracy: 0.9764 - val_loss: 0.1114 - val_accuracy: 0.9744\n",
      "Epoch 591/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0714 - accuracy: 0.9729 - val_loss: 0.1101 - val_accuracy: 0.9744\n",
      "Epoch 592/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0739 - accuracy: 0.9683 - val_loss: 0.1098 - val_accuracy: 0.9744\n",
      "Epoch 593/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0712 - accuracy: 0.9734 - val_loss: 0.1106 - val_accuracy: 0.9744\n",
      "Epoch 594/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0661 - accuracy: 0.9764 - val_loss: 0.1111 - val_accuracy: 0.9744\n",
      "Epoch 595/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0699 - accuracy: 0.9773 - val_loss: 0.1118 - val_accuracy: 0.9744\n",
      "Epoch 596/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0719 - accuracy: 0.9751 - val_loss: 0.1112 - val_accuracy: 0.9744\n",
      "Epoch 597/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0725 - accuracy: 0.9759 - val_loss: 0.1111 - val_accuracy: 0.9744\n",
      "Epoch 598/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0706 - accuracy: 0.9719 - val_loss: 0.1112 - val_accuracy: 0.9744\n",
      "Epoch 599/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0691 - accuracy: 0.9729 - val_loss: 0.1148 - val_accuracy: 0.9692\n",
      "Epoch 600/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0664 - accuracy: 0.9801 - val_loss: 0.1119 - val_accuracy: 0.9744\n",
      "Epoch 601/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0635 - accuracy: 0.9739 - val_loss: 0.1117 - val_accuracy: 0.9744\n",
      "Epoch 602/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0673 - accuracy: 0.9744 - val_loss: 0.1150 - val_accuracy: 0.9692\n",
      "Epoch 603/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0672 - accuracy: 0.9799 - val_loss: 0.1094 - val_accuracy: 0.9744\n",
      "Epoch 604/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0692 - accuracy: 0.9721 - val_loss: 0.1101 - val_accuracy: 0.9744\n",
      "Epoch 605/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0680 - accuracy: 0.9702 - val_loss: 0.1104 - val_accuracy: 0.9744\n",
      "Epoch 606/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0652 - accuracy: 0.9795 - val_loss: 0.1130 - val_accuracy: 0.9744\n",
      "Epoch 607/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0727 - accuracy: 0.9705 - val_loss: 0.1097 - val_accuracy: 0.9744\n",
      "Epoch 608/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0704 - accuracy: 0.9690 - val_loss: 0.1096 - val_accuracy: 0.9744\n",
      "Epoch 609/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0616 - accuracy: 0.9766 - val_loss: 0.1145 - val_accuracy: 0.9692\n",
      "Epoch 610/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0670 - accuracy: 0.9810 - val_loss: 0.1087 - val_accuracy: 0.9744\n",
      "Epoch 611/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0650 - accuracy: 0.9725 - val_loss: 0.1080 - val_accuracy: 0.9744\n",
      "Epoch 612/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0662 - accuracy: 0.9719 - val_loss: 0.1097 - val_accuracy: 0.9744\n",
      "Epoch 613/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0663 - accuracy: 0.9795 - val_loss: 0.1099 - val_accuracy: 0.9744\n",
      "Epoch 614/2000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0700 - accuracy: 0.9744 - val_loss: 0.1081 - val_accuracy: 0.9692\n",
      "Epoch 615/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0646 - accuracy: 0.9710 - val_loss: 0.1083 - val_accuracy: 0.9744\n",
      "Epoch 616/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0593 - accuracy: 0.9756 - val_loss: 0.1137 - val_accuracy: 0.9744\n",
      "Epoch 617/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0699 - accuracy: 0.9781 - val_loss: 0.1090 - val_accuracy: 0.9744\n",
      "Epoch 618/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0613 - accuracy: 0.9762 - val_loss: 0.1091 - val_accuracy: 0.9744\n",
      "Epoch 619/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0624 - accuracy: 0.9764 - val_loss: 0.1127 - val_accuracy: 0.9744\n",
      "Epoch 620/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0644 - accuracy: 0.9779 - val_loss: 0.1121 - val_accuracy: 0.9744\n",
      "Epoch 621/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0610 - accuracy: 0.9810 - val_loss: 0.1113 - val_accuracy: 0.9744\n",
      "Epoch 622/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0657 - accuracy: 0.9758 - val_loss: 0.1083 - val_accuracy: 0.9744\n",
      "Epoch 623/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0640 - accuracy: 0.9786 - val_loss: 0.1076 - val_accuracy: 0.9744\n",
      "Epoch 624/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0643 - accuracy: 0.9749 - val_loss: 0.1071 - val_accuracy: 0.9744\n",
      "Epoch 625/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0674 - accuracy: 0.9781 - val_loss: 0.1085 - val_accuracy: 0.9744\n",
      "Epoch 626/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0665 - accuracy: 0.9788 - val_loss: 0.1084 - val_accuracy: 0.9744\n",
      "Epoch 627/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0618 - accuracy: 0.9761 - val_loss: 0.1108 - val_accuracy: 0.9744\n",
      "Epoch 628/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0677 - accuracy: 0.9797 - val_loss: 0.1124 - val_accuracy: 0.9744\n",
      "Epoch 629/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0673 - accuracy: 0.9797 - val_loss: 0.1128 - val_accuracy: 0.9692\n",
      "Epoch 630/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0629 - accuracy: 0.9723 - val_loss: 0.1129 - val_accuracy: 0.9744\n",
      "Epoch 631/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0696 - accuracy: 0.9746 - val_loss: 0.1166 - val_accuracy: 0.9744\n",
      "Epoch 632/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0728 - accuracy: 0.9768 - val_loss: 0.1100 - val_accuracy: 0.9692\n",
      "Epoch 633/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0619 - accuracy: 0.9732 - val_loss: 0.1101 - val_accuracy: 0.9692\n",
      "Epoch 634/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0695 - accuracy: 0.9744 - val_loss: 0.1137 - val_accuracy: 0.9744\n",
      "Epoch 635/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0649 - accuracy: 0.9766 - val_loss: 0.1105 - val_accuracy: 0.9692\n",
      "Epoch 636/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0621 - accuracy: 0.9723 - val_loss: 0.1100 - val_accuracy: 0.9692\n",
      "Epoch 637/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0664 - accuracy: 0.9719 - val_loss: 0.1144 - val_accuracy: 0.9744\n",
      "Epoch 638/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0699 - accuracy: 0.9775 - val_loss: 0.1091 - val_accuracy: 0.9692\n",
      "Epoch 639/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0661 - accuracy: 0.9729 - val_loss: 0.1092 - val_accuracy: 0.9692\n",
      "Epoch 640/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0656 - accuracy: 0.9732 - val_loss: 0.1104 - val_accuracy: 0.9744\n",
      "Epoch 641/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0680 - accuracy: 0.9783 - val_loss: 0.1135 - val_accuracy: 0.9744\n",
      "Epoch 642/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0631 - accuracy: 0.9730 - val_loss: 0.1109 - val_accuracy: 0.9744\n",
      "Epoch 643/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0583 - accuracy: 0.9749 - val_loss: 0.1129 - val_accuracy: 0.9744\n",
      "Epoch 644/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0666 - accuracy: 0.9783 - val_loss: 0.1110 - val_accuracy: 0.9744\n",
      "Epoch 645/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0666 - accuracy: 0.9781 - val_loss: 0.1103 - val_accuracy: 0.9692\n",
      "Epoch 646/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0676 - accuracy: 0.9714 - val_loss: 0.1108 - val_accuracy: 0.9692\n",
      "Epoch 647/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0622 - accuracy: 0.9758 - val_loss: 0.1137 - val_accuracy: 0.9744\n",
      "Epoch 648/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0622 - accuracy: 0.9803 - val_loss: 0.1129 - val_accuracy: 0.9744\n",
      "Epoch 649/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0672 - accuracy: 0.9758 - val_loss: 0.1120 - val_accuracy: 0.9692\n",
      "Epoch 650/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0701 - accuracy: 0.9722 - val_loss: 0.1119 - val_accuracy: 0.9744\n",
      "Epoch 651/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0662 - accuracy: 0.9759 - val_loss: 0.1111 - val_accuracy: 0.9744\n",
      "Epoch 652/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0644 - accuracy: 0.9788 - val_loss: 0.1115 - val_accuracy: 0.9744\n",
      "Epoch 653/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0597 - accuracy: 0.9797 - val_loss: 0.1104 - val_accuracy: 0.9744\n",
      "Epoch 654/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0598 - accuracy: 0.9769 - val_loss: 0.1104 - val_accuracy: 0.9692\n",
      "Epoch 655/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0693 - accuracy: 0.9755 - val_loss: 0.1125 - val_accuracy: 0.9744\n",
      "Epoch 656/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0622 - accuracy: 0.9783 - val_loss: 0.1101 - val_accuracy: 0.9692\n",
      "Epoch 657/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0645 - accuracy: 0.9734 - val_loss: 0.1104 - val_accuracy: 0.9692\n",
      "Epoch 658/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0603 - accuracy: 0.9775 - val_loss: 0.1125 - val_accuracy: 0.9744\n",
      "Epoch 659/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0646 - accuracy: 0.9797 - val_loss: 0.1119 - val_accuracy: 0.9744\n",
      "Epoch 660/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0637 - accuracy: 0.9786 - val_loss: 0.1119 - val_accuracy: 0.9692\n",
      "Epoch 661/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0609 - accuracy: 0.9779 - val_loss: 0.1160 - val_accuracy: 0.9744\n",
      "Epoch 662/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0597 - accuracy: 0.9788 - val_loss: 0.1124 - val_accuracy: 0.9744\n",
      "Epoch 663/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0657 - accuracy: 0.9756 - val_loss: 0.1123 - val_accuracy: 0.9692\n",
      "Epoch 664/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0674 - accuracy: 0.9727 - val_loss: 0.1118 - val_accuracy: 0.9744\n",
      "Epoch 665/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0639 - accuracy: 0.9795 - val_loss: 0.1101 - val_accuracy: 0.9692\n",
      "Epoch 666/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0657 - accuracy: 0.9729 - val_loss: 0.1132 - val_accuracy: 0.9692\n",
      "Epoch 667/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0642 - accuracy: 0.9723 - val_loss: 0.1114 - val_accuracy: 0.9692\n",
      "Epoch 668/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0646 - accuracy: 0.9758 - val_loss: 0.1186 - val_accuracy: 0.9744\n",
      "Epoch 669/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0658 - accuracy: 0.9783 - val_loss: 0.1116 - val_accuracy: 0.9744\n",
      "Epoch 670/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0609 - accuracy: 0.9756 - val_loss: 0.1116 - val_accuracy: 0.9692\n",
      "Epoch 671/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0618 - accuracy: 0.9764 - val_loss: 0.1143 - val_accuracy: 0.9744\n",
      "Epoch 672/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0578 - accuracy: 0.9830 - val_loss: 0.1120 - val_accuracy: 0.9744\n",
      "Epoch 673/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0641 - accuracy: 0.9766 - val_loss: 0.1131 - val_accuracy: 0.9692\n",
      "Epoch 674/2000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0706 - accuracy: 0.9692 - val_loss: 0.1125 - val_accuracy: 0.9744\n",
      "Epoch 675/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0658 - accuracy: 0.9807 - val_loss: 0.1131 - val_accuracy: 0.9744\n",
      "Epoch 676/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0609 - accuracy: 0.9762 - val_loss: 0.1111 - val_accuracy: 0.9692\n",
      "Epoch 677/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0646 - accuracy: 0.9749 - val_loss: 0.1121 - val_accuracy: 0.9744\n",
      "Epoch 678/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0597 - accuracy: 0.9832 - val_loss: 0.1135 - val_accuracy: 0.9744\n",
      "Epoch 679/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0651 - accuracy: 0.9775 - val_loss: 0.1112 - val_accuracy: 0.9692\n",
      "Epoch 680/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0595 - accuracy: 0.9727 - val_loss: 0.1112 - val_accuracy: 0.9692\n",
      "Epoch 681/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0668 - accuracy: 0.9721 - val_loss: 0.1100 - val_accuracy: 0.9744\n",
      "Epoch 682/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0630 - accuracy: 0.9775 - val_loss: 0.1097 - val_accuracy: 0.9744\n",
      "Epoch 683/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0616 - accuracy: 0.9797 - val_loss: 0.1098 - val_accuracy: 0.9744\n",
      "Epoch 684/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0604 - accuracy: 0.9788 - val_loss: 0.1100 - val_accuracy: 0.9744\n",
      "Epoch 685/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0554 - accuracy: 0.9810 - val_loss: 0.1108 - val_accuracy: 0.9744\n",
      "Epoch 686/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 0.1099 - val_accuracy: 0.9692\n",
      "Epoch 687/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0621 - accuracy: 0.9758 - val_loss: 0.1098 - val_accuracy: 0.9692\n",
      "Epoch 688/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0613 - accuracy: 0.9716 - val_loss: 0.1105 - val_accuracy: 0.9744\n",
      "Epoch 689/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0640 - accuracy: 0.9770 - val_loss: 0.1109 - val_accuracy: 0.9744\n",
      "Epoch 690/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0642 - accuracy: 0.9790 - val_loss: 0.1112 - val_accuracy: 0.9744\n",
      "Epoch 691/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0619 - accuracy: 0.9781 - val_loss: 0.1113 - val_accuracy: 0.9692\n",
      "Epoch 692/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0634 - accuracy: 0.9736 - val_loss: 0.1123 - val_accuracy: 0.9744\n",
      "Epoch 693/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0592 - accuracy: 0.9779 - val_loss: 0.1137 - val_accuracy: 0.9744\n",
      "Epoch 694/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0614 - accuracy: 0.9783 - val_loss: 0.1115 - val_accuracy: 0.9692\n",
      "Epoch 695/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0638 - accuracy: 0.9775 - val_loss: 0.1100 - val_accuracy: 0.9692\n",
      "Epoch 696/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0637 - accuracy: 0.9736 - val_loss: 0.1096 - val_accuracy: 0.9692\n",
      "Epoch 697/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0615 - accuracy: 0.9788 - val_loss: 0.1118 - val_accuracy: 0.9744\n",
      "Epoch 698/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0658 - accuracy: 0.9777 - val_loss: 0.1098 - val_accuracy: 0.9744\n",
      "Epoch 699/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0615 - accuracy: 0.9756 - val_loss: 0.1101 - val_accuracy: 0.9692\n",
      "Epoch 700/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0597 - accuracy: 0.9753 - val_loss: 0.1123 - val_accuracy: 0.9744\n",
      "Epoch 701/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0606 - accuracy: 0.9792 - val_loss: 0.1126 - val_accuracy: 0.9744\n",
      "Epoch 702/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0617 - accuracy: 0.9818 - val_loss: 0.1116 - val_accuracy: 0.9692\n",
      "Epoch 703/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0618 - accuracy: 0.9761 - val_loss: 0.1111 - val_accuracy: 0.9744\n",
      "Epoch 704/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0617 - accuracy: 0.9785 - val_loss: 0.1091 - val_accuracy: 0.9692\n",
      "Epoch 705/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0546 - accuracy: 0.9801 - val_loss: 0.1085 - val_accuracy: 0.9744\n",
      "Epoch 706/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0641 - accuracy: 0.9785 - val_loss: 0.1090 - val_accuracy: 0.9744\n",
      "Epoch 707/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0629 - accuracy: 0.9768 - val_loss: 0.1063 - val_accuracy: 0.9692\n",
      "Epoch 708/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0638 - accuracy: 0.9721 - val_loss: 0.1061 - val_accuracy: 0.9692\n",
      "Epoch 709/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0599 - accuracy: 0.9751 - val_loss: 0.1122 - val_accuracy: 0.9744\n",
      "Epoch 710/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0615 - accuracy: 0.9812 - val_loss: 0.1073 - val_accuracy: 0.9692\n",
      "Epoch 711/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0634 - accuracy: 0.9790 - val_loss: 0.1087 - val_accuracy: 0.9692\n",
      "Epoch 712/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0619 - accuracy: 0.9736 - val_loss: 0.1092 - val_accuracy: 0.9744\n",
      "Epoch 713/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0610 - accuracy: 0.9790 - val_loss: 0.1088 - val_accuracy: 0.9744\n",
      "Epoch 714/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0541 - accuracy: 0.9782 - val_loss: 0.1060 - val_accuracy: 0.9744\n",
      "Epoch 715/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0575 - accuracy: 0.9798 - val_loss: 0.1082 - val_accuracy: 0.9744\n",
      "Epoch 716/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0618 - accuracy: 0.9790 - val_loss: 0.1063 - val_accuracy: 0.9744\n",
      "Epoch 717/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0625 - accuracy: 0.9749 - val_loss: 0.1059 - val_accuracy: 0.9692\n",
      "Epoch 718/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0603 - accuracy: 0.9781 - val_loss: 0.1074 - val_accuracy: 0.9744\n",
      "Epoch 719/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0588 - accuracy: 0.9781 - val_loss: 0.1073 - val_accuracy: 0.9692\n",
      "Epoch 720/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0575 - accuracy: 0.9803 - val_loss: 0.1085 - val_accuracy: 0.9744\n",
      "Epoch 721/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0583 - accuracy: 0.9775 - val_loss: 0.1088 - val_accuracy: 0.9692\n",
      "Epoch 722/2000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.0567 - accuracy: 0.9779 - val_loss: 0.1089 - val_accuracy: 0.9692\n",
      "Epoch 723/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0594 - accuracy: 0.9722 - val_loss: 0.1102 - val_accuracy: 0.9744\n",
      "Epoch 724/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0583 - accuracy: 0.9775 - val_loss: 0.1079 - val_accuracy: 0.9744\n",
      "Epoch 725/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0542 - accuracy: 0.9825 - val_loss: 0.1051 - val_accuracy: 0.9692\n",
      "Epoch 726/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0569 - accuracy: 0.9762 - val_loss: 0.1049 - val_accuracy: 0.9692\n",
      "Epoch 727/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0608 - accuracy: 0.9758 - val_loss: 0.1054 - val_accuracy: 0.9692\n",
      "Epoch 728/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0597 - accuracy: 0.9797 - val_loss: 0.1056 - val_accuracy: 0.9692\n",
      "Epoch 729/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0582 - accuracy: 0.9776 - val_loss: 0.1054 - val_accuracy: 0.9692\n",
      "Epoch 730/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0578 - accuracy: 0.9771 - val_loss: 0.1089 - val_accuracy: 0.9744\n",
      "Epoch 731/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0618 - accuracy: 0.9759 - val_loss: 0.1075 - val_accuracy: 0.9692\n",
      "Epoch 732/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0632 - accuracy: 0.9761 - val_loss: 0.1099 - val_accuracy: 0.9744\n",
      "Epoch 733/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0557 - accuracy: 0.9827 - val_loss: 0.1093 - val_accuracy: 0.9692\n",
      "Epoch 734/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0562 - accuracy: 0.9769 - val_loss: 0.1094 - val_accuracy: 0.9692\n",
      "Epoch 735/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0628 - accuracy: 0.9731 - val_loss: 0.1123 - val_accuracy: 0.9744\n",
      "Epoch 736/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0584 - accuracy: 0.9817 - val_loss: 0.1091 - val_accuracy: 0.9744\n",
      "Epoch 737/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0619 - accuracy: 0.9792 - val_loss: 0.1104 - val_accuracy: 0.9692\n",
      "Epoch 738/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0606 - accuracy: 0.9727 - val_loss: 0.1094 - val_accuracy: 0.9744\n",
      "Epoch 739/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0549 - accuracy: 0.9818 - val_loss: 0.1119 - val_accuracy: 0.9744\n",
      "Epoch 740/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0558 - accuracy: 0.9817 - val_loss: 0.1107 - val_accuracy: 0.9692\n",
      "Epoch 741/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0589 - accuracy: 0.9749 - val_loss: 0.1098 - val_accuracy: 0.9692\n",
      "Epoch 742/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0624 - accuracy: 0.9722 - val_loss: 0.1168 - val_accuracy: 0.9744\n",
      "Epoch 743/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0636 - accuracy: 0.9851 - val_loss: 0.1078 - val_accuracy: 0.9692\n",
      "Epoch 744/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0557 - accuracy: 0.9742 - val_loss: 0.1076 - val_accuracy: 0.9692\n",
      "Epoch 745/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0580 - accuracy: 0.9738 - val_loss: 0.1101 - val_accuracy: 0.9744\n",
      "Epoch 746/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0618 - accuracy: 0.9800 - val_loss: 0.1080 - val_accuracy: 0.9692\n",
      "Epoch 747/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0609 - accuracy: 0.9798 - val_loss: 0.1089 - val_accuracy: 0.9692\n",
      "Epoch 748/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0634 - accuracy: 0.9722 - val_loss: 0.1088 - val_accuracy: 0.9692\n",
      "Epoch 749/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0563 - accuracy: 0.9803 - val_loss: 0.1100 - val_accuracy: 0.9744\n",
      "Epoch 750/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0606 - accuracy: 0.9783 - val_loss: 0.1099 - val_accuracy: 0.9744\n",
      "Epoch 751/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0592 - accuracy: 0.9805 - val_loss: 0.1097 - val_accuracy: 0.9692\n",
      "Epoch 752/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0587 - accuracy: 0.9792 - val_loss: 0.1099 - val_accuracy: 0.9692\n",
      "Epoch 753/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0545 - accuracy: 0.9791 - val_loss: 0.1107 - val_accuracy: 0.9744\n",
      "Epoch 754/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0552 - accuracy: 0.9805 - val_loss: 0.1138 - val_accuracy: 0.9744\n",
      "Epoch 755/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0560 - accuracy: 0.9818 - val_loss: 0.1079 - val_accuracy: 0.9692\n",
      "Epoch 756/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0519 - accuracy: 0.9801 - val_loss: 0.1072 - val_accuracy: 0.9692\n",
      "Epoch 757/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0525 - accuracy: 0.9781 - val_loss: 0.1084 - val_accuracy: 0.9744\n",
      "Epoch 758/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0572 - accuracy: 0.9790 - val_loss: 0.1060 - val_accuracy: 0.9692\n",
      "Epoch 759/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0611 - accuracy: 0.9727 - val_loss: 0.1062 - val_accuracy: 0.9692\n",
      "Epoch 760/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0565 - accuracy: 0.9736 - val_loss: 0.1097 - val_accuracy: 0.9744\n",
      "Epoch 761/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0601 - accuracy: 0.9775 - val_loss: 0.1085 - val_accuracy: 0.9692\n",
      "Epoch 762/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0577 - accuracy: 0.9784 - val_loss: 0.1088 - val_accuracy: 0.9692\n",
      "Epoch 763/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0588 - accuracy: 0.9783 - val_loss: 0.1114 - val_accuracy: 0.9744\n",
      "Epoch 764/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0601 - accuracy: 0.9798 - val_loss: 0.1083 - val_accuracy: 0.9692\n",
      "Epoch 765/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0522 - accuracy: 0.9747 - val_loss: 0.1082 - val_accuracy: 0.9692\n",
      "Epoch 766/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0535 - accuracy: 0.9818 - val_loss: 0.1101 - val_accuracy: 0.9744\n",
      "Epoch 767/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0559 - accuracy: 0.9818 - val_loss: 0.1069 - val_accuracy: 0.9692\n",
      "Epoch 768/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 0.1057 - val_accuracy: 0.9692\n",
      "Epoch 769/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0508 - accuracy: 0.9771 - val_loss: 0.1056 - val_accuracy: 0.9692\n",
      "Epoch 770/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0562 - accuracy: 0.9792 - val_loss: 0.1082 - val_accuracy: 0.9744\n",
      "Epoch 771/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0611 - accuracy: 0.9798 - val_loss: 0.1056 - val_accuracy: 0.9692\n",
      "Epoch 772/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0628 - accuracy: 0.9759 - val_loss: 0.1089 - val_accuracy: 0.9692\n",
      "Epoch 773/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0604 - accuracy: 0.9768 - val_loss: 0.1116 - val_accuracy: 0.9744\n",
      "Epoch 774/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0598 - accuracy: 0.9807 - val_loss: 0.1094 - val_accuracy: 0.9744\n",
      "Epoch 775/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.1046 - val_accuracy: 0.9692\n",
      "Epoch 776/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0570 - accuracy: 0.9722 - val_loss: 0.1055 - val_accuracy: 0.9692\n",
      "Epoch 777/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0510 - accuracy: 0.9797 - val_loss: 0.1077 - val_accuracy: 0.9744\n",
      "Epoch 778/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0539 - accuracy: 0.9797 - val_loss: 0.1047 - val_accuracy: 0.9692\n",
      "Epoch 779/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0576 - accuracy: 0.9795 - val_loss: 0.1054 - val_accuracy: 0.9692\n",
      "Epoch 780/2000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0505 - accuracy: 0.9776 - val_loss: 0.1094 - val_accuracy: 0.9744\n",
      "Epoch 781/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0553 - accuracy: 0.9820 - val_loss: 0.1090 - val_accuracy: 0.9744\n",
      "Epoch 782/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0578 - accuracy: 0.9790 - val_loss: 0.1053 - val_accuracy: 0.9692\n",
      "Epoch 783/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0612 - accuracy: 0.9727 - val_loss: 0.1050 - val_accuracy: 0.9692\n",
      "Epoch 784/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0591 - accuracy: 0.9761 - val_loss: 0.1129 - val_accuracy: 0.9744\n",
      "Epoch 785/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0611 - accuracy: 0.9829 - val_loss: 0.1070 - val_accuracy: 0.9692\n",
      "Epoch 786/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0532 - accuracy: 0.9815 - val_loss: 0.1072 - val_accuracy: 0.9692\n",
      "Epoch 787/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0557 - accuracy: 0.9751 - val_loss: 0.1161 - val_accuracy: 0.9641\n",
      "Epoch 788/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0553 - accuracy: 0.9856 - val_loss: 0.1056 - val_accuracy: 0.9692\n",
      "Epoch 789/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0558 - accuracy: 0.9741 - val_loss: 0.1063 - val_accuracy: 0.9692\n",
      "Epoch 790/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0659 - accuracy: 0.9739 - val_loss: 0.1077 - val_accuracy: 0.9744\n",
      "Epoch 791/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0599 - accuracy: 0.9822 - val_loss: 0.1052 - val_accuracy: 0.9744\n",
      "Epoch 792/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0587 - accuracy: 0.9814 - val_loss: 0.1027 - val_accuracy: 0.9692\n",
      "Epoch 793/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0616 - accuracy: 0.9714 - val_loss: 0.1024 - val_accuracy: 0.9692\n",
      "Epoch 794/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0538 - accuracy: 0.9779 - val_loss: 0.1093 - val_accuracy: 0.9744\n",
      "Epoch 795/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0553 - accuracy: 0.9851 - val_loss: 0.1045 - val_accuracy: 0.9692\n",
      "Epoch 796/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0562 - accuracy: 0.9762 - val_loss: 0.1056 - val_accuracy: 0.9692\n",
      "Epoch 797/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0595 - accuracy: 0.9744 - val_loss: 0.1134 - val_accuracy: 0.9744\n",
      "Epoch 798/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0538 - accuracy: 0.9801 - val_loss: 0.1081 - val_accuracy: 0.9692\n",
      "Epoch 799/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0563 - accuracy: 0.9781 - val_loss: 0.1070 - val_accuracy: 0.9692\n",
      "Epoch 800/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0559 - accuracy: 0.9805 - val_loss: 0.1109 - val_accuracy: 0.9744\n",
      "Epoch 801/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0601 - accuracy: 0.9792 - val_loss: 0.1074 - val_accuracy: 0.9744\n",
      "Epoch 802/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0557 - accuracy: 0.9818 - val_loss: 0.1063 - val_accuracy: 0.9692\n",
      "Epoch 803/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0569 - accuracy: 0.9729 - val_loss: 0.1068 - val_accuracy: 0.9692\n",
      "Epoch 804/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0517 - accuracy: 0.9758 - val_loss: 0.1124 - val_accuracy: 0.9744\n",
      "Epoch 805/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0593 - accuracy: 0.9837 - val_loss: 0.1067 - val_accuracy: 0.9692\n",
      "Epoch 806/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0536 - accuracy: 0.9798 - val_loss: 0.1084 - val_accuracy: 0.9692\n",
      "Epoch 807/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0593 - accuracy: 0.9759 - val_loss: 0.1054 - val_accuracy: 0.9692\n",
      "Epoch 808/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0575 - accuracy: 0.9807 - val_loss: 0.1128 - val_accuracy: 0.9641\n",
      "Epoch 809/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0625 - accuracy: 0.9797 - val_loss: 0.1031 - val_accuracy: 0.9692\n",
      "Epoch 810/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0558 - accuracy: 0.9738 - val_loss: 0.1031 - val_accuracy: 0.9692\n",
      "Epoch 811/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0576 - accuracy: 0.9785 - val_loss: 0.1070 - val_accuracy: 0.9744\n",
      "Epoch 812/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0566 - accuracy: 0.9822 - val_loss: 0.1054 - val_accuracy: 0.9744\n",
      "Epoch 813/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0523 - accuracy: 0.9784 - val_loss: 0.1053 - val_accuracy: 0.9692\n",
      "Epoch 814/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0582 - accuracy: 0.9778 - val_loss: 0.1105 - val_accuracy: 0.9744\n",
      "Epoch 815/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0575 - accuracy: 0.9836 - val_loss: 0.1072 - val_accuracy: 0.9692\n",
      "Epoch 816/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0473 - accuracy: 0.9813 - val_loss: 0.1084 - val_accuracy: 0.9692\n",
      "Epoch 817/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0539 - accuracy: 0.9734 - val_loss: 0.1089 - val_accuracy: 0.9744\n",
      "Epoch 818/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0538 - accuracy: 0.9820 - val_loss: 0.1064 - val_accuracy: 0.9744\n",
      "Epoch 819/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0584 - accuracy: 0.9800 - val_loss: 0.1050 - val_accuracy: 0.9692\n",
      "Epoch 820/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0549 - accuracy: 0.9814 - val_loss: 0.1064 - val_accuracy: 0.9744\n",
      "Epoch 821/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0555 - accuracy: 0.9798 - val_loss: 0.1070 - val_accuracy: 0.9744\n",
      "Epoch 822/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0559 - accuracy: 0.9812 - val_loss: 0.1062 - val_accuracy: 0.9744\n",
      "Epoch 823/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0570 - accuracy: 0.9814 - val_loss: 0.1072 - val_accuracy: 0.9744\n",
      "Epoch 824/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0524 - accuracy: 0.9827 - val_loss: 0.1070 - val_accuracy: 0.9692\n",
      "Epoch 825/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0558 - accuracy: 0.9807 - val_loss: 0.1074 - val_accuracy: 0.9692\n",
      "Epoch 826/2000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.0559 - accuracy: 0.9805 - val_loss: 0.1082 - val_accuracy: 0.9692\n",
      "Epoch 827/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0464 - accuracy: 0.9832 - val_loss: 0.1091 - val_accuracy: 0.9692\n",
      "Epoch 828/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0567 - accuracy: 0.9807 - val_loss: 0.1097 - val_accuracy: 0.9692\n",
      "Epoch 829/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0528 - accuracy: 0.9820 - val_loss: 0.1099 - val_accuracy: 0.9692\n",
      "Epoch 830/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0529 - accuracy: 0.9827 - val_loss: 0.1078 - val_accuracy: 0.9692\n",
      "Epoch 831/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0562 - accuracy: 0.9795 - val_loss: 0.1072 - val_accuracy: 0.9692\n",
      "Epoch 832/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0452 - accuracy: 0.9823 - val_loss: 0.1131 - val_accuracy: 0.9744\n",
      "Epoch 833/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0621 - accuracy: 0.9817 - val_loss: 0.1086 - val_accuracy: 0.9744\n",
      "Epoch 834/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0548 - accuracy: 0.9773 - val_loss: 0.1078 - val_accuracy: 0.9692\n",
      "Epoch 835/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0571 - accuracy: 0.9764 - val_loss: 0.1105 - val_accuracy: 0.9744\n",
      "Epoch 836/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0498 - accuracy: 0.9818 - val_loss: 0.1146 - val_accuracy: 0.9692\n",
      "Epoch 837/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0586 - accuracy: 0.9822 - val_loss: 0.1101 - val_accuracy: 0.9692\n",
      "Epoch 838/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0592 - accuracy: 0.9758 - val_loss: 0.1093 - val_accuracy: 0.9692\n",
      "Epoch 839/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0552 - accuracy: 0.9827 - val_loss: 0.1163 - val_accuracy: 0.9641\n",
      "Epoch 840/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0569 - accuracy: 0.9844 - val_loss: 0.1089 - val_accuracy: 0.9692\n",
      "Epoch 841/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0577 - accuracy: 0.9752 - val_loss: 0.1073 - val_accuracy: 0.9692\n",
      "Epoch 842/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0595 - accuracy: 0.9741 - val_loss: 0.1277 - val_accuracy: 0.9692\n",
      "Epoch 843/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0684 - accuracy: 0.9844 - val_loss: 0.1085 - val_accuracy: 0.9692\n",
      "Epoch 844/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0539 - accuracy: 0.9786 - val_loss: 0.1120 - val_accuracy: 0.9692\n",
      "Epoch 845/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0510 - accuracy: 0.9786 - val_loss: 0.1150 - val_accuracy: 0.9744\n",
      "Epoch 846/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0528 - accuracy: 0.9844 - val_loss: 0.1149 - val_accuracy: 0.9692\n",
      "Epoch 847/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0580 - accuracy: 0.9831 - val_loss: 0.1079 - val_accuracy: 0.9692\n",
      "Epoch 848/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0580 - accuracy: 0.9744 - val_loss: 0.1060 - val_accuracy: 0.9692\n",
      "Epoch 849/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0558 - accuracy: 0.9814 - val_loss: 0.1123 - val_accuracy: 0.9744\n",
      "Epoch 850/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0543 - accuracy: 0.9829 - val_loss: 0.1053 - val_accuracy: 0.9692\n",
      "Epoch 851/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0496 - accuracy: 0.9823 - val_loss: 0.1054 - val_accuracy: 0.9692\n",
      "Epoch 852/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0489 - accuracy: 0.9803 - val_loss: 0.1090 - val_accuracy: 0.9744\n",
      "Epoch 853/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0541 - accuracy: 0.9842 - val_loss: 0.1071 - val_accuracy: 0.9744\n",
      "Epoch 854/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0536 - accuracy: 0.9818 - val_loss: 0.1055 - val_accuracy: 0.9692\n",
      "Epoch 855/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0541 - accuracy: 0.9759 - val_loss: 0.1059 - val_accuracy: 0.9692\n",
      "Epoch 856/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0522 - accuracy: 0.9792 - val_loss: 0.1060 - val_accuracy: 0.9692\n",
      "Epoch 857/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0463 - accuracy: 0.9825 - val_loss: 0.1063 - val_accuracy: 0.9744\n",
      "Epoch 858/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0516 - accuracy: 0.9820 - val_loss: 0.1058 - val_accuracy: 0.9744\n",
      "Epoch 859/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0544 - accuracy: 0.9807 - val_loss: 0.1043 - val_accuracy: 0.9692\n",
      "Epoch 860/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0483 - accuracy: 0.9840 - val_loss: 0.1040 - val_accuracy: 0.9692\n",
      "Epoch 861/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0546 - accuracy: 0.9773 - val_loss: 0.1042 - val_accuracy: 0.9692\n",
      "Epoch 862/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0517 - accuracy: 0.9818 - val_loss: 0.1045 - val_accuracy: 0.9692\n",
      "Epoch 863/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0530 - accuracy: 0.9798 - val_loss: 0.1049 - val_accuracy: 0.9692\n",
      "Epoch 864/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0498 - accuracy: 0.9827 - val_loss: 0.1064 - val_accuracy: 0.9744\n",
      "Epoch 865/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0514 - accuracy: 0.9829 - val_loss: 0.1070 - val_accuracy: 0.9744\n",
      "Epoch 866/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0537 - accuracy: 0.9814 - val_loss: 0.1075 - val_accuracy: 0.9692\n",
      "Epoch 867/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0559 - accuracy: 0.9794 - val_loss: 0.1077 - val_accuracy: 0.9692\n",
      "Epoch 868/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0553 - accuracy: 0.9800 - val_loss: 0.1076 - val_accuracy: 0.9692\n",
      "Epoch 869/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0499 - accuracy: 0.9814 - val_loss: 0.1083 - val_accuracy: 0.9744\n",
      "Epoch 870/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0513 - accuracy: 0.9829 - val_loss: 0.1068 - val_accuracy: 0.9744\n",
      "Epoch 871/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0509 - accuracy: 0.9844 - val_loss: 0.1041 - val_accuracy: 0.9692\n",
      "Epoch 872/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0554 - accuracy: 0.9792 - val_loss: 0.1045 - val_accuracy: 0.9692\n",
      "Epoch 873/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0489 - accuracy: 0.9814 - val_loss: 0.1037 - val_accuracy: 0.9692\n",
      "Epoch 874/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0500 - accuracy: 0.9805 - val_loss: 0.1034 - val_accuracy: 0.9692\n",
      "Epoch 875/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0556 - accuracy: 0.9775 - val_loss: 0.1037 - val_accuracy: 0.9692\n",
      "Epoch 876/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0564 - accuracy: 0.9785 - val_loss: 0.1100 - val_accuracy: 0.9692\n",
      "Epoch 877/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0528 - accuracy: 0.9836 - val_loss: 0.1045 - val_accuracy: 0.9692\n",
      "Epoch 878/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0481 - accuracy: 0.9803 - val_loss: 0.1045 - val_accuracy: 0.9692\n",
      "Epoch 879/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0540 - accuracy: 0.9783 - val_loss: 0.1057 - val_accuracy: 0.9744\n",
      "Epoch 880/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0507 - accuracy: 0.9842 - val_loss: 0.1056 - val_accuracy: 0.9744\n",
      "Epoch 881/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0482 - accuracy: 0.9836 - val_loss: 0.1038 - val_accuracy: 0.9692\n",
      "Epoch 882/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0487 - accuracy: 0.9779 - val_loss: 0.1050 - val_accuracy: 0.9692\n",
      "Epoch 883/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0496 - accuracy: 0.9851 - val_loss: 0.1083 - val_accuracy: 0.9744\n",
      "Epoch 884/2000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0527 - accuracy: 0.9844 - val_loss: 0.1064 - val_accuracy: 0.9692\n",
      "Epoch 885/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0540 - accuracy: 0.9795 - val_loss: 0.1056 - val_accuracy: 0.9692\n",
      "Epoch 886/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0597 - accuracy: 0.9722 - val_loss: 0.1111 - val_accuracy: 0.9692\n",
      "Epoch 887/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0558 - accuracy: 0.9837 - val_loss: 0.1029 - val_accuracy: 0.9692\n",
      "Epoch 888/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0503 - accuracy: 0.9764 - val_loss: 0.1025 - val_accuracy: 0.9692\n",
      "Epoch 889/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0497 - accuracy: 0.9822 - val_loss: 0.1105 - val_accuracy: 0.9692\n",
      "Epoch 890/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0540 - accuracy: 0.9851 - val_loss: 0.1052 - val_accuracy: 0.9744\n",
      "Epoch 891/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0515 - accuracy: 0.9837 - val_loss: 0.1028 - val_accuracy: 0.9692\n",
      "Epoch 892/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0545 - accuracy: 0.9777 - val_loss: 0.1030 - val_accuracy: 0.9692\n",
      "Epoch 893/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0507 - accuracy: 0.9814 - val_loss: 0.1059 - val_accuracy: 0.9744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f54417ae390>"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 실행\n",
    "model.fit(X, Y, batch_size=500, epochs=2000, validation_split=.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbMVw8PaGC3J",
    "outputId": "d8d027d8-70d9-4a9d-95da-2f5991ae860e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9815\n",
      "\n",
      " Accuracy : 0.9815\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(\"\\n Accuracy : %.4f\" %(model.evaluate(X, Y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMQXnCo5Ea6X"
   },
   "source": [
    "# 와인종류 예측하기  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73b-OBYQHH-P"
   },
   "source": [
    "## 패키지 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "3_nbQwNAHNwb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# 시드값 설정\n",
    "seed = 50\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8j_GsVEcHsos"
   },
   "source": [
    "## 데이터세트 로드 및 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "N47rh40pHyYW"
   },
   "outputs": [],
   "source": [
    "df_pre  = pd.read_csv(\"/content/sample_data/wine.csv\", header = None)\n",
    "df = df_pre.sample(frac = 0.15)\n",
    "dataset = df.values\n",
    "\n",
    "X = dataset[:, 0:12]\n",
    "Y = dataset[:, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6unU5L_6IIJ5"
   },
   "source": [
    "## 모델 생성 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "FW059OAeINLu"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZhSuPWbI9fG"
   },
   "source": [
    "## 모델저장 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "JzEZ5TguJGs5"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = \"/content/sample_data/model/\"\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "  os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = MODEL_DIR+\"{epoch:02d}-{val_loss:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "wwMhOBbgJYKq"
   },
   "outputs": [],
   "source": [
    "# 모델 업데이트 저장\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss', verbose = 0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "CG_tqqa2J-p6"
   },
   "outputs": [],
   "source": [
    "# 학습 자동 중단 설정\n",
    "early_stoppng = EarlyStopping(monitor = 'val_loss',patience = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Exjt5mvAKe-3",
    "outputId": "8810d450-f525-4c6a-d29f-6df501b8ef33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5444f997b8>"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#수행\n",
    "model.fit(X, Y, validation_split=0.2, epochs=3500, batch_size=500, verbose = 0,callbacks=[checkpointer, early_stoppng])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvOnUccQK9Tq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "와인종류예측.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
