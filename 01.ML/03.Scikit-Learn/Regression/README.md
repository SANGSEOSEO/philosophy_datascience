### 회귀 알고리즘

회귀는 현대 통계학을 이루는 큰 축이며 유전적 특성을 연구한 영국의 통계학자 갈톤(Galton)이 수행한 연구에서 유래했다는 것이 일반적이다.

"부모의 키가 크더라도 자식의 키가 대를 이어 무한정 커지지 않으며 , 부모의 키가 작더라도 대를 이어 자식의 키가 무한정 작아지지 않는다"

#### 회귀 개요

* 회귀는 여러 개의 독립변수와 한 개의 종속변수 간의 상관관계를 모델링하는 기법을 통칭하며, 결정값이 주어지는 지도학습

회귀분석은 이처럼 데이터 값이 평균과 같은 일정값으로 돌아가려는 경향을 이용한 통계학 기법

아파트 가격의 결정은 방개수, 아파트 크기, 주변 학군, 근처 지하철 역 갯수등 다양한 독립변수로의 결합으로 이루어진다고 가정해보자.

그럼, 아래와 같은 수식을 생각해본다면,
$$
Y = W_1 * X_1 + W_2 * X_2 + W_3 * X_3 + .... + W_n * X_n
$$
`Y는 종속변수, 즉 아파트 가격`
$$
X_1, X_2, X_3, ....X_n 은 방 개수, 아파트 크기, 주변학군등의 독립변수
$$

$$
W_1, W_2, W_3, ....W_n은 이 독립변수의 값에 영향을 미치는 회귀계수
$$

<span style="color:red"><b>`머신러닝 회귀 예측`의 핵심은 주어진 피처와 결정 값 데이터 기반에서 학습을 통해 최적의 회귀 계수를 찾아내는 것</b></span>

#### 회귀의 유형

* 회귀는 회귀 계수의 선형/비선형 여부, 독립변수의 개수, 종속변수의 개수에 따라 여러가지 유형으로 나눌 수 있습니다. 회귀에서 가장 중요한 것은 바로 회귀계수(`coefficient`)입니다. 이 회귀계수가 `선형이냐 비선형`에 따라 선형 회귀와 비선형 회귀로 나눌 수 있습니다. 그리고 독립 변수의 갯수가 한 개인지 여러 개인지에 따라 단일회귀, 다중 회귀로 나뉩니다.

  | 독립변수 갯수      | 회귀 계수의 결합    |
  | ------------------ | ------------------- |
  | 1개 : 단일 회귀    | 선형 : 선형 회귀    |
  | 여러 개: 다중 회귀 | 비선형: 비선형 회귀 |

#### 분류와 회귀

| 분류(Classification)                                         | 회귀(Regression)                             |
| ------------------------------------------------------------ | -------------------------------------------- |
| 결과값 : category값(이산값)으로 0, 1, 2,3과 같이 불연속적인 값<br />등급, 고양이나 개냐 | 숫자값으로 연속적인 값<br />예) 비율, 점유울 |

#### 선형회귀의 종류

* 일반 선형 회귀 : 예측값과 실제 값의 `RSS(Residual Sum of Squares)`를 최소화 할 수 있도록 회귀 계수를 최적화하며, 규제(Regulation)를 적용하지 않은 모델

* 릿지(Ridge): 릿지 회귀는 선형 회귀에 L2규제를 추가한 회귀 모델

* 라쏘(Lasso) : 라쏘 회귀는 선형 회귀에 L1규제를 적용한 방식

* 엘라스틱넷(ElasticNet) : L2, L1규제를 함께 결합한 모델

* 로지스틱 회귀(Logistic Regression) : 로지스틱 회귀는 회귀라는 이름이 붙어 있지만, 사실은 분류에 사용되는 선형모델

  예) 0, 1의 값을 예측(이산) - 바이너리 분류에 효과적

  

#### 단순 선형 회귀(Simple Regression)를 통한 회귀의 이해

주택 가격이 단순히 주택의 크기로만 결정되는 단순 선형 회귀로 가정하면 다음과 같이 주택가격은 주택 크기에 대해 선형(직선 형태)의 관계로 표현 할 수 있다.

회귀는 우측의 이미지처럼 `실제값과 모델 사이의 오류값의 차이를 최소화 하는 것`을 목표로 하며, 점선 `빨간색 회귀선과 같이 오류차이가 많이 나지 않아야 함.

| <img src="https://user-images.githubusercontent.com/70785000/122632039-07c30980-d10b-11eb-950c-e0106cba710a.PNG" alt="regression_1" style="zoom:80%;" /> | <img src="https://user-images.githubusercontent.com/70785000/122632286-d0edf300-d10c-11eb-853d-5805356da673.PNG" alt="regression_2" style="zoom:80%;" /> |
| ------------------------------------------------------------ | ------------------------------------------------------------ |

<span style="color:red">`최적의 회귀 모델을 만든다는 것은 바로 전체 데이터의 잔차(오류 값)합이 최소가 되는 모델을 만든다는 의미이며, 동시에 오류 값이 최소가 될 수 있는 최적의 회귀계수를 찾는다는 의미도 된다.`</span>

