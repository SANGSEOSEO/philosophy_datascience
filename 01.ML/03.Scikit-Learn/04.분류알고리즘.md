# 분류알고리즘

분류는 학습데이터로 주어진 데이터의 피처와 레이블 값(결정 값, 클래스 값)을 머신러닝 알고리즘으로 학습해 모델을 생성하고, 이렇게 생성된 모델에 새로운 데이터 값이 주어졌을때 미지의 레이블 값을 예측하는 것.

## 대표적인 분류 알고리즘

* 베이즈통계와 생성 모델에 기반한 나이브 베이즈
* 독립변수와 종속 변수의 선형 관계성에 기반한 <span style="color:red">Logistic Regression</span>
* 데이터 균일도에 따른 규칙 기반의 결정트리
* 개별 클래스 간의 최대 분류 마진을 효과적으로 찾아주는 SVM(Support Vector Machine)
* 근접 거리를 기준으로 하는 최소 근접(Nearest Neighbor)알고리즘
* 심층 연결 기반의 신경망(Neural Network)
* 서로 다른 혹은 같은 머신러닝 알고리즘을 결합한 앙상블

### 결정트리와 앙상블

* 결정트리는 매우 쉽고 유연하게 적용될 수 있는 알고리즘.또한 데이터의 스케일링이나 정규화등의 사전 가공의 영향이 매우 적다. 하지만 예측 성능을 향상 시키지 위해 복잡한 규칙 구조를 가져야 하며, 이로 인한 과적합이 발생해 반대로 예측 성능이 저하될수도 있다는 단점이 있다.
* 앙상블은 이와 달리, 결정트리를 약한 학습기(예측 성능이 떨어지는 학습 알고리즘)로 여러개를 결합해 확률적 보완과 오류가 발생한 부분에 대한 가중치를 갱신하면서 예측 성능을 향상 시킨다.(GBM, XGBoost, LightGBM)

### 결정 트리

* 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리 기반의 분류 규칙을 만듦.

* 따라서 데이터의 어떤 기준을 바탕으로 규칙을 만들어야 가장 효율적인 분류가 될 것인가가 알고리즘의 성능을 크게 좌우.

  ![](C:\Users\서한나\Downloads\의사결정트리.PNG)

* 규칙노드로 표시된 노드는 규칙조건이 되는것이고, 리프 노드로 표시된 노드는 결정된 클래스값.그리고 새로운 규칙 조건마다 서브트리가 생성됩니다. 데이터세트에 피처가 있고 이러한 피처가 결합해 규칙 조건을 만들 때마다 규칙노드가 만들어집니다.
* 트리의 깊이가 깊을 수록 결정 트리의 예측 성능이 저하될 가능성이 존재.
* 가능하다면 적은 결정 노드로 포은 예측 정확도를 가지려면 데이터를 분류시 최대한 많은 데이터가 해당 분류에 속할 수 있도록 결정노드의 규칙이 정해져야 합니다.
* 리프노드로 결정된 노드는 정보 균일도가 높은 데이터가 모여있다고 이해하자.
* 정보 균일도 측정 계수 : 엔트로피를 이용한 정보 이득 지수와 지니계수가 있다.

#### 정보이득

* 정보이득은 <span style="color:red">엔트로피</span>라는 개념을 기반으로 함.<span style="color:red">주어진 데이터집합의 혼잡도</span>를 의미함
* 서로 다른 값이 섞여 있으면 엔트로피가 높고, 같은 값이 섞여 있으면 엔트로피가 낮습니다. 정보이득 지수는 1에서 엔트로피지수를 뺀 값.

결정트리 알고리즘은 정보이득 지수가 높거나, 지니계수가 낮은 조건을 찾아서 자식 트리노드에 걸쳐 반복적으로 분할한 뒤, 데이터 모두 특정분류에 속하게 되면 분할을 멈추고 분류를 결정함

#### 결정트리 파라미터

| 파라미터명        | 설명                                                         |
| ----------------- | ------------------------------------------------------------ |
| min_samples_split | * 노드를 분할하기 위한 최소한의 샘플 데이터 수로 과적합제어에 사용<br />* 디폴트는 2이고 작제 설정할 수록 분할되는 노드가 많아져 과적합 가능성이 커짐<br>*과적합을 제어,1로 설정할 경우 분할되는 노드가 많아져서 과적합 생김 |
| min_samples_leaf  | * 말단 노드(Leaf)가 되기 위한 최소한의 샘플 데이터 수 <br>* 과적합 제어용도.그러나 비대칭의 데이터의 경우 특정 클래스의 데이터가 극도로 작을 수 있으므로 이 경우는 작게 설정 필요. |
| max_features      | * 최적의 분할을 위해 고려할 최대 피처 갯수.디폴트는 None으로 데이터 세트의 모든 피처를 사용해 분할 수행.<br> * int형으로 지정하면 대상 피처의 개수, float형으로 지정하면 전체 피처 중 대상 피처의 퍼센트임.<br>* `sqrt`는 전체 피처 중 sqrt(전체 피처 개수)<br>* `auto`로 지정하면 `sqrt`와 동일 <br>* `log`는 전체 피처 중 log2(전체 피처갯수) 선정 <br>* `None`은 전체 피처 선정 |
| max_depths        | * 트리의 최대 깊이 <br>* 디폴트는 None.None으로 설정하면 완벽하게 클래스가 결정 값이 될때 까지 깊이를 계속 분할하거나 노드가 가지는 데이터 갯수가 min_samples_split보다 작아질때까지 계속 깊이를 증가시킴 <br>* 깊이가 깊어지면 min_samples_split설정대로 최대 분할하여 과적할 할 수 있으므로 적절한 값으로 제어 필요 |
| max_leaf_nodes    | * 말단 노드(Leaf)의 최대 갯수                                |

#### Graphviz패키지 설치

* [윈도우 버전 graphviz다운로드](https:/graphviz.gitlab.io/_pages/Download/Download_windows.html)

* 파이썬 레퍼 설치 : pip install graphviz
* 사용자 환경변수 Path에 값 : 설치경로\Graphviz2.38\bin추가
* 시스템환경변수 Path에 값 : 설치경로\Graphviz2.38\bin\dot.exe 추가 