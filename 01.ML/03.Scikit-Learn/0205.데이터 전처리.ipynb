{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 인코딩\n",
    "* Label encoding : 카테고리형 피처를 코드형 숫자값으로 변환\n",
    "* One Hot Encoding : 피처값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당하는 칼럼에만 `1`을 포함하고 나머지 컬럼에는 `0`을 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 레이블 인코딩\n",
    "* LabelEncoder클래스로 구현 : `fit()`과 `transform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값 :  [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# LabelEncoder객체를 생성한 후 ,fit()과 transform()으로 레이블 인코딩\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "\n",
    "print('인코딩 변환값 : ', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 클래스 :  ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "print('인코딩 클래스 : ', encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코딩 원본값 :  ['TV' '냉장고' '전자레인지' '컴퓨터' '선풍기' '선풍기' '믹서' '믹서']\n"
     ]
    }
   ],
   "source": [
    "print('디코딩 원본값 : ', encoder.inverse_transform([0, 1, 4, 5, 3, 3, 2, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원-핫 인코딩(One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoding \n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# 먼저 숫자값으로 변환을 위해 LabelEncoder로 변환합니다.\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "\n",
    "# 2차원 데이터로 변환합니다.\n",
    "labels = labels.reshape(-1, 1)\n",
    "\n",
    "# 원-핫 인코딩\n",
    "oh_encode = OneHotEncoder()\n",
    "oh_encode.fit(labels)\n",
    "oh_labels = oh_encode.transform(labels)\n",
    "\n",
    "print('One-Hot Encoding ')\n",
    "print(oh_labels.toarray())\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `get_dummies()`를 이용한 원-핫 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자레인지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
       "0        1         0        0         0           0         0\n",
       "1        0         1        0         0           0         0\n",
       "2        0         0        0         0           1         0\n",
       "3        0         0        0         0           0         1\n",
       "4        0         0        0         1           0         0\n",
       "5        0         0        0         1           0         0\n",
       "6        0         0        1         0           0         0\n",
       "7        0         0        1         0           0         0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'item':['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피처 스케일링과 정규화\n",
    "서로 다른 변수의 값의 범위를 일정한 수준으로 맞추는 작업을 말함.\n",
    "* 표준화 : 데이터의 피처 각각이 평균이 `0`이고 분산이 `1`인 가우시안 정규분포를 가진값으로 변환\n",
    "* 정규화 : 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해주는 개념.즉, 개별 데이터의 크기를 모두 똑같은 단위로 변경하는것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler\n",
    "* 개별 피처를 평균이 `0`이고, 분산이 `1`인 값으로 변환(가우시안 정규분포)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 평균값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature들의 분산 값\n",
      "sepal length (cm)    0.828066\n",
      "sepal width (cm)     0.435866\n",
      "petal length (cm)    1.765298\n",
      "petal width (cm)     0.762238\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트를 로딩하고 DataFrame으로 변환합니다.\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data = iris_data, columns = iris.feature_names)\n",
    "\n",
    "\n",
    "print('feature들의 평균값')\n",
    "print(iris_df.mean())\n",
    "\n",
    "print('\\nfeature들의 분산 값')\n",
    "print(iris_df.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> ['T', '__abs__', '__add__', '__and__', '__array__', '__array_finalize__', '__array_function__', '__array_interface__', '__array_prepare__', '__array_priority__', '__array_struct__', '__array_ufunc__', '__array_wrap__', '__bool__', '__class__', '__complex__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__ilshift__', '__imatmul__', '__imod__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__xor__', 'all', 'any', 'argmax', 'argmin', 'argpartition', 'argsort', 'astype', 'base', 'byteswap', 'choose', 'clip', 'compress', 'conj', 'conjugate', 'copy', 'ctypes', 'cumprod', 'cumsum', 'data', 'diagonal', 'dot', 'dtype', 'dump', 'dumps', 'fill', 'flags', 'flat', 'flatten', 'getfield', 'imag', 'item', 'itemset', 'itemsize', 'max', 'mean', 'min', 'nbytes', 'ndim', 'newbyteorder', 'nonzero', 'partition', 'prod', 'ptp', 'put', 'ravel', 'real', 'repeat', 'reshape', 'resize', 'round', 'searchsorted', 'setfield', 'setflags', 'shape', 'size', 'sort', 'squeeze', 'std', 'strides', 'sum', 'swapaxes', 'take', 'tobytes', 'tofile', 'tolist', 'tostring', 'trace', 'transpose', 'var', 'view']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#StandardScaler객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# StandardScaler로 데이터 세트 변환.\n",
    "# fit() 과 transform()호출\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "print(type(iris_scaled), dir(iris_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 평균값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature들의 분산값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#transform() 시 스케일변환된 데이터 세트가 numpy.ndarray()로 반환돼 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns = iris.feature_names)\n",
    "print('feature들의 평균값')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\nfeature들의 분산값')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모든 컬럼 값의 평균이 0에 아주 가까운 값으로 , 그리고 분산은 1에 아주 가까운 값으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler\n",
    "* 데이터 값을 `0`과 `1`사이의 범위 값으로 변환(음수값이 있으면 `-1`에서 `1`값으로 변환)\n",
    "* 데이터의 분포가 가우시안 분포가 아닐 경우에,Min, Max Scale을 적용해 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#MinMaxScaler()로 데이터 세트 변환, fit(), transform()호출\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 최솟값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "feature들의 최댓값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#transform() 시 스케일변환된 데이터 세트가 numpy.ndarray()로 반환돼 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns = iris.feature_names)\n",
    "print('feature들의 최솟값')\n",
    "print(iris_df_scaled.min())\n",
    "print('feature들의 최댓값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모든 피처에서 `0`과 `1`사이의 값으로 변환되는 스케일링이 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터와 테스트  데이터의 스케일링 변환 시 유의점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 학습 데이터는 0부터 10까지 , 테스트 데이터는 0부터 5까지 값을 가지는 데이터 세트로 생성\n",
    "# Scaler클래스의 fist(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1, 1)로 차원 변경\n",
    "train_array = np.arange(0, 11).reshape(-1, 1)\n",
    "test_array = np.arange(0,6).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터 :  [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "scaled된 train_array 데이터 :  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0 ~ 1값으로 변환\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit()하게 되면 train_array 데이터의 최솟값이 0, 최댓값이 10으로 설정\n",
    "scaler.fit(train_array)\n",
    "\n",
    "# 1 / 10 scale로 train_array 데이터 변환함, 원본 10 -> 1 로 변환됨.\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print('원본 train_array 데이터 : ', np.round(train_array.reshape(-1), 2))\n",
    "print('scaled된 train_array 데이터 : ', np.round(train_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 테스트 데이터세트를 변환하는데 ,fit()을 호출해 스케일링 기준 정보를 다시 적용한뒤 transform()를 수행해 보면..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 test_array 데이터 : [0 1 2 3 4 5]\n",
      "scaled된 test_array 데이터 : [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정됨\n",
    "scaler.fit(test_array)\n",
    "\n",
    "# 1 / 5 scale로 test_array데이터 변환함, 원본 5 -> 1로 변환.\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "# test_array의 scale변환 출력.\n",
    "print('원본 test_array 데이터 :', np.round(test_array.reshape(-1),2))\n",
    "print('scaled된 test_array 데이터 :', np.round(test_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 테스트 데이터세트를 변환하는데 ,fit()을 호출하지 않고 학습데이터로 fit()한 후 , 수행한 MinMaxScaler의 객체를 이용해 transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터 : [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "scaled된 train_array 데이터 : [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "\n",
      "원본 test_array 데이터 : [0 1 2 3 4 5]\n",
      "scaled된 test_array 데이터 : [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "print('원본 train_array 데이터 :', np.round(train_array.reshape(-1),2))\n",
    "print('scaled된 train_array 데이터 :', np.round(train_scaled.reshape(-1),2))\n",
    "\n",
    "# test_array에 scale변환을 할때 반드시 fit()을 호출하지 않고 transform()만으로 변환해야 함.\n",
    "test_scaled = scaler.transform(test_array)\n",
    "print('\\n원본 test_array 데이터 :', np.round(test_array.reshape(-1),2))\n",
    "print('scaled된 test_array 데이터 :', np.round(test_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 보는 바와 같이 학습된 스케일링 기준이 적용됨을 확인.(1 / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습데이터와 테스트 데이터의 `fit()`, `transform()`,`fit_transform()` 스케일링시 유의점."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1) 가능하다면 전체 데이터의 스케일링 변환을 적용한 뒤 학습과 테스트 데이터로 분리\n",
    "* 2) 1)이 여의치 않다면 테스트 데이터 변환 시에는 `fit()`이나 `transform()`을 적용하지 않고 학습 데이터로 이미 `fit()`된 Scaler객체를 이용해 `transform()`으로 변환"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
