{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사이킷런으로 수행하는 타이타닉 생존자 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "* 널처리\n",
    "* 불필요한 속성 제거\n",
    "* 인코딩 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 및 검증/예측 평가\n",
    "* 결정트리, 랜덤 포레스트, 로지스틱회귀\n",
    "* K Fold교차 검증\n",
    "* cross_val_score와 GridSearchCV()수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 로드 및 데이터읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글폰트 설치\n",
    "import platform\n",
    "import os\n",
    "from matplotlib import font_manager, rc\n",
    "path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "font_name = font_manager.FontProperties(fname = path).get_name()\n",
    "rc('font', family = font_name)\n",
    "\n",
    "# 마이너스 부호 표시 \n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\dataAnalysis\\\\philosophy_datascience\\\\01.ML\\\\03.Scikit-Learn'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(\"../03.Scikit-Learn/titanic/titanic_train.csv\")\n",
    "display(titanic_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼에 대한 설명\n",
    "* PassengerId : 탑승자 데이터 일련번호\n",
    "* survived : 생존여부,  0 - 사망, 1 - 생존\n",
    "* Pclass : 티켓의 선실등급, 1 - 일등석, 2 - 이등석, 3- 삼등석\n",
    "* sex : 탑승자 성별\n",
    "* name : 탑승자 이름\n",
    "* Age : 탑승자 나이\n",
    "* Sibsp : 동승한 형제자매 혹은 배우자 인원수\n",
    "* parch : 동승한 부모님또는 어린이 인원수 \n",
    "* ticket : 티켓 번호\n",
    "* fare : 요금\n",
    "* cabin : 선실번호\n",
    "* embarked : 중간 정착항구 C - Cherbourg, Q - Queenstown, S - Southhampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(titanic_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 널 컬럼에 대한 처리\n",
    "* 사이킷런은 널값을 허용하지 않으므로 널값 처리방법 결정 필요\n",
    "* Age, Cabin, Embarked 피처가 널인 갯수가 존재함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True) # 원본 데이터셋을 변경\n",
    "titanic_df['Cabin'].fillna('C', inplace=True)\n",
    "titanic_df['Embarked'].fillna('N', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬럼별 데이터 세트 널 값 갯수  PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('컬럼별 데이터 세트 널 값 갯수 ', titanic_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 세트 널 값 갯수  0\n"
     ]
    }
   ],
   "source": [
    "print('전체 데이터 세트 널 값 갯수 ', titanic_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문자열 feature들의 값 분포도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex값 분포 :\n",
      " male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      " Cabin값 분포 : \n",
      " C              687\n",
      "G6               4\n",
      "B96 B98          4\n",
      "C23 C25 C27      4\n",
      "F33              3\n",
      "              ... \n",
      "A23              1\n",
      "D6               1\n",
      "A16              1\n",
      "B73              1\n",
      "B38              1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "\n",
      " Embarked 값 분포 : \n",
      " S    644\n",
      "C    168\n",
      "Q     77\n",
      "N      2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Sex값 분포 :\\n', titanic_df['Sex'].value_counts())\n",
    "print('\\n Cabin값 분포 : \\n', titanic_df['Cabin'].value_counts())\n",
    "print('\\n Embarked 값 분포 : \\n', titanic_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    746\n",
       "B     47\n",
       "D     33\n",
       "E     32\n",
       "A     15\n",
       "F     13\n",
       "G      4\n",
       "T      1\n",
       "Name: Cabin, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cabin\n",
       "0     C\n",
       "1     C\n",
       "2     C"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cabin피처의 경우는 앞에 한 글자만 취하기로 함.\n",
    "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
    "display(titanic_df['Cabin'].value_counts())\n",
    "display(titanic_df[['Cabin']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 알고리즘 적용전 EDA\n",
    "* 어떤 유형의 승객이 생존확률이 높았는지 확인\n",
    "* 성별이 생존율에 영향을 주었는가?\n",
    "* 좌석의 등급은 생존률에 영향을 주었는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성별과 생존율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  0            81\n",
       "        1           233\n",
       "male    0           468\n",
       "        1           109\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.groupby(['Sex', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x135b0f4fd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = 'Sex', y = 'Survived', data = titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x135d1bfbe0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = 'Sex', y = 'Survived', data = titanic_df, hue='Sex')  # hue옵션은 범례"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선실등급과 생존율\n",
    "* 힘없고 가난한 자는 100년전에도 동일하게 죽어갔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass  Survived\n",
       "1       0            80\n",
       "        1           136\n",
       "2       0            97\n",
       "        1            87\n",
       "3       0           372\n",
       "        1           119\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.groupby(['Pclass', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x135d24a940>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', data=titanic_df, hue='Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성별에 따른 생존율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 age에 따라 구분 값을 변환하는 함수 설정, DataFrame의 apply lambda식에 사용\n",
    "def get_category(age):\n",
    "    cat = ''\n",
    "    if age <= -1: cat = 'Unknown'\n",
    "    elif age <= 5: cat = 'Baby'\n",
    "    elif age <= 12: cat = 'Child'\n",
    "    elif age <= 18: cat = 'Teenager'\n",
    "    elif age <= 25: cat = 'Student'\n",
    "    elif age <= 35: cat = 'Young Adult'\n",
    "    elif age <= 60: cat = 'Adult'\n",
    "    else: cat = 'Elderly'\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 막대 그래프의 크기 figure설정\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# x축의 값을 순차적으로 표시하기 위한 설정\n",
    "group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']\n",
    "\n",
    "# lambda식에 위에서 생성한 get_category()함수를 반환값으로 지정함.\n",
    "# get_category(x)는 입력값으로 'Age'칼럼값을 받아서 해당하는 cat반환\n",
    "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x:get_category(x))\n",
    "\n",
    "sns.barplot(x='Age_cat', y='Survived', data=titanic_df, hue='Sex', order=group_names)\n",
    "titanic_df.drop(labels = 'Age_cat', axis = 1, inplace = True, errors = 'ignore')  # ignore는 에러가 나더라도 무시함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 함수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문자열 카테고리 피처를 숫자형 카테고리 피처로 변환\n",
    "* 인코딩은 사이킷런의 LabelEncoder클래스 이용\n",
    "* `fit()`과 `transform()`메소드 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "\n",
       "             Ticket     Fare  Cabin  Embarked  \n",
       "0         A/5 21171   7.2500      2         3  \n",
       "1          PC 17599  71.2833      2         0  \n",
       "2  STON/O2. 3101282   7.9250      2         3  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_features(df):\n",
    "    '''\n",
    "    데이터프레임의 문자열피처를 숫자형으로 인코딩\n",
    "    '''\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le  = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head(n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna(df):\n",
    "    '''\n",
    "    NaN, Null값 처리 \n",
    "    '''\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def drop_features(df):\n",
    "    '''\n",
    "    drop the unnecessar feature for Machine Learning\n",
    "    When it fails, ignore erros message.\n",
    "    '''\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True, errors='ignire')\n",
    "    return df\n",
    "\n",
    "def format_features(df):\n",
    "    '''\n",
    "    데이터프레임의 문자열피처를 숫자형으로 인코딩\n",
    "    '''\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le  = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "def transform_features(df):\n",
    "    '''\n",
    "    main function for data preprocessing\n",
    "    '''\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본 데이터 재가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터를 재로딩, \n",
    "# 피처 데이터세트와 레이블 데이터 세트 추출.\n",
    "titanic_df = pd.read_csv(\"../03.Scikit-Learn/titanic/titanic_train.csv\")\n",
    "\n",
    "X_titanic_df = titanic_df.drop('Survived', axis = 1)  # feature data\n",
    "y_titanic_df = titanic_df['Survived']  # label data\n",
    "X_titanic_df = transform_features(X_titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터 세트 추출\n",
    "* test_size = 0.2의 의미는 훈련용 데이터세트가 전체의 80%이고 검증용이 20%라는 의미."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=.2, random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성한 ML모델에 대한 학습 , 예측, 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV  # 교차 검증 점수, 교차검증,그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 정확도 : 0.7598\n",
      "RandomForestClassifier 정확도 : 0.7542\n",
      "Regression 정확도 : 0.7430\n"
     ]
    }
   ],
   "source": [
    "# 결정트리,Random Forest, 로지스틱 회귀를 위한 사이킷런 Classifier클래스 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=2021)\n",
    "rf_clf = RandomForestClassifier(random_state=2021)\n",
    "lr_clf = LogisticRegression(random_state=2021)\n",
    "\n",
    "# DecisionTreeClassifier학습 /에측 평가 \n",
    "dt_clf.fit(X_train, y_train)\n",
    "df_pred = dt_clf.predict(X_test)\n",
    "print('DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy_score(y_test, df_pred)))\n",
    "\n",
    "# RandomForestClassifier 학습/예측/평가\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('RandomForestClassifier 정확도 : {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "\n",
    "# LogisticeRegression 학습/예측/평가\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print('Regression 정확도 : {0:.4f}'.format(accuracy_score(y_test, lr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fit in module sklearn.tree._classes:\n",
      "\n",
      "fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    Build a decision tree classifier from the training set (X, y).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "        The training input samples. Internally, it will be converted to\n",
      "        ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "        to a sparse ``csc_matrix``.\n",
      "    \n",
      "    y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "        The target values (class labels) as integers or strings.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights. If None, then samples are equally weighted. Splits\n",
      "        that would create child nodes with net zero or negative weight are\n",
      "        ignored while searching for a split in each node. Splits are also\n",
      "        ignored if they would result in any single class carrying a\n",
      "        negative weight in either child node.\n",
      "    \n",
      "    check_input : bool, default=True\n",
      "        Allow to bypass several input checking.\n",
      "        Don't use this parameter unless you know what you do.\n",
      "    \n",
      "    X_idx_sorted : array-like of shape (n_samples, n_features),                 default=None\n",
      "        The indexes of the sorted training input samples. If many tree\n",
      "        are grown on the same dataset, this allows the ordering to be\n",
      "        cached between trees. If None, the data will be sorted here.\n",
      "        Don't use this parameter unless you know what to do.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    self : DecisionTreeClassifier\n",
      "        Fitted estimator.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DecisionTreeClassifier.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function predict in module sklearn.tree._classes:\n",
      "\n",
      "predict(self, X, check_input=True)\n",
      "    Predict class or regression value for X.\n",
      "    \n",
      "    For a classification model, the predicted class for each sample in X is\n",
      "    returned. For a regression model, the predicted value based on X is\n",
      "    returned.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "        The input samples. Internally, it will be converted to\n",
      "        ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "        to a sparse ``csr_matrix``.\n",
      "    \n",
      "    check_input : bool, default=True\n",
      "        Allow to bypass several input checking.\n",
      "        Don't use this parameter unless you know what you do.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "        The predicted classes, or the predict values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DecisionTreeClassifier.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3개의 알고리즘 중 LogisticRegression이 타 알고리즘에 비해 높은 정확도를 갖지만, 아직 최적화작업을 수행하지 않았고, 데이터 양도 충분치 않기때문에 어떤 알고리즘이 성능이 더 좋다고 평가 할 수는 없다.\n",
    "* 교차검증으로 결정트리 모델을 평가해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차검증\n",
    "* KFOLD클래스 , cross_val_score(), GridSearchCV클래스 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFold 교차 검증 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function split in module sklearn.model_selection._split:\n",
      "\n",
      "split(self, X, y=None, groups=None)\n",
      "    Generate indices to split data into training and test set.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like of shape (n_samples, n_features)\n",
      "        Training data, where n_samples is the number of samples\n",
      "        and n_features is the number of features.\n",
      "    \n",
      "    y : array-like of shape (n_samples,), default=None\n",
      "        The target variable for supervised learning problems.\n",
      "    \n",
      "    groups : array-like of shape (n_samples,), default=None\n",
      "        Group labels for the samples used while splitting the dataset into\n",
      "        train/test set.\n",
      "    \n",
      "    Yields\n",
      "    ------\n",
      "    train : ndarray\n",
      "        The training set indices for that split.\n",
      "    \n",
      "    test : ndarray\n",
      "        The testing set indices for that split.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KFold.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7486\n",
      "교차 검증 1 정확도: 0.7697\n",
      "교차 검증 2 정확도: 0.7865\n",
      "교차 검증 3 정확도: 0.7697\n",
      "교차 검증 4 정확도: 0.8202\n",
      "평균 정확도: 0.7789\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score   # 정확도 \n",
    "def exec_kfold(clf, folds=5):\n",
    "    # 폴드 세트를 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위한  리스트 객체 생성.\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    cv_scores = []\n",
    "    \n",
    "    # KFold 교차 검증 수행. \n",
    "    for n_iter , (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "        X_train, X_test = X_titanic_df.iloc[train_index], X_titanic_df.iloc[test_index]\n",
    "        y_train, y_test = y_titanic_df.iloc[train_index], y_titanic_df.iloc[test_index]\n",
    "        \n",
    "        #X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        #y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "        # Classifier 학습, 예측, 정확도 계산 \n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(\"교차 검증 {0} 정확도: {1:.4f}\".format(n_iter, accuracy))     \n",
    "        cv_scores.append(accuracy)\n",
    "    \n",
    "    # 5개 fold에서의 평균 정확도 계산. \n",
    "    mean_score = np.mean(cv_scores)\n",
    "    print(\"평균 정확도: {0:.4f}\".format(mean_score)) \n",
    "# exec_kfold 호출\n",
    "exec_kfold(dt_clf , folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7821\n",
      "교차 검증 1 정확도: 0.8090\n",
      "교차 검증 2 정확도: 0.8371\n",
      "교차 검증 3 정확도: 0.7697\n",
      "교차 검증 4 정확도: 0.8596\n",
      "평균 정확도: 0.8115\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트\n",
    "exec_kfold(rf_clf , folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.8045\n",
      "교차 검증 1 정확도: 0.7809\n",
      "교차 검증 2 정확도: 0.7753\n",
      "교차 검증 3 정확도: 0.7472\n",
      "교차 검증 4 정확도: 0.8146\n",
      "평균 정확도: 0.7845\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 리그래션\n",
    "exec_kfold(lr_clf , folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_val_score() 교차 검증 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def get_cross_val_score(clfs, ftr_df, label_df, cv):\n",
    "    '''\n",
    "    Show cross validation scores\n",
    "    '''\n",
    "    for clf in clfs:\n",
    "        scores = cross_val_score(clf, ftr_df, label_df, cv = cv)\n",
    "        print(\"############# %s\" % clf) \n",
    "        for idx, accuracy in enumerate(scores):            \n",
    "            print(\"{0}번째 교차검증 정확도 : {1:.4f}\".format(idx, accuracy))\n",
    "        print(\"평균 정확도 : {0:.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cross_val_score in module sklearn.model_selection._validation:\n",
      "\n",
      "cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
      "    Evaluate a score by cross-validation\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    estimator : estimator object implementing 'fit'\n",
      "        The object to use to fit the data.\n",
      "    \n",
      "    X : array-like of shape (n_samples, n_features)\n",
      "        The data to fit. Can be for example a list, or an array.\n",
      "    \n",
      "    y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
      "        The target variable to try to predict in the case of\n",
      "        supervised learning.\n",
      "    \n",
      "    groups : array-like of shape (n_samples,), default=None\n",
      "        Group labels for the samples used while splitting the dataset into\n",
      "        train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "        instance (e.g., :class:`GroupKFold`).\n",
      "    \n",
      "    scoring : str or callable, default=None\n",
      "        A str (see model evaluation documentation) or\n",
      "        a scorer callable object / function with signature\n",
      "        ``scorer(estimator, X, y)`` which should return only\n",
      "        a single value.\n",
      "    \n",
      "        Similar to :func:`cross_validate`\n",
      "        but only a single metric is permitted.\n",
      "    \n",
      "        If None, the estimator's default scorer (if available) is used.\n",
      "    \n",
      "    cv : int, cross-validation generator or an iterable, default=None\n",
      "        Determines the cross-validation splitting strategy.\n",
      "        Possible inputs for cv are:\n",
      "    \n",
      "        - None, to use the default 5-fold cross validation,\n",
      "        - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "        - :term:`CV splitter`,\n",
      "        - An iterable yielding (train, test) splits as arrays of indices.\n",
      "    \n",
      "        For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "        other cases, :class:`KFold` is used.\n",
      "    \n",
      "        Refer :ref:`User Guide <cross_validation>` for the various\n",
      "        cross-validation strategies that can be used here.\n",
      "    \n",
      "        .. versionchanged:: 0.22\n",
      "            ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "    \n",
      "    n_jobs : int, default=None\n",
      "        The number of CPUs to use to do the computation.\n",
      "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "        for more details.\n",
      "    \n",
      "    verbose : int, default=0\n",
      "        The verbosity level.\n",
      "    \n",
      "    fit_params : dict, default=None\n",
      "        Parameters to pass to the fit method of the estimator.\n",
      "    \n",
      "    pre_dispatch : int or str, default='2*n_jobs'\n",
      "        Controls the number of jobs that get dispatched during parallel\n",
      "        execution. Reducing this number can be useful to avoid an\n",
      "        explosion of memory consumption when more jobs get dispatched\n",
      "        than CPUs can process. This parameter can be:\n",
      "    \n",
      "            - None, in which case all the jobs are immediately\n",
      "              created and spawned. Use this for lightweight and\n",
      "              fast-running jobs, to avoid delays due to on-demand\n",
      "              spawning of the jobs\n",
      "    \n",
      "            - An int, giving the exact number of total jobs that are\n",
      "              spawned\n",
      "    \n",
      "            - A str, giving an expression as a function of n_jobs,\n",
      "              as in '2*n_jobs'\n",
      "    \n",
      "    error_score : 'raise' or numeric, default=np.nan\n",
      "        Value to assign to the score if an error occurs in estimator fitting.\n",
      "        If set to 'raise', the error is raised.\n",
      "        If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "        does not affect the refit step, which will always raise the error.\n",
      "    \n",
      "        .. versionadded:: 0.20\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    scores : array of float, shape=(len(list(cv)),)\n",
      "        Array of scores of the estimator for each run of the cross validation.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn import datasets, linear_model\n",
      "    >>> from sklearn.model_selection import cross_val_score\n",
      "    >>> diabetes = datasets.load_diabetes()\n",
      "    >>> X = diabetes.data[:150]\n",
      "    >>> y = diabetes.target[:150]\n",
      "    >>> lasso = linear_model.Lasso()\n",
      "    >>> print(cross_val_score(lasso, X, y, cv=3))\n",
      "    [0.33150734 0.08022311 0.03531764]\n",
      "    \n",
      "    See Also\n",
      "    ---------\n",
      "    :func:`sklearn.model_selection.cross_validate`:\n",
      "        To run cross-validation on multiple metrics and also to return\n",
      "        train scores, fit times and score times.\n",
      "    \n",
      "    :func:`sklearn.model_selection.cross_val_predict`:\n",
      "        Get predictions from each split of cross-validation for diagnostic\n",
      "        purposes.\n",
      "    \n",
      "    :func:`sklearn.metrics.make_scorer`:\n",
      "        Make a scorer from a performance metric or loss function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# DecisionTreeClassifier(random_state=2021)\n",
      "0번째 교차검증 정확도 : 0.7542\n",
      "1번째 교차검증 정확도 : 0.7753\n",
      "2번째 교차검증 정확도 : 0.8090\n",
      "3번째 교차검증 정확도 : 0.7809\n",
      "4번째 교차검증 정확도 : 0.8258\n",
      "평균 정확도 : 0.7890\n",
      "############# RandomForestClassifier(random_state=2021)\n",
      "0번째 교차검증 정확도 : 0.7933\n",
      "1번째 교차검증 정확도 : 0.7921\n",
      "2번째 교차검증 정확도 : 0.8539\n",
      "3번째 교차검증 정확도 : 0.7753\n",
      "4번째 교차검증 정확도 : 0.8539\n",
      "평균 정확도 : 0.8137\n",
      "############# LogisticRegression(random_state=2021)\n",
      "0번째 교차검증 정확도 : 0.7989\n",
      "1번째 교차검증 정확도 : 0.7697\n",
      "2번째 교차검증 정확도 : 0.7809\n",
      "3번째 교차검증 정확도 : 0.7753\n",
      "4번째 교차검증 정확도 : 0.7978\n",
      "평균 정확도 : 0.7845\n"
     ]
    }
   ],
   "source": [
    "clfs = [dt_clf, rf_clf, lr_clf]\n",
    "get_cross_val_score(clfs, X_titanic_df, y_titanic_df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV 클래스 이용\n",
    "\n",
    "* 최적 하이퍼 파라미터 튜닝 성능 측정(max_depths, min_samples_split, min_sample_leaf)\n",
    "* 위의 주어진 파라미터값을 변경해가면서 최적 파라미터 값을 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      " |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      " |  estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list/tuple or dict, default=None\n",
      " |      A single str (see :ref:`scoring_parameter`) or a callable\n",
      " |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      " |  \n",
      " |      For evaluating multiple metrics, either give a list of (unique) strings\n",
      " |      or a dict with names as keys and callables as values.\n",
      " |  \n",
      " |      NOTE that when using custom scorers, each scorer should return a single\n",
      " |      value. Metric functions returning a list/array of values can be wrapped\n",
      " |      into multiple scorers that return one value each.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |      If None, the estimator's score method is used.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default=n_jobs\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  iid : bool, default=False\n",
      " |      If True, return the average score across folds, weighted by the number\n",
      " |      of samples in each test set. In this case, the data is assumed to be\n",
      " |      identically distributed across the folds, and the loss minimized is\n",
      " |      the total loss per sample, and not the mean loss across the folds.\n",
      " |  \n",
      " |      .. deprecated:: 0.22\n",
      " |          Parameter ``iid`` is deprecated in 0.22 and will be removed in 0.24\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  verbose : integer\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  :class:`ParameterGrid`:\n",
      " |      generates all the combinations of a hyperparameter grid.\n",
      " |  \n",
      " |  :func:`sklearn.model_selection.train_test_split`:\n",
      " |      utility function to split the data into a development set usable\n",
      " |      for fitting a GridSearchCV instance and an evaluation set for\n",
      " |      its final evaluation.\n",
      " |  \n",
      " |  :func:`sklearn.metrics.make_scorer`:\n",
      " |      Make a scorer from a performance metric or loss function.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  n_features_in_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"max_depth\": [2, 3, 5, 10],\n",
    "             \"min_samples_split\": [2, 3, 5],\n",
    "             \"min_samples_leaf\": [1, 5, 8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hyper_parameter(clf, params,n_cv):\n",
    "    '''\n",
    "    Show hyper parameter tuning\n",
    "    '''\n",
    "    grid_clf = GridSearchCV(clf, param_grid = params, scoring='accuracy', cv=n_cv)\n",
    "    grid_clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"GridSearchCV 최적 하이터 파라미터 : \", grid_clf.best_params_)\n",
    "    print(\"GridSearchCV 최고 정확도 : {0:.4f}\".format(grid_clf.best_score_))\n",
    "    \n",
    "    # refit=True옵션으로 인해 최적의 Estimator를 알수있음.\n",
    "    best_clf = grid_clf.best_estimator_\n",
    "    \n",
    "    predictions = best_clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이터 파라미터 :  {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도 : 0.8314\n",
      "테스트 세트에서의 DecisionTreeClassifier 정확도 : 0.7542\n"
     ]
    }
   ],
   "source": [
    "show_hyper_parameter(dt_clf, parameters, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이터 파라미터 :  {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도 : 0.8413\n",
      "테스트 세트에서의 DecisionTreeClassifier 정확도 : 0.7318\n"
     ]
    }
   ],
   "source": [
    "show_hyper_parameter(rf_clf, parameters, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML지도학습 프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "- 데이터클랜징\n",
    "- 결손값 처리(Null/NaN)\n",
    "- 데이터인코딩(레이블, 원-핫 인코딩)\n",
    "- 데이터 스케일링\n",
    "- 이상치 제거\n",
    "- Feature선택, 추출 및 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터세트 분리\n",
    "- 학습 데이터/테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델학습 및 검증 평가\n",
    "- 알고리즘 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측수행\n",
    "- 테스트 데이터로 예측수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가\n",
    "- 예측평가"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
