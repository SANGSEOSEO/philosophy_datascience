{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사이킷런으로 수행하는 타이타닉 생존자 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리 로드 및 데이터읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "# 한글폰트 설치\n",
    "path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "font_name = font_manager.FontProperties(fname = path).get_name()\n",
    "rc('font', family = font_name)\n",
    "\n",
    "# 마이너스 부호 표시 \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\dataAnalysis\\\\philosophy_datascience\\\\01.ML\\\\03.Scikit-Learn'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ##  학습 데이터 정보 ### \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(\"./titanic/titanic_train.csv\")\n",
    "print(\"\\n ##  학습 데이터 정보 ### \\n\")\n",
    "print(titanic_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 널값 처리 \n",
    "* 사이킷런은 널값을 허용하지 않으므로 널값 처리방법 결정 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace = True)\n",
    "titanic_df['Cabin'].fillna('N', inplace = True)\n",
    "titanic_df['Embarked'].fillna('N', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬럼별 데이터 세트 널 값 갯수  PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('컬럼별 데이터 세트 널 값 갯수 ', titanic_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 세트 널 값 갯수  0\n"
     ]
    }
   ],
   "source": [
    "print('전체 데이터 세트 널 값 갯수 ', titanic_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문자열 feature들의 값 분류 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex값 분포 :\n",
      " male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      " Cabin값 분포 : \n",
      " N              687\n",
      "B96 B98          4\n",
      "C23 C25 C27      4\n",
      "G6               4\n",
      "F33              3\n",
      "              ... \n",
      "E68              1\n",
      "A24              1\n",
      "B73              1\n",
      "C90              1\n",
      "B42              1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "\n",
      " Embarked 값 분포 : \n",
      " S    644\n",
      "C    168\n",
      "Q     77\n",
      "N      2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Sex값 분포 :\\n', titanic_df['Sex'].value_counts())\n",
    "print('\\n Cabin값 분포 : \\n', titanic_df['Cabin'].value_counts())\n",
    "print('\\n Embarked 값 분포 : \\n', titanic_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    N\n",
      "1    C\n",
      "2    N\n",
      "Name: Cabin, dtype: object\n"
     ]
    }
   ],
   "source": [
    "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
    "print(titanic_df['Cabin'].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 알고리즘 적용전 EDA\n",
    "* 어떤 유형의 승객이 생존확률이 높았는지 확인\n",
    "* 성별이 생존율에 영향을 주었는가?\n",
    "* 좌석의 등급은 생존률에 영향을 주었는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성별과 생존율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  0            81\n",
       "        1           233\n",
       "male    0           468\n",
       "        1           109\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.groupby(['Sex', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa27c554df0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = 'Sex', y = 'Survived', data = titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 객실 등급과 생존율\n",
    "* 힘없고 가난한 자는 100년전에도 동일하게 죽어갔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass  Survived\n",
       "1       0            80\n",
       "        1           136\n",
       "2       0            97\n",
       "        1            87\n",
       "3       0           372\n",
       "        1           119\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.groupby(['Pclass', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa27cadddf0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = 'Pclass', y = 'Survived', data = titanic_df, hue = 'Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성별에 따른 생존율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 age에 따라 구분 값을 변환하는 함수 설정, DataFrame의 apply lambda식에 사용\n",
    "def get_category(age):\n",
    "    cat = ''\n",
    "    if age <= -1: cat = 'Unknown'\n",
    "    elif age <= 5: cat = 'Baby'\n",
    "    elif age <= 12: cat = 'Child'\n",
    "    elif age <= 18: cat = 'Teenager'\n",
    "    elif age <= 25: cat = 'Student'\n",
    "    elif age <= 35: cat = 'Young Adult'\n",
    "    elif age <= 60: cat = 'Adult'\n",
    "    else: cat = 'Elderly'\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa27d302e50>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 막대 그래프의 크기 figure설정\n",
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "# x축의 값을 순차적으로 표시하기 위한 설정\n",
    "group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']\n",
    "\n",
    "# lambda식에 위에서 생성한 get_category()함수를 반환값으로 지정함.\n",
    "# get_category(x)는 입력값으로 'Age'칼럼값을 받아서 해당하는 cat반환\n",
    "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x: get_category(x))\n",
    "sns.barplot(x= 'Age_cat', y= 'Survived', hue = 'Sex', data = titanic_df, order = group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.drop(labels = 'Age_cat', axis = 1, inplace = True, errors = 'ignore')  # ignore는 에러가 나더라도 무시함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문자열 카테고리 피처를 숫자형 카테고리 피처로 변환\n",
    "* 인코딩은 사이킷런의 LabelEncoder클래스 이용\n",
    "* `fit()`과 `transform()`메소드 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_features(dataDF):\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "        \n",
    "    return dataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = encode_features(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "\n",
       "             Ticket     Fare  Cabin  Embarked  \n",
       "0         A/5 21171   7.2500      7         3  \n",
       "1          PC 17599  71.2833      2         0  \n",
       "2  STON/O2. 3101282   7.9250      7         3  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.head(n = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 널처리 함수 \n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace = True)\n",
    "    df['Cabin'].fillna('N', inplace = True)\n",
    "    df['Embarked'].fillna('N', inplace = True)\n",
    "    df['Fare'].fillna(0, inplace  = True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거 \n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis = 1, inplace = True,errors = 'ignore')\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행\n",
    "def format_features(df):\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "        \n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 데이터 전처리 함수 호출 \n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본 데이터 재가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터를 재로딩, \n",
    "# 피처 데이터세트와 레이블 데이터 세트 추출.\n",
    "titanic_df = pd.read_csv(\"./titanic/titanic_train.csv\")\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic_df = transform_features(X_titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터 세트 추출\n",
    "* test_size = 0.2의 의미는 훈련용 데이터세트가 전체의 80%이고 검증용이 20%라는 의미."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size = 0.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성한 ML모델에 대한 학습 , 예측, 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 정확도 : 0.7989\n",
      "RandomForestClassifier 정확도 : 0.8436\n",
      "Regression 정확도 : 0.8603\n"
     ]
    }
   ],
   "source": [
    "# 결정트리,Random Forest, 로지스틱 회귀를 위한 사이킷런 Classifier클래스 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state = 11)\n",
    "rf_clf = RandomForestClassifier(random_state = 11)\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# DecisionTreeClassifier학습 /에측 평가 \n",
    "dt_clf.fit(X_train, y_train)\n",
    "df_pred = dt_clf.predict(X_test)\n",
    "print('DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy_score(y_test, df_pred)))\n",
    "\n",
    "# RandomForestClassifier 학습/예측/평가\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('RandomForestClassifier 정확도 : {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "\n",
    "# LogisticeRegression 학습/예측/평가\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print('Regression 정확도 : {0:.4f}'.format(accuracy_score(y_test, lr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fit in module sklearn.tree._classes:\n",
      "\n",
      "fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    Build a decision tree classifier from the training set (X, y).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "        The training input samples. Internally, it will be converted to\n",
      "        ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "        to a sparse ``csc_matrix``.\n",
      "    \n",
      "    y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "        The target values (class labels) as integers or strings.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights. If None, then samples are equally weighted. Splits\n",
      "        that would create child nodes with net zero or negative weight are\n",
      "        ignored while searching for a split in each node. Splits are also\n",
      "        ignored if they would result in any single class carrying a\n",
      "        negative weight in either child node.\n",
      "    \n",
      "    check_input : bool, default=True\n",
      "        Allow to bypass several input checking.\n",
      "        Don't use this parameter unless you know what you do.\n",
      "    \n",
      "    X_idx_sorted : array-like of shape (n_samples, n_features),                 default=None\n",
      "        The indexes of the sorted training input samples. If many tree\n",
      "        are grown on the same dataset, this allows the ordering to be\n",
      "        cached between trees. If None, the data will be sorted here.\n",
      "        Don't use this parameter unless you know what to do.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    self : DecisionTreeClassifier\n",
      "        Fitted estimator.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DecisionTreeClassifier.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function predict in module sklearn.tree._classes:\n",
      "\n",
      "predict(self, X, check_input=True)\n",
      "    Predict class or regression value for X.\n",
      "    \n",
      "    For a classification model, the predicted class for each sample in X is\n",
      "    returned. For a regression model, the predicted value based on X is\n",
      "    returned.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "        The input samples. Internally, it will be converted to\n",
      "        ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "        to a sparse ``csr_matrix``.\n",
      "    \n",
      "    check_input : bool, default=True\n",
      "        Allow to bypass several input checking.\n",
      "        Don't use this parameter unless you know what you do.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "        The predicted classes, or the predict values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DecisionTreeClassifier.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3개의 알고리즘 중 LogisticRegression이 타 알고리즘에 비해 높은 정확도를 갖지만, 아직 최적화작업을 수행하지 않았고, 데이터 양도 충분치 않기때문에 어떤 알고리즘이 성능이 더 좋다고 평가 할 수는 없다.\n",
    "* 교차검증으로 결정트리 모델을 평가해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차검증\n",
    "* KFOLD클래스 , cross_val_score(), GridSearchCV클래스 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFOLD 교차 검증 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function split in module sklearn.model_selection._split:\n",
      "\n",
      "split(self, X, y=None, groups=None)\n",
      "    Generate indices to split data into training and test set.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like of shape (n_samples, n_features)\n",
      "        Training data, where n_samples is the number of samples\n",
      "        and n_features is the number of features.\n",
      "    \n",
      "    y : array-like of shape (n_samples,), default=None\n",
      "        The target variable for supervised learning problems.\n",
      "    \n",
      "    groups : array-like of shape (n_samples,), default=None\n",
      "        Group labels for the samples used while splitting the dataset into\n",
      "        train/test set.\n",
      "    \n",
      "    Yields\n",
      "    ------\n",
      "    train : ndarray\n",
      "        The training set indices for that split.\n",
      "    \n",
      "    test : ndarray\n",
      "        The testing set indices for that split.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KFold.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7486\n",
      "교차 검증 1 정확도: 0.7640\n",
      "교차 검증 2 정확도: 0.8202\n",
      "교차 검증 3 정확도: 0.7809\n",
      "교차 검증 4 정확도: 0.7921\n",
      "평균 정확도: 0.7812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def exec_kfold(clf, folds=5):\n",
    "    # 폴드 세트를 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위한  리스트 객체 생성.\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    \n",
    "    # KFold 교차 검증 수행. \n",
    "    for iter_count , (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "        # Classifier 학습, 예측, 정확도 계산 \n",
    "        clf.fit(X_train, y_train) \n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))     \n",
    "    \n",
    "    # 5개 fold에서의 평균 정확도 계산. \n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"평균 정확도: {0:.4f}\".format(mean_score)) \n",
    "# exec_kfold 호출\n",
    "exec_kfold(dt_clf , folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross_val_score() 교차 검증 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cross_val_score in module sklearn.model_selection._validation:\n",
      "\n",
      "cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
      "    Evaluate a score by cross-validation\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    estimator : estimator object implementing 'fit'\n",
      "        The object to use to fit the data.\n",
      "    \n",
      "    X : array-like of shape (n_samples, n_features)\n",
      "        The data to fit. Can be for example a list, or an array.\n",
      "    \n",
      "    y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
      "        The target variable to try to predict in the case of\n",
      "        supervised learning.\n",
      "    \n",
      "    groups : array-like of shape (n_samples,), default=None\n",
      "        Group labels for the samples used while splitting the dataset into\n",
      "        train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "        instance (e.g., :class:`GroupKFold`).\n",
      "    \n",
      "    scoring : str or callable, default=None\n",
      "        A str (see model evaluation documentation) or\n",
      "        a scorer callable object / function with signature\n",
      "        ``scorer(estimator, X, y)`` which should return only\n",
      "        a single value.\n",
      "    \n",
      "        Similar to :func:`cross_validate`\n",
      "        but only a single metric is permitted.\n",
      "    \n",
      "        If None, the estimator's default scorer (if available) is used.\n",
      "    \n",
      "    cv : int, cross-validation generator or an iterable, default=None\n",
      "        Determines the cross-validation splitting strategy.\n",
      "        Possible inputs for cv are:\n",
      "    \n",
      "        - None, to use the default 5-fold cross validation,\n",
      "        - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "        - :term:`CV splitter`,\n",
      "        - An iterable yielding (train, test) splits as arrays of indices.\n",
      "    \n",
      "        For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "        other cases, :class:`KFold` is used.\n",
      "    \n",
      "        Refer :ref:`User Guide <cross_validation>` for the various\n",
      "        cross-validation strategies that can be used here.\n",
      "    \n",
      "        .. versionchanged:: 0.22\n",
      "            ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "    \n",
      "    n_jobs : int, default=None\n",
      "        The number of CPUs to use to do the computation.\n",
      "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "        for more details.\n",
      "    \n",
      "    verbose : int, default=0\n",
      "        The verbosity level.\n",
      "    \n",
      "    fit_params : dict, default=None\n",
      "        Parameters to pass to the fit method of the estimator.\n",
      "    \n",
      "    pre_dispatch : int or str, default='2*n_jobs'\n",
      "        Controls the number of jobs that get dispatched during parallel\n",
      "        execution. Reducing this number can be useful to avoid an\n",
      "        explosion of memory consumption when more jobs get dispatched\n",
      "        than CPUs can process. This parameter can be:\n",
      "    \n",
      "            - None, in which case all the jobs are immediately\n",
      "              created and spawned. Use this for lightweight and\n",
      "              fast-running jobs, to avoid delays due to on-demand\n",
      "              spawning of the jobs\n",
      "    \n",
      "            - An int, giving the exact number of total jobs that are\n",
      "              spawned\n",
      "    \n",
      "            - A str, giving an expression as a function of n_jobs,\n",
      "              as in '2*n_jobs'\n",
      "    \n",
      "    error_score : 'raise' or numeric, default=np.nan\n",
      "        Value to assign to the score if an error occurs in estimator fitting.\n",
      "        If set to 'raise', the error is raised.\n",
      "        If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "        does not affect the refit step, which will always raise the error.\n",
      "    \n",
      "        .. versionadded:: 0.20\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    scores : array of float, shape=(len(list(cv)),)\n",
      "        Array of scores of the estimator for each run of the cross validation.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn import datasets, linear_model\n",
      "    >>> from sklearn.model_selection import cross_val_score\n",
      "    >>> diabetes = datasets.load_diabetes()\n",
      "    >>> X = diabetes.data[:150]\n",
      "    >>> y = diabetes.target[:150]\n",
      "    >>> lasso = linear_model.Lasso()\n",
      "    >>> print(cross_val_score(lasso, X, y, cv=3))\n",
      "    [0.33150734 0.08022311 0.03531764]\n",
      "    \n",
      "    See Also\n",
      "    ---------\n",
      "    :func:`sklearn.model_selection.cross_validate`:\n",
      "        To run cross-validation on multiple metrics and also to return\n",
      "        train scores, fit times and score times.\n",
      "    \n",
      "    :func:`sklearn.model_selection.cross_val_predict`:\n",
      "        Get predictions from each split of cross-validation for diagnostic\n",
      "        purposes.\n",
      "    \n",
      "    :func:`sklearn.metrics.make_scorer`:\n",
      "        Make a scorer from a performance metric or loss function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도 : 0.7486\n",
      "교차 검증 1 정확도 : 0.7753\n",
      "교차 검증 2 정확도 : 0.8090\n",
      "교차 검증 3 정확도 : 0.7584\n",
      "교차 검증 4 정확도 : 0.8034\n",
      "평균 정확도 0.7789\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv = 5)\n",
    "\n",
    "for iter_count, accuracy in enumerate(scores):\n",
    "    print(\"교차 검증 {0} 정확도 : {1:.4f}\".format(iter_count, accuracy))\n",
    "    \n",
    "print(\"평균 정확도 {0:.4f}\".format(np.mean(scores)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV 클래스 이용\n",
    "* 최적 하이퍼 파라미터 튜닝 성능 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      " |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      " |  estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list/tuple or dict, default=None\n",
      " |      A single str (see :ref:`scoring_parameter`) or a callable\n",
      " |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      " |  \n",
      " |      For evaluating multiple metrics, either give a list of (unique) strings\n",
      " |      or a dict with names as keys and callables as values.\n",
      " |  \n",
      " |      NOTE that when using custom scorers, each scorer should return a single\n",
      " |      value. Metric functions returning a list/array of values can be wrapped\n",
      " |      into multiple scorers that return one value each.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |      If None, the estimator's score method is used.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default=n_jobs\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  iid : bool, default=False\n",
      " |      If True, return the average score across folds, weighted by the number\n",
      " |      of samples in each test set. In this case, the data is assumed to be\n",
      " |      identically distributed across the folds, and the loss minimized is\n",
      " |      the total loss per sample, and not the mean loss across the folds.\n",
      " |  \n",
      " |      .. deprecated:: 0.22\n",
      " |          Parameter ``iid`` is deprecated in 0.22 and will be removed in 0.24\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  verbose : integer\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  :class:`ParameterGrid`:\n",
      " |      generates all the combinations of a hyperparameter grid.\n",
      " |  \n",
      " |  :func:`sklearn.model_selection.train_test_split`:\n",
      " |      utility function to split the data into a development set usable\n",
      " |      for fitting a GridSearchCV instance and an evaluation set for\n",
      " |      its final evaluation.\n",
      " |  \n",
      " |  :func:`sklearn.metrics.make_scorer`:\n",
      " |      Make a scorer from a performance metric or loss function.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  n_features_in_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이터 파라미터 :  {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "GridSearchCV 최고 정확도 : 0.7993\n",
      "테스트 세트에서의 DecisionTreeClassifier 정확도 : 0.8659\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"max_depth\": [2, 3, 5, 10],\n",
    "             \"min_samples_split\": [2, 3, 5],\n",
    "             \"min_samples_leaf\": [1, 5, 8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf, param_grid = parameters, scoring = 'accuracy', cv = 5)\n",
    "grid_dclf.fit(X_train, y_train)\n",
    "\n",
    "print(\"GridSearchCV 최적 하이터 파라미터 : \", grid_dclf.best_params_)\n",
    "print(\"GridSearchCV 최고 정확도 : {0:.4f}\".format(grid_dclf.best_score_))\n",
    "\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 \n",
    "dpredctions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, dpredctions)\n",
    "print(\"테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
